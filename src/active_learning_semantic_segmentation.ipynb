{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Perception_4_ActiveLearning_7_OnlineLearning.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import visualize, pickle_load, pickle_save\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "# segmentation models wrapper\n",
    "from segmodel import SegModel, model_selection_function\n",
    "# anomaly detection functions\n",
    "from anomaly_detection import sample_selection_function\n",
    "# datasets wrapper\n",
    "from dataset import CamVid, BDD100K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CamVid directories\n",
    "# DATA_DIR = './data/CamVid/'\n",
    "\n",
    "# x_train_dir = os.path.join(DATA_DIR, 'train')\n",
    "# y_train_dir = os.path.join(DATA_DIR, 'trainannot')\n",
    "\n",
    "# x_valid_dir = os.path.join(DATA_DIR, 'val')\n",
    "# y_valid_dir = os.path.join(DATA_DIR, 'valannot')\n",
    "\n",
    "# x_test_dir = os.path.join(DATA_DIR, 'test')\n",
    "# y_test_dir = os.path.join(DATA_DIR, 'testannot')\n",
    "\n",
    "# BDD100K directories\n",
    "DATA_DIR = '/home/ruslan/datasets/bdd100k/seg/'\n",
    "x_train_dir = os.path.join(DATA_DIR, 'images/train')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'labels/train')\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, 'images/val')\n",
    "y_valid_dir = os.path.join(DATA_DIR, 'labels/val')\n",
    "\n",
    "x_test_dir = os.path.join(DATA_DIR, 'images/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data paths\n",
    "X_train_paths = np.array([os.path.join(x_train_dir, image_name) for image_name in os.listdir(x_train_dir)])[:300]\n",
    "y_train_paths = np.array([os.path.join(y_train_dir, image_name) for image_name in os.listdir(y_train_dir)])[:300]\n",
    "\n",
    "X_valid_paths = np.array([os.path.join(x_valid_dir, image_name) for image_name in os.listdir(x_valid_dir)])[:100]\n",
    "y_valid_paths = np.array([os.path.join(y_valid_dir, image_name) for image_name in os.listdir(y_valid_dir)])\n",
    "\n",
    "X_test_paths = np.array([os.path.join(x_test_dir, image_name) for image_name in os.listdir(x_test_dir)])[:100]\n",
    "#y_test_paths = np.array([os.path.join(y_test_dir, image_name) for image_name in os.listdir(y_test_dir)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active Learning experiment\n",
    "\n",
    "- X_train, y_train: is used partially to train a model\n",
    "- X_valid, y_valid: is used fully for validation\n",
    "- X_test, y_test: is used as an unlabelled set to detect anomalies and add labels to train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main AL experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def al_experiment(model_str,\n",
    "                  samples_selection_fn,\n",
    "                  k,\n",
    "                  visualize_most_uncertain=False,\n",
    "                  verbose_train=False,\n",
    "                  random_seed=0):\n",
    "    # define model from its name\n",
    "    model = model_selection_function(model_str)\n",
    "    model.epochs = MODEL_TRAIN_EPOCHS\n",
    "    # define samples selection function from its name\n",
    "    samples_selection_fn = sample_selection_function(samples_selection_str)\n",
    "    \n",
    "    # select k random samples from initial dataset and treat it as initially labelled data\n",
    "    X = np.copy(X_train_paths)\n",
    "    y = np.copy(y_train_paths)\n",
    "    np.random.seed(random_seed)\n",
    "    initial_selection = np.random.choice(len(X), INITIAL_N_TRAIN_IMAGES, replace=False) # k\n",
    "    X_train_paths_part = X[initial_selection]\n",
    "    y_train_paths_part = y[initial_selection]\n",
    "\n",
    "    X_test = np.delete(X, initial_selection)\n",
    "    y_test = np.delete(X, initial_selection)\n",
    "\n",
    "    IoUs = [0.]\n",
    "    N_train_samples = [len(X_train_paths_part)]\n",
    "\n",
    "    # main loop\n",
    "    while len(X_train_paths_part) <= MAX_QUEERY_IMAGES:\n",
    "        # train model\n",
    "        print('Labelled set size: ', len(X_train_paths_part))\n",
    "        print('Unlabelled set size: ', len(X_test))\n",
    "        print(f'\\nTraining a model for {MODEL_TRAIN_EPOCHS} epochs...')\n",
    "        model.train(X_train_paths_part,\n",
    "                    y_train_paths_part,\n",
    "                    X_valid_paths,\n",
    "                    y_valid_paths,\n",
    "                    Dataset=BDD100K,\n",
    "                    verbose=verbose_train)\n",
    "\n",
    "        # remeber results\n",
    "        print(f'IoU so far: {model.max_iou_score}')\n",
    "        IoUs.append(model.max_iou_score)\n",
    "        N_train_samples.append(len(X_train_paths_part))\n",
    "        \n",
    "        if len(X_test) < k:\n",
    "            print('\\nNo more images in Unlabelled set')\n",
    "            break\n",
    "            \n",
    "        selected_images_indexes = samples_selection_fn(X_test, k, model)\n",
    "\n",
    "        # Add labels for uncertain images to train data\n",
    "        #print('Labelled set before: ', len(X_train_paths_part))\n",
    "        X_train_paths_part = np.concatenate([X_train_paths_part, X_test[selected_images_indexes]])\n",
    "        y_train_paths_part = np.concatenate([y_train_paths_part, y_test[selected_images_indexes]])\n",
    "        #print('Labelled set after: ', len(X_train_paths_part))\n",
    "\n",
    "        # Visualization\n",
    "        if visualize_most_uncertain:\n",
    "            print('Visualizing most uncertain results so far:')\n",
    "            for i in selected_images_indexes[:1]:\n",
    "                img_path = X_test[i]\n",
    "                image = cv2.imread(img_path)[...,(2,1,0)]\n",
    "                gt_mask = cv2.imread(y_test_paths[i])\n",
    "                pr_mask = model.predict([img_path])\n",
    "                mask_np = pr_mask.squeeze().cpu().numpy().round()\n",
    "\n",
    "                visualize(image=image, car_mask=mask_np[0,...], road_mask=mask_np[1,...])\n",
    "\n",
    "        # Remove labelled data from validation set\n",
    "        #print('Unlabelled set before: ', len(X_test))\n",
    "        X_test = np.delete(X_test, selected_images_indexes)\n",
    "        y_test = np.delete(y_test, selected_images_indexes)\n",
    "        #print('Unlabelled set after: ', len(X_test))\n",
    "        \n",
    "    print(f'Max IoU score: {np.max(IoUs)}')\n",
    "    print('----------------------------------------\\n')\n",
    "    return IoUs, N_train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_QUEERY_IMAGES = 120 # 220 # maximum number of images to train on during AL loop\n",
    "MODEL_TRAIN_EPOCHS = 1 # 5 # number of epochs to train a model during one AL cicle\n",
    "INITIAL_N_TRAIN_IMAGES = 60 # 20, initial number of accessible labelled images\n",
    "NUM_UNCERTAIN_IMAGES = [10]#, 20]#, 40, 60] # k: number of uncertain images to label at each AL cicle\n",
    "SAMPLES_SELECTIONS = ['Margin', 'Random', 'Entropy']\n",
    "MODELS = ['Unet']#, 'Linknet', 'FPN', 'PSPNet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet_Nsamples_120_epochs_1_N0_60_Ks_10_Margin_Random_Entropy_.pkl\n"
     ]
    }
   ],
   "source": [
    "name = ''\n",
    "for model in MODELS:\n",
    "    name += model + '_'\n",
    "name += 'Nsamples_'+str(MAX_QUEERY_IMAGES)\n",
    "name += '_epochs_'+str(MODEL_TRAIN_EPOCHS)\n",
    "name += '_N0_'+str(INITIAL_N_TRAIN_IMAGES)\n",
    "name += '_Ks_'\n",
    "for k in NUM_UNCERTAIN_IMAGES:\n",
    "    name += str(k) + '_'\n",
    "for fn in SAMPLES_SELECTIONS:\n",
    "    name += fn + '_'\n",
    "RESULTS_FNAME = name+'.pkl'\n",
    "print(RESULTS_FNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model name: Unet\n",
      "------------------------------------\n",
      "\n",
      "Samples selection function: Margin\n",
      "------------------------------------\n",
      "\n",
      "Number of samples to label on one iteration, k=10\n",
      "------------------------------------\n",
      "Labelled set size:  60\n",
      "Unlabelled set size:  240\n",
      "\n",
      "Training a model for 1 epochs...\n",
      "\n",
      "Epoch: 0\n",
      "train: 100%|██████████| 8/8 [00:15<00:00,  1.88s/it, dice_loss - 0.9565, iou_score - 5.149e-05]\n",
      "valid: 100%|██████████| 100/100 [00:14<00:00,  6.72it/s, dice_loss - 0.9605, iou_score - 0.0002759]\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU so far: 0.00027594741409756046\n",
      "Inference on unlabelled data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:18<00:00, 12.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min margin: 5.10,             Mean margin: 8.05,             Max margin: 9.84\n",
      "Labelled set size:  70\n",
      "Unlabelled set size:  230\n",
      "\n",
      "Training a model for 1 epochs...\n",
      "\n",
      "Epoch: 0\n",
      "\r",
      "train:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 9/9 [00:17<00:00,  1.95s/it, dice_loss - 0.9468, iou_score - 0.0001634]\n",
      "valid: 100%|██████████| 100/100 [00:15<00:00,  6.61it/s, dice_loss - 0.9491, iou_score - 0.0002746]\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/230 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU so far: 0.00027458306670131896\n",
      "Inference on unlabelled data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:18<00:00, 12.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min margin: 6.98,             Mean margin: 9.08,             Max margin: 9.59\n",
      "Labelled set size:  80\n",
      "Unlabelled set size:  220\n",
      "\n",
      "Training a model for 1 epochs...\n",
      "\n",
      "Epoch: 0\n",
      "\r",
      "train:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 10/10 [00:19<00:00,  1.96s/it, dice_loss - 0.9345, iou_score - 0.0005683]\n",
      "valid: 100%|██████████| 100/100 [00:14<00:00,  6.69it/s, dice_loss - 0.9337, iou_score - 0.003491]\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/220 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU so far: 0.0034905777251435463\n",
      "Inference on unlabelled data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [00:18<00:00, 11.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min margin: 4.25,             Mean margin: 8.32,             Max margin: 9.50\n",
      "Labelled set size:  90\n",
      "Unlabelled set size:  210\n",
      "\n",
      "Training a model for 1 epochs...\n",
      "\n",
      "Epoch: 0\n",
      "\r",
      "train:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 12/12 [00:21<00:00,  1.83s/it, dice_loss - 0.9172, iou_score - 0.006352]\n",
      "valid: 100%|██████████| 100/100 [00:14<00:00,  6.68it/s, dice_loss - 0.8996, iou_score - 0.04252]\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/210 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU so far: 0.042519463011093585\n",
      "Inference on unlabelled data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210/210 [00:16<00:00, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min margin: 3.55,             Mean margin: 7.92,             Max margin: 9.44\n",
      "Labelled set size:  100\n",
      "Unlabelled set size:  200\n",
      "\n",
      "Training a model for 1 epochs...\n",
      "\n",
      "Epoch: 0\n",
      "\r",
      "train:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 13/13 [00:23<00:00,  1.83s/it, dice_loss - 0.8905, iou_score - 0.04939]\n",
      "valid: 100%|██████████| 100/100 [00:14<00:00,  6.67it/s, dice_loss - 0.9055, iou_score - 0.04181]\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU so far: 0.04181337986207926\n",
      "Inference on unlabelled data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:15<00:00, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min margin: 6.07,             Mean margin: 8.58,             Max margin: 9.57\n",
      "Labelled set size:  110\n",
      "Unlabelled set size:  190\n",
      "\n",
      "Training a model for 1 epochs...\n",
      "\n",
      "Epoch: 0\n",
      "\r",
      "train:   0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 14/14 [00:24<00:00,  1.79s/it, dice_loss - 0.8715, iou_score - 0.09207]\n",
      "valid: 100%|██████████| 100/100 [00:15<00:00,  6.36it/s, dice_loss - 0.8883, iou_score - 0.06712]\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU so far: 0.06712398571004416\n",
      "Inference on unlabelled data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:14<00:00, 13.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min margin: 3.06,             Mean margin: 7.21,             Max margin: 9.53\n",
      "Labelled set size:  120\n",
      "Unlabelled set size:  180\n",
      "\n",
      "Training a model for 1 epochs...\n",
      "\n",
      "Epoch: 0\n",
      "\r",
      "train:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 15/15 [00:24<00:00,  1.66s/it, dice_loss - 0.8262, iou_score - 0.1652]\n",
      "valid: 100%|██████████| 100/100 [00:15<00:00,  6.64it/s, dice_loss - 0.8996, iou_score - 0.0552]\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU so far: 0.05520060291341972\n",
      "Inference on unlabelled data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:13<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min margin: 3.55,             Mean margin: 8.00,             Max margin: 9.67\n",
      "Max IoU score: 0.06712398571004416\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Samples selection function: Random\n",
      "------------------------------------\n",
      "\n",
      "Number of samples to label on one iteration, k=10\n",
      "------------------------------------\n",
      "Labelled set size:  60\n",
      "Unlabelled set size:  240\n",
      "\n",
      "Training a model for 1 epochs...\n",
      "\n",
      "Epoch: 0\n",
      "train: 100%|██████████| 8/8 [00:14<00:00,  1.87s/it, dice_loss - 0.9559, iou_score - 0.0004753]\n",
      "valid: 100%|██████████| 100/100 [00:14<00:00,  6.68it/s, dice_loss - 0.9517, iou_score - 4.439e-13]\n",
      "Model saved!\n",
      "IoU so far: 4.4387243094403884e-13\n",
      "Labelled set size:  70\n",
      "Unlabelled set size:  230\n",
      "\n",
      "Training a model for 1 epochs...\n",
      "\n",
      "Epoch: 0\n",
      "train: 100%|██████████| 9/9 [00:17<00:00,  1.89s/it, dice_loss - 0.9488, iou_score - 0.002451] \n",
      "valid: 100%|██████████| 100/100 [00:14<00:00,  6.96it/s, dice_loss - 0.9242, iou_score - 0.01838]\n",
      "Model saved!\n",
      "IoU so far: 0.01838080269108045\n",
      "Labelled set size:  80\n",
      "Unlabelled set size:  220\n",
      "\n",
      "Training a model for 1 epochs...\n",
      "\n",
      "Epoch: 0\n",
      "train: 100%|██████████| 10/10 [00:18<00:00,  1.85s/it, dice_loss - 0.9396, iou_score - 0.007763]\n",
      "valid: 100%|██████████| 100/100 [00:14<00:00,  6.94it/s, dice_loss - 0.9035, iou_score - 0.02112]\n",
      "Model saved!\n",
      "IoU so far: 0.02111964053898635\n",
      "Labelled set size:  90\n",
      "Unlabelled set size:  210\n",
      "\n",
      "Training a model for 1 epochs...\n",
      "\n",
      "Epoch: 0\n",
      "train: 100%|██████████| 12/12 [00:20<00:00,  1.69s/it, dice_loss - 0.9276, iou_score - 0.01584]\n",
      "valid: 100%|██████████| 100/100 [00:14<00:00,  6.95it/s, dice_loss - 0.8926, iou_score - 0.03389]\n",
      "Model saved!\n",
      "IoU so far: 0.03388883077223397\n",
      "Labelled set size:  100\n",
      "Unlabelled set size:  200\n",
      "\n",
      "Training a model for 1 epochs...\n",
      "\n",
      "Epoch: 0\n",
      "train: 100%|██████████| 13/13 [00:22<00:00,  1.73s/it, dice_loss - 0.916, iou_score - 0.03597] \n",
      "valid: 100%|██████████| 100/100 [00:14<00:00,  6.91it/s, dice_loss - 0.8579, iou_score - 0.08032]\n",
      "Model saved!\n",
      "IoU so far: 0.08032469086312631\n",
      "Labelled set size:  110\n",
      "Unlabelled set size:  190\n",
      "\n",
      "Training a model for 1 epochs...\n",
      "\n",
      "Epoch: 0\n",
      "train: 100%|██████████| 14/14 [00:23<00:00,  1.66s/it, dice_loss - 0.9082, iou_score - 0.04283]\n",
      "valid: 100%|██████████| 100/100 [00:14<00:00,  6.72it/s, dice_loss - 0.8475, iou_score - 0.09043]\n",
      "Model saved!\n",
      "IoU so far: 0.09043103269068524\n",
      "Labelled set size:  120\n",
      "Unlabelled set size:  180\n",
      "\n",
      "Training a model for 1 epochs...\n",
      "\n",
      "Epoch: 0\n",
      "train:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "# choose model\n",
    "for model_str in MODELS:\n",
    "    print(f'\\nModel name: {model_str}')\n",
    "    print('------------------------------------')\n",
    "    results[model_str] = {}\n",
    "    \n",
    "    # choose samples selection function\n",
    "    for samples_selection_str in SAMPLES_SELECTIONS:\n",
    "        print(f'\\nSamples selection function: {samples_selection_str}')\n",
    "        print('------------------------------------')\n",
    "        results[model_str][samples_selection_str] = {}\n",
    "        \n",
    "        # choose number of samples to select for labelling from inference results\n",
    "        for k in NUM_UNCERTAIN_IMAGES:\n",
    "            print(f'\\nNumber of samples to label on one iteration, k={k}')\n",
    "            print('------------------------------------')\n",
    "            results[model_str][samples_selection_str][str(k)] = {}\n",
    "            \n",
    "            IoUs, N_train_samples = al_experiment(model_str, samples_selection_str, k, verbose_train=True)\n",
    "            \n",
    "            results[model_str][samples_selection_str][str(k)]['IoUs'] = IoUs\n",
    "            results[model_str][samples_selection_str][str(k)]['N_train_samples'] = N_train_samples\n",
    "            \n",
    "pickle_save(RESULTS_FNAME, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle_load(RESULTS_FNAME)\n",
    "# results = pickle_load('Unet_epochs_2_N0_80_Ks_10_20_Margin_Random_Entropy_.pkl')\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# choose model\n",
    "for model_str in MODELS:    \n",
    "    # choose samples selection function\n",
    "    for samples_selection_str in SAMPLES_SELECTIONS:        \n",
    "        # choose number of samples to select for labelling from inference results\n",
    "        for k in NUM_UNCERTAIN_IMAGES:\n",
    "\n",
    "            ious = results[model_str][samples_selection_str][str(k)]['IoUs']\n",
    "            n_train = results[model_str][samples_selection_str][str(k)]['N_train_samples']\n",
    "\n",
    "            plt.plot(np.array(n_train[1:]), ious[1:], label=model_str+'_'+samples_selection_str+'_k='+str(k))\n",
    "        \n",
    "plt.grid()\n",
    "plt.title('Active Learning Results', fontsize=18)\n",
    "plt.xlabel('N images / full train set size', fontsize=16)\n",
    "plt.ylabel('IoU', fontsize=16)\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
