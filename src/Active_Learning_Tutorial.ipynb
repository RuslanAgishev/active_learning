{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x19OpFguwPXR"
   },
   "source": [
    "We start with all the needed dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6MWwUTInv-oj"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from scipy import stats\n",
    "from pylab import rcParams\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "#from sklearn.mixture import GaussianMixture\n",
    "#from sklearn.svm import LinearSVC, SVC\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.ensemble import RandomForestClassifier, \\\n",
    "#    GradientBoostingClassifier\n",
    "\n",
    "max_queried = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WrFIsF1wvzCg"
   },
   "source": [
    "We start by downloading our data and splitting it to train and test, according to known MNIST definitions 60K/10K split. later the train-set will be split to train and validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ojzg4Gjwpgh"
   },
   "outputs": [],
   "source": [
    "trainset_size = 60000  # ie., testset_size = 10000\n",
    "\n",
    "def download():\n",
    "    # mnist = fetch_mldata('MNIST original')\n",
    "    mnist = fetch_openml(\"mnist_784\")\n",
    "    X = mnist.data.astype('float64')\n",
    "    y = mnist.target\n",
    "    print ('MNIST:', X.shape, y.shape)\n",
    "    return (X, y)\n",
    "\n",
    "\n",
    "def split(train_size):\n",
    "    X_train_full = X[:train_size]\n",
    "    y_train_full = y[:train_size]\n",
    "    X_test = X[train_size:]\n",
    "    y_test = y[train_size:]\n",
    "    return (X_train_full, y_train_full, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yrb6IW2ExGST"
   },
   "source": [
    "We create a modular class representation, 'BaseModel' is a base model for the class architecture, you can implement new models and use them interchangeably or in addition to all other models.\n",
    "our current implementations include SVM, logistic regression, random forest and gradient boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2coy8C7xGqS"
   },
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit_predict(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class SvmModel(BaseModel):\n",
    "\n",
    "    model_type = 'Support Vector Machine with linear Kernel'\n",
    "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('training svm...')\n",
    "        self.classifier = SVC(C=1, kernel='linear', probability=True,\n",
    "                              class_weight=c_weight)\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        self.test_y_predicted = self.classifier.predict(X_test)\n",
    "        self.val_y_predicted = self.classifier.predict(X_val)\n",
    "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
    "                self.test_y_predicted)\n",
    "\n",
    "\n",
    "class LogModel(BaseModel):\n",
    "\n",
    "    model_type = 'Multinominal Logistic Regression' \n",
    "    \n",
    "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('training multinomial logistic regression')\n",
    "        train_samples = X_train.shape[0]\n",
    "        self.classifier = LogisticRegression(\n",
    "            C=50. / train_samples,\n",
    "            multi_class='multinomial',\n",
    "            penalty='l1',\n",
    "            solver='saga',\n",
    "            tol=0.1,\n",
    "            class_weight=c_weight,\n",
    "            )\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        self.test_y_predicted = self.classifier.predict(X_test)\n",
    "        self.val_y_predicted = self.classifier.predict(X_val)\n",
    "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
    "                self.test_y_predicted)\n",
    "\n",
    "class RfModel(BaseModel):\n",
    "\n",
    "    model_type = 'Random Forest'\n",
    "    \n",
    "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('training random forest...')\n",
    "        self.classifier = RandomForestClassifier(n_estimators=500, class_weight=c_weight)\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        self.test_y_predicted = self.classifier.predict(X_test)\n",
    "        self.val_y_predicted = self.classifier.predict(X_val)\n",
    "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X51UCCeEzqb9"
   },
   "source": [
    "Our 'TrainModel' class accepts one of the previously in defined learning algorithms, trains using the training set and gets performance measurements from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEcquMhTzqlC"
   },
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "\n",
    "    def __init__(self, model_object):        \n",
    "        self.accuracies = []\n",
    "        self.model_object = model_object()        \n",
    "\n",
    "    def print_model_type(self):\n",
    "        print (self.model_object.model_type)\n",
    "\n",
    "    # we train normally and get probabilities for the validation set. i.e., we use the probabilities to select the most uncertain samples\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('Train set:', X_train.shape, 'y:', y_train.shape)\n",
    "        print ('Val   set:', X_val.shape)\n",
    "        print ('Test  set:', X_test.shape)\n",
    "        t0 = time.time()\n",
    "        (X_train, X_val, X_test, self.val_y_predicted,\n",
    "         self.test_y_predicted) = \\\n",
    "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
    "        self.run_time = time.time() - t0\n",
    "        return (X_train, X_val, X_test)  # we return them in case we use PCA, with all the other algorithms, this is not needed.\n",
    "\n",
    "    # we want accuracy only for the test set\n",
    "\n",
    "    def get_test_accuracy(self, i, y_test):\n",
    "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
    "        self.accuracies.append(classif_rate)               \n",
    "        print('--------------------------------')\n",
    "        print('Iteration:',i)\n",
    "        print('--------------------------------')\n",
    "        print('y-test set:',y_test.shape)\n",
    "        print('Example run in %.3f s' % self.run_time,'\\n')\n",
    "        print(\"Accuracy rate for %f \" % (classif_rate))    \n",
    "        print(\"Classification report for classifier %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
    "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
    "        print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vYar8S_jyYQ9"
   },
   "source": [
    "We create a modular selection function class representation, 'BaseSelectionFunction' is a base class for various sample selection methods. Using this architecture, you can implement new selection methods and use them in addition or instead of previous methods, for experimental purposes. Our current implementations include random-selection, entropy-selection, margin sampling-selection and minimum standard deviation-selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ni-E8tN7yYX2"
   },
   "outputs": [],
   "source": [
    "class BaseSelectionFunction(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class RandomSelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        random_state = check_random_state(0)\n",
    "        selection = np.random.choice(probas_val.shape[0], initial_labeled_samples, replace=False)\n",
    "\n",
    "#     print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',initial_labeled_samples)\n",
    "\n",
    "        return selection\n",
    "\n",
    "\n",
    "class EntropySelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
    "        selection = (np.argsort(e)[::-1])[:initial_labeled_samples]\n",
    "        return selection\n",
    "      \n",
    "      \n",
    "class MarginSamplingSelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        rev = np.sort(probas_val, axis=1)[:, ::-1]\n",
    "        values = rev[:, 0] - rev[:, 1]\n",
    "        selection = np.argsort(values)[:initial_labeled_samples]\n",
    "        return selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ym7QEvD0yI9Z"
   },
   "source": [
    "We have a class that is used to normalize using a MinMax Scaler in the range of [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5aRcKj4D0SQJ"
   },
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \n",
    "    def normalize(self, X_train, X_val, X_test):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        X_train = self.scaler.fit_transform(X_train)\n",
    "        X_val   = self.scaler.transform(X_val)\n",
    "        X_test  = self.scaler.transform(X_test)\n",
    "        return (X_train, X_val, X_test) \n",
    "    \n",
    "    def inverse(self, X_train, X_val, X_test):\n",
    "        X_train = self.scaler.inverse_transform(X_train)\n",
    "        X_val   = self.scaler.inverse_transform(X_val)\n",
    "        X_test  = self.scaler.inverse_transform(X_test)\n",
    "        return (X_train, X_val, X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pl_AfuOx0fkM"
   },
   "source": [
    "Initially we would like to get a random sampling from the unlabeled data-pool, this is done using random.choice without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1GJB6Kb0e54"
   },
   "outputs": [],
   "source": [
    "def get_k_random_samples(initial_labeled_samples, X_train_full,\n",
    "                         y_train_full):\n",
    "    random_state = check_random_state(0)\n",
    "    permutation = np.random.choice(trainset_size,\n",
    "                                   initial_labeled_samples,\n",
    "                                   replace=False)\n",
    "    print ()\n",
    "    print ('initial random chosen samples', permutation.shape),\n",
    "#            permutation)\n",
    "    X_train = X_train_full[permutation]\n",
    "    y_train = y_train_full[permutation]\n",
    "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "    bin_count = np.bincount(y_train.astype('int64'))\n",
    "    unique = np.unique(y_train.astype('int64'))\n",
    "    print (\n",
    "        'initial train set:',\n",
    "        X_train.shape,\n",
    "        y_train.shape,\n",
    "        'unique(labels):',\n",
    "        bin_count,\n",
    "        unique,\n",
    "        )\n",
    "    return (permutation, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SeRHks3K0wQO"
   },
   "source": [
    "This is the main class that initiates the active-learning process according to the algorithm described in the introduction. In short, we select 'k' random samples, train a model, select the most informative samples, remove from the validation set, query their labels and retrain using those samples until reaching the stop criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRtOTPPvyJGx"
   },
   "outputs": [],
   "source": [
    "class TheAlgorithm(object):\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    def __init__(self, initial_labeled_samples, model_object, selection_function):\n",
    "        self.initial_labeled_samples = initial_labeled_samples\n",
    "        self.model_object = model_object\n",
    "        self.sample_selection_function = selection_function\n",
    "\n",
    "    def run(self, X_train_full, y_train_full, X_test, y_test):\n",
    "\n",
    "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
    "\n",
    "        (permutation, X_train, y_train) = \\\n",
    "            get_k_random_samples(self.initial_labeled_samples,\n",
    "                                 X_train_full, y_train_full)\n",
    "        self.queried = self.initial_labeled_samples\n",
    "        self.samplecount = [self.initial_labeled_samples]\n",
    "\n",
    "        # permutation, X_train, y_train = get_equally_k_random_samples(self.initial_labeled_samples,classes)\n",
    "\n",
    "        # assign the val set the rest of the 'unlabelled' training data\n",
    "\n",
    "        X_val = np.array([])\n",
    "        y_val = np.array([])\n",
    "        X_val = np.copy(X_train_full)\n",
    "        X_val = np.delete(X_val, permutation, axis=0)\n",
    "        y_val = np.copy(y_train_full)\n",
    "        y_val = np.delete(y_val, permutation, axis=0)\n",
    "        print ('val set:', X_val.shape, y_val.shape, permutation.shape)\n",
    "        print ()\n",
    "\n",
    "        # normalize data\n",
    "\n",
    "        normalizer = Normalize()\n",
    "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
    "        \n",
    "        self.clf_model = TrainModel(self.model_object)\n",
    "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
    "        active_iteration = 1\n",
    "        self.clf_model.get_test_accuracy(1, y_test)\n",
    "\n",
    "        # fpfn = self.clf_model.test_y_predicted.ravel() != y_val.ravel()\n",
    "        # print(fpfn)\n",
    "        # self.fpfncount = []\n",
    "        # self.fpfncount.append(fpfn.sum() / y_test.shape[0] * 100)\n",
    "\n",
    "        while self.queried < max_queried:\n",
    "\n",
    "            active_iteration += 1\n",
    "\n",
    "            # get validation probabilities\n",
    "\n",
    "            probas_val = \\\n",
    "                self.clf_model.model_object.classifier.predict_proba(X_val)\n",
    "            print ('val predicted:',\n",
    "                   self.clf_model.val_y_predicted.shape,\n",
    "                   self.clf_model.val_y_predicted)\n",
    "            print ('probabilities:', probas_val.shape, '\\n',\n",
    "                   np.argmax(probas_val, axis=1))\n",
    "\n",
    "            # select samples using a selection function\n",
    "\n",
    "            uncertain_samples = \\\n",
    "                self.sample_selection_function.select(probas_val, self.initial_labeled_samples)\n",
    "\n",
    "            # normalization needs to be inversed and recalculated based on the new train and test set.\n",
    " \n",
    "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
    "\n",
    "            # get the uncertain samples from the validation set\n",
    "\n",
    "            print ('trainset before', X_train.shape, y_train.shape)\n",
    "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
    "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
    "            print ('trainset after', X_train.shape, y_train.shape)\n",
    "            self.samplecount.append(X_train.shape[0])\n",
    "\n",
    "            bin_count = np.bincount(y_train.astype('int64'))\n",
    "            unique = np.unique(y_train.astype('int64'))\n",
    "            print (\n",
    "                'updated train set:',\n",
    "                X_train.shape,\n",
    "                y_train.shape,\n",
    "                'unique(labels):',\n",
    "                bin_count,\n",
    "                unique,\n",
    "                )\n",
    "\n",
    "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
    "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
    "            print ('val set:', X_val.shape, y_val.shape)\n",
    "            print ()\n",
    "\n",
    "            # normalize again after creating the 'new' train/test sets\n",
    "            normalizer = Normalize()\n",
    "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
    "\n",
    "            self.queried += self.initial_labeled_samples\n",
    "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
    "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
    "\n",
    "        print ('final active learning accuracies',\n",
    "               self.clf_model.accuracies)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K7OZblsL00L2"
   },
   "source": [
    "We download the data, split to train validation and test, we run the experiment by iterating over all of our training algorithms X all of our selection functions X all possible k's in the range of [10,25,50,125,250]. The accuracy results are kept in a dictionary and pickle-saved to a unique file as soon as the model finishes training - this is crucial when using google colaboratory as it tends to disconnect from time to time. We also limit our training to a maximum of 500 queried samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XzrAvJz00dk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST: (70000, 784) (70000,)\n",
      "train: (60000, 784) (60000,)\n",
      "test : (10000, 784) (10000,)\n",
      "unique classes 10\n",
      "stopping at: 500\n",
      "Count = 1, using model = SvmModel, selection_function = RandomSelection, k = 250, iteration = 0.\n",
      "\n",
      "initial random chosen samples (250,)\n",
      "initial train set: (250, 784) (250,) unique(labels): [22 36 27 28 26 24 20 21 25 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,) (250,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.021 s \n",
      "\n",
      "Accuracy rate for 84.150000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93       980\n",
      "           1       0.89      0.98      0.93      1135\n",
      "           2       0.81      0.81      0.81      1032\n",
      "           3       0.83      0.83      0.83      1010\n",
      "           4       0.77      0.85      0.81       982\n",
      "           5       0.75      0.84      0.79       892\n",
      "           6       0.91      0.86      0.89       958\n",
      "           7       0.88      0.88      0.88      1028\n",
      "           8       0.85      0.70      0.77       974\n",
      "           9       0.81      0.72      0.76      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 915    1    8    2    3   33    8    9    1    0]\n",
      " [   0 1107    2    4    0    1    4    0   16    1]\n",
      " [  19   35  836   36   16    8   21   22   32    7]\n",
      " [   6   10   27  840    2   61    4   20   36    4]\n",
      " [   1    7   24    1  834    3    5    4    6   97]\n",
      " [  15   10   16   45   18  749   16    4    9   10]\n",
      " [  17    4   42    1   19   46  827    1    1    0]\n",
      " [   1   46   25    5   20    1    1  900    9   20]\n",
      " [  12   17   38   58   20   91   18    9  681   30]\n",
      " [   9   10   18   18  155    7    0   55   11  726]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 5 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [48 58 51 47 51 48 54 45 51 47] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 20.914 s \n",
      "\n",
      "Accuracy rate for 86.910000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       980\n",
      "           1       0.92      0.97      0.94      1135\n",
      "           2       0.82      0.87      0.84      1032\n",
      "           3       0.86      0.81      0.84      1010\n",
      "           4       0.85      0.90      0.87       982\n",
      "           5       0.79      0.84      0.81       892\n",
      "           6       0.91      0.90      0.91       958\n",
      "           7       0.89      0.86      0.88      1028\n",
      "           8       0.85      0.76      0.80       974\n",
      "           9       0.85      0.80      0.83      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 938    1    3    1    1   21    9    5    1    0]\n",
      " [   0 1102    5    2    0    2    5    1   18    0]\n",
      " [  10   25  900   23   13    5   16   14   23    3]\n",
      " [   3    8   38  822    2   63    6   18   42    8]\n",
      " [   2    3   25    1  882    2   11    0    7   49]\n",
      " [   7    8   11   61   13  745   15    5   20    7]\n",
      " [  18    3   47    0    7   17  863    1    2    0]\n",
      " [   0   33   38    3   16    3    0  884    5   46]\n",
      " [   8   13   28   30   19   72   23    9  743   29]\n",
      " [   7    7    9   11   89   11    1   51   11  812]]\n",
      "--------------------------------\n",
      "final active learning accuracies [84.15, 86.91]\n",
      "saved Active-learning-experiment-1.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['README.md', 'Active-learning-experiment-1.pkl', 'Active_Learning_Tutorial.ipynb', '.ipynb_checkpoints', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 2, using model = SvmModel, selection_function = RandomSelection, k = 125, iteration = 0.\n",
      "\n",
      "initial random chosen samples (125,)\n",
      "initial train set: (125, 784) (125,) unique(labels): [14 15 11 15 13  9 11 15  9 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,) (125,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.443 s \n",
      "\n",
      "Accuracy rate for 74.540000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83       980\n",
      "           1       0.85      0.95      0.90      1135\n",
      "           2       0.87      0.67      0.76      1032\n",
      "           3       0.62      0.74      0.68      1010\n",
      "           4       0.63      0.77      0.69       982\n",
      "           5       0.72      0.49      0.58       892\n",
      "           6       0.81      0.90      0.86       958\n",
      "           7       0.83      0.84      0.84      1028\n",
      "           8       0.78      0.50      0.61       974\n",
      "           9       0.63      0.61      0.62      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.74      0.74     10000\n",
      "weighted avg       0.75      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 908    0    5    1    5   24   20   13    4    0]\n",
      " [   0 1078    2    1    1    1    6    1   39    6]\n",
      " [ 110   65  689   29   24    4   38   43   20   10]\n",
      " [  55   29   10  746    2   64   30   19   31   24]\n",
      " [   6    8    6    3  759    2   28   16    1  153]\n",
      " [  65   17    9  229   28  433   36   12   22   41]\n",
      " [  36    8    9    1   24   10  865    1    0    4]\n",
      " [   0   26   19    4   62    1    1  866   10   39]\n",
      " [  31   31   37  170   23   53   36   20  490   83]\n",
      " [   6    5    3   16  285    8    2   51   13  620]]\n",
      "--------------------------------\n",
      "val predicted: (59875,) ['3' '0' '4' ... '9' '6' '9']\n",
      "probabilities: (59875, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (125, 784) (125,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [27 28 25 29 23 21 27 29 20 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 11.364 s \n",
      "\n",
      "Accuracy rate for 80.670000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91       980\n",
      "           1       0.89      0.98      0.93      1135\n",
      "           2       0.86      0.76      0.81      1032\n",
      "           3       0.71      0.83      0.77      1010\n",
      "           4       0.69      0.79      0.74       982\n",
      "           5       0.74      0.70      0.72       892\n",
      "           6       0.83      0.92      0.87       958\n",
      "           7       0.88      0.87      0.87      1028\n",
      "           8       0.89      0.60      0.71       974\n",
      "           9       0.72      0.63      0.67      1009\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.81      0.80      0.80     10000\n",
      "weighted avg       0.81      0.81      0.80     10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 928    0    2    1    2   13   30    3    1    0]\n",
      " [   0 1114    2    2    0    3    5    1    8    0]\n",
      " [  48   38  785   53   12    6   40   27   19    4]\n",
      " [  15   15   10  842    1   62   13   15   27   10]\n",
      " [   5    6    7    1  779   14   20   11    1  138]\n",
      " [  19   16    7  160   10  627   34    9    3    7]\n",
      " [  14    7   18    1   12   19  885    0    0    2]\n",
      " [   4   22   11    8   44    7    2  890    6   34]\n",
      " [   9   29   58  103   13   82   36   10  582   52]\n",
      " [  12    6   10   13  256   18    2   47   10  635]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [42 39 38 44 33 32 39 42 30 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.318 s \n",
      "\n",
      "Accuracy rate for 84.160000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       980\n",
      "           1       0.91      0.98      0.94      1135\n",
      "           2       0.88      0.78      0.83      1032\n",
      "           3       0.72      0.83      0.77      1010\n",
      "           4       0.84      0.82      0.83       982\n",
      "           5       0.77      0.71      0.74       892\n",
      "           6       0.87      0.91      0.89       958\n",
      "           7       0.90      0.88      0.89      1028\n",
      "           8       0.87      0.66      0.75       974\n",
      "           9       0.78      0.85      0.81      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 949    0    2    2    0    9   10    2    5    1]\n",
      " [   0 1108    2    2    0    2    4    1   16    0]\n",
      " [  47   36  806   47   10    5   31   20   24    6]\n",
      " [  11    6   18  842    2   75   13   15   22    6]\n",
      " [   9    4   10    0  810    7   19    2    3  118]\n",
      " [  26   12    8  148    6  629   26   13   12   12]\n",
      " [  17    7   22    0   19   12  876    0    3    2]\n",
      " [   6   22   10    8   25    9    1  901    2   44]\n",
      " [   7   20   38  106   15   59   21   16  642   50]\n",
      " [  10    5    2   15   77    7    1   31    8  853]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59625, 10) \n",
      " [5 0 4 ... 5 6 9]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [47 57 50 53 45 48 48 53 48 51] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 19.986 s \n",
      "\n",
      "Accuracy rate for 86.620000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       980\n",
      "           1       0.91      0.98      0.95      1135\n",
      "           2       0.85      0.82      0.84      1032\n",
      "           3       0.82      0.85      0.83      1010\n",
      "           4       0.89      0.82      0.85       982\n",
      "           5       0.80      0.79      0.80       892\n",
      "           6       0.89      0.92      0.91       958\n",
      "           7       0.90      0.88      0.89      1028\n",
      "           8       0.89      0.76      0.82       974\n",
      "           9       0.79      0.87      0.83      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 938    0    7    2    0   15   12    1    1    4]\n",
      " [   0 1111    1    6    0    2    4    0   10    1]\n",
      " [  33   35  849   29    5    2   21   20   26   12]\n",
      " [   5   14   33  857    2   53    9   11   20    6]\n",
      " [   4    5   14    0  806    7   17    5    5  119]\n",
      " [  24    7   12   86    2  706   23    7   15   10]\n",
      " [  13    5   30    0    9   16  878    0    4    3]\n",
      " [   5   19   16    7   18   10    0  902    5   46]\n",
      " [   6   14   28   46   13   57   17   19  738   36]\n",
      " [   8    6    4   12   49   16    1   32    4  877]]\n",
      "--------------------------------\n",
      "final active learning accuracies [74.53999999999999, 80.67, 84.16, 86.61999999999999]\n",
      "saved Active-learning-experiment-2.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-2.pkl', 'README.md', 'Active-learning-experiment-1.pkl', 'Active_Learning_Tutorial.ipynb', '.ipynb_checkpoints', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 3, using model = SvmModel, selection_function = RandomSelection, k = 50, iteration = 0.\n",
      "\n",
      "initial random chosen samples (50,)\n",
      "initial train set: (50, 784) (50,) unique(labels): [6 2 6 7 9 5 4 3 1 7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,) (50,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.576 s \n",
      "\n",
      "Accuracy rate for 67.520000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84       980\n",
      "           1       0.85      0.88      0.87      1135\n",
      "           2       0.76      0.67      0.71      1032\n",
      "           3       0.62      0.79      0.69      1010\n",
      "           4       0.43      0.79      0.56       982\n",
      "           5       0.60      0.67      0.63       892\n",
      "           6       0.88      0.68      0.77       958\n",
      "           7       0.91      0.71      0.80      1028\n",
      "           8       0.85      0.02      0.04       974\n",
      "           9       0.52      0.68      0.59      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.73      0.67      0.65     10000\n",
      "weighted avg       0.73      0.68      0.65     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 801    0   28    5   12   67   32    1    0   34]\n",
      " [   0 1000   13    8  104    7    2    0    0    1]\n",
      " [  25   29  690  142   52   32    9    7    3   43]\n",
      " [  19    7   15  801   30   82    3   10    1   42]\n",
      " [   0    7    3    0  774   62    9    0    0  127]\n",
      " [  16   28    6   64  115  600   14    6    0   43]\n",
      " [  21   13   69    4  173   26  650    0    0    2]\n",
      " [   3   46   18    8  119    6    0  732    0   96]\n",
      " [  38   32   62  257  173  119   19    5   22  247]\n",
      " [  10   14    5   11  238    7    0   42    0  682]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59950, 10) \n",
      " [5 0 4 ... 5 6 9]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [11  5 11 13 16 10  5 14  5 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.342 s \n",
      "\n",
      "Accuracy rate for 75.520000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87       980\n",
      "           1       0.80      0.96      0.88      1135\n",
      "           2       0.72      0.75      0.74      1032\n",
      "           3       0.75      0.82      0.78      1010\n",
      "           4       0.58      0.87      0.70       982\n",
      "           5       0.68      0.71      0.69       892\n",
      "           6       0.92      0.71      0.80       958\n",
      "           7       0.87      0.85      0.86      1028\n",
      "           8       0.76      0.35      0.47       974\n",
      "           9       0.68      0.62      0.65      1009\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.77      0.75      0.75     10000\n",
      "weighted avg       0.77      0.76      0.75     10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 851    1   18    2   17   64    9    6    1   11]\n",
      " [   0 1095    1    8   20    6    2    0    3    0]\n",
      " [  25   51  775   44   48   22    7   26   14   20]\n",
      " [   9   16   44  829   10   40    3   12   35   12]\n",
      " [   2   16    3    0  853    2    9    3    0   94]\n",
      " [  19   27    3   62   45  631   14    7   45   39]\n",
      " [  15   16  134    1   81   29  680    0    2    0]\n",
      " [   2   38   19    6   51    5    0  877    0   30]\n",
      " [  30   84   73  135   87  119   12    5  337   92]\n",
      " [  14   19    2   16  248   10    0   68    8  624]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59900, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [15 10 17 16 22 14 13 19  8 16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 7.673 s \n",
      "\n",
      "Accuracy rate for 80.190000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89       980\n",
      "           1       0.79      0.97      0.87      1135\n",
      "           2       0.78      0.79      0.79      1032\n",
      "           3       0.77      0.86      0.82      1010\n",
      "           4       0.71      0.83      0.77       982\n",
      "           5       0.74      0.72      0.73       892\n",
      "           6       0.91      0.85      0.88       958\n",
      "           7       0.91      0.84      0.87      1028\n",
      "           8       0.81      0.44      0.57       974\n",
      "           9       0.72      0.81      0.76      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.81      0.80      0.79     10000\n",
      "weighted avg       0.81      0.80      0.80     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 859    1   46    4   14   32   18    4    0    2]\n",
      " [   0 1100    6    5    4    1    2    0   17    0]\n",
      " [  23   68  820   22   36   10   11   17   15   10]\n",
      " [   8   19   30  871    4   22    0    7   32   17]\n",
      " [   1   12    4    0  818    2   14    2    0  129]\n",
      " [  13   26    3  106   42  638   22    6   29    7]\n",
      " [   6   35   21    9   45   29  811    0    2    0]\n",
      " [   2   41   29    3   31    5    0  859    4   54]\n",
      " [  14   72   82   92   61  121    8    4  428   92]\n",
      " [  15   13    4   12   92    7    2   46    3  815]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59850, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [18 15 22 22 26 16 20 25 18 18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 9.613 s \n",
      "\n",
      "Accuracy rate for 84.260000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       980\n",
      "           1       0.85      0.95      0.90      1135\n",
      "           2       0.85      0.82      0.83      1032\n",
      "           3       0.83      0.86      0.84      1010\n",
      "           4       0.76      0.86      0.81       982\n",
      "           5       0.85      0.67      0.75       892\n",
      "           6       0.90      0.91      0.90       958\n",
      "           7       0.91      0.83      0.87      1028\n",
      "           8       0.77      0.80      0.79       974\n",
      "           9       0.79      0.79      0.79      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 891    0   23    4   13   25   15    3    5    1]\n",
      " [   0 1082    9    3    1    1    2    0   37    0]\n",
      " [  21   47  843    7   30    4   14   16   41    9]\n",
      " [   9   13   35  869    5   15    1    6   44   13]\n",
      " [   1   10    3    0  842    1   16    2    4  103]\n",
      " [  10   17    7  107   29  595   41    3   74    9]\n",
      " [   7   15   15    0   32   13  870    0    6    0]\n",
      " [   2   38   36    1   30    6    0  854   15   46]\n",
      " [   8   37   13   42   26   28    7    3  784   26]\n",
      " [  11   13    5   14  101    9    3   50    7  796]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59800, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [24 19 28 23 32 21 25 28 24 26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 11.361 s \n",
      "\n",
      "Accuracy rate for 85.770000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       980\n",
      "           1       0.88      0.95      0.91      1135\n",
      "           2       0.85      0.83      0.84      1032\n",
      "           3       0.86      0.84      0.85      1010\n",
      "           4       0.82      0.88      0.85       982\n",
      "           5       0.84      0.73      0.78       892\n",
      "           6       0.92      0.91      0.92       958\n",
      "           7       0.92      0.86      0.89      1028\n",
      "           8       0.77      0.78      0.78       974\n",
      "           9       0.80      0.84      0.82      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 919    0   21    2    2   18    9    1    4    4]\n",
      " [   0 1074    5    2    1    3    0    0   50    0]\n",
      " [  25   30  855    5   27    2   11   21   44   12]\n",
      " [   8   14   42  851    4   18    2    9   51   11]\n",
      " [   1    7    2    0  868    1    8    0    3   92]\n",
      " [  12   14    5   93   20  647   27    2   48   24]\n",
      " [   7   16   25    0   12   17  875    0    6    0]\n",
      " [   4   22   35    0   32    3    1  879   14   38]\n",
      " [  10   35   13   28   24   55   14    4  760   31]\n",
      " [  10   14    4   14   69    7    2   37    3  849]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [28 22 33 29 36 25 30 35 32 30] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 13.277 s \n",
      "\n",
      "Accuracy rate for 86.160000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       980\n",
      "           1       0.89      0.98      0.93      1135\n",
      "           2       0.87      0.82      0.84      1032\n",
      "           3       0.86      0.87      0.86      1010\n",
      "           4       0.83      0.87      0.85       982\n",
      "           5       0.84      0.70      0.76       892\n",
      "           6       0.92      0.92      0.92       958\n",
      "           7       0.91      0.86      0.89      1028\n",
      "           8       0.80      0.79      0.79       974\n",
      "           9       0.79      0.83      0.81      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 926    0    8    2    2   19   11    3    3    6]\n",
      " [   0 1115    2    4    1    4    0    0    9    0]\n",
      " [  28   34  844    4   20    6   13   24   46   13]\n",
      " [  13   13   34  874    4   21    0    9   35    7]\n",
      " [   1    7    3    1  855    2    7    0    5  101]\n",
      " [  32   11    5   73   19  627   29    2   66   28]\n",
      " [   7    8   24    0   15   12  881    0   11    0]\n",
      " [   5   25   35    2   26    4    1  889   13   28]\n",
      " [  12   29    9   35   20   49   15    5  766   34]\n",
      " [   8   12    3   16   71    6    1   46    7  839]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59700, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [31 25 39 34 42 33 36 41 36 33] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.397 s \n",
      "\n",
      "Accuracy rate for 86.580000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       980\n",
      "           1       0.89      0.98      0.93      1135\n",
      "           2       0.86      0.81      0.83      1032\n",
      "           3       0.86      0.87      0.86      1010\n",
      "           4       0.83      0.88      0.85       982\n",
      "           5       0.83      0.76      0.79       892\n",
      "           6       0.92      0.91      0.91       958\n",
      "           7       0.90      0.86      0.88      1028\n",
      "           8       0.83      0.78      0.81       974\n",
      "           9       0.81      0.83      0.82      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.87      0.87      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 940    0    4    2    2   11   12    1    3    5]\n",
      " [   0 1111    4    2    1    3    0    0   14    0]\n",
      " [  22   36  837   21   24    6   11   25   39   11]\n",
      " [   4    8   37  877    6   34    2   11   25    6]\n",
      " [   1    7    2    0  860    2    9    0    7   94]\n",
      " [  21   10    8   68   14  676   30    3   41   21]\n",
      " [   8   10   28    1   18   14  872    0    7    0]\n",
      " [   5   28   39    1   31    4    0  881   12   27]\n",
      " [  14   26    9   36   23   52   17    4  763   30]\n",
      " [   8   13    6   17   60    8    0   53    3  841]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59650, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [35 31 44 39 44 40 39 49 43 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 16.766 s \n",
      "\n",
      "Accuracy rate for 86.650000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       980\n",
      "           1       0.87      0.97      0.92      1135\n",
      "           2       0.87      0.78      0.82      1032\n",
      "           3       0.85      0.87      0.86      1010\n",
      "           4       0.84      0.88      0.86       982\n",
      "           5       0.81      0.78      0.80       892\n",
      "           6       0.93      0.94      0.93       958\n",
      "           7       0.90      0.86      0.88      1028\n",
      "           8       0.82      0.80      0.81       974\n",
      "           9       0.83      0.81      0.82      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 925    0    5    1    1   21   17    3    2    5]\n",
      " [   0 1105    2    2    1    1    1    0   23    0]\n",
      " [  22   64  810   15   24    9   13   17   48   10]\n",
      " [   7   13   34  881    5   42    3    9   13    3]\n",
      " [   1    7    2    0  867    3    8    2    5   87]\n",
      " [  20   14    7   75   12  693   16    3   38   14]\n",
      " [   5    6   14    0   10   14  900    0    9    0]\n",
      " [   2   26   42    0   24    5    0  886   21   22]\n",
      " [  12   17   10   44   21   50   13    3  780   24]\n",
      " [   6   12    6   19   67   13    1   58    9  818]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59600, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [39 36 47 46 50 43 41 55 49 44] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 18.153 s \n",
      "\n",
      "Accuracy rate for 87.180000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       980\n",
      "           1       0.87      0.98      0.92      1135\n",
      "           2       0.88      0.79      0.83      1032\n",
      "           3       0.84      0.88      0.86      1010\n",
      "           4       0.85      0.89      0.87       982\n",
      "           5       0.83      0.79      0.81       892\n",
      "           6       0.93      0.94      0.93       958\n",
      "           7       0.90      0.85      0.87      1028\n",
      "           8       0.83      0.80      0.81       974\n",
      "           9       0.85      0.82      0.84      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 924    0    5    3    1   20   19    3    1    4]\n",
      " [   0 1115    2    2    0    1    1    0   14    0]\n",
      " [  19   58  815   20   22    8   11   18   52    9]\n",
      " [   7   17   27  892    3   37    3    9   11    4]\n",
      " [   3    8    2    0  878    4    8    2    8   69]\n",
      " [  16   13    5   76   10  708   18    3   36    7]\n",
      " [   4    9   10    1   10   14  904    0    6    0]\n",
      " [   2   27   40    1   25    4    0  873   23   33]\n",
      " [  11   25    9   46   23   47   11    4  779   19]\n",
      " [   5   10    6   17   63   11    1   56   10  830]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59550, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [45 43 52 48 55 49 46 58 53 51] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 19.640 s \n",
      "\n",
      "Accuracy rate for 87.090000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       980\n",
      "           1       0.87      0.98      0.92      1135\n",
      "           2       0.89      0.79      0.84      1032\n",
      "           3       0.86      0.87      0.87      1010\n",
      "           4       0.85      0.90      0.87       982\n",
      "           5       0.81      0.78      0.80       892\n",
      "           6       0.91      0.94      0.92       958\n",
      "           7       0.92      0.85      0.88      1028\n",
      "           8       0.82      0.80      0.81       974\n",
      "           9       0.86      0.84      0.85      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 930    0    4    2    1   16   21    2    0    4]\n",
      " [   0 1111    2    2    0    0    2    0   18    0]\n",
      " [  22   61  815   13   24    8   10   19   51    9]\n",
      " [   7   13   28  883    3   39    6    9   16    6]\n",
      " [   3    6    3    0  884    7    9    0   11   59]\n",
      " [  16   11    2   77   14  697   26    3   40    6]\n",
      " [   8    7   12    1    8   16  897    0    9    0]\n",
      " [   2   27   39    1   25    6    0  871   19   38]\n",
      " [  14   27    9   34   17   60   11    5  776   21]\n",
      " [   8   10    5   18   66   10    1   38    8  845]]\n",
      "--------------------------------\n",
      "final active learning accuracies [67.52, 75.52, 80.19, 84.26, 85.77, 86.16, 86.58, 86.65, 87.18, 87.09]\n",
      "saved Active-learning-experiment-3.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-2.pkl', 'README.md', 'Active-learning-experiment-1.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', '.ipynb_checkpoints', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 4, using model = SvmModel, selection_function = RandomSelection, k = 25, iteration = 0.\n",
      "\n",
      "initial random chosen samples (25,)\n",
      "initial train set: (25, 784) (25,) unique(labels): [3 3 2 2 3 0 1 4 3 4] [0 1 2 3 4 6 7 8 9]\n",
      "val set: (59975, 784) (59975,) (25,)\n",
      "\n",
      "Train set: (25, 784) y: (25,)\n",
      "Val   set: (59975, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 1.411 s \n",
      "\n",
      "Accuracy rate for 55.490000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.74      0.68       980\n",
      "           1       0.59      0.98      0.74      1135\n",
      "           2       0.61      0.64      0.63      1032\n",
      "           3       0.63      0.38      0.48      1010\n",
      "           4       0.44      0.29      0.35       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.99      0.34      0.50       958\n",
      "           7       0.57      0.75      0.65      1028\n",
      "           8       0.55      0.59      0.57       974\n",
      "           9       0.38      0.71      0.49      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.54      0.54      0.51     10000\n",
      "weighted avg       0.54      0.55      0.52     10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 725    2   74   33   17    0    3   20   40   66]\n",
      " [  13 1116    1    0    0    0    0    5    0    0]\n",
      " [  57  106  664   46   37    0    1   51   33   37]\n",
      " [  89  139  101  387    2    0    0  137  144   11]\n",
      " [  10   29   21    1  286    0    0   84    9  542]\n",
      " [ 138  168   52   70   16    0    0   55  207  186]\n",
      " [  63   79  119   62  226    0  321    6    7   75]\n",
      " [  10   49    4    4    5    0    0  767   11  178]\n",
      " [  30  183   35   13    9    0    0   51  570   83]\n",
      " [  13   22   16    0   57    0    0  172   16  713]]\n",
      "--------------------------------\n",
      "val predicted: (59975,) ['0' '0' '7' ... '0' '4' '9']\n",
      "probabilities: (59975, 9) \n",
      " [0 0 8 ... 0 8 8]\n",
      "trainset before (25, 784) (25,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [ 3  5  3  5  4  1  4  9  6 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.756 s \n",
      "\n",
      "Accuracy rate for 64.210000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.68      0.75       980\n",
      "           1       0.66      0.99      0.79      1135\n",
      "           2       0.66      0.63      0.64      1032\n",
      "           3       0.67      0.63      0.65      1010\n",
      "           4       0.76      0.36      0.49       982\n",
      "           5       0.83      0.03      0.05       892\n",
      "           6       0.82      0.82      0.82       958\n",
      "           7       0.62      0.80      0.70      1028\n",
      "           8       0.60      0.55      0.57       974\n",
      "           9       0.43      0.81      0.57      1009\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.69      0.63      0.60     10000\n",
      "weighted avg       0.69      0.64      0.61     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 670    3   66   51    2    2   34   24   68   60]\n",
      " [   0 1123    1    2    0    0    7    2    0    0]\n",
      " [  25   93  654   34   14    0   64   38   46   64]\n",
      " [   2   76   93  632    2    0   14   69   64   58]\n",
      " [   3   28   22    0  358    0   14  121    0  436]\n",
      " [  69  133   40  161   14   24   28  133  162  128]\n",
      " [  18   31   73   12   12    0  789   13    5    5]\n",
      " [   0   45    5    2    6    0    0  819    4  147]\n",
      " [   8  137   29   40   11    3   15   26  531  174]\n",
      " [   2   22   15    5   54    0    0   78   12  821]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['3' '0' '7' ... '9' '6' '9']\n",
      "probabilities: (59950, 10) \n",
      " [3 0 7 ... 9 6 9]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (75, 784) (75,)\n",
      "updated train set: (75, 784) (75,) unique(labels): [ 3  7  4  8  7  3  8 11 12 12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59925, 784) (59925,)\n",
      "\n",
      "Train set: (75, 784) y: (75,)\n",
      "Val   set: (59925, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.977 s \n",
      "\n",
      "Accuracy rate for 71.630000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.66      0.76       980\n",
      "           1       0.79      0.99      0.88      1135\n",
      "           2       0.82      0.55      0.66      1032\n",
      "           3       0.74      0.76      0.75      1010\n",
      "           4       0.82      0.75      0.78       982\n",
      "           5       0.64      0.18      0.29       892\n",
      "           6       0.61      0.91      0.73       958\n",
      "           7       0.80      0.79      0.80      1028\n",
      "           8       0.55      0.71      0.62       974\n",
      "           9       0.61      0.78      0.69      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.71      0.69     10000\n",
      "weighted avg       0.73      0.72      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 651    1   33   27    1   69  100   17   66   15]\n",
      " [   0 1123    0    2    2    0    6    2    0    0]\n",
      " [  24   73  563   44   15    0  159   23   99   32]\n",
      " [   0   28   10  763    3   13   38   25   86   44]\n",
      " [   3   22    4    0  733    0   55   16    3  146]\n",
      " [  39   46    3  133   17  164  131   32  275   52]\n",
      " [   2    4   60    1   10    0  873    3    5    0]\n",
      " [   0   46    2    1   18    0    5  813   11  132]\n",
      " [   5   56    8   47    9    8   56   12  691   82]\n",
      " [   3   22    2    9   90    1    8   72   13  789]]\n",
      "--------------------------------\n",
      "val predicted: (59925,) ['3' '0' '9' ... '9' '6' '9']\n",
      "probabilities: (59925, 10) \n",
      " [3 0 9 ... 9 6 9]\n",
      "trainset before (75, 784) (75,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 4 11  6 11  9  5 11 12 14 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.290 s \n",
      "\n",
      "Accuracy rate for 74.950000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.67      0.79       980\n",
      "           1       0.81      0.98      0.89      1135\n",
      "           2       0.84      0.63      0.72      1032\n",
      "           3       0.75      0.78      0.76      1010\n",
      "           4       0.80      0.74      0.77       982\n",
      "           5       0.68      0.37      0.48       892\n",
      "           6       0.69      0.94      0.80       958\n",
      "           7       0.77      0.83      0.80      1028\n",
      "           8       0.63      0.71      0.67       974\n",
      "           9       0.64      0.77      0.70      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.76      0.74      0.74     10000\n",
      "weighted avg       0.76      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 657    0   12   20    6  103   96   13   66    7]\n",
      " [   0 1108   16    3    1    0    4    2    1    0]\n",
      " [  21   55  654   90   16    1   69   19   76   31]\n",
      " [   0   28    7  784    4   35   37   32   44   39]\n",
      " [   1   12   33    0  729    0   34   11    2  160]\n",
      " [   0   51    3   73   19  332  106   74  193   41]\n",
      " [   5    3   31    1    6    3  903    2    4    0]\n",
      " [   0   39    8    4   14    0    4  858    2   99]\n",
      " [   1   55    7   68   11   16   50   19  689   58]\n",
      " [   3   15    5    8  103    1    2   79   12  781]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '9' ... '5' '6' '9']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 9 ... 5 6 9]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (125, 784) (125,)\n",
      "updated train set: (125, 784) (125,) unique(labels): [ 4 12  8 16 12  7 18 14 15 19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.272 s \n",
      "\n",
      "Accuracy rate for 76.490000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.63      0.77       980\n",
      "           1       0.84      0.97      0.90      1135\n",
      "           2       0.81      0.65      0.72      1032\n",
      "           3       0.68      0.78      0.73      1010\n",
      "           4       0.82      0.81      0.81       982\n",
      "           5       0.64      0.46      0.54       892\n",
      "           6       0.73      0.95      0.82       958\n",
      "           7       0.80      0.86      0.83      1028\n",
      "           8       0.68      0.69      0.68       974\n",
      "           9       0.72      0.79      0.75      1009\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.77      0.76      0.76     10000\n",
      "weighted avg       0.77      0.76      0.76     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 622    0   46   30    5  136   88    8   43    2]\n",
      " [   0 1103   17    3    1    1    5    1    4    0]\n",
      " [   9   58  674  114   14    1   67   34   46   15]\n",
      " [   0   23   11  791    2   46   21   26   65   25]\n",
      " [   0    9   36    0  791    1   41    7    3   94]\n",
      " [   1   25    3  126   26  412   65   53  138   43]\n",
      " [   5    5   18    2    3    7  906    2   10    0]\n",
      " [   0   33   11    3   15    0    6  880    0   80]\n",
      " [   0   48    8   82   11   32   41   26  673   53]\n",
      " [   3   14    7    7  100    3    6   57   15  797]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59875,) ['3' '0' '3' ... '5' '6' '9']\n",
      "probabilities: (59875, 10) \n",
      " [3 0 9 ... 5 6 9]\n",
      "trainset before (125, 784) (125,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [ 6 14  8 18 14 12 23 18 17 20] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 7.636 s \n",
      "\n",
      "Accuracy rate for 80.090000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.72      0.81       980\n",
      "           1       0.83      0.99      0.90      1135\n",
      "           2       0.85      0.63      0.72      1032\n",
      "           3       0.69      0.79      0.74      1010\n",
      "           4       0.84      0.86      0.85       982\n",
      "           5       0.76      0.66      0.71       892\n",
      "           6       0.76      0.94      0.84       958\n",
      "           7       0.84      0.89      0.86      1028\n",
      "           8       0.76      0.69      0.72       974\n",
      "           9       0.80      0.80      0.80      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.81      0.80      0.80     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 707    0   38   37    3   93   72    9   20    1]\n",
      " [   0 1124    0    3    0    1    4    1    2    0]\n",
      " [  15   82  650   90   13    2   76   44   37   23]\n",
      " [   2   20   11  798    5   35   15   33   72   19]\n",
      " [   1    6   31    0  849    1   41    3    4   46]\n",
      " [   4   14    3  139   20  592   34   12   57   17]\n",
      " [  24    3   10    0    4    8  901    2    6    0]\n",
      " [   2   32    7    2   12    5    3  914    0   51]\n",
      " [   3   55    9   72   18   37   38   23  670   49]\n",
      " [   4   14    9    8   91    5    7   49   18  804]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59850, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (175, 784) (175,)\n",
      "updated train set: (175, 784) (175,) unique(labels): [ 7 15 13 20 22 13 27 19 17 22] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59825, 784) (59825,)\n",
      "\n",
      "Train set: (175, 784) y: (175,)\n",
      "Val   set: (59825, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 8.811 s \n",
      "\n",
      "Accuracy rate for 82.110000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.74      0.83       980\n",
      "           1       0.84      0.99      0.91      1135\n",
      "           2       0.84      0.73      0.78      1032\n",
      "           3       0.74      0.80      0.77      1010\n",
      "           4       0.81      0.92      0.86       982\n",
      "           5       0.75      0.72      0.73       892\n",
      "           6       0.82      0.95      0.88       958\n",
      "           7       0.86      0.89      0.88      1028\n",
      "           8       0.79      0.67      0.73       974\n",
      "           9       0.82      0.79      0.80      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 721    0   57   17    4  109   53    4   12    3]\n",
      " [   0 1121    0    3    0    2    4    2    3    0]\n",
      " [  10   73  750   62   22    2   48   26   30    9]\n",
      " [   2   18    8  804    6   39   13   34   67   19]\n",
      " [   0    8   15    0  899    3   13    3    3   38]\n",
      " [   3   16    6  117   22  639   31   12   32   14]\n",
      " [   8    4   13    0   11    9  907    0    6    0]\n",
      " [   0   24   12    3   16    3    3  920    0   47]\n",
      " [   2   54   19   66   31   43   31   23  657   48]\n",
      " [   4   12   15   11  104    8    3   42   17  793]]\n",
      "--------------------------------\n",
      "val predicted: (59825,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59825, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (175, 784) (175,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [ 9 19 16 23 23 17 28 23 19 23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.009 s \n",
      "\n",
      "Accuracy rate for 82.250000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.74      0.83       980\n",
      "           1       0.83      0.99      0.90      1135\n",
      "           2       0.79      0.72      0.75      1032\n",
      "           3       0.77      0.80      0.79      1010\n",
      "           4       0.82      0.91      0.87       982\n",
      "           5       0.76      0.77      0.77       892\n",
      "           6       0.81      0.95      0.87       958\n",
      "           7       0.87      0.88      0.88      1028\n",
      "           8       0.81      0.67      0.73       974\n",
      "           9       0.81      0.78      0.80      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.83      0.82      0.82     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 724    0   92   12    1   74   53    4   12    8]\n",
      " [   0 1121    1    2    2    1    4    2    2    0]\n",
      " [  11   76  738   50   17    3   71   26   33    7]\n",
      " [   2   16    9  811    4   49   10   28   63   18]\n",
      " [   0   16   18    0  895    2   13    4    2   32]\n",
      " [   2    9    6   89   25  686   27   10   25   13]\n",
      " [   8    4   16    1   10    8  906    0    5    0]\n",
      " [   0   26   16    7   12    4    3  907    1   52]\n",
      " [   4   42   18   71   30   64   24   19  652   50]\n",
      " [   4   34   19    8   91    9    3   42   14  785]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (225, 784) (225,)\n",
      "updated train set: (225, 784) (225,) unique(labels): [12 25 16 27 26 17 29 24 23 26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59775, 784) (59775,)\n",
      "\n",
      "Train set: (225, 784) y: (225,)\n",
      "Val   set: (59775, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.813 s \n",
      "\n",
      "Accuracy rate for 82.650000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.79      0.86       980\n",
      "           1       0.84      0.99      0.91      1135\n",
      "           2       0.82      0.70      0.76      1032\n",
      "           3       0.76      0.82      0.79      1010\n",
      "           4       0.82      0.90      0.86       982\n",
      "           5       0.77      0.75      0.76       892\n",
      "           6       0.83      0.94      0.88       958\n",
      "           7       0.88      0.87      0.87      1028\n",
      "           8       0.80      0.71      0.75       974\n",
      "           9       0.81      0.78      0.79      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.82      0.82     10000\n",
      "weighted avg       0.83      0.83      0.82     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 772    0   61   14    2   69   31    4   23    4]\n",
      " [   0 1121    0    3    2    1    4    1    3    0]\n",
      " [  14   72  725   57   18    2   70   27   40    7]\n",
      " [   4   17    9  830    2   48    9   25   50   16]\n",
      " [   0   18   20    0  881    2   14    3    1   43]\n",
      " [   3    9    8   98   19  669   28   14   31   13]\n",
      " [  14    4   16    1    9    8  898    0    8    0]\n",
      " [   2   26   15    7   18    3    2  893    1   61]\n",
      " [   4   25    9   76   32   57   23   15  690   43]\n",
      " [   5   36   17   11   93    7    2   38   14  786]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59775,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59775, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (225, 784) (225,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [16 30 18 29 27 21 33 24 24 28] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 11.863 s \n",
      "\n",
      "Accuracy rate for 83.300000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86       980\n",
      "           1       0.84      0.99      0.91      1135\n",
      "           2       0.83      0.72      0.77      1032\n",
      "           3       0.80      0.81      0.80      1010\n",
      "           4       0.83      0.90      0.86       982\n",
      "           5       0.76      0.76      0.76       892\n",
      "           6       0.85      0.93      0.89       958\n",
      "           7       0.88      0.87      0.88      1028\n",
      "           8       0.81      0.74      0.77       974\n",
      "           9       0.82      0.78      0.80      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 791    0   54   10    3   90   17    2   13    0]\n",
      " [   0 1120    1    3    1    1    4    1    4    0]\n",
      " [  21   73  738   51   15    2   54   27   45    6]\n",
      " [  11   16    6  821    2   55   10   24   51   14]\n",
      " [   3   19   22    0  880    2   12    3    1   40]\n",
      " [  10   14    6   81   19  680   31   10   30   11]\n",
      " [  14    3   18    1    8   11  895    1    7    0]\n",
      " [   0   26   16    7   18    3    2  895    0   61]\n",
      " [  10   22   12   48   29   46   25   17  719   46]\n",
      " [   6   35   18    8   89    8    2   37   15  791]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (275, 784) (275,)\n",
      "updated train set: (275, 784) (275,) unique(labels): [18 33 20 33 29 23 35 27 27 30] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59725, 784) (59725,)\n",
      "\n",
      "Train set: (275, 784) y: (275,)\n",
      "Val   set: (59725, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.801 s \n",
      "\n",
      "Accuracy rate for 84.020000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87       980\n",
      "           1       0.83      0.99      0.90      1135\n",
      "           2       0.86      0.71      0.78      1032\n",
      "           3       0.81      0.84      0.82      1010\n",
      "           4       0.82      0.90      0.86       982\n",
      "           5       0.76      0.75      0.76       892\n",
      "           6       0.86      0.93      0.89       958\n",
      "           7       0.88      0.87      0.88      1028\n",
      "           8       0.84      0.76      0.80       974\n",
      "           9       0.83      0.79      0.81      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 813    0   35    8    3   90   14    2   14    1]\n",
      " [   0 1122    0    3    1    1    4    1    3    0]\n",
      " [  20   80  737   48   15    1   48   27   45   11]\n",
      " [  11   19    6  845    4   54   10   24   25   12]\n",
      " [   2   21   20    0  887    2   12    3    1   34]\n",
      " [  12   16    4   81   22  672   30   10   31   14]\n",
      " [  14    4   19    2    7   11  894    1    6    0]\n",
      " [   0   23   16    7   12    2    2  899    1   66]\n",
      " [   7   28    9   42   33   44   25   17  739   30]\n",
      " [   7   33   12    9   94    9    1   34   16  794]]\n",
      "--------------------------------\n",
      "val predicted: (59725,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59725, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (275, 784) (275,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [19 36 23 37 33 26 36 27 30 33] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 13.785 s \n",
      "\n",
      "Accuracy rate for 85.050000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       980\n",
      "           1       0.84      0.98      0.91      1135\n",
      "           2       0.86      0.72      0.78      1032\n",
      "           3       0.83      0.84      0.83      1010\n",
      "           4       0.84      0.90      0.87       982\n",
      "           5       0.77      0.79      0.78       892\n",
      "           6       0.87      0.93      0.90       958\n",
      "           7       0.89      0.87      0.88      1028\n",
      "           8       0.86      0.76      0.81       974\n",
      "           9       0.83      0.81      0.82      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 860    0   29    4    3   63   14    2    5    0]\n",
      " [   0 1117    0    3    0    2    4    0    9    0]\n",
      " [  18   86  745   53   16    2   36   24   42   10]\n",
      " [   8   12   10  850    3   65    9   23   20   10]\n",
      " [   2   20   18    0  885    1   12    3    1   40]\n",
      " [   8   13    6   63   23  702   30   11   22   14]\n",
      " [  15    4   21    2    5   11  894    0    6    0]\n",
      " [   1   22   17    6   13    2    2  899    0   66]\n",
      " [   9   26   10   38   29   53   27   19  736   27]\n",
      " [   6   32   12    9   76    9    1   34   13  817]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59700, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (325, 784) (325,)\n",
      "updated train set: (325, 784) (325,) unique(labels): [21 40 26 38 35 26 38 29 37 35] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59675, 784) (59675,)\n",
      "\n",
      "Train set: (325, 784) y: (325,)\n",
      "Val   set: (59675, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.008 s \n",
      "\n",
      "Accuracy rate for 85.150000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91       980\n",
      "           1       0.84      0.99      0.91      1135\n",
      "           2       0.84      0.74      0.78      1032\n",
      "           3       0.82      0.84      0.83      1010\n",
      "           4       0.86      0.89      0.87       982\n",
      "           5       0.78      0.77      0.78       892\n",
      "           6       0.88      0.92      0.90       958\n",
      "           7       0.89      0.87      0.88      1028\n",
      "           8       0.83      0.78      0.81       974\n",
      "           9       0.83      0.80      0.82      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 864    0   29    4    3   58   14    2    6    0]\n",
      " [   0 1120    1    2    1    1    4    1    5    0]\n",
      " [  13   78  763   48    6    3   29   22   64    6]\n",
      " [   8   13    9  852    1   58    7   22   26   14]\n",
      " [   2   20   27    0  877    1   11    3    3   38]\n",
      " [  10   16   16   76   17  686   26    9   23   13]\n",
      " [  15    4   23    3    6   11  886    1    9    0]\n",
      " [   1   25   17    4   13    2    2  896    1   67]\n",
      " [   7   19   12   36   23   47   24   18  762   26]\n",
      " [   5   33   16    9   77   10    2   31   17  809]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59675,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59675, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (325, 784) (325,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [23 42 27 40 40 29 40 31 42 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.847 s \n",
      "\n",
      "Accuracy rate for 85.670000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.90       980\n",
      "           1       0.85      0.98      0.91      1135\n",
      "           2       0.85      0.75      0.79      1032\n",
      "           3       0.85      0.84      0.85      1010\n",
      "           4       0.84      0.91      0.88       982\n",
      "           5       0.78      0.80      0.79       892\n",
      "           6       0.89      0.94      0.92       958\n",
      "           7       0.88      0.87      0.88      1028\n",
      "           8       0.83      0.80      0.82       974\n",
      "           9       0.85      0.80      0.83      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.85     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 847    0   33    4    4   69   16    2    5    0]\n",
      " [   1 1111    3    2    0    2    3    2   11    0]\n",
      " [  12   65  769   38   11    2   27   39   65    4]\n",
      " [   8   16   13  848    3   59    4   21   26   12]\n",
      " [   2   17   20    0  892    1   11    4    3   32]\n",
      " [  11   13   13   58   23  710   26    9   20    9]\n",
      " [  13    4   14    2    6    8  903    0    8    0]\n",
      " [   2   26   18    5   17    1    2  895    0   62]\n",
      " [   7   18   13   28   21   46   20   15  780   26]\n",
      " [   6   35   14    8   79    8    1   27   19  812]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59650, 10) \n",
      " [5 0 4 ... 5 6 9]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [24 43 31 42 44 30 41 32 49 39] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 16.875 s \n",
      "\n",
      "Accuracy rate for 86.180000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       980\n",
      "           1       0.87      0.97      0.92      1135\n",
      "           2       0.87      0.79      0.83      1032\n",
      "           3       0.87      0.84      0.86      1010\n",
      "           4       0.82      0.92      0.87       982\n",
      "           5       0.79      0.78      0.78       892\n",
      "           6       0.89      0.94      0.91       958\n",
      "           7       0.89      0.85      0.87      1028\n",
      "           8       0.86      0.82      0.84       974\n",
      "           9       0.84      0.81      0.82      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 851    0   34    4    3   69   16    2    1    0]\n",
      " [   1 1097    3    1    3    3    2    2   23    0]\n",
      " [  11   55  820   27   23    1   30   33   27    5]\n",
      " [   3   16   13  852    4   62    5   17   27   11]\n",
      " [   2   14   10    0  907    1   12    1    4   31]\n",
      " [  14   14    9   56   29  699   28    8   25   10]\n",
      " [  11    4   18    1    9    7  905    0    3    0]\n",
      " [   3   21   18    4   23    2    3  876    4   74]\n",
      " [   7   15    7   26   20   40   21   18  797   23]\n",
      " [   8   22   11    9   88    6    0   32   19  814]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59625, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [28 45 33 46 46 30 44 34 53 41] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 17.510 s \n",
      "\n",
      "Accuracy rate for 86.840000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       980\n",
      "           1       0.89      0.97      0.93      1135\n",
      "           2       0.87      0.83      0.85      1032\n",
      "           3       0.87      0.84      0.85      1010\n",
      "           4       0.82      0.92      0.86       982\n",
      "           5       0.83      0.78      0.80       892\n",
      "           6       0.89      0.95      0.92       958\n",
      "           7       0.89      0.86      0.87      1028\n",
      "           8       0.86      0.81      0.83       974\n",
      "           9       0.84      0.81      0.82      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 894    0   25    4    2   35   15    2    3    0]\n",
      " [   1 1099    3    1    4    3    4    2   18    0]\n",
      " [  13   33  859   20   24    2   22   32   20    7]\n",
      " [  10   13   20  848    2   56    7   18   28    8]\n",
      " [   2   14   10    1  899    1   11    2    4   38]\n",
      " [  13   13    9   59   28  692   33    7   30    8]\n",
      " [  14    4   16    0    9    6  909    0    0    0]\n",
      " [   3   21   17    6   22    2    3  880    2   72]\n",
      " [   8   17   14   28   21   36   22   17  789   22]\n",
      " [   6   21   11    8   91    5    0   30   22  815]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59600, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (425, 784) (425,)\n",
      "updated train set: (425, 784) (425,) unique(labels): [30 45 35 49 50 35 48 36 54 43] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59575, 784) (59575,)\n",
      "\n",
      "Train set: (425, 784) y: (425,)\n",
      "Val   set: (59575, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 18.488 s \n",
      "\n",
      "Accuracy rate for 87.410000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       980\n",
      "           1       0.90      0.97      0.93      1135\n",
      "           2       0.89      0.86      0.87      1032\n",
      "           3       0.88      0.83      0.86      1010\n",
      "           4       0.82      0.92      0.87       982\n",
      "           5       0.82      0.79      0.81       892\n",
      "           6       0.89      0.95      0.92       958\n",
      "           7       0.90      0.85      0.87      1028\n",
      "           8       0.88      0.81      0.84       974\n",
      "           9       0.85      0.81      0.83      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 913    0   14    1    4   33   12    2    1    0]\n",
      " [   0 1097    2    2    4    2    6    2   20    0]\n",
      " [   9   29  883   18   25    2   17   28   16    5]\n",
      " [  12   11   23  843    2   67    5   18   20    9]\n",
      " [   2   13    7    2  907    1   12    1    3   34]\n",
      " [  14    9   10   51   24  707   34    5   29    9]\n",
      " [  15    3   15    1   11    7  906    0    0    0]\n",
      " [   5   22   20    5   21    2    3  875    1   74]\n",
      " [  10   14   12   28   22   36   26   17  791   18]\n",
      " [   6   21   11    9   89    7    1   28   18  819]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59575,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59575, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (425, 784) (425,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [34 46 42 53 51 37 49 38 56 44] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 19.060 s \n",
      "\n",
      "Accuracy rate for 87.630000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       980\n",
      "           1       0.89      0.97      0.93      1135\n",
      "           2       0.89      0.85      0.87      1032\n",
      "           3       0.87      0.84      0.86      1010\n",
      "           4       0.82      0.92      0.87       982\n",
      "           5       0.84      0.79      0.81       892\n",
      "           6       0.91      0.94      0.92       958\n",
      "           7       0.90      0.85      0.87      1028\n",
      "           8       0.88      0.82      0.85       974\n",
      "           9       0.84      0.82      0.83      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.87      0.87     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 936    0   12    0    3   18    7    2    2    0]\n",
      " [   0 1101    3    2    3    2    5    2   17    0]\n",
      " [  12   33  874   21   22    4   16   31   14    5]\n",
      " [  12   11   25  848    1   60    4   16   21   12]\n",
      " [   2   14    7    2  906    1   12    1    3   34]\n",
      " [  14    9   10   52   25  702   29    6   36    9]\n",
      " [  18    3   13    1   12    7  902    0    2    0]\n",
      " [   6   24   20    5   19    1    3  874    1   75]\n",
      " [  14   15   11   32   22   33   15   17  795   20]\n",
      " [   7   21   12   10   88    6    1   23   16  825]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59550, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (475, 784) (475,)\n",
      "updated train set: (475, 784) (475,) unique(labels): [38 49 42 59 53 37 52 41 58 46] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59525, 784) (59525,)\n",
      "\n",
      "Train set: (475, 784) y: (475,)\n",
      "Val   set: (59525, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 19.503 s \n",
      "\n",
      "Accuracy rate for 87.820000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       980\n",
      "           1       0.90      0.97      0.93      1135\n",
      "           2       0.89      0.85      0.87      1032\n",
      "           3       0.86      0.85      0.86      1010\n",
      "           4       0.83      0.92      0.87       982\n",
      "           5       0.86      0.78      0.82       892\n",
      "           6       0.91      0.94      0.93       958\n",
      "           7       0.89      0.86      0.87      1028\n",
      "           8       0.86      0.82      0.84       974\n",
      "           9       0.85      0.81      0.83      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 945    0    7    2    3   10   10    1    2    0]\n",
      " [   0 1101    2    3    3    2    4    3   17    0]\n",
      " [  13   33  874   24   21    3   15   28   18    3]\n",
      " [   7   10   21  863    2   53    3   19   22   10]\n",
      " [   2   14    7    1  901    1   12    3    3   38]\n",
      " [  14   10   10   52   25  696   28   12   37    8]\n",
      " [  16    3   15    1   11    5  903    0    4    0]\n",
      " [   6   23   19    7   16    2    2  886    1   66]\n",
      " [  11   14   11   39   21   31   10   17  799   21]\n",
      " [   8   21   11   10   85    7    1   30   22  814]]\n",
      "--------------------------------\n",
      "val predicted: (59525,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59525, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (475, 784) (475,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [42 52 47 60 55 38 52 46 60 48] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 20.225 s \n",
      "\n",
      "Accuracy rate for 87.830000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       980\n",
      "           1       0.90      0.97      0.93      1135\n",
      "           2       0.90      0.85      0.88      1032\n",
      "           3       0.86      0.84      0.85      1010\n",
      "           4       0.82      0.92      0.87       982\n",
      "           5       0.86      0.77      0.81       892\n",
      "           6       0.91      0.94      0.92       958\n",
      "           7       0.89      0.87      0.88      1028\n",
      "           8       0.85      0.82      0.84       974\n",
      "           9       0.86      0.81      0.83      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 950    0    3    2    4    7   11    1    2    0]\n",
      " [   0 1098    3    5    2    2    3    3   19    0]\n",
      " [  10   26  882   24   20    4   15   31   16    4]\n",
      " [   8    6   24  852    5   52    3   22   29    9]\n",
      " [   2   14    8    1  901    1   13    3    4   35]\n",
      " [  15    9    9   53   26  688   29    9   43   11]\n",
      " [  16    3   15    1   14    6  898    0    5    0]\n",
      " [   5   20   18    4   18    2    2  899    1   59]\n",
      " [  10   17   15   35   21   28    9   18  801   20]\n",
      " [  11   22    5    8   89    7    1   29   23  814]]\n",
      "--------------------------------\n",
      "final active learning accuracies [55.489999999999995, 64.21, 71.63000000000001, 74.95, 76.49000000000001, 80.08999999999999, 82.11, 82.25, 82.65, 83.3, 84.02, 85.05, 85.15, 85.67, 86.18, 86.83999999999999, 87.41, 87.63, 87.82, 87.83]\n",
      "saved Active-learning-experiment-4.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'README.md', 'Active-learning-experiment-1.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', '.ipynb_checkpoints', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 5, using model = SvmModel, selection_function = RandomSelection, k = 10, iteration = 0.\n",
      "\n",
      "initial random chosen samples (10,)\n",
      "initial train set: (10, 784) (10,) unique(labels): [2 0 3 1 2 0 1 0 1] [0 2 3 4 6 8]\n",
      "val set: (59990, 784) (59990,) (10,)\n",
      "\n",
      "Train set: (10, 784) y: (10,)\n",
      "Val   set: (59990, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.584 s \n",
      "\n",
      "Accuracy rate for 30.120000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71       980\n",
      "           1       0.00      0.00      0.00      1135\n",
      "           2       0.26      0.91      0.41      1032\n",
      "           3       0.39      0.05      0.08      1010\n",
      "           4       0.18      0.86      0.30       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.81      0.17      0.29       958\n",
      "           7       0.00      0.00      0.00      1028\n",
      "           8       0.60      0.34      0.43       974\n",
      "           9       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.30     10000\n",
      "   macro avg       0.30      0.30      0.22     10000\n",
      "weighted avg       0.29      0.30      0.22     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[686   0 214   1  48   0  18   0  13   0]\n",
      " [  0   0 301   0 831   0   0   0   3   0]\n",
      " [ 16   0 938   2  65   0   0   0  11   0]\n",
      " [  4   0 666  47 203   0   0   0  90   0]\n",
      " [ 16   0  96   8 848   0  12   0   2   0]\n",
      " [129   0 227  21 426   0   4   0  85   0]\n",
      " [ 31   0 685   0  70   0 166   0   6   0]\n",
      " [  7   0  69   4 944   0   1   0   3   0]\n",
      " [ 40   0 324   4 279   0   0   0 327   0]\n",
      " [ 18   0  35  35 915   0   3   0   3   0]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59990,) ['2' '0' '4' ... '8' '4' '8']\n",
      "probabilities: (59990, 6) \n",
      " [1 0 1 ... 3 0 1]\n",
      "trainset before (10, 784) (10,)\n",
      "trainset after (20, 784) (20,)\n",
      "updated train set: (20, 784) (20,) unique(labels): [3 1 5 2 3 1 1 2 1 1] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59980, 784) (59980,)\n",
      "\n",
      "Train set: (20, 784) y: (20,)\n",
      "Val   set: (59980, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 1.116 s \n",
      "\n",
      "Accuracy rate for 41.540000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.78       980\n",
      "           1       0.84      0.41      0.55      1135\n",
      "           2       0.34      0.86      0.49      1032\n",
      "           3       0.62      0.32      0.42      1010\n",
      "           4       0.29      0.70      0.41       982\n",
      "           5       0.25      0.07      0.10       892\n",
      "           6       0.90      0.17      0.28       958\n",
      "           7       0.22      0.47      0.30      1028\n",
      "           8       0.86      0.24      0.38       974\n",
      "           9       0.53      0.13      0.21      1009\n",
      "\n",
      "    accuracy                           0.42     10000\n",
      "   macro avg       0.57      0.41      0.39     10000\n",
      "weighted avg       0.57      0.42      0.40     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[715   1 105  11  18   3   6 120   1   0]\n",
      " [  0 469 108   0  27   0   0 531   0   0]\n",
      " [  6  18 887   9  42   1   1  65   3   0]\n",
      " [  5   0 437 319  82  11   0 141  14   1]\n",
      " [  0   9  32  28 692  32  10 177   0   2]\n",
      " [ 40   5 185  54 258  59   1 268  19   3]\n",
      " [ 40   6 450   3 220   0 162  77   0   0]\n",
      " [  2  25  33  11 342  19   0 481   0 115]\n",
      " [ 27  24 337  37 198   9   0 107 235   0]\n",
      " [ 10   2  14  46 524 102   0 175   1 135]]\n",
      "--------------------------------\n",
      "val predicted: (59980,) ['7' '0' '5' ... '4' '7' '7']\n",
      "probabilities: (59980, 10) \n",
      " [2 0 2 ... 4 2 4]\n",
      "trainset before (20, 784) (20,)\n",
      "trainset after (30, 784) (30,)\n",
      "updated train set: (30, 784) (30,) unique(labels): [4 1 5 6 4 2 3 2 2 1] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59970, 784) (59970,)\n",
      "\n",
      "Train set: (30, 784) y: (30,)\n",
      "Val   set: (59970, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 1.646 s \n",
      "\n",
      "Accuracy rate for 51.150000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.79      0.84       980\n",
      "           1       0.88      0.39      0.54      1135\n",
      "           2       0.69      0.69      0.69      1032\n",
      "           3       0.39      0.85      0.53      1010\n",
      "           4       0.37      0.71      0.49       982\n",
      "           5       0.53      0.11      0.19       892\n",
      "           6       0.64      0.76      0.69       958\n",
      "           7       0.28      0.40      0.33      1028\n",
      "           8       0.59      0.29      0.39       974\n",
      "           9       0.48      0.10      0.16      1009\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.58      0.51      0.49     10000\n",
      "weighted avg       0.58      0.51      0.49     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[773   1  23  86  12  18  47  16   4   0]\n",
      " [  0 444  20  59   6   0 117 484   5   0]\n",
      " [ 19  10 711 144  27   4  63  38  16   0]\n",
      " [  5   0  61 863  10   8  18  19  26   0]\n",
      " [  7   6   8  60 700  24  37 131   8   1]\n",
      " [ 21   4  16 320 103 101  55 156 114   2]\n",
      " [  9   1  78  13  90   9 727  24   7   0]\n",
      " [  7  22  18 172 283   0   1 413   8 104]\n",
      " [  3  12  85 329 122  11  72  55 285   0]\n",
      " [ 14   2   6 193 530  16   1 142   7  98]]\n",
      "--------------------------------\n",
      "val predicted: (59970,) ['8' '0' '3' ... '8' '7' '7']\n",
      "probabilities: (59970, 10) \n",
      " [3 0 3 ... 3 3 3]\n",
      "trainset before (30, 784) (30,)\n",
      "trainset after (40, 784) (40,)\n",
      "updated train set: (40, 784) (40,) unique(labels): [5 2 5 8 6 2 4 4 3 1] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59960, 784) (59960,)\n",
      "\n",
      "Train set: (40, 784) y: (40,)\n",
      "Val   set: (59960, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.129 s \n",
      "\n",
      "Accuracy rate for 59.500000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84       980\n",
      "           1       0.84      0.83      0.83      1135\n",
      "           2       0.77      0.66      0.71      1032\n",
      "           3       0.40      0.92      0.55      1010\n",
      "           4       0.42      0.77      0.55       982\n",
      "           5       0.74      0.08      0.14       892\n",
      "           6       0.68      0.73      0.71       958\n",
      "           7       0.50      0.67      0.57      1028\n",
      "           8       0.83      0.37      0.51       974\n",
      "           9       0.68      0.06      0.12      1009\n",
      "\n",
      "    accuracy                           0.59     10000\n",
      "   macro avg       0.68      0.59      0.55     10000\n",
      "weighted avg       0.68      0.59      0.56     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[763   1  12  92  12   4  65  28   3   0]\n",
      " [  0 938   7 140   1   0  14  35   0   0]\n",
      " [ 18  41 679 158  45   1  46  32  12   0]\n",
      " [  4   4  24 933   2   2  17  13  11   0]\n",
      " [  3   8   1  39 758   2  38 131   2   0]\n",
      " [ 21  30  17 395  59  71  96 169  34   0]\n",
      " [  5   4  53   7 170   3 698  18   0   0]\n",
      " [  3  42  15 154  89   0   1 687   7  30]\n",
      " [ 11  42  72 303  98   6  46  37 359   0]\n",
      " [ 10   8   5 134 550   7   0 229   2  64]]\n",
      "--------------------------------\n",
      "val predicted: (59960,) ['3' '0' '3' ... '8' '6' '7']\n",
      "probabilities: (59960, 10) \n",
      " [3 0 3 ... 3 6 3]\n",
      "trainset before (40, 784) (40,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [8 3 5 8 8 2 6 4 5 1] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.555 s \n",
      "\n",
      "Accuracy rate for 64.650000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       980\n",
      "           1       0.81      0.97      0.88      1135\n",
      "           2       0.87      0.64      0.73      1032\n",
      "           3       0.49      0.89      0.63      1010\n",
      "           4       0.42      0.91      0.57       982\n",
      "           5       0.82      0.07      0.13       892\n",
      "           6       0.75      0.78      0.76       958\n",
      "           7       0.67      0.64      0.66      1028\n",
      "           8       0.73      0.51      0.60       974\n",
      "           9       0.64      0.05      0.10      1009\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.70      0.64      0.59     10000\n",
      "weighted avg       0.70      0.65      0.60     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 889    1    0   24    8    1   39   16    2    0]\n",
      " [   0 1099    8    1    0    0    9    0   18    0]\n",
      " [  32   51  657  124   72    1   51   16   28    0]\n",
      " [  20   14   24  899    3    2   17   11   20    0]\n",
      " [   0   12    2   16  898    1   25   27    1    0]\n",
      " [  59   56    9  330  111   62   77  114   74    0]\n",
      " [  19   11   17    6  138    3  749   14    1    0]\n",
      " [   9   51    6  146  102    0    2  663   18   31]\n",
      " [  27   46   30  210  122    3   33    9  494    0]\n",
      " [  18   11    3   76  700    3    0  125   18   55]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59950,) ['8' '0' '4' ... '8' '6' '4']\n",
      "probabilities: (59950, 10) \n",
      " [3 0 4 ... 8 6 4]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (60, 784) (60,)\n",
      "updated train set: (60, 784) (60,) unique(labels): [ 9  6  6 12  8  2  6  5  5  1] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59940, 784) (59940,)\n",
      "\n",
      "Train set: (60, 784) y: (60,)\n",
      "Val   set: (59940, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.092 s \n",
      "\n",
      "Accuracy rate for 65.020000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       980\n",
      "           1       0.80      0.97      0.87      1135\n",
      "           2       0.84      0.67      0.75      1032\n",
      "           3       0.46      0.92      0.61      1010\n",
      "           4       0.43      0.91      0.58       982\n",
      "           5       0.77      0.06      0.10       892\n",
      "           6       0.82      0.77      0.80       958\n",
      "           7       0.67      0.69      0.68      1028\n",
      "           8       0.77      0.48      0.59       974\n",
      "           9       0.75      0.05      0.09      1009\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.72      0.64      0.60     10000\n",
      "weighted avg       0.72      0.65      0.60     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 886    1    1   46    6    1   22   15    2    0]\n",
      " [   0 1098    2    9    0    0    6    0   20    0]\n",
      " [  32   40  692  161   51    1   17   16   22    0]\n",
      " [   4   15   19  925    4    1    8    8   26    0]\n",
      " [   1   13    1   20  890    1   23   31    2    0]\n",
      " [  39   62   19  416  103   50   52  118   33    0]\n",
      " [  24    6   39    7  130    3  735   13    1    0]\n",
      " [   5   67   14  114   90    0    1  706   15   16]\n",
      " [  24   61   29  230  115    3   27   14  471    0]\n",
      " [  17   13    4   75  696    5    0  132   18   49]]\n",
      "--------------------------------\n",
      "val predicted: (59940,) ['8' '0' '4' ... '8' '6' '4']\n",
      "probabilities: (59940, 10) \n",
      " [3 0 4 ... 3 6 4]\n",
      "trainset before (60, 784) (60,)\n",
      "trainset after (70, 784) (70,)\n",
      "updated train set: (70, 784) (70,) unique(labels): [10  6  7 13  8  3  7  8  6  2] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59930, 784) (59930,)\n",
      "\n",
      "Train set: (70, 784) y: (70,)\n",
      "Val   set: (59930, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.578 s \n",
      "\n",
      "Accuracy rate for 66.700000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       980\n",
      "           1       0.81      0.95      0.88      1135\n",
      "           2       0.84      0.68      0.75      1032\n",
      "           3       0.47      0.91      0.62      1010\n",
      "           4       0.46      0.90      0.61       982\n",
      "           5       0.71      0.17      0.28       892\n",
      "           6       0.84      0.75      0.79       958\n",
      "           7       0.68      0.75      0.71      1028\n",
      "           8       0.76      0.49      0.60       974\n",
      "           9       0.72      0.08      0.14      1009\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.72      0.66      0.63     10000\n",
      "weighted avg       0.72      0.67      0.63     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 880    1    3   25    6   14   33   16    2    0]\n",
      " [   0 1082    3   28    0    0    5    0   17    0]\n",
      " [  24   36  699  178   41    2   10   15   27    0]\n",
      " [   3   13   29  923    1    2    6   10   22    1]\n",
      " [   0   12    0   26  884    2   24   27    3    4]\n",
      " [  30   56   19  368   75  154   46  117   27    0]\n",
      " [  22    7   27   13  148   12  719    9    1    0]\n",
      " [   3   55   14   78   50    0    1  771   31   25]\n",
      " [  26   57   38  241   87   21   15   11  477    1]\n",
      " [  16   16    5   82  623    9    0  156   21   81]]\n",
      "--------------------------------\n",
      "val predicted: (59930,) ['3' '0' '4' ... '3' '6' '4']\n",
      "probabilities: (59930, 10) \n",
      " [3 0 4 ... 3 6 4]\n",
      "trainset before (70, 784) (70,)\n",
      "trainset after (80, 784) (80,)\n",
      "updated train set: (80, 784) (80,) unique(labels): [10  8  8 14  9  4  8  9  7  3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59920, 784) (59920,)\n",
      "\n",
      "Train set: (80, 784) y: (80,)\n",
      "Val   set: (59920, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.048 s \n",
      "\n",
      "Accuracy rate for 68.810000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       980\n",
      "           1       0.82      0.96      0.88      1135\n",
      "           2       0.81      0.76      0.78      1032\n",
      "           3       0.51      0.91      0.65      1010\n",
      "           4       0.51      0.91      0.66       982\n",
      "           5       0.75      0.28      0.41       892\n",
      "           6       0.86      0.74      0.80       958\n",
      "           7       0.66      0.59      0.62      1028\n",
      "           8       0.80      0.49      0.61       974\n",
      "           9       0.56      0.29      0.38      1009\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.72      0.68      0.67     10000\n",
      "weighted avg       0.72      0.69      0.67     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 867    0    3   26    6   22   34   20    2    0]\n",
      " [   0 1084    2   26    0    0    5    0   18    0]\n",
      " [  20   38  783  115   29    2   10   13   22    0]\n",
      " [   5   13   36  922    2    2    5    7   17    1]\n",
      " [   0   10    5   22  889    3   23   22    4    4]\n",
      " [  18   60    8  334   65  251   27  109   17    3]\n",
      " [  21    5   28   10  151   22  712    8    1    0]\n",
      " [   3   48   33   65   43    0    0  602   24  210]\n",
      " [  26   48   56  230   77   21   13   11  482   10]\n",
      " [  15   13   12   73  465   10    0  116   16  289]]\n",
      "--------------------------------\n",
      "val predicted: (59920,) ['3' '0' '4' ... '3' '6' '4']\n",
      "probabilities: (59920, 10) \n",
      " [3 0 4 ... 3 6 2]\n",
      "trainset before (80, 784) (80,)\n",
      "trainset after (90, 784) (90,)\n",
      "updated train set: (90, 784) (90,) unique(labels): [10  8 10 14 13  4  9  9  8  5] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59910, 784) (59910,)\n",
      "\n",
      "Train set: (90, 784) y: (90,)\n",
      "Val   set: (59910, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.471 s \n",
      "\n",
      "Accuracy rate for 70.280000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       980\n",
      "           1       0.85      0.95      0.89      1135\n",
      "           2       0.81      0.78      0.79      1032\n",
      "           3       0.53      0.90      0.67      1010\n",
      "           4       0.52      0.93      0.67       982\n",
      "           5       0.78      0.27      0.40       892\n",
      "           6       0.85      0.77      0.81       958\n",
      "           7       0.72      0.55      0.62      1028\n",
      "           8       0.78      0.53      0.63       974\n",
      "           9       0.58      0.42      0.48      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.73      0.70      0.69     10000\n",
      "weighted avg       0.73      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 848    0   17   22    9   21   40   19    1    3]\n",
      " [   0 1078    2   24    6    0    5    1   19    0]\n",
      " [  14   38  806   76   34    2   16   10   24   12]\n",
      " [   4    8   45  909    5    2    6   10   20    1]\n",
      " [   0   11    4    6  910    2   28    6    1   14]\n",
      " [  16   39   10  307  130  240   24   84   31   11]\n",
      " [  15    5   45    6  122   14  742    6    1    2]\n",
      " [   3   43   21   72   50    0    0  563   34  242]\n",
      " [  18   42   46  223   77   18   14    7  513   16]\n",
      " [  14   10    4   68  397    9    0   71   17  419]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59910,) ['3' '0' '4' ... '8' '6' '4']\n",
      "probabilities: (59910, 10) \n",
      " [3 0 4 ... 8 6 4]\n",
      "trainset before (90, 784) (90,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [10  9 10 15 14  5 10 10 11  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.013 s \n",
      "\n",
      "Accuracy rate for 73.480000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       980\n",
      "           1       0.82      0.95      0.88      1135\n",
      "           2       0.82      0.77      0.79      1032\n",
      "           3       0.61      0.87      0.72      1010\n",
      "           4       0.56      0.92      0.70       982\n",
      "           5       0.83      0.46      0.59       892\n",
      "           6       0.87      0.81      0.84       958\n",
      "           7       0.70      0.61      0.65      1028\n",
      "           8       0.79      0.63      0.70       974\n",
      "           9       0.61      0.42      0.50      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.75      0.73      0.73     10000\n",
      "weighted avg       0.75      0.73      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 852    2   16   23   10   23   35   16    3    0]\n",
      " [   0 1082    2   14    0    0    5    2   30    0]\n",
      " [  15   56  790   52   27    7   16   17   41   11]\n",
      " [   3   15   45  881    5   17    6   12   25    1]\n",
      " [   0    7    4    5  900    1   28   21    1   15]\n",
      " [  10   50    8  200  112  409   17   62   19    5]\n",
      " [  15    6   42    7   88   11  774   11    4    0]\n",
      " [   2   59   19   52   29    1    1  631   19  215]\n",
      " [  14   40   26  149   73   20   12   14  610   16]\n",
      " [  14    9    6   61  360    4    0  120   16  419]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '4' ... '3' '6' '4']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 4 ... 3 6 8]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (110, 784) (110,)\n",
      "updated train set: (110, 784) (110,) unique(labels): [13 13 10 16 14  6 10 11 11  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59890, 784) (59890,)\n",
      "\n",
      "Train set: (110, 784) y: (110,)\n",
      "Val   set: (59890, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.665 s \n",
      "\n",
      "Accuracy rate for 73.830000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       980\n",
      "           1       0.82      0.95      0.88      1135\n",
      "           2       0.85      0.74      0.79      1032\n",
      "           3       0.63      0.89      0.74      1010\n",
      "           4       0.57      0.91      0.70       982\n",
      "           5       0.83      0.45      0.58       892\n",
      "           6       0.89      0.79      0.84       958\n",
      "           7       0.63      0.66      0.64      1028\n",
      "           8       0.80      0.63      0.70       974\n",
      "           9       0.64      0.40      0.49      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.76      0.73      0.73     10000\n",
      "weighted avg       0.76      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 896    2    5   16    1   14   20   24    2    0]\n",
      " [   0 1083    3   16    0    0    5    1   27    0]\n",
      " [  21   49  761   52   21    6   17   50   44   11]\n",
      " [   1   11   42  896    5   11    4   14   26    0]\n",
      " [   1    9    4    5  889    0   23   37    1   13]\n",
      " [  19   53    6  206  104  399   16   71   16    2]\n",
      " [  19    6   31   10   86    8  760   34    4    0]\n",
      " [   1   52   16   46   27    0    0  678   18  190]\n",
      " [  17   41   23  123   75   36   11   19  614   15]\n",
      " [  15    9    3   58  341    7    0  152   17  407]]\n",
      "--------------------------------\n",
      "val predicted: (59890,) ['3' '0' '4' ... '3' '6' '4']\n",
      "probabilities: (59890, 10) \n",
      " [3 0 4 ... 3 6 8]\n",
      "trainset before (110, 784) (110,)\n",
      "trainset after (120, 784) (120,)\n",
      "updated train set: (120, 784) (120,) unique(labels): [15 13 12 16 15  7 10 12 12  8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59880, 784) (59880,)\n",
      "\n",
      "Train set: (120, 784) y: (120,)\n",
      "Val   set: (59880, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.253 s \n",
      "\n",
      "Accuracy rate for 76.640000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       980\n",
      "           1       0.85      0.95      0.90      1135\n",
      "           2       0.82      0.82      0.82      1032\n",
      "           3       0.67      0.90      0.77      1010\n",
      "           4       0.60      0.90      0.72       982\n",
      "           5       0.89      0.53      0.67       892\n",
      "           6       0.90      0.77      0.83       958\n",
      "           7       0.72      0.69      0.70      1028\n",
      "           8       0.81      0.63      0.71       974\n",
      "           9       0.65      0.48      0.55      1009\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.78      0.76      0.76     10000\n",
      "weighted avg       0.78      0.77      0.76     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 929    1    1   16    1    3   20    2    3    4]\n",
      " [   0 1082    2   15    0    0    5    2   29    0]\n",
      " [  22   35  848   21   17    4    5   31   40    9]\n",
      " [   2   10   27  910    4   10    2   17   27    1]\n",
      " [   3   10    7    6  882    0   21   18    1   34]\n",
      " [  15   37   10  166   77  476   15   50   16   30]\n",
      " [  21    3   92    7   86    5  733    5    4    2]\n",
      " [   3   54   15   40   25    2    0  707   11  171]\n",
      " [  19   37   28  121   79   30    9   22  616   13]\n",
      " [  15    7    2   50  311    5    0  126   12  481]]\n",
      "--------------------------------\n",
      "val predicted: (59880,) ['3' '0' '4' ... '3' '6' '8']\n",
      "probabilities: (59880, 10) \n",
      " [3 0 4 ... 3 6 8]\n",
      "trainset before (120, 784) (120,)\n",
      "trainset after (130, 784) (130,)\n",
      "updated train set: (130, 784) (130,) unique(labels): [15 15 13 17 16  8 11 13 12 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59870, 784) (59870,)\n",
      "\n",
      "Train set: (130, 784) y: (130,)\n",
      "Val   set: (59870, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.629 s \n",
      "\n",
      "Accuracy rate for 76.830000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       980\n",
      "           1       0.87      0.95      0.91      1135\n",
      "           2       0.82      0.81      0.82      1032\n",
      "           3       0.66      0.89      0.76      1010\n",
      "           4       0.63      0.92      0.75       982\n",
      "           5       0.75      0.50      0.60       892\n",
      "           6       0.92      0.77      0.84       958\n",
      "           7       0.75      0.70      0.72      1028\n",
      "           8       0.81      0.62      0.71       974\n",
      "           9       0.63      0.52      0.57      1009\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.78      0.76      0.76     10000\n",
      "weighted avg       0.78      0.77      0.76     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 922    1    5   17    0    5   19    4    2    5]\n",
      " [   0 1083    2   16    0    4    5    0   24    1]\n",
      " [  21   32  839   21   25   14    3   27   43    7]\n",
      " [   2   10   24  902    8   17    4   14   27    2]\n",
      " [   4    5    5    2  900    3    9    7    1   46]\n",
      " [  13   19   12  192   75  446   15   48   19   53]\n",
      " [  19    5   91    7   69   23  735    3    3    3]\n",
      " [   3   44   16   37   29    2    0  722    8  167]\n",
      " [  12   37   21  117   53   77   10   20  608   19]\n",
      " [  14    6    4   47  274    6    0  119   13  526]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59870,) ['3' '0' '4' ... '9' '6' '5']\n",
      "probabilities: (59870, 10) \n",
      " [3 0 4 ... 9 6 8]\n",
      "trainset before (130, 784) (130,)\n",
      "trainset after (140, 784) (140,)\n",
      "updated train set: (140, 784) (140,) unique(labels): [16 15 14 18 16  8 13 15 13 12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59860, 784) (59860,)\n",
      "\n",
      "Train set: (140, 784) y: (140,)\n",
      "Val   set: (59860, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.980 s \n",
      "\n",
      "Accuracy rate for 77.680000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       980\n",
      "           1       0.88      0.95      0.91      1135\n",
      "           2       0.86      0.81      0.83      1032\n",
      "           3       0.67      0.89      0.76      1010\n",
      "           4       0.65      0.91      0.76       982\n",
      "           5       0.76      0.49      0.60       892\n",
      "           6       0.92      0.88      0.90       958\n",
      "           7       0.75      0.69      0.72      1028\n",
      "           8       0.80      0.64      0.71       974\n",
      "           9       0.61      0.52      0.56      1009\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.78      0.77      0.77     10000\n",
      "weighted avg       0.78      0.78      0.77     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 930    1    5   15    0    4   16    3    2    4]\n",
      " [   0 1081    2   17    0    3    6    0   25    1]\n",
      " [  21   32  835   21   25   13   14   24   39    8]\n",
      " [   2    8   22  901    8   18    4   12   29    6]\n",
      " [   2    5   10    1  891    7   10    6    1   49]\n",
      " [  14   17    8  195   71  436   18   48   33   52]\n",
      " [  10    5   44    6   27   13  846    2    4    1]\n",
      " [   3   43   16   37   26    1    0  706    9  187]\n",
      " [  18   37   22  105   51   71    7   24  620   19]\n",
      " [  11    6    7   49  272    6    0  121   15  522]]\n",
      "--------------------------------\n",
      "val predicted: (59860,) ['3' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59860, 10) \n",
      " [3 0 4 ... 9 6 8]\n",
      "trainset before (140, 784) (140,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [17 18 16 20 18  8 13 15 13 12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 7.280 s \n",
      "\n",
      "Accuracy rate for 77.380000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       980\n",
      "           1       0.87      0.95      0.91      1135\n",
      "           2       0.83      0.82      0.83      1032\n",
      "           3       0.66      0.89      0.76      1010\n",
      "           4       0.65      0.91      0.76       982\n",
      "           5       0.79      0.45      0.57       892\n",
      "           6       0.92      0.88      0.90       958\n",
      "           7       0.75      0.68      0.72      1028\n",
      "           8       0.80      0.63      0.71       974\n",
      "           9       0.61      0.52      0.56      1009\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.78      0.77      0.76     10000\n",
      "weighted avg       0.78      0.77      0.77     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 925    1   12   15    0    4   14    3    2    4]\n",
      " [   0 1082    2   18    0    2    6    0   24    1]\n",
      " [  13   35  851   18   26   10   15   20   35    9]\n",
      " [   2   14   25  901    6   13    4   11   28    6]\n",
      " [   1    3   10    1  895    4   11    6    1   50]\n",
      " [  15   22    9  216   73  403   19   48   34   53]\n",
      " [  11    6   51    5   28    9  841    2    4    1]\n",
      " [   3   41   28   37   26    0    0  701    8  184]\n",
      " [  20   39   21  107   57   62    8   23  617   20]\n",
      " [  10    7   17   48  269    5    0  117   14  522]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['3' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59850, 10) \n",
      " [3 0 4 ... 9 6 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (160, 784) (160,)\n",
      "updated train set: (160, 784) (160,) unique(labels): [19 20 17 22 18  8 14 15 14 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59840, 784) (59840,)\n",
      "\n",
      "Train set: (160, 784) y: (160,)\n",
      "Val   set: (59840, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 7.785 s \n",
      "\n",
      "Accuracy rate for 77.770000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       980\n",
      "           1       0.87      0.97      0.92      1135\n",
      "           2       0.83      0.84      0.83      1032\n",
      "           3       0.66      0.89      0.76      1010\n",
      "           4       0.65      0.89      0.75       982\n",
      "           5       0.79      0.46      0.58       892\n",
      "           6       0.93      0.88      0.90       958\n",
      "           7       0.75      0.68      0.72      1028\n",
      "           8       0.82      0.63      0.71       974\n",
      "           9       0.61      0.54      0.57      1009\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.78      0.77      0.77     10000\n",
      "weighted avg       0.78      0.78      0.77     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 924    1   13   14    0    4   15    3    2    4]\n",
      " [   0 1103    2    9    0    1    4    0   15    1]\n",
      " [  13   24  863   22   23   10   11   20   36   10]\n",
      " [   2   19   23  901    5   16    4   11   25    4]\n",
      " [   1    7   10    1  872    3   10    6    1   71]\n",
      " [  15   19   11  217   76  409   14   50   33   48]\n",
      " [  11    5   50    7   25    9  846    1    4    0]\n",
      " [   3   41   28   36   26    1    1  703    7  182]\n",
      " [  20   40   21  106   59   58    9   23  616   22]\n",
      " [  12    7   16   46  253    5    0  117   13  540]]\n",
      "--------------------------------\n",
      "val predicted: (59840,) ['3' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59840, 10) \n",
      " [3 0 4 ... 3 6 8]\n",
      "trainset before (160, 784) (160,)\n",
      "trainset after (170, 784) (170,)\n",
      "updated train set: (170, 784) (170,) unique(labels): [20 20 19 24 18 10 16 15 14 14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59830, 784) (59830,)\n",
      "\n",
      "Train set: (170, 784) y: (170,)\n",
      "Val   set: (59830, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 8.232 s \n",
      "\n",
      "Accuracy rate for 79.170000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       980\n",
      "           1       0.87      0.97      0.92      1135\n",
      "           2       0.80      0.77      0.78      1032\n",
      "           3       0.69      0.91      0.79      1010\n",
      "           4       0.72      0.89      0.79       982\n",
      "           5       0.75      0.51      0.61       892\n",
      "           6       0.92      0.90      0.91       958\n",
      "           7       0.80      0.68      0.73      1028\n",
      "           8       0.82      0.61      0.70       974\n",
      "           9       0.65      0.69      0.67      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.78     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 923    1   14   10    0    7   18    2    1    4]\n",
      " [   0 1100    3   12    0    3    3    1   13    0]\n",
      " [  17   39  792   39   30   21   16   16   50   12]\n",
      " [   0    6   26  922    8   16    2    9   17    4]\n",
      " [   1    7   11    1  871    2   11    5    1   72]\n",
      " [  13   19   22  182   58  458   13   41   21   65]\n",
      " [  10    5   36    5   23   11  866    1    1    0]\n",
      " [   2   37   29   32   28    2    1  699   12  186]\n",
      " [  15   39   45   93   48   90    7   17  593   27]\n",
      " [  10    8   10   36  149    4    0   86   13  693]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59830,) ['3' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59830, 10) \n",
      " [3 0 4 ... 3 6 8]\n",
      "trainset before (170, 784) (170,)\n",
      "trainset after (180, 784) (180,)\n",
      "updated train set: (180, 784) (180,) unique(labels): [21 23 22 25 19 10 16 15 14 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59820, 784) (59820,)\n",
      "\n",
      "Train set: (180, 784) y: (180,)\n",
      "Val   set: (59820, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 8.620 s \n",
      "\n",
      "Accuracy rate for 79.590000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       980\n",
      "           1       0.87      0.98      0.92      1135\n",
      "           2       0.80      0.78      0.79      1032\n",
      "           3       0.70      0.91      0.79      1010\n",
      "           4       0.72      0.89      0.80       982\n",
      "           5       0.75      0.51      0.60       892\n",
      "           6       0.93      0.91      0.92       958\n",
      "           7       0.81      0.69      0.74      1028\n",
      "           8       0.82      0.60      0.69       974\n",
      "           9       0.66      0.69      0.68      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.80      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 925    1   12    9    0    8   18    2    1    4]\n",
      " [   0 1114    3    3    0    2    3    1    9    0]\n",
      " [  17   38  807   37   24   20   13   16   50   10]\n",
      " [   0    5   29  920    7   15    2   10   19    3]\n",
      " [   1    7    9    1  876    2   11    4    1   70]\n",
      " [  12   22   22  184   58  452   13   41   22   66]\n",
      " [  10    6   31    5   23   11  870    1    1    0]\n",
      " [   2   35   30   34   27    2    1  709   12  176]\n",
      " [  14   40   49   93   46   90    9   16  586   31]\n",
      " [  10   11   12   33  148    3    0   79   13  700]]\n",
      "--------------------------------\n",
      "val predicted: (59820,) ['3' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59820, 10) \n",
      " [3 0 4 ... 9 6 9]\n",
      "trainset before (180, 784) (180,)\n",
      "trainset after (190, 784) (190,)\n",
      "updated train set: (190, 784) (190,) unique(labels): [21 25 22 26 21 12 16 15 17 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59810, 784) (59810,)\n",
      "\n",
      "Train set: (190, 784) y: (190,)\n",
      "Val   set: (59810, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 9.168 s \n",
      "\n",
      "Accuracy rate for 80.860000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       980\n",
      "           1       0.88      0.98      0.93      1135\n",
      "           2       0.84      0.77      0.80      1032\n",
      "           3       0.72      0.90      0.80      1010\n",
      "           4       0.74      0.90      0.81       982\n",
      "           5       0.75      0.59      0.66       892\n",
      "           6       0.92      0.90      0.91       958\n",
      "           7       0.84      0.69      0.76      1028\n",
      "           8       0.78      0.69      0.73       974\n",
      "           9       0.68      0.69      0.69      1009\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.81      0.80      0.80     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 922    1   12    8    0   10   19    2    2    4]\n",
      " [   0 1116    2    6    0    2    3    1    5    0]\n",
      " [  15   41  790   34   25   22   14   15   68    8]\n",
      " [   0    3   22  906    6   18    2    9   41    3]\n",
      " [   1    8    9    1  879    4   10    4    2   64]\n",
      " [  10   18   20  172   36  529   13   17   32   45]\n",
      " [  10    5   31    6   24   12  866    1    3    0]\n",
      " [   2   34   25   33   29    1    1  711   17  175]\n",
      " [  14   38   16   59   32  104   10   10  668   23]\n",
      " [  11   11    9   34  150    4    0   74   17  699]]\n",
      "--------------------------------\n",
      "val predicted: (59810,) ['3' '0' '4' ... '9' '6' '5']\n",
      "probabilities: (59810, 10) \n",
      " [3 0 4 ... 9 6 5]\n",
      "trainset before (190, 784) (190,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [22 28 23 27 23 13 16 15 18 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 9.350 s \n",
      "\n",
      "Accuracy rate for 80.890000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       980\n",
      "           1       0.87      0.98      0.92      1135\n",
      "           2       0.85      0.76      0.80      1032\n",
      "           3       0.72      0.90      0.80      1010\n",
      "           4       0.74      0.89      0.81       982\n",
      "           5       0.77      0.58      0.66       892\n",
      "           6       0.92      0.90      0.91       958\n",
      "           7       0.83      0.69      0.76      1028\n",
      "           8       0.78      0.70      0.74       974\n",
      "           9       0.69      0.69      0.69      1009\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.81      0.81      0.80     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 922    1   13    8    0   11   19    2    0    4]\n",
      " [   0 1116    2    7    0    1    3    1    5    0]\n",
      " [  15   42  786   31   25   19   14   16   74   10]\n",
      " [   0    4   24  908    6   16    2   10   39    1]\n",
      " [   1    9    7    1  875    4   10    5    2   68]\n",
      " [  13   17   22  173   38  520   13   19   33   44]\n",
      " [  10    5   33    5   24   11  866    1    3    0]\n",
      " [   2   35   21   33   28    1    1  712   20  175]\n",
      " [  11   39   14   62   36   91    9   10  686   16]\n",
      " [  10   12    7   34  145    3    0   78   22  698]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['3' '0' '4' ... '9' '6' '5']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 4 ... 9 6 5]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (210, 784) (210,)\n",
      "updated train set: (210, 784) (210,) unique(labels): [23 29 24 27 24 14 17 15 21 16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59790, 784) (59790,)\n",
      "\n",
      "Train set: (210, 784) y: (210,)\n",
      "Val   set: (59790, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 21\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 9.680 s \n",
      "\n",
      "Accuracy rate for 81.240000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       980\n",
      "           1       0.88      0.98      0.92      1135\n",
      "           2       0.85      0.77      0.81      1032\n",
      "           3       0.74      0.88      0.81      1010\n",
      "           4       0.74      0.90      0.81       982\n",
      "           5       0.79      0.61      0.69       892\n",
      "           6       0.92      0.91      0.92       958\n",
      "           7       0.84      0.68      0.75      1028\n",
      "           8       0.76      0.71      0.74       974\n",
      "           9       0.69      0.72      0.70      1009\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.81      0.81      0.81     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 919    1   14    8    0    8   22    2    2    4]\n",
      " [   0 1109    2    5    0    2    4    1   12    0]\n",
      " [  13   41  797   28   24   17   10   17   72   13]\n",
      " [   0    4   32  889    5   14    4    9   51    2]\n",
      " [   2    6   10    2  880    3    8    6    1   64]\n",
      " [  11   18   18  148   46  542   14   18   34   43]\n",
      " [   7    5   26    5   22   12  874    2    4    1]\n",
      " [   2   38   20   34   29    1    0  696   21  187]\n",
      " [  11   33   18   52   38   87   12   11  696   16]\n",
      " [   9   12    4   26  139    2    0   70   25  722]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59790,) ['3' '0' '4' ... '3' '6' '5']\n",
      "probabilities: (59790, 10) \n",
      " [3 0 4 ... 9 6 8]\n",
      "trainset before (210, 784) (210,)\n",
      "trainset after (220, 784) (220,)\n",
      "updated train set: (220, 784) (220,) unique(labels): [25 29 24 28 24 14 18 16 25 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59780, 784) (59780,)\n",
      "\n",
      "Train set: (220, 784) y: (220,)\n",
      "Val   set: (59780, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 22\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.015 s \n",
      "\n",
      "Accuracy rate for 81.480000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       980\n",
      "           1       0.88      0.98      0.92      1135\n",
      "           2       0.85      0.77      0.81      1032\n",
      "           3       0.74      0.88      0.81      1010\n",
      "           4       0.75      0.89      0.81       982\n",
      "           5       0.80      0.59      0.68       892\n",
      "           6       0.91      0.92      0.92       958\n",
      "           7       0.84      0.69      0.76      1028\n",
      "           8       0.75      0.73      0.74       974\n",
      "           9       0.70      0.73      0.71      1009\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.82      0.81      0.81     10000\n",
      "weighted avg       0.82      0.81      0.81     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 917    1   14    8    0    7   26    2    3    2]\n",
      " [   0 1108    2    4    0    2    4    1   14    0]\n",
      " [  14   41  796   27   24   17   14   16   73   10]\n",
      " [   0    5   30  889    6   15    3    9   51    2]\n",
      " [   1    7   10    2  876    3   12    5    1   65]\n",
      " [  12   16   17  149   46  530   15   18   46   43]\n",
      " [   7    5   22    5   17   11  884    2    5    0]\n",
      " [   2   38   17   34   29    0    0  708   22  178]\n",
      " [  12   31   20   54   39   75   11   12  708   12]\n",
      " [   9   12    4   25  134    2    0   66   25  732]]\n",
      "--------------------------------\n",
      "val predicted: (59780,) ['3' '0' '4' ... '8' '6' '5']\n",
      "probabilities: (59780, 10) \n",
      " [3 0 4 ... 8 6 5]\n",
      "trainset before (220, 784) (220,)\n",
      "trainset after (230, 784) (230,)\n",
      "updated train set: (230, 784) (230,) unique(labels): [27 29 25 29 25 15 18 17 26 19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59770, 784) (59770,)\n",
      "\n",
      "Train set: (230, 784) y: (230,)\n",
      "Val   set: (59770, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 23\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.378 s \n",
      "\n",
      "Accuracy rate for 82.230000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       980\n",
      "           1       0.88      0.98      0.92      1135\n",
      "           2       0.86      0.79      0.82      1032\n",
      "           3       0.74      0.89      0.81      1010\n",
      "           4       0.75      0.90      0.82       982\n",
      "           5       0.80      0.60      0.69       892\n",
      "           6       0.91      0.92      0.92       958\n",
      "           7       0.85      0.70      0.77      1028\n",
      "           8       0.77      0.73      0.75       974\n",
      "           9       0.73      0.74      0.73      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 919    1   12    8    0    7   24    2    3    4]\n",
      " [   0 1108    2    6    0    1    4    1   13    0]\n",
      " [  15   39  813   31   23   17   14   18   51   11]\n",
      " [   0    6   26  901    6   13    2   12   42    2]\n",
      " [   1    8    8    3  885    3   12    5    2   55]\n",
      " [  11   16   16  147   45  535   15   19   47   41]\n",
      " [   8    5   25    5   15   11  881    2    6    0]\n",
      " [   2   40   22   38   28    0    0  724   19  155]\n",
      " [  12   30   22   48   43   76   11    9  710   13]\n",
      " [   9   12    4   23  128    3    0   58   25  747]]\n",
      "--------------------------------\n",
      "val predicted: (59770,) ['3' '0' '4' ... '8' '6' '5']\n",
      "probabilities: (59770, 10) \n",
      " [3 0 4 ... 5 6 5]\n",
      "trainset before (230, 784) (230,)\n",
      "trainset after (240, 784) (240,)\n",
      "updated train set: (240, 784) (240,) unique(labels): [27 29 25 32 26 17 19 18 26 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59760, 784) (59760,)\n",
      "\n",
      "Train set: (240, 784) y: (240,)\n",
      "Val   set: (59760, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 24\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.762 s \n",
      "\n",
      "Accuracy rate for 82.800000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       980\n",
      "           1       0.87      0.98      0.92      1135\n",
      "           2       0.86      0.79      0.82      1032\n",
      "           3       0.73      0.91      0.81      1010\n",
      "           4       0.76      0.89      0.82       982\n",
      "           5       0.80      0.60      0.68       892\n",
      "           6       0.91      0.91      0.91       958\n",
      "           7       0.86      0.74      0.80      1028\n",
      "           8       0.81      0.72      0.76       974\n",
      "           9       0.76      0.77      0.76      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.82      0.82     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 920    1   11    4    0    9   28    2    3    2]\n",
      " [   0 1108    1    7    0    2    3    1   13    0]\n",
      " [  12   38  812   37   24   20   14   16   48   11]\n",
      " [   0    7   20  917    3   20    0    9   30    4]\n",
      " [   2    8    9    2  875    2   14    5    1   64]\n",
      " [  10   18   17  157   47  534   16   22   34   37]\n",
      " [  10    6   25    3   21   10  875    3    5    0]\n",
      " [   2   40   26   38   27    0    0  762   16  117]\n",
      " [   8   30   18   70   40   70   11    9  703   15]\n",
      " [  10   11    5   26  107    3    0   55   18  774]]\n",
      "--------------------------------\n",
      "val predicted: (59760,) ['3' '0' '4' ... '8' '6' '8']\n",
      "probabilities: (59760, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (240, 784) (240,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [27 31 25 32 30 17 20 19 27 22] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 25\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 11.198 s \n",
      "\n",
      "Accuracy rate for 82.960000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       980\n",
      "           1       0.86      0.98      0.92      1135\n",
      "           2       0.86      0.79      0.82      1032\n",
      "           3       0.73      0.90      0.81      1010\n",
      "           4       0.78      0.89      0.83       982\n",
      "           5       0.79      0.60      0.68       892\n",
      "           6       0.91      0.92      0.92       958\n",
      "           7       0.87      0.74      0.80      1028\n",
      "           8       0.81      0.73      0.77       974\n",
      "           9       0.76      0.77      0.77      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.82     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 918    1   12    3    0    9   28    2    5    2]\n",
      " [   0 1116    1    6    0    2    3    1    6    0]\n",
      " [  12   37  814   37   22   21   14   15   50   10]\n",
      " [   0   10   21  910    2   22    0    7   33    5]\n",
      " [   2    8   10    2  878    2   13    4    2   61]\n",
      " [  11   19   17  154   48  535   15   22   34   37]\n",
      " [   8    7   23    3   20   11  879    1    6    0]\n",
      " [   2   43   26   37   26    1    0  759   16  118]\n",
      " [   8   36   19   69   31   71    9   10  709   12]\n",
      " [   9   15    5   25  104    3    0   53   17  778]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59750,) ['3' '0' '4' ... '8' '6' '9']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (260, 784) (260,)\n",
      "updated train set: (260, 784) (260,) unique(labels): [28 33 27 32 34 17 21 19 27 22] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59740, 784) (59740,)\n",
      "\n",
      "Train set: (260, 784) y: (260,)\n",
      "Val   set: (59740, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 26\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 11.373 s \n",
      "\n",
      "Accuracy rate for 83.010000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       980\n",
      "           1       0.86      0.98      0.92      1135\n",
      "           2       0.85      0.79      0.82      1032\n",
      "           3       0.73      0.90      0.81      1010\n",
      "           4       0.78      0.90      0.83       982\n",
      "           5       0.79      0.60      0.68       892\n",
      "           6       0.92      0.92      0.92       958\n",
      "           7       0.87      0.74      0.80      1028\n",
      "           8       0.80      0.73      0.77       974\n",
      "           9       0.76      0.77      0.76      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 917    1   14    3    0    9   27    2    5    2]\n",
      " [   0 1115    1    6    0    2    3    1    7    0]\n",
      " [  11   39  817   37   20   17   10   15   56   10]\n",
      " [   0   10   19  913    2   22    0    7   32    5]\n",
      " [   1    8   12    2  881    2   13    4    2   57]\n",
      " [  11   19   18  154   46  536   15   22   35   36]\n",
      " [   8    7   24    3   18   12  879    1    6    0]\n",
      " [   2   43   31   35   27    1    0  757   14  118]\n",
      " [   6   35   23   68   29   71    9    9  714   10]\n",
      " [  10   15    6   25  108    3    0   53   17  772]]\n",
      "--------------------------------\n",
      "val predicted: (59740,) ['3' '0' '4' ... '8' '6' '9']\n",
      "probabilities: (59740, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (260, 784) (260,)\n",
      "trainset after (270, 784) (270,)\n",
      "updated train set: (270, 784) (270,) unique(labels): [28 34 28 34 36 18 21 21 28 22] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59730, 784) (59730,)\n",
      "\n",
      "Train set: (270, 784) y: (270,)\n",
      "Val   set: (59730, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 27\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 11.970 s \n",
      "\n",
      "Accuracy rate for 83.640000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       980\n",
      "           1       0.88      0.98      0.92      1135\n",
      "           2       0.84      0.80      0.82      1032\n",
      "           3       0.75      0.91      0.82      1010\n",
      "           4       0.77      0.91      0.83       982\n",
      "           5       0.83      0.64      0.72       892\n",
      "           6       0.92      0.91      0.91       958\n",
      "           7       0.87      0.75      0.81      1028\n",
      "           8       0.81      0.73      0.77       974\n",
      "           9       0.77      0.76      0.77      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.84      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 918    0   14    3    0    8   28    2    5    2]\n",
      " [   0 1113    2    7    0    1    3    2    7    0]\n",
      " [  15   29  830   36   20   10   10   15   61    6]\n",
      " [   1   11   18  919    3   14    0    9   30    5]\n",
      " [   1    8   12    2  890    2   11    3    2   51]\n",
      " [   9   18   23  120   51  569   16   22   29   35]\n",
      " [   7    6   30    3   21   10  871    4    6    0]\n",
      " [   1   30   27   36   32    1    0  776   10  115]\n",
      " [   9   43   23   67   29   66    9   10  708   10]\n",
      " [  10   14    5   26  111    4    0   53   16  770]]\n",
      "--------------------------------\n",
      "val predicted: (59730,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59730, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (270, 784) (270,)\n",
      "trainset after (280, 784) (280,)\n",
      "updated train set: (280, 784) (280,) unique(labels): [30 35 29 34 36 19 23 21 30 23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59720, 784) (59720,)\n",
      "\n",
      "Train set: (280, 784) y: (280,)\n",
      "Val   set: (59720, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 28\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.216 s \n",
      "\n",
      "Accuracy rate for 83.720000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       980\n",
      "           1       0.88      0.98      0.93      1135\n",
      "           2       0.84      0.81      0.83      1032\n",
      "           3       0.75      0.90      0.82      1010\n",
      "           4       0.79      0.90      0.84       982\n",
      "           5       0.82      0.67      0.74       892\n",
      "           6       0.92      0.91      0.92       958\n",
      "           7       0.87      0.75      0.81      1028\n",
      "           8       0.80      0.72      0.76       974\n",
      "           9       0.77      0.76      0.77      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 918    0   14    5    0   10   25    2    4    2]\n",
      " [   0 1112    1    7    0    3    1    1   10    0]\n",
      " [  14   30  837   36   14   10   15   14   54    8]\n",
      " [   1    7   19  905    3   18    0    9   43    5]\n",
      " [   1    8   12    2  884    4   10    3    2   56]\n",
      " [   9   15   19  121   36  598   16   18   35   25]\n",
      " [   7    6   28    0   19   15  874    5    4    0]\n",
      " [   1   29   28   31   29    4    0  773   11  122]\n",
      " [  10   37   30   74   28   63    8   11  701   12]\n",
      " [  11   16    7   25  108    7    1   49   15  770]]\n",
      "--------------------------------\n",
      "val predicted: (59720,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59720, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (280, 784) (280,)\n",
      "trainset after (290, 784) (290,)\n",
      "updated train set: (290, 784) (290,) unique(labels): [32 37 29 34 36 20 25 21 31 25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59710, 784) (59710,)\n",
      "\n",
      "Train set: (290, 784) y: (290,)\n",
      "Val   set: (59710, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 29\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.643 s \n",
      "\n",
      "Accuracy rate for 83.350000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       980\n",
      "           1       0.88      0.98      0.93      1135\n",
      "           2       0.84      0.81      0.82      1032\n",
      "           3       0.75      0.90      0.82      1010\n",
      "           4       0.79      0.90      0.84       982\n",
      "           5       0.81      0.66      0.73       892\n",
      "           6       0.92      0.91      0.91       958\n",
      "           7       0.88      0.73      0.80      1028\n",
      "           8       0.79      0.71      0.75       974\n",
      "           9       0.75      0.77      0.76      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 916    0   13    5    0    8   28    2    4    4]\n",
      " [   0 1113    2    7    0    2    1    1    9    0]\n",
      " [  15   34  834   36   12   11   13   14   57    6]\n",
      " [   1    7   19  906    3   18    0    8   43    5]\n",
      " [   1   10   12    1  882    4   10    3    2   57]\n",
      " [   8   10   18  131   30  590   18   16   35   36]\n",
      " [   7    6   29    0   18   17  872    5    4    0]\n",
      " [   1   32   33   31   31    4    0  752   12  132]\n",
      " [  10   37   29   72   27   70    9   10  696   14]\n",
      " [  10   16    7   24  112    7    1   44   14  774]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59710,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59710, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (290, 784) (290,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [34 37 29 37 37 20 27 21 33 25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 30\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 13.448 s \n",
      "\n",
      "Accuracy rate for 83.410000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       980\n",
      "           1       0.88      0.98      0.93      1135\n",
      "           2       0.85      0.81      0.83      1032\n",
      "           3       0.75      0.90      0.81      1010\n",
      "           4       0.79      0.90      0.84       982\n",
      "           5       0.82      0.65      0.72       892\n",
      "           6       0.92      0.91      0.91       958\n",
      "           7       0.88      0.73      0.80      1028\n",
      "           8       0.80      0.72      0.76       974\n",
      "           9       0.75      0.77      0.76      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 933    0    5    4    1    4   27    2    1    3]\n",
      " [   0 1111    2    7    0    3    2    1    9    0]\n",
      " [  19   37  834   28   14   12   11   15   56    6]\n",
      " [   2    7   15  907    3   19    1    9   42    5]\n",
      " [   4   10   13    3  880    3    8    3    2   56]\n",
      " [  14   11   13  134   29  579   18   16   42   36]\n",
      " [   9    5   32    2   19   12  869    6    4    0]\n",
      " [   0   33   29   34   31    5    0  755   10  131]\n",
      " [  11   38   28   69   27   66   11   10  700   14]\n",
      " [   5   15    9   28  114    4    2   45   14  773]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['3' '0' '4' ... '5' '6' '0']\n",
      "probabilities: (59700, 10) \n",
      " [3 0 4 ... 5 6 0]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (310, 784) (310,)\n",
      "updated train set: (310, 784) (310,) unique(labels): [35 38 29 38 37 20 29 23 33 28] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59690, 784) (59690,)\n",
      "\n",
      "Train set: (310, 784) y: (310,)\n",
      "Val   set: (59690, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 31\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 13.755 s \n",
      "\n",
      "Accuracy rate for 83.690000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       980\n",
      "           1       0.88      0.98      0.93      1135\n",
      "           2       0.86      0.81      0.83      1032\n",
      "           3       0.75      0.90      0.82      1010\n",
      "           4       0.79      0.90      0.84       982\n",
      "           5       0.82      0.64      0.72       892\n",
      "           6       0.92      0.91      0.91       958\n",
      "           7       0.87      0.77      0.82      1028\n",
      "           8       0.80      0.72      0.76       974\n",
      "           9       0.75      0.77      0.76      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.84      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 931    0    6    4    1    4   24    2    1    7]\n",
      " [   0 1110    2    7    0    3    2    2    9    0]\n",
      " [  18   39  831   29   14   11   12   13   56    9]\n",
      " [   2    7   15  907    3   19    1    8   42    6]\n",
      " [   4    9   10    3  879    4    7    4    1   61]\n",
      " [  15   10   13  129   27  570   19   18   42   49]\n",
      " [   6    5   32    1   20   11  871    8    4    0]\n",
      " [   1   25   26   35   31    5    0  794    8  103]\n",
      " [  11   41   26   66   26   62   11    9  699   23]\n",
      " [   3   11    6   29  112    2    2   56   11  777]]\n",
      "--------------------------------\n",
      "val predicted: (59690,) ['3' '0' '4' ... '5' '6' '0']\n",
      "probabilities: (59690, 10) \n",
      " [3 0 5 ... 5 6 9]\n",
      "trainset before (310, 784) (310,)\n",
      "trainset after (320, 784) (320,)\n",
      "updated train set: (320, 784) (320,) unique(labels): [35 39 32 39 37 22 29 24 33 30] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59680, 784) (59680,)\n",
      "\n",
      "Train set: (320, 784) y: (320,)\n",
      "Val   set: (59680, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 32\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 14.064 s \n",
      "\n",
      "Accuracy rate for 83.680000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       980\n",
      "           1       0.88      0.98      0.93      1135\n",
      "           2       0.86      0.81      0.83      1032\n",
      "           3       0.76      0.90      0.82      1010\n",
      "           4       0.79      0.89      0.84       982\n",
      "           5       0.83      0.66      0.74       892\n",
      "           6       0.92      0.90      0.91       958\n",
      "           7       0.87      0.75      0.81      1028\n",
      "           8       0.80      0.72      0.76       974\n",
      "           9       0.74      0.78      0.76      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 932    0    6    4    1    4   23    2    1    7]\n",
      " [   0 1109    2    6    0    3    2    2   11    0]\n",
      " [  18   38  832   29   13   10   13   14   56    9]\n",
      " [   2    8   14  905    3   19    1   10   43    5]\n",
      " [   3    9   10    2  873    4    6    5    3   67]\n",
      " [  16    9   11  127   23  590   18   17   37   44]\n",
      " [   8    5   33    1   22   12  866    7    4    0]\n",
      " [   1   26   30   33   28    4    0  774    7  125]\n",
      " [  10   41   27   65   29   62   11    9  698   22]\n",
      " [   3   11    7   23  113    2    0   51   10  789]]\n",
      "--------------------------------\n",
      "val predicted: (59680,) ['3' '0' '4' ... '5' '6' '0']\n",
      "probabilities: (59680, 10) \n",
      " [3 0 4 ... 5 6 5]\n",
      "trainset before (320, 784) (320,)\n",
      "trainset after (330, 784) (330,)\n",
      "updated train set: (330, 784) (330,) unique(labels): [36 40 33 39 37 24 29 24 36 32] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59670, 784) (59670,)\n",
      "\n",
      "Train set: (330, 784) y: (330,)\n",
      "Val   set: (59670, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 33\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 14.542 s \n",
      "\n",
      "Accuracy rate for 84.230000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       980\n",
      "           1       0.89      0.98      0.93      1135\n",
      "           2       0.87      0.81      0.84      1032\n",
      "           3       0.78      0.89      0.83      1010\n",
      "           4       0.79      0.88      0.83       982\n",
      "           5       0.84      0.68      0.75       892\n",
      "           6       0.93      0.90      0.91       958\n",
      "           7       0.87      0.76      0.81      1028\n",
      "           8       0.80      0.75      0.77       974\n",
      "           9       0.74      0.79      0.76      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 938    0    5    3    1    5   18    2    2    6]\n",
      " [   0 1109    1    6    0    4    2    2   11    0]\n",
      " [  17   32  838   29   14   13   10   13   54   12]\n",
      " [   2    8   15  902    2   22    1   10   43    5]\n",
      " [   3    9   11    2  868    3    9    5    2   70]\n",
      " [  17   10   14  108   23  604   17   17   46   36]\n",
      " [   6    5   30    2   25   12  865    7    5    1]\n",
      " [   1   24   27   31   28    3    0  777    8  129]\n",
      " [   8   39   16   57   29   53   11    9  728   24]\n",
      " [   5   11    4   21  111    3    1   48   11  794]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59670,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59670, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (330, 784) (330,)\n",
      "trainset after (340, 784) (340,)\n",
      "updated train set: (340, 784) (340,) unique(labels): [36 40 35 41 38 25 30 24 36 35] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59660, 784) (59660,)\n",
      "\n",
      "Train set: (340, 784) y: (340,)\n",
      "Val   set: (59660, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 34\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 14.946 s \n",
      "\n",
      "Accuracy rate for 84.260000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       980\n",
      "           1       0.90      0.98      0.93      1135\n",
      "           2       0.88      0.81      0.84      1032\n",
      "           3       0.77      0.90      0.83      1010\n",
      "           4       0.81      0.89      0.85       982\n",
      "           5       0.83      0.66      0.74       892\n",
      "           6       0.92      0.92      0.92       958\n",
      "           7       0.88      0.75      0.81      1028\n",
      "           8       0.80      0.74      0.77       974\n",
      "           9       0.72      0.80      0.76      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.85      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 938    0    5    4    1    5   16    2    2    7]\n",
      " [   0 1109    1    7    0    4    2    2   10    0]\n",
      " [  16   32  835   31    9   14   12   14   54   15]\n",
      " [   1    8   14  904    2   23    1    9   42    6]\n",
      " [   5    7   12    1  873    3    6    5    1   69]\n",
      " [  16   10   12  117   20  590   19   17   44   47]\n",
      " [   6    5   27    1   19    9  878    5    5    3]\n",
      " [   1   22   23   30   29    2    0  769    8  144]\n",
      " [   7   36   16   56   23   59   16   10  723   28]\n",
      " [   6   10    4   21  102    4    1   41   13  807]]\n",
      "--------------------------------\n",
      "val predicted: (59660,) ['3' '0' '4' ... '5' '6' '0']\n",
      "probabilities: (59660, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (340, 784) (340,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [37 43 36 41 39 25 33 24 36 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 35\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.297 s \n",
      "\n",
      "Accuracy rate for 84.480000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       980\n",
      "           1       0.89      0.98      0.93      1135\n",
      "           2       0.88      0.81      0.84      1032\n",
      "           3       0.77      0.89      0.83      1010\n",
      "           4       0.81      0.90      0.85       982\n",
      "           5       0.82      0.66      0.73       892\n",
      "           6       0.92      0.92      0.92       958\n",
      "           7       0.89      0.75      0.82      1028\n",
      "           8       0.80      0.74      0.77       974\n",
      "           9       0.73      0.81      0.77      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.85      0.84      0.84     10000\n",
      "weighted avg       0.85      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 939    0    6    4    1    5   15    2    2    6]\n",
      " [   0 1109    1    6    0    3    2    2   12    0]\n",
      " [  18   33  832   32   10   13   11   13   54   16]\n",
      " [   1    7   14  902    3   23    1    9   43    7]\n",
      " [   3    7   10    1  879    4    8    3    1   66]\n",
      " [  16    9   12  116   19  591   20   17   46   46]\n",
      " [   6    5   25    1   19   10  882    4    5    1]\n",
      " [   1   21   23   30   30    4    0  775    8  136]\n",
      " [   6   39   16   56   22   60   18    9  724   24]\n",
      " [   5   10    5   25   97    4    1   36   11  815]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59650, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (360, 784) (360,)\n",
      "updated train set: (360, 784) (360,) unique(labels): [38 44 36 42 39 26 35 25 39 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59640, 784) (59640,)\n",
      "\n",
      "Train set: (360, 784) y: (360,)\n",
      "Val   set: (59640, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 36\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.337 s \n",
      "\n",
      "Accuracy rate for 84.980000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       980\n",
      "           1       0.90      0.98      0.94      1135\n",
      "           2       0.90      0.80      0.85      1032\n",
      "           3       0.78      0.90      0.84      1010\n",
      "           4       0.81      0.89      0.85       982\n",
      "           5       0.83      0.70      0.76       892\n",
      "           6       0.92      0.92      0.92       958\n",
      "           7       0.88      0.77      0.82      1028\n",
      "           8       0.80      0.75      0.78       974\n",
      "           9       0.74      0.80      0.77      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 938    0    4    4    1    5   18    2    1    7]\n",
      " [   0 1111    1    6    0    3    2    2    9    1]\n",
      " [  17   35  825   29   10   15   12   18   54   17]\n",
      " [   1    2    8  911    3   18    1    8   53    5]\n",
      " [   4    7    9    1  877    6    8    3    4   63]\n",
      " [  17    9   11  113   17  628   18   18   29   32]\n",
      " [   7    6   27    1   19   13  877    2    4    2]\n",
      " [   1   18   18   29   32    3    0  792   14  121]\n",
      " [   7   34   13   50   24   59   14    9  734   30]\n",
      " [   5    8    4   25   99    4    1   44   14  805]]\n",
      "--------------------------------\n",
      "val predicted: (59640,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59640, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (360, 784) (360,)\n",
      "trainset after (370, 784) (370,)\n",
      "updated train set: (370, 784) (370,) unique(labels): [40 46 37 43 39 26 35 25 40 39] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59630, 784) (59630,)\n",
      "\n",
      "Train set: (370, 784) y: (370,)\n",
      "Val   set: (59630, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 37\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.972 s \n",
      "\n",
      "Accuracy rate for 85.380000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       980\n",
      "           1       0.91      0.98      0.94      1135\n",
      "           2       0.89      0.80      0.84      1032\n",
      "           3       0.78      0.90      0.84      1010\n",
      "           4       0.83      0.90      0.87       982\n",
      "           5       0.84      0.71      0.77       892\n",
      "           6       0.93      0.92      0.92       958\n",
      "           7       0.89      0.76      0.82      1028\n",
      "           8       0.80      0.76      0.78       974\n",
      "           9       0.75      0.83      0.79      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 943    0    5    4    1    3   15    2    1    6]\n",
      " [   0 1108    1    7    0    3    2    2   12    0]\n",
      " [  17   36  825   29    9   15   11   18   53   19]\n",
      " [   1    2   10  910    3   18    1    8   52    5]\n",
      " [   3    7    7    1  886    6    8    3    1   60]\n",
      " [  17    9   12  112   16  630   18   16   30   32]\n",
      " [   6    6   27    1   19   13  878    2    4    2]\n",
      " [   1   17   22   27   33    3    0  781   17  127]\n",
      " [   7   31   12   50   24   58   14    7  743   28]\n",
      " [   5    8    5   22   75    4    1   43   12  834]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59630,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59630, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (370, 784) (370,)\n",
      "trainset after (380, 784) (380,)\n",
      "updated train set: (380, 784) (380,) unique(labels): [40 46 40 43 41 27 36 26 42 39] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59620, 784) (59620,)\n",
      "\n",
      "Train set: (380, 784) y: (380,)\n",
      "Val   set: (59620, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 38\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 16.117 s \n",
      "\n",
      "Accuracy rate for 85.390000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       980\n",
      "           1       0.90      0.98      0.94      1135\n",
      "           2       0.86      0.80      0.83      1032\n",
      "           3       0.79      0.89      0.84      1010\n",
      "           4       0.83      0.90      0.87       982\n",
      "           5       0.85      0.72      0.78       892\n",
      "           6       0.93      0.91      0.92       958\n",
      "           7       0.90      0.76      0.82      1028\n",
      "           8       0.81      0.78      0.79       974\n",
      "           9       0.74      0.82      0.78      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 938    0   11    4    1    4   14    2    0    6]\n",
      " [   0 1108    1    5    0    3    2    2   13    1]\n",
      " [  17   41  830   18   13   13    8   13   61   18]\n",
      " [   1    4   15  901    4   18    1    6   54    6]\n",
      " [   2    7   10    1  884    6    7    2    2   61]\n",
      " [  15    9   13  111   17  638   19   16   23   31]\n",
      " [   4    6   34    1   22   10  872    3    4    2]\n",
      " [   1   17   26   30   18    3    0  782   14  137]\n",
      " [   8   31   13   46   22   51   15    6  755   27]\n",
      " [   6    9    7   20   80    5    0   41   10  831]]\n",
      "--------------------------------\n",
      "val predicted: (59620,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59620, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (380, 784) (380,)\n",
      "trainset after (390, 784) (390,)\n",
      "updated train set: (390, 784) (390,) unique(labels): [41 46 41 44 42 27 37 27 43 42] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59610, 784) (59610,)\n",
      "\n",
      "Train set: (390, 784) y: (390,)\n",
      "Val   set: (59610, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 39\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 16.457 s \n",
      "\n",
      "Accuracy rate for 85.630000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       980\n",
      "           1       0.91      0.98      0.94      1135\n",
      "           2       0.85      0.82      0.83      1032\n",
      "           3       0.78      0.88      0.83      1010\n",
      "           4       0.85      0.89      0.87       982\n",
      "           5       0.86      0.71      0.78       892\n",
      "           6       0.93      0.91      0.92       958\n",
      "           7       0.89      0.78      0.83      1028\n",
      "           8       0.80      0.77      0.79       974\n",
      "           9       0.76      0.83      0.80      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 936    0   13    6    1    5   13    2    0    4]\n",
      " [   0 1108    2    5    0    2    2    2   13    1]\n",
      " [  17   35  842   15   11   11   12   13   59   17]\n",
      " [   0    3   19  892    4   15    1    8   62    6]\n",
      " [   2    7    9    1  878    5    8    3    2   67]\n",
      " [  12    9   14  122   18  636   17   18   19   27]\n",
      " [   3    6   42    2   16   10  869    4    5    1]\n",
      " [   1   16   27   28   19    3    0  806   15  113]\n",
      " [   7   31   12   54   20   49   15    6  754   26]\n",
      " [   5    9    7   19   69    4    0   42   12  842]]\n",
      "--------------------------------\n",
      "val predicted: (59610,) ['3' '0' '4' ... '5' '6' '0']\n",
      "probabilities: (59610, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (390, 784) (390,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [43 46 42 45 43 30 37 27 45 42] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 40\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 16.747 s \n",
      "\n",
      "Accuracy rate for 85.740000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.91      0.98      0.94      1135\n",
      "           2       0.86      0.82      0.84      1032\n",
      "           3       0.78      0.89      0.83      1010\n",
      "           4       0.85      0.90      0.87       982\n",
      "           5       0.85      0.71      0.78       892\n",
      "           6       0.93      0.91      0.92       958\n",
      "           7       0.89      0.79      0.84      1028\n",
      "           8       0.81      0.77      0.79       974\n",
      "           9       0.76      0.84      0.80      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.85      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 940    0   10    6    0    4   13    2    0    5]\n",
      " [   0 1108    2    5    0    3    2    2   13    0]\n",
      " [  17   35  843   16   12   10   12   13   57   17]\n",
      " [   0    3   17  900    4   15    1    8   56    6]\n",
      " [   2    7    8    1  879    6    7    3    2   67]\n",
      " [  12    9   12  124   16  636   18   17   22   26]\n",
      " [   4    6   41    2   16   10  869    4    5    1]\n",
      " [   1   16   27   31   19    2    0  807   13  112]\n",
      " [   3   31   11   57   19   56   15    6  748   28]\n",
      " [   5    9    7   18   70    5    0   41   10  844]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59600, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (410, 784) (410,)\n",
      "updated train set: (410, 784) (410,) unique(labels): [43 47 42 46 44 32 38 30 46 42] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59590, 784) (59590,)\n",
      "\n",
      "Train set: (410, 784) y: (410,)\n",
      "Val   set: (59590, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 41\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 17.377 s \n",
      "\n",
      "Accuracy rate for 86.170000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.90      0.98      0.94      1135\n",
      "           2       0.86      0.82      0.84      1032\n",
      "           3       0.80      0.88      0.84      1010\n",
      "           4       0.85      0.89      0.87       982\n",
      "           5       0.85      0.73      0.78       892\n",
      "           6       0.93      0.91      0.92       958\n",
      "           7       0.89      0.81      0.85      1028\n",
      "           8       0.82      0.77      0.79       974\n",
      "           9       0.77      0.84      0.80      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 939    0    9    6    0    6   13    2    0    5]\n",
      " [   0 1111    2    5    0    3    2    2   10    0]\n",
      " [  17   35  845   17   12   10   12   13   54   17]\n",
      " [   0    5   17  893    4   18    1   10   56    6]\n",
      " [   2    7   10    0  878    6    6    3    2   68]\n",
      " [  10    9   13  109   18  651   19   18   19   26]\n",
      " [   4    5   37    1   16   12  874    4    4    1]\n",
      " [   0   17   26   13   19    2    0  832   13  106]\n",
      " [   3   30   11   59   19   54   15    7  749   27]\n",
      " [   5    9    7   14   71    5    0   42   11  845]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59590,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59590, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (410, 784) (410,)\n",
      "trainset after (420, 784) (420,)\n",
      "updated train set: (420, 784) (420,) unique(labels): [44 48 43 46 45 32 40 31 48 43] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59580, 784) (59580,)\n",
      "\n",
      "Train set: (420, 784) y: (420,)\n",
      "Val   set: (59580, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 42\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 17.738 s \n",
      "\n",
      "Accuracy rate for 86.280000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.90      0.98      0.94      1135\n",
      "           2       0.87      0.83      0.85      1032\n",
      "           3       0.80      0.88      0.84      1010\n",
      "           4       0.85      0.90      0.87       982\n",
      "           5       0.85      0.73      0.78       892\n",
      "           6       0.93      0.91      0.92       958\n",
      "           7       0.90      0.80      0.85      1028\n",
      "           8       0.83      0.77      0.80       974\n",
      "           9       0.76      0.84      0.80      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 942    0    9    6    0    5   11    3    0    4]\n",
      " [   0 1108    1    5    0    6    2    2   10    1]\n",
      " [  17   32  853   16   12   10   12   12   49   19]\n",
      " [   0    4   19  893    4   18    1    9   56    6]\n",
      " [   2    9    6    0  883    6    8    3    2   63]\n",
      " [  11   10   14  107   18  650   21   17   16   28]\n",
      " [   5    6   34    1   18   12  874    2    5    1]\n",
      " [   1   16   30   12   14    2    0  827   11  115]\n",
      " [   2   30   11   61   17   51   15    6  750   31]\n",
      " [   4   10    8   12   73    6    0   38   10  848]]\n",
      "--------------------------------\n",
      "val predicted: (59580,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59580, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (420, 784) (420,)\n",
      "trainset after (430, 784) (430,)\n",
      "updated train set: (430, 784) (430,) unique(labels): [44 49 46 47 45 33 42 31 48 45] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59570, 784) (59570,)\n",
      "\n",
      "Train set: (430, 784) y: (430,)\n",
      "Val   set: (59570, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 43\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 18.029 s \n",
      "\n",
      "Accuracy rate for 86.380000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.91      0.98      0.94      1135\n",
      "           2       0.87      0.84      0.86      1032\n",
      "           3       0.80      0.89      0.84      1010\n",
      "           4       0.84      0.88      0.86       982\n",
      "           5       0.86      0.74      0.79       892\n",
      "           6       0.93      0.92      0.92       958\n",
      "           7       0.90      0.81      0.85      1028\n",
      "           8       0.84      0.77      0.80       974\n",
      "           9       0.75      0.83      0.79      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 941    0    9    6    0    7   10    3    0    4]\n",
      " [   0 1110    1    5    0    6    2    2    8    1]\n",
      " [  14   26  872   18   10    7   10   12   45   18]\n",
      " [   0    5   20  898    2   17    1    8   52    7]\n",
      " [   3   10    6    0  864    4   10    3    2   80]\n",
      " [  10    9   16  106   18  659   18   17   16   23]\n",
      " [   5    5   33    1   18   11  878    2    4    1]\n",
      " [   1   17   25   16   16    1    0  829   11  112]\n",
      " [   1   29   14   62   15   50   15    6  748   34]\n",
      " [   5   10    6   15   84    5    0   37    8  839]]\n",
      "--------------------------------\n",
      "val predicted: (59570,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59570, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (430, 784) (430,)\n",
      "trainset after (440, 784) (440,)\n",
      "updated train set: (440, 784) (440,) unique(labels): [45 50 47 47 48 34 42 31 49 47] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59560, 784) (59560,)\n",
      "\n",
      "Train set: (440, 784) y: (440,)\n",
      "Val   set: (59560, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 44\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 18.310 s \n",
      "\n",
      "Accuracy rate for 86.570000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.91      0.98      0.94      1135\n",
      "           2       0.87      0.84      0.86      1032\n",
      "           3       0.80      0.89      0.84      1010\n",
      "           4       0.84      0.89      0.86       982\n",
      "           5       0.86      0.74      0.79       892\n",
      "           6       0.93      0.92      0.92       958\n",
      "           7       0.91      0.80      0.85      1028\n",
      "           8       0.84      0.76      0.80       974\n",
      "           9       0.76      0.85      0.80      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 943    0    8    6    0    8   10    2    0    3]\n",
      " [   0 1111    2    4    0    5    2    2    8    1]\n",
      " [  12   31  871   15   14    7   10   12   43   17]\n",
      " [   0    5   21  896    3   18    1    8   51    7]\n",
      " [   2   10    6    0  875    4   10    3    2   70]\n",
      " [  11    8   15  103   22  662   16   17   17   21]\n",
      " [   5    5   33    1   20   10  878    1    4    1]\n",
      " [   1   18   27   14   17    1    0  823   11  116]\n",
      " [   1   29   14   63   15   52   14    6  745   35]\n",
      " [   4   10    6   14   79    7    0   27    9  853]]\n",
      "--------------------------------\n",
      "val predicted: (59560,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59560, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (440, 784) (440,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [45 50 48 48 49 36 44 32 49 49] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 45\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 18.923 s \n",
      "\n",
      "Accuracy rate for 86.420000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.91      0.98      0.94      1135\n",
      "           2       0.86      0.84      0.85      1032\n",
      "           3       0.79      0.89      0.84      1010\n",
      "           4       0.86      0.89      0.87       982\n",
      "           5       0.85      0.72      0.78       892\n",
      "           6       0.93      0.92      0.92       958\n",
      "           7       0.90      0.80      0.85      1028\n",
      "           8       0.84      0.77      0.80       974\n",
      "           9       0.76      0.85      0.80      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 936    0   12    8    0    7   11    2    0    4]\n",
      " [   0 1111    2    4    0    4    2    3    8    1]\n",
      " [  13   31  871   16   13    7   11   12   43   15]\n",
      " [   0    5   20  896    1   21    1   10   50    6]\n",
      " [   1    9    8    0  878    6   11    3    2   64]\n",
      " [  10    8   15  120   20  641   17   17   16   28]\n",
      " [   3    5   33    1   19   10  880    2    4    1]\n",
      " [   1   18   29   15   14    1    0  826   10  114]\n",
      " [   4   30   13   59   14   49   16    6  746   37]\n",
      " [   4   10    6   15   67    7    0   34    9  857]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59550,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59550, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (460, 784) (460,)\n",
      "updated train set: (460, 784) (460,) unique(labels): [45 51 49 50 50 37 45 34 49 50] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59540, 784) (59540,)\n",
      "\n",
      "Train set: (460, 784) y: (460,)\n",
      "Val   set: (59540, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 46\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 19.259 s \n",
      "\n",
      "Accuracy rate for 86.560000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.91      0.98      0.94      1135\n",
      "           2       0.87      0.85      0.86      1032\n",
      "           3       0.79      0.89      0.84      1010\n",
      "           4       0.85      0.91      0.88       982\n",
      "           5       0.85      0.72      0.78       892\n",
      "           6       0.93      0.92      0.93       958\n",
      "           7       0.90      0.81      0.86      1028\n",
      "           8       0.84      0.75      0.79       974\n",
      "           9       0.76      0.84      0.80      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.87      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 941    0   11    8    0    6   10    1    0    3]\n",
      " [   0 1110    3    4    0    4    2    2    8    2]\n",
      " [  14   30  873   16   14    8   10   11   43   13]\n",
      " [   0    5   19  900    2   21    2    6   47    8]\n",
      " [   1    6    8    0  892    4    8    3    2   58]\n",
      " [  10    7   16  121   20  641   15   19   16   27]\n",
      " [   3    5   31    1   19   11  882    1    4    1]\n",
      " [   1   19   25   16   12    1    0  835   10  109]\n",
      " [   3   29   12   59   14   51   17    7  734   48]\n",
      " [   4   10    7   14   72    6    0   39    9  848]]\n",
      "--------------------------------\n",
      "val predicted: (59540,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59540, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (460, 784) (460,)\n",
      "trainset after (470, 784) (470,)\n",
      "updated train set: (470, 784) (470,) unique(labels): [46 53 49 50 51 38 45 36 51 51] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59530, 784) (59530,)\n",
      "\n",
      "Train set: (470, 784) y: (470,)\n",
      "Val   set: (59530, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 47\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 19.744 s \n",
      "\n",
      "Accuracy rate for 86.380000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       980\n",
      "           1       0.91      0.98      0.94      1135\n",
      "           2       0.87      0.84      0.86      1032\n",
      "           3       0.79      0.89      0.84      1010\n",
      "           4       0.85      0.91      0.88       982\n",
      "           5       0.85      0.71      0.78       892\n",
      "           6       0.93      0.92      0.93       958\n",
      "           7       0.89      0.81      0.85      1028\n",
      "           8       0.84      0.75      0.79       974\n",
      "           9       0.76      0.84      0.80      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 933    0   11    9    0    7   12    5    0    3]\n",
      " [   0 1112    3    4    0    4    2    1    8    1]\n",
      " [  15   29  871   16   12    8   10   12   43   16]\n",
      " [   0    5   19  898    3   21    1    8   48    7]\n",
      " [   1    6    8    0  892    3    9    3    2   58]\n",
      " [   8    8   16  120   23  637   16   21   17   26]\n",
      " [   3    5   29    1   16   11  885    3    4    1]\n",
      " [   1   22   25   15   15    1    0  830   10  109]\n",
      " [   3   30   12   60   16   51   17    6  732   47]\n",
      " [   4    9    7   14   71    6    0   40   10  848]]\n",
      "--------------------------------\n",
      "val predicted: (59530,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59530, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (470, 784) (470,)\n",
      "trainset after (480, 784) (480,)\n",
      "updated train set: (480, 784) (480,) unique(labels): [46 55 50 52 52 38 46 36 53 52] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59520, 784) (59520,)\n",
      "\n",
      "Train set: (480, 784) y: (480,)\n",
      "Val   set: (59520, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 48\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 20.027 s \n",
      "\n",
      "Accuracy rate for 86.370000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       980\n",
      "           1       0.91      0.98      0.94      1135\n",
      "           2       0.87      0.84      0.85      1032\n",
      "           3       0.79      0.90      0.84      1010\n",
      "           4       0.86      0.91      0.88       982\n",
      "           5       0.86      0.71      0.77       892\n",
      "           6       0.92      0.92      0.92       958\n",
      "           7       0.89      0.80      0.85      1028\n",
      "           8       0.84      0.76      0.80       974\n",
      "           9       0.76      0.84      0.80      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 928    0   12    9    0    7   16    5    0    3]\n",
      " [   0 1110    3    4    0    3    2    1   11    1]\n",
      " [  15   29  869   15   12    8   11   12   45   16]\n",
      " [   0    5   18  908    2   20    0    7   41    9]\n",
      " [   1    6    7    0  893    2   10    3    2   58]\n",
      " [   9    7   15  122   22  631   19   21   20   26]\n",
      " [   3    5   31    1   18   10  883    2    4    1]\n",
      " [   1   22   25   15   16    1    0  827   10  111]\n",
      " [   3   30   14   61   13   50   14    6  737   46]\n",
      " [   4    9    7   16   67    6    0   41    8  851]]\n",
      "--------------------------------\n",
      "val predicted: (59520,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59520, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (480, 784) (480,)\n",
      "trainset after (490, 784) (490,)\n",
      "updated train set: (490, 784) (490,) unique(labels): [46 57 53 53 54 39 46 37 53 52] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59510, 784) (59510,)\n",
      "\n",
      "Train set: (490, 784) y: (490,)\n",
      "Val   set: (59510, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 49\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 20.382 s \n",
      "\n",
      "Accuracy rate for 86.440000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       980\n",
      "           1       0.91      0.98      0.94      1135\n",
      "           2       0.87      0.85      0.86      1032\n",
      "           3       0.80      0.89      0.84      1010\n",
      "           4       0.84      0.91      0.87       982\n",
      "           5       0.85      0.73      0.79       892\n",
      "           6       0.92      0.92      0.92       958\n",
      "           7       0.89      0.81      0.85      1028\n",
      "           8       0.85      0.76      0.80       974\n",
      "           9       0.76      0.84      0.80      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 926    0   13    9    0    7   16    5    1    3]\n",
      " [   0 1111    3    4    0    4    2    2    8    1]\n",
      " [  11   30  875   14   17    8   10   11   42   14]\n",
      " [   0    6   23  899    2   27    1    6   39    7]\n",
      " [   1    5    7    1  890    3   13    3    2   57]\n",
      " [   9    8   14   97   25  650   19   26   21   23]\n",
      " [   2    5   30    1   25    9  880    3    3    0]\n",
      " [   1   19   22   18   18    1    0  830   10  109]\n",
      " [   3   26   16   59   15   49   16    7  737   46]\n",
      " [   5    9    8   19   67    5    0   43    7  846]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59510,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59510, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (490, 784) (490,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [47 57 54 56 54 40 47 38 54 53] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 50\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 20.695 s \n",
      "\n",
      "Accuracy rate for 86.540000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       980\n",
      "           1       0.91      0.97      0.94      1135\n",
      "           2       0.86      0.85      0.85      1032\n",
      "           3       0.80      0.88      0.84      1010\n",
      "           4       0.84      0.91      0.87       982\n",
      "           5       0.85      0.73      0.79       892\n",
      "           6       0.92      0.91      0.92       958\n",
      "           7       0.89      0.81      0.85      1028\n",
      "           8       0.85      0.77      0.81       974\n",
      "           9       0.77      0.84      0.80      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.87      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 931    0   14   11    0    6   10    4    1    3]\n",
      " [   0 1105    2    8    0    3    2    2   12    1]\n",
      " [  12   30  873   11   16    9   12   11   44   14]\n",
      " [   0    3   24  892    4   28    1    8   44    6]\n",
      " [   1    5    8    1  891    3   13    3    1   56]\n",
      " [  10   10   14   97   23  653   19   23   20   23]\n",
      " [   2    4   30    2   26   12  876    3    3    0]\n",
      " [   1   19   24   16   18    1    0  832    8  109]\n",
      " [   2   25   14   56   12   44   17    5  753   46]\n",
      " [   5    8    8   21   66    6    0   43    4  848]]\n",
      "--------------------------------\n",
      "final active learning accuracies [30.12, 41.54, 51.15, 59.5, 64.64999999999999, 65.02, 66.7, 68.81, 70.28, 73.48, 73.83, 76.64, 76.83, 77.68, 77.38000000000001, 77.77, 79.17, 79.59, 80.86, 80.89, 81.24, 81.47999999999999, 82.23, 82.8, 82.96, 83.00999999999999, 83.64, 83.72, 83.35000000000001, 83.41, 83.69, 83.67999999999999, 84.23, 84.26, 84.48, 84.98, 85.38, 85.39, 85.63, 85.74000000000001, 86.17, 86.28, 86.38, 86.57000000000001, 86.42, 86.56, 86.38, 86.37, 86.44, 86.53999999999999]\n",
      "saved Active-learning-experiment-5.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'README.md', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-5.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', '.ipynb_checkpoints', 'LICENSE', '.git']\n",
      "{\n",
      "  \"SvmModel\": {\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          30.12,\n",
      "          41.54,\n",
      "          51.15,\n",
      "          59.5,\n",
      "          64.64999999999999,\n",
      "          65.02,\n",
      "          66.7,\n",
      "          68.81,\n",
      "          70.28,\n",
      "          73.48,\n",
      "          73.83,\n",
      "          76.64,\n",
      "          76.83,\n",
      "          77.68,\n",
      "          77.38000000000001,\n",
      "          77.77,\n",
      "          79.17,\n",
      "          79.59,\n",
      "          80.86,\n",
      "          80.89,\n",
      "          81.24,\n",
      "          81.47999999999999,\n",
      "          82.23,\n",
      "          82.8,\n",
      "          82.96,\n",
      "          83.00999999999999,\n",
      "          83.64,\n",
      "          83.72,\n",
      "          83.35000000000001,\n",
      "          83.41,\n",
      "          83.69,\n",
      "          83.67999999999999,\n",
      "          84.23,\n",
      "          84.26,\n",
      "          84.48,\n",
      "          84.98,\n",
      "          85.38,\n",
      "          85.39,\n",
      "          85.63,\n",
      "          85.74000000000001,\n",
      "          86.17,\n",
      "          86.28,\n",
      "          86.38,\n",
      "          86.57000000000001,\n",
      "          86.42,\n",
      "          86.56,\n",
      "          86.38,\n",
      "          86.37,\n",
      "          86.44,\n",
      "          86.53999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.53999999999999,\n",
      "          80.67,\n",
      "          84.16,\n",
      "          86.61999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          55.489999999999995,\n",
      "          64.21,\n",
      "          71.63000000000001,\n",
      "          74.95,\n",
      "          76.49000000000001,\n",
      "          80.08999999999999,\n",
      "          82.11,\n",
      "          82.25,\n",
      "          82.65,\n",
      "          83.3,\n",
      "          84.02,\n",
      "          85.05,\n",
      "          85.15,\n",
      "          85.67,\n",
      "          86.18,\n",
      "          86.83999999999999,\n",
      "          87.41,\n",
      "          87.63,\n",
      "          87.82,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.15,\n",
      "          86.91\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          67.52,\n",
      "          75.52,\n",
      "          80.19,\n",
      "          84.26,\n",
      "          85.77,\n",
      "          86.16,\n",
      "          86.58,\n",
      "          86.65,\n",
      "          87.18,\n",
      "          87.09\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 6, using model = SvmModel, selection_function = MarginSamplingSelection, k = 250, iteration = 0.\n",
      "\n",
      "initial random chosen samples (250,)\n",
      "initial train set: (250, 784) (250,) unique(labels): [21 28 29 22 34 34 18 19 17 28] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,) (250,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.025 s \n",
      "\n",
      "Accuracy rate for 82.870000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       980\n",
      "           1       0.87      0.97      0.91      1135\n",
      "           2       0.81      0.77      0.79      1032\n",
      "           3       0.82      0.77      0.80      1010\n",
      "           4       0.86      0.81      0.83       982\n",
      "           5       0.66      0.83      0.74       892\n",
      "           6       0.94      0.84      0.89       958\n",
      "           7       0.90      0.82      0.86      1028\n",
      "           8       0.87      0.67      0.76       974\n",
      "           9       0.72      0.83      0.77      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 931    1    6    3    1   34    0    2    2    0]\n",
      " [   0 1098   26    5    0    1    4    0    1    0]\n",
      " [  23   56  797   27    7   23   22   17   50   10]\n",
      " [   5   12   17  782    1  144    3    8   22   16]\n",
      " [   4    3   17    1  797    9    5    4    3  139]\n",
      " [  10   25   12   35   15  743    4    8    8   32]\n",
      " [  31   14   26    3   18   63  802    0    0    1]\n",
      " [   3   21   49   12   16    5    2  848    5   67]\n",
      " [  19   28   29   67   15   95    5    9  649   58]\n",
      " [  14   11    5   21   61    5    3   45    4  840]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [28 35 55 70 72 55 35 32 71 47] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 22.889 s \n",
      "\n",
      "Accuracy rate for 87.590000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       980\n",
      "           1       0.92      0.96      0.94      1135\n",
      "           2       0.84      0.83      0.84      1032\n",
      "           3       0.86      0.87      0.87      1010\n",
      "           4       0.86      0.93      0.89       982\n",
      "           5       0.80      0.80      0.80       892\n",
      "           6       0.96      0.89      0.92       958\n",
      "           7       0.92      0.84      0.88      1028\n",
      "           8       0.81      0.83      0.82       974\n",
      "           9       0.85      0.81      0.83      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.87      0.87     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 952    0    4    3    1   13    2    1    3    1]\n",
      " [   0 1095   10    4    1    1    2    0   22    0]\n",
      " [  13   18  857   16   16   12   12   10   75    3]\n",
      " [   3    5   23  883    2   55    1    8   25    5]\n",
      " [   1    8   15    1  913    1    4    2    3   34]\n",
      " [   8   17   14   63   14  716    4    2   33   21]\n",
      " [  14    6   23    0   11   48  851    0    5    0]\n",
      " [   6   21   42   10   16    2    1  863    7   60]\n",
      " [   4   12   22   35   13   42   10    5  809   22]\n",
      " [  14    7    8   13   76    3    1   52   15  820]]\n",
      "--------------------------------\n",
      "final active learning accuracies [82.87, 87.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved Active-learning-experiment-6.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'README.md', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', '.ipynb_checkpoints', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 7, using model = SvmModel, selection_function = MarginSamplingSelection, k = 125, iteration = 0.\n",
      "\n",
      "initial random chosen samples (125,)\n",
      "initial train set: (125, 784) (125,) unique(labels): [10 13  7 14 16 10  7 17 13 18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,) (125,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.424 s \n",
      "\n",
      "Accuracy rate for 76.800000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86       980\n",
      "           1       0.79      0.98      0.87      1135\n",
      "           2       0.86      0.56      0.68      1032\n",
      "           3       0.69      0.74      0.71      1010\n",
      "           4       0.77      0.75      0.76       982\n",
      "           5       0.65      0.68      0.67       892\n",
      "           6       0.87      0.84      0.85       958\n",
      "           7       0.82      0.88      0.85      1028\n",
      "           8       0.78      0.57      0.66       974\n",
      "           9       0.65      0.79      0.71      1009\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.76      0.76     10000\n",
      "weighted avg       0.77      0.77      0.76     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 835    1    3   40    2   81    9    3    4    2]\n",
      " [   0 1108    1    5    0    0    6    0   13    2]\n",
      " [  55  130  581   73   17    4   11   60   62   39]\n",
      " [   7   30   15  749    1  106   12   25   39   26]\n",
      " [   3    6    3    0  741    4   18   17    0  190]\n",
      " [  26   35    5  106   34  609   18   13   26   20]\n",
      " [  22   14   53    5   22   17  801    2    3   19]\n",
      " [   2   21    8    1   16    8    0  904   10   58]\n",
      " [  10   51    5  100   23   95   46   22  558   64]\n",
      " [  11    9    0   14  107    9    0   61    4  794]]\n",
      "--------------------------------\n",
      "val predicted: (59875,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59875, 10) \n",
      " [5 0 4 ... 5 6 9]\n",
      "trainset before (125, 784) (125,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [23 18 25 27 31 28 16 26 32 24] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.200 s \n",
      "\n",
      "Accuracy rate for 83.960000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       980\n",
      "           1       0.89      0.97      0.93      1135\n",
      "           2       0.83      0.72      0.77      1032\n",
      "           3       0.75      0.80      0.77      1010\n",
      "           4       0.84      0.85      0.84       982\n",
      "           5       0.78      0.76      0.77       892\n",
      "           6       0.94      0.86      0.90       958\n",
      "           7       0.84      0.88      0.86      1028\n",
      "           8       0.81      0.79      0.80       974\n",
      "           9       0.79      0.81      0.80      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 936    0    7   19    0    7    7    2    2    0]\n",
      " [   0 1098    1   22    0    3    5    0    6    0]\n",
      " [  25   77  740   37   13    6    9   28   90    7]\n",
      " [   3    4   17  808    2  101    3   18   37   17]\n",
      " [   1    5   15    1  830    1    4   13    5  107]\n",
      " [  14   11   11  107   21  678    9    7   29    5]\n",
      " [  15    5   55    7   31   16  821    3    5    0]\n",
      " [   1   15   25   13   10    1    0  902    8   53]\n",
      " [   9   16   12   48   20   44   12   19  769   25]\n",
      " [   9    4    6   20   57   14    0   82    3  814]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '2' '8']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [27 23 36 39 43 37 39 40 42 49] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 17.770 s \n",
      "\n",
      "Accuracy rate for 87.080000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       980\n",
      "           1       0.94      0.97      0.95      1135\n",
      "           2       0.87      0.84      0.85      1032\n",
      "           3       0.80      0.85      0.82      1010\n",
      "           4       0.87      0.89      0.88       982\n",
      "           5       0.84      0.74      0.79       892\n",
      "           6       0.95      0.89      0.92       958\n",
      "           7       0.87      0.89      0.88      1028\n",
      "           8       0.83      0.82      0.82       974\n",
      "           9       0.82      0.85      0.83      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 928    0   10   12    0    7   13   10    0    0]\n",
      " [   0 1100    2    5    1    3    1    1   20    2]\n",
      " [  27   14  871   18   20    1    7   24   45    5]\n",
      " [   3   11   28  855    2   31    2   16   43   19]\n",
      " [   1    0    9    2  873    4    8    8    4   73]\n",
      " [  11   12    4  111   34  660   10    5   33   12]\n",
      " [   9    4   40    4   14   33  850    1    3    0]\n",
      " [   2   10   16    5    6    0    0  917   13   59]\n",
      " [  10   16   21   44   15   34    5   13  801   15]\n",
      " [   8    8    5   17   41   12    0   57    8  853]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['3' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59625, 10) \n",
      " [3 0 4 ... 5 6 5]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [30 28 47 53 57 62 47 54 60 62] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 23.698 s \n",
      "\n",
      "Accuracy rate for 88.940000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       980\n",
      "           1       0.96      0.97      0.96      1135\n",
      "           2       0.87      0.85      0.86      1032\n",
      "           3       0.85      0.88      0.87      1010\n",
      "           4       0.89      0.90      0.90       982\n",
      "           5       0.85      0.81      0.83       892\n",
      "           6       0.95      0.90      0.93       958\n",
      "           7       0.88      0.91      0.90      1028\n",
      "           8       0.84      0.85      0.85       974\n",
      "           9       0.86      0.85      0.85      1009\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 932    0   12    5    2   11   14    3    1    0]\n",
      " [   0 1104    2    6    1    4    1    1   15    1]\n",
      " [  24   23  877   16   10    2    3   16   57    4]\n",
      " [  11    2   21  888    0   36    1   18   25    8]\n",
      " [   1    0   13    0  885    2    6    2    3   70]\n",
      " [   9    6   10   74   16  720   10   12   29    6]\n",
      " [   8    3   35    1   15   21  865    1    9    0]\n",
      " [   2    6   22    8    3    1    1  940    6   39]\n",
      " [   6    7   13   29   16   43    7   15  826   12]\n",
      " [  10    4    5   14   46    9    0   56    8  857]]\n",
      "--------------------------------\n",
      "final active learning accuracies [76.8, 83.96000000000001, 87.08, 88.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved Active-learning-experiment-7.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'README.md', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', '.ipynb_checkpoints', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 8, using model = SvmModel, selection_function = MarginSamplingSelection, k = 50, iteration = 0.\n",
      "\n",
      "initial random chosen samples (50,)\n",
      "initial train set: (50, 784) (50,) unique(labels): [2 4 2 5 2 8 6 9 5 7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,) (50,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.556 s \n",
      "\n",
      "Accuracy rate for 59.740000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.56      0.68       980\n",
      "           1       0.81      0.90      0.85      1135\n",
      "           2       0.57      0.27      0.37      1032\n",
      "           3       0.65      0.67      0.66      1010\n",
      "           4       0.83      0.26      0.40       982\n",
      "           5       0.42      0.79      0.55       892\n",
      "           6       0.75      0.72      0.73       958\n",
      "           7       0.63      0.67      0.65      1028\n",
      "           8       0.65      0.53      0.58       974\n",
      "           9       0.34      0.60      0.43      1009\n",
      "\n",
      "    accuracy                           0.60     10000\n",
      "   macro avg       0.65      0.60      0.59     10000\n",
      "weighted avg       0.66      0.60      0.59     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 545    1  106    6    0  210   22    1    2   87]\n",
      " [   0 1016    1   18    0   70    3    1   24    2]\n",
      " [  22  149  279   91    0   55  135   39  130  132]\n",
      " [   5   13    3  680    1  217    9   22   32   28]\n",
      " [   0    9   39    0  255   71   19   59   27  503]\n",
      " [   7   12    2   90    0  707   18    4    7   45]\n",
      " [  14    3   47    1    2  136  685    2    0   68]\n",
      " [   0   21    6    7    1   42    0  686   22  243]\n",
      " [  14   26    1  131    1  146   22   34  512   87]\n",
      " [   5    4    7   16   46   44    5  245   28  609]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['3' '0' '2' ... '5' '5' '5']\n",
      "probabilities: (59950, 10) \n",
      " [5 0 5 ... 5 5 5]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 5 10  7 20  3 10  9  9 16 11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.110 s \n",
      "\n",
      "Accuracy rate for 70.570000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.77      0.84       980\n",
      "           1       0.83      0.98      0.90      1135\n",
      "           2       0.76      0.59      0.67      1032\n",
      "           3       0.70      0.78      0.74      1010\n",
      "           4       0.83      0.29      0.43       982\n",
      "           5       0.52      0.74      0.61       892\n",
      "           6       0.83      0.81      0.82       958\n",
      "           7       0.70      0.62      0.66      1028\n",
      "           8       0.70      0.76      0.73       974\n",
      "           9       0.49      0.69      0.57      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.73      0.70      0.70     10000\n",
      "weighted avg       0.73      0.71      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 752    0   30   14    0  127   31    0    2   24]\n",
      " [   0 1107    2    3    0    3    3    0   15    2]\n",
      " [  13  102  609  113    0   21   27   30   90   27]\n",
      " [   2   11   14  789    1  132    5    5   34   17]\n",
      " [   1   18   49   29  288   85   46   47   68  351]\n",
      " [   4   27   11   64    2  660   29    1   57   37]\n",
      " [  16    7   36    9    3   90  778    0   13    6]\n",
      " [   1   25   31   43   15   47    2  635   18  211]\n",
      " [  13   29    8   43    7   51   10   23  742   48]\n",
      " [  10   10    9   20   31   42    3  161   26  697]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['5' '0' '3' ... '5' '5' '5']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 3 ... 5 5 5]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [ 9 11 19 21  9 19 12 15 21 14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 7.634 s \n",
      "\n",
      "Accuracy rate for 79.120000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       980\n",
      "           1       0.83      0.97      0.90      1135\n",
      "           2       0.83      0.72      0.77      1032\n",
      "           3       0.84      0.73      0.78      1010\n",
      "           4       0.84      0.69      0.76       982\n",
      "           5       0.59      0.85      0.70       892\n",
      "           6       0.87      0.86      0.87       958\n",
      "           7       0.82      0.76      0.79      1028\n",
      "           8       0.73      0.79      0.76       974\n",
      "           9       0.69      0.67      0.68      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 848    0   20    5    1   60   26    5    9    6]\n",
      " [   0 1103    1    2    0    6    3    0   18    2]\n",
      " [  12   84  738   54    2   10   23   16   79   14]\n",
      " [   3   19   18  734    1  174    4    7   41    9]\n",
      " [   1   16   20    3  679   59   24    3   28  149]\n",
      " [  13   18    8   22    2  758   25    6   37    3]\n",
      " [  10    6   18    3   18   69  825    0    8    1]\n",
      " [   4   29   49    6   24   26    2  781   19   88]\n",
      " [   6   33    8   32    9   69   12   10  768   27]\n",
      " [  11   13    9    9   68   55    3  124   39  678]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['5' '0' '5' ... '5' '6' '5']\n",
      "probabilities: (59850, 10) \n",
      " [5 0 5 ... 5 6 5]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [10 17 25 26 20 21 12 20 27 22] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.063 s \n",
      "\n",
      "Accuracy rate for 83.250000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       980\n",
      "           1       0.89      0.98      0.93      1135\n",
      "           2       0.87      0.83      0.85      1032\n",
      "           3       0.87      0.77      0.82      1010\n",
      "           4       0.84      0.74      0.79       982\n",
      "           5       0.68      0.81      0.74       892\n",
      "           6       0.89      0.85      0.87       958\n",
      "           7       0.85      0.86      0.86      1028\n",
      "           8       0.80      0.82      0.81       974\n",
      "           9       0.72      0.76      0.74      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 863    0   24   12    3   39   22    4    7    6]\n",
      " [   0 1110    2    1    0    6    3    0   12    1]\n",
      " [  18   35  860   21    7    6   17   20   37   11]\n",
      " [   3   14   17  778    0  121    3   23   44    7]\n",
      " [   0    8    9    4  726   14   19    4   10  188]\n",
      " [   9   26    6   30    9  723   25    5   53    6]\n",
      " [  13    5   23    2   19   58  815    1   14    8]\n",
      " [   3   21   33    4   21   13    1  884    1   47]\n",
      " [   7   20   10   33   12   54    8   13  795   22]\n",
      " [  13   10    7   10   68   25    3   84   18  771]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59800,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59800, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [17 18 29 30 26 27 18 26 30 29] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.571 s \n",
      "\n",
      "Accuracy rate for 84.190000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       980\n",
      "           1       0.91      0.97      0.94      1135\n",
      "           2       0.89      0.81      0.85      1032\n",
      "           3       0.86      0.77      0.81      1010\n",
      "           4       0.86      0.79      0.82       982\n",
      "           5       0.69      0.81      0.74       892\n",
      "           6       0.92      0.86      0.89       958\n",
      "           7       0.88      0.87      0.87      1028\n",
      "           8       0.81      0.79      0.80       974\n",
      "           9       0.75      0.79      0.77      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.85      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 918    0    2    5    0   39    8    1    1    6]\n",
      " [   0 1104    1    2    0    9    4    0   14    1]\n",
      " [  34   29  836   32    8   12   13   17   41   10]\n",
      " [   3    7   16  778    0  133    4   18   42    9]\n",
      " [  11    7   10    1  772   12   12    5    6  146]\n",
      " [  32   13    2   34    8  721   20    3   45   14]\n",
      " [  23    4   24    9   24   27  828    0   12    7]\n",
      " [  17   20   32    5    8   10    0  892    3   41]\n",
      " [  14   21    8   35   11   63    7   13  770   32]\n",
      " [  23   10    6    7   63   20    0   64   16  800]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 9 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [20 19 36 35 38 37 21 30 33 31] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 14.913 s \n",
      "\n",
      "Accuracy rate for 86.440000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90       980\n",
      "           1       0.92      0.98      0.95      1135\n",
      "           2       0.88      0.85      0.86      1032\n",
      "           3       0.88      0.82      0.85      1010\n",
      "           4       0.88      0.85      0.87       982\n",
      "           5       0.73      0.87      0.79       892\n",
      "           6       0.95      0.88      0.91       958\n",
      "           7       0.89      0.88      0.88      1028\n",
      "           8       0.87      0.77      0.82       974\n",
      "           9       0.81      0.79      0.80      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 915    0    8    2    0   38   11    1    2    3]\n",
      " [   0 1109    2    4    0    6    2    0   12    0]\n",
      " [  33   27  881    9   10    9    8   15   33    7]\n",
      " [   2    5   18  831    3  103    2   11   28    7]\n",
      " [  10    4    9    2  838    8    9    2    2   98]\n",
      " [  16   10    6   51    5  775    6    1   16    6]\n",
      " [  27    3   29    3   17   23  846    0    5    5]\n",
      " [  18   22   28    4    7    9    0  900    4   36]\n",
      " [  20   21    8   33   16   72    9   15  748   32]\n",
      " [  19   11   16    8   52   23    0   70    9  801]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59700, 10) \n",
      " [5 0 9 ... 5 6 8]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [22 20 41 42 52 39 25 37 36 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 17.586 s \n",
      "\n",
      "Accuracy rate for 87.300000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93       980\n",
      "           1       0.92      0.97      0.95      1135\n",
      "           2       0.88      0.87      0.87      1032\n",
      "           3       0.86      0.85      0.85      1010\n",
      "           4       0.87      0.88      0.87       982\n",
      "           5       0.76      0.83      0.79       892\n",
      "           6       0.94      0.91      0.93       958\n",
      "           7       0.89      0.88      0.89      1028\n",
      "           8       0.87      0.78      0.82       974\n",
      "           9       0.83      0.80      0.82      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 934    0    6    1    1   23    9    1    2    3]\n",
      " [   0 1101    3    3    0   11    3    1   13    0]\n",
      " [  20   19  896   13   11   12    8   16   30    7]\n",
      " [   6    4   26  856    2   71    3   11   25    6]\n",
      " [   6    2   10    1  862    9    6    6    1   79]\n",
      " [  21   11    1   59    9  742   12    3   29    5]\n",
      " [  16    3   22    1   13   27  870    1    4    1]\n",
      " [   7   22   30    9   13    6    0  902    2   37]\n",
      " [  14   20    9   43   16   61   12   13  758   28]\n",
      " [  15   10   14   14   66   19    0   56    6  809]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59650, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [25 21 46 46 58 41 27 39 49 48] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 19.859 s \n",
      "\n",
      "Accuracy rate for 87.810000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       980\n",
      "           1       0.94      0.97      0.96      1135\n",
      "           2       0.88      0.88      0.88      1032\n",
      "           3       0.89      0.82      0.85      1010\n",
      "           4       0.84      0.87      0.85       982\n",
      "           5       0.79      0.85      0.82       892\n",
      "           6       0.95      0.91      0.93       958\n",
      "           7       0.90      0.88      0.89      1028\n",
      "           8       0.86      0.81      0.83       974\n",
      "           9       0.83      0.80      0.81      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 948    0    6    2    1   13    7    1    0    2]\n",
      " [   0 1101    1    4    0   12    4    1   12    0]\n",
      " [  23   13  913    3   12    7   10   14   28    9]\n",
      " [   3    6   34  833    1   73    3   12   38    7]\n",
      " [   8    0   13    2  851    5    4    8    1   90]\n",
      " [  22    6    7   37   11  755   12    3   34    5]\n",
      " [  16    3   20    1    9   29  874    2    4    0]\n",
      " [   6   18   27    7   22    4    0  909    2   33]\n",
      " [  11   17    8   40   18   48    9   13  789   21]\n",
      " [  16    6   12   11   84    9    0   51   12  808]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59600, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [25 24 54 54 61 48 31 43 56 54] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 22.051 s \n",
      "\n",
      "Accuracy rate for 87.580000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.87      0.86      0.86      1032\n",
      "           3       0.89      0.82      0.86      1010\n",
      "           4       0.85      0.87      0.86       982\n",
      "           5       0.78      0.86      0.82       892\n",
      "           6       0.94      0.90      0.92       958\n",
      "           7       0.90      0.87      0.88      1028\n",
      "           8       0.86      0.82      0.84       974\n",
      "           9       0.82      0.81      0.81      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 939    0    6    2    1   18    9    2    1    2]\n",
      " [   0 1112    3    5    0    2    1    3    8    1]\n",
      " [  28   15  885    9    9    5   18   12   43    8]\n",
      " [   5    7   26  830    2   96    3   12   24    5]\n",
      " [   7    0    9    2  851    8    8    8    3   86]\n",
      " [  17    6   10   31   10  770    9    4   29    6]\n",
      " [  16    3   28    1    6   30  866    1    7    0]\n",
      " [   6   19   24   12   16    6    0  892    3   50]\n",
      " [  11   18   17   30   12   42   12   13  799   20]\n",
      " [  17    8   10    8   90    9    0   43   10  814]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59550, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [30 28 62 64 63 57 31 45 61 59] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 24.155 s \n",
      "\n",
      "Accuracy rate for 88.630000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.87      0.88      0.87      1032\n",
      "           3       0.90      0.86      0.88      1010\n",
      "           4       0.86      0.89      0.88       982\n",
      "           5       0.82      0.87      0.84       892\n",
      "           6       0.94      0.90      0.92       958\n",
      "           7       0.90      0.88      0.89      1028\n",
      "           8       0.87      0.82      0.84       974\n",
      "           9       0.85      0.81      0.83      1009\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.88     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 950    0    4    3    1   11    7    2    2    0]\n",
      " [   0 1109    4    3    0    2    1    3   12    1]\n",
      " [  29   12  909    4    8    6   14   12   33    5]\n",
      " [   4    5   34  870    1   59    2   14   17    4]\n",
      " [   8    3   10    0  878    4    7    5    3   64]\n",
      " [  10    5    7   28   12  775   12    4   30    9]\n",
      " [  18    4   25    2    9   35  859    1    5    0]\n",
      " [   8   16   27   12   15    4    0  901    3   42]\n",
      " [   9   14   19   34   11   43   13   10  798   23]\n",
      " [  16    8    8   12   82   10    0   47   12  814]]\n",
      "--------------------------------\n",
      "final active learning accuracies [59.74, 70.57, 79.12, 83.25, 84.19, 86.44, 87.3, 87.81, 87.58, 88.63]\n",
      "saved Active-learning-experiment-8.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'README.md', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', '.ipynb_checkpoints', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 9, using model = SvmModel, selection_function = MarginSamplingSelection, k = 25, iteration = 0.\n",
      "\n",
      "initial random chosen samples (25,)\n",
      "initial train set: (25, 784) (25,) unique(labels): [4 4 1 1 2 1 3 3 3 3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59975, 784) (59975,) (25,)\n",
      "\n",
      "Train set: (25, 784) y: (25,)\n",
      "Val   set: (59975, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 1.379 s \n",
      "\n",
      "Accuracy rate for 48.210000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.91      0.73       980\n",
      "           1       0.39      0.94      0.55      1135\n",
      "           2       0.95      0.21      0.34      1032\n",
      "           3       0.58      0.18      0.27      1010\n",
      "           4       0.46      0.06      0.11       982\n",
      "           5       0.89      0.09      0.16       892\n",
      "           6       0.54      0.79      0.64       958\n",
      "           7       0.67      0.73      0.70      1028\n",
      "           8       0.28      0.31      0.29       974\n",
      "           9       0.36      0.52      0.43      1009\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.57      0.47      0.42     10000\n",
      "weighted avg       0.57      0.48      0.43     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 887   27    0    1    1    1   29    3   25    6]\n",
      " [   1 1067    0    0    0    0   10    0   57    0]\n",
      " [  73  260  212    1    5    1  116   27  315   22]\n",
      " [  88  411    2  179    0    4   74   27  214   11]\n",
      " [  18   96    1    3   62    0  154   55   16  577]\n",
      " [ 253  228    0   42   30   79   83   37  114   26]\n",
      " [  69   97    6    0    5    0  757    1    5   18]\n",
      " [   7  139    0    6    2    0   13  755   20   86]\n",
      " [  38  271    3   20   29    4  119   24  300  166]\n",
      " [  24  144    0   54    2    0   50  198   14  523]]\n",
      "--------------------------------\n",
      "val predicted: (59975,) ['8' '0' '8' ... '8' '6' '8']\n",
      "probabilities: (59975, 10) \n",
      " [6 0 7 ... 9 1 9]\n",
      "trainset before (25, 784) (25,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [5 6 4 4 7 5 4 4 4 7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.707 s \n",
      "\n",
      "Accuracy rate for 59.870000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.81      0.72       980\n",
      "           1       0.62      0.93      0.75      1135\n",
      "           2       0.63      0.62      0.63      1032\n",
      "           3       0.66      0.45      0.53      1010\n",
      "           4       0.57      0.53      0.55       982\n",
      "           5       0.53      0.38      0.44       892\n",
      "           6       0.74      0.66      0.70       958\n",
      "           7       0.84      0.52      0.64      1028\n",
      "           8       0.45      0.19      0.27       974\n",
      "           9       0.44      0.82      0.57      1009\n",
      "\n",
      "    accuracy                           0.60     10000\n",
      "   macro avg       0.61      0.59      0.58     10000\n",
      "weighted avg       0.61      0.60      0.58     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 791   12   34    3   10  107    7    6    7    3]\n",
      " [   1 1052    2    1    2    1   14    0   62    0]\n",
      " [  67  113  644    0   35    8   25   17   87   36]\n",
      " [  35  169  119  451    4  130   29   10   45   18]\n",
      " [  11   18   10    1  521    0   21    7    1  392]\n",
      " [ 152   82   20  113   95  341   23   12   13   41]\n",
      " [  69   35   77    0  119   20  636    0    2    0]\n",
      " [   8   65    9    0   27    1    9  534    7  368]\n",
      " [  82  113  107  107   43   31   86    7  185  213]\n",
      " [  13   26    5    8   66    8    4   46    1  832]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59950,) ['5' '0' '4' ... '5' '4' '8']\n",
      "probabilities: (59950, 10) \n",
      " [5 0 4 ... 5 4 9]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (75, 784) (75,)\n",
      "updated train set: (75, 784) (75,) unique(labels): [ 6  6  5 11  8  8  9  5  9  8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59925, 784) (59925,)\n",
      "\n",
      "Train set: (75, 784) y: (75,)\n",
      "Val   set: (59925, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.964 s \n",
      "\n",
      "Accuracy rate for 70.070000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82       980\n",
      "           1       0.79      0.86      0.83      1135\n",
      "           2       0.78      0.50      0.61      1032\n",
      "           3       0.60      0.85      0.70      1010\n",
      "           4       0.71      0.61      0.65       982\n",
      "           5       0.74      0.46      0.57       892\n",
      "           6       0.75      0.88      0.81       958\n",
      "           7       0.84      0.64      0.73      1028\n",
      "           8       0.61      0.61      0.61       974\n",
      "           9       0.53      0.73      0.62      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.72      0.70      0.69     10000\n",
      "weighted avg       0.72      0.70      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[823   0   8  19   5  96  23   2   4   0]\n",
      " [  0 979   0   3   1   0   8   0 117  27]\n",
      " [ 20 104 518  65  33   7 112  11 128  34]\n",
      " [  6  23   4 858   0   7  31   3  60  18]\n",
      " [ 23  11  25   9 595   1  31  16   6 265]\n",
      " [ 41  26   4 255  48 408  38   5  36  31]\n",
      " [  8  14  35   0  39  15 841   0   6   0]\n",
      " [ 53  42   7  22  23   0   7 656  15 203]\n",
      " [ 17  23  46 155  27  11  27  12 595  61]\n",
      " [ 30  16  15  43  71   5   6  76  13 734]]\n",
      "--------------------------------\n",
      "val predicted: (59925,) ['5' '0' '0' ... '5' '4' '9']\n",
      "probabilities: (59925, 10) \n",
      " [3 0 0 ... 5 5 8]\n",
      "trainset before (75, 784) (75,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 8  8 10 12 15 10 11  5  9 12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.240 s \n",
      "\n",
      "Accuracy rate for 73.880000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       980\n",
      "           1       0.83      0.94      0.88      1135\n",
      "           2       0.75      0.61      0.67      1032\n",
      "           3       0.67      0.82      0.74      1010\n",
      "           4       0.63      0.76      0.69       982\n",
      "           5       0.87      0.57      0.69       892\n",
      "           6       0.79      0.87      0.83       958\n",
      "           7       0.95      0.62      0.75      1028\n",
      "           8       0.69      0.57      0.62       974\n",
      "           9       0.55      0.72      0.62      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.76      0.74      0.74     10000\n",
      "weighted avg       0.76      0.74      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 852    1   21   16    7   27   50    0    3    3]\n",
      " [   0 1072    1    3    1    0    4    0   46    8]\n",
      " [  19   62  634   30   55    4   63    9  112   44]\n",
      " [   5   26   29  829    9    7   23    2   50   30]\n",
      " [  13    3   15    1  743    1    8    0    1  197]\n",
      " [  18   26    7  198   51  509   52    2   19   10]\n",
      " [   4   16   55    1   38    9  832    0    3    0]\n",
      " [  42   44    8   24   59    0    3  638    7  203]\n",
      " [  17   25   73  119   41   25   18    1  552  103]\n",
      " [  27   19    6   24  177    4    2   19    4  727]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['5' '0' '0' ... '5' '6' '9']\n",
      "probabilities: (59900, 10) \n",
      " [5 0 0 ... 5 6 8]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (125, 784) (125,)\n",
      "updated train set: (125, 784) (125,) unique(labels): [ 9  8 15 13 15 13 16 10 10 16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.697 s \n",
      "\n",
      "Accuracy rate for 79.620000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       980\n",
      "           1       0.88      0.94      0.91      1135\n",
      "           2       0.80      0.71      0.75      1032\n",
      "           3       0.77      0.84      0.80      1010\n",
      "           4       0.73      0.76      0.74       982\n",
      "           5       0.88      0.67      0.76       892\n",
      "           6       0.78      0.93      0.85       958\n",
      "           7       0.92      0.76      0.83      1028\n",
      "           8       0.77      0.61      0.68       974\n",
      "           9       0.64      0.81      0.71      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.80      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 893    0    9   10    3   19   44    0    1    1]\n",
      " [   0 1063    2    3    1    0   10    1   46    9]\n",
      " [  17   44  731   24   34    6   84   21   57   14]\n",
      " [   6   13   22  844    6   20   14    8   51   26]\n",
      " [   3    2   20    1  749    0   15    6    2  184]\n",
      " [  21   28   12  114   51  600   40    2    6   18]\n",
      " [   5    7   20    1   15   17  888    0    5    0]\n",
      " [  35   19   17    4   41    2    9  781    5  115]\n",
      " [  19   18   76   85   31   20   28    5  597   95]\n",
      " [  23   10   10   14   98    1    3   29    5  816]]\n",
      "--------------------------------\n",
      "val predicted: (59875,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59875, 10) \n",
      " [5 0 4 ... 5 6 9]\n",
      "trainset before (125, 784) (125,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [13  8 20 15 18 20 17 10 11 18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 7.934 s \n",
      "\n",
      "Accuracy rate for 80.990000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       980\n",
      "           1       0.90      0.94      0.92      1135\n",
      "           2       0.78      0.79      0.78      1032\n",
      "           3       0.80      0.77      0.79      1010\n",
      "           4       0.74      0.84      0.79       982\n",
      "           5       0.79      0.71      0.75       892\n",
      "           6       0.87      0.90      0.88       958\n",
      "           7       0.93      0.76      0.83      1028\n",
      "           8       0.75      0.64      0.69       974\n",
      "           9       0.68      0.78      0.73      1009\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.81      0.81      0.81     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 921    0   12    5    6   17   17    0    1    1]\n",
      " [   0 1064    2    2    1    1    9    1   49    6]\n",
      " [  16   28  819   14   25    4   37   13   64   12]\n",
      " [   6   15   62  782    6   39    8    8   63   21]\n",
      " [   1    2   22    1  827    0   10    5    3  111]\n",
      " [  34   25    9   89   44  637   34    2    6   12]\n",
      " [  21    6   28    1   14   18  861    0    9    0]\n",
      " [  21   18   31    9   42    6    4  778    4  115]\n",
      " [  15   17   56   61   22   77   14    6  620   86]\n",
      " [  17   10   14   10  131    5    1   25    6  790]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59850,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59850, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (175, 784) (175,)\n",
      "updated train set: (175, 784) (175,) unique(labels): [15 10 23 18 20 23 21 14 13 18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59825, 784) (59825,)\n",
      "\n",
      "Train set: (175, 784) y: (175,)\n",
      "Val   set: (59825, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 9.214 s \n",
      "\n",
      "Accuracy rate for 82.700000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       980\n",
      "           1       0.90      0.94      0.92      1135\n",
      "           2       0.80      0.79      0.79      1032\n",
      "           3       0.83      0.81      0.82      1010\n",
      "           4       0.77      0.86      0.82       982\n",
      "           5       0.79      0.77      0.78       892\n",
      "           6       0.87      0.91      0.89       958\n",
      "           7       0.89      0.83      0.86      1028\n",
      "           8       0.78      0.65      0.71       974\n",
      "           9       0.72      0.74      0.73      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.82     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 927    0    9    3    0   19   21    0    0    1]\n",
      " [   0 1072    3    2    2    1    3    1   46    5]\n",
      " [  14   32  816   16   20    6   38   17   64    9]\n",
      " [   8   12   43  816    4   47    7   11   44   18]\n",
      " [   1    3   24    0  847    3   13    6    4   81]\n",
      " [  29   17   10   76   28  690   26    1    6    9]\n",
      " [  22    5   27    0   10   16  876    0    2    0]\n",
      " [   5   15   25    6   16    4    2  850    5  100]\n",
      " [  15   23   48   53   32   79   16    9  631   68]\n",
      " [  10    8   20   12  135   11    1   63    4  745]]\n",
      "--------------------------------\n",
      "val predicted: (59825,) ['5' '0' '4' ... '5' '0' '5']\n",
      "probabilities: (59825, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (175, 784) (175,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [16 10 24 20 23 30 22 18 18 19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.491 s \n",
      "\n",
      "Accuracy rate for 83.200000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       980\n",
      "           1       0.93      0.93      0.93      1135\n",
      "           2       0.81      0.80      0.81      1032\n",
      "           3       0.84      0.81      0.82      1010\n",
      "           4       0.74      0.91      0.81       982\n",
      "           5       0.77      0.79      0.78       892\n",
      "           6       0.90      0.91      0.90       958\n",
      "           7       0.88      0.87      0.87      1028\n",
      "           8       0.77      0.71      0.74       974\n",
      "           9       0.79      0.63      0.70      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 934    0    4    2    1   24   10    4    0    1]\n",
      " [   0 1052    4    2    1    3    3    0   69    1]\n",
      " [  15   26  827   18    8   13   31   16   70    8]\n",
      " [   9   10   37  820    3   66    4   11   33   17]\n",
      " [   4    2   26    1  891    8   10    5    4   31]\n",
      " [  29   10    8   78   22  703   26    2    8    6]\n",
      " [  24    4   29    0   10   15  872    0    4    0]\n",
      " [   5   15   22    2   17    2    2  890    8   65]\n",
      " [  18   10   46   47   26   72   14    8  692   41]\n",
      " [  14    6   17    9  230    8    1   79    6  639]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (225, 784) (225,)\n",
      "updated train set: (225, 784) (225,) unique(labels): [17 12 27 24 25 33 23 20 21 23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59775, 784) (59775,)\n",
      "\n",
      "Train set: (225, 784) y: (225,)\n",
      "Val   set: (59775, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 11.635 s \n",
      "\n",
      "Accuracy rate for 84.130000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91       980\n",
      "           1       0.94      0.92      0.93      1135\n",
      "           2       0.82      0.82      0.82      1032\n",
      "           3       0.82      0.82      0.82      1010\n",
      "           4       0.77      0.92      0.84       982\n",
      "           5       0.79      0.78      0.78       892\n",
      "           6       0.91      0.89      0.90       958\n",
      "           7       0.91      0.87      0.89      1028\n",
      "           8       0.78      0.71      0.74       974\n",
      "           9       0.80      0.70      0.75      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 934    0    5    2    1   27    7    3    0    1]\n",
      " [   0 1045    4    2    0    6    3    0   73    2]\n",
      " [  17   23  849   18    5   11   22   10   71    6]\n",
      " [   8   10   37  830    3   52    4    9   26   31]\n",
      " [   3    3   24    0  905    4   12    7    2   22]\n",
      " [  30    6   10   87   26  693   18    3   11    8]\n",
      " [  31    6   31    0   10   20  855    0    5    0]\n",
      " [   3   13   24    2   15    3    1  898    8   61]\n",
      " [  22    8   40   60   23   59   12    5  694   51]\n",
      " [  16    3   14   10  189    7    1   57    2  710]]\n",
      "--------------------------------\n",
      "val predicted: (59775,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59775, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (225, 784) (225,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [20 12 31 25 26 38 25 23 23 27] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.870 s \n",
      "\n",
      "Accuracy rate for 84.620000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       980\n",
      "           1       0.95      0.92      0.93      1135\n",
      "           2       0.81      0.85      0.83      1032\n",
      "           3       0.83      0.84      0.83      1010\n",
      "           4       0.76      0.90      0.83       982\n",
      "           5       0.78      0.78      0.78       892\n",
      "           6       0.92      0.87      0.90       958\n",
      "           7       0.87      0.88      0.88      1028\n",
      "           8       0.80      0.74      0.77       974\n",
      "           9       0.84      0.70      0.76      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.84      0.84     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 945    0    3    2    2   15    9    4    0    0]\n",
      " [   0 1044    5    2    0    4    4    0   75    1]\n",
      " [  16   19  876   12    8   12   20   17   48    4]\n",
      " [   6    7   38  847    2   46    1   20   26   17]\n",
      " [   4    3   25    1  886    3    9    6    3   42]\n",
      " [  25    5   13   89   33  698   15    2    7    5]\n",
      " [  28    4   50    0   11   18  838    0    8    1]\n",
      " [   4   10   30    8   19    2    0  906    2   47]\n",
      " [  18    9   26   48   28   80   12   14  718   21]\n",
      " [  16    3   14   12  172   12    0   70    6  704]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59750,) ['3' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 6 5]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (275, 784) (275,)\n",
      "updated train set: (275, 784) (275,) unique(labels): [20 14 33 28 29 40 26 27 29 29] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59725, 784) (59725,)\n",
      "\n",
      "Train set: (275, 784) y: (275,)\n",
      "Val   set: (59725, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 14.032 s \n",
      "\n",
      "Accuracy rate for 85.530000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       980\n",
      "           1       0.95      0.94      0.94      1135\n",
      "           2       0.83      0.86      0.85      1032\n",
      "           3       0.84      0.84      0.84      1010\n",
      "           4       0.78      0.90      0.83       982\n",
      "           5       0.79      0.80      0.80       892\n",
      "           6       0.92      0.87      0.90       958\n",
      "           7       0.87      0.89      0.88      1028\n",
      "           8       0.81      0.76      0.78       974\n",
      "           9       0.85      0.72      0.78      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.86      0.86      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 946    0    3    1    3   16    7    3    1    0]\n",
      " [   0 1064    2    2    0    7    3    0   55    2]\n",
      " [  13   18  887   15    5    9   21   13   48    3]\n",
      " [   6    4   34  849    1   39    3   19   33   22]\n",
      " [   3    2   25    0  880    3   10    8    4   47]\n",
      " [  28    6   14   78   26  713   16    2    5    4]\n",
      " [  26    3   51    0   13   16  838    0   10    1]\n",
      " [   4    8   18    6   29    7    0  914    7   35]\n",
      " [  14   11   23   49   24   72   10   14  739   18]\n",
      " [  15    2   10   12  150   15    0   74    8  723]]\n",
      "--------------------------------\n",
      "val predicted: (59725,) ['5' '0' '4' ... '5' '0' '5']\n",
      "probabilities: (59725, 10) \n",
      " [5 0 4 ... 5 2 5]\n",
      "trainset before (275, 784) (275,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [20 19 34 31 32 40 27 29 34 34] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.517 s \n",
      "\n",
      "Accuracy rate for 86.320000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       980\n",
      "           1       0.94      0.95      0.94      1135\n",
      "           2       0.84      0.85      0.85      1032\n",
      "           3       0.85      0.85      0.85      1010\n",
      "           4       0.81      0.90      0.85       982\n",
      "           5       0.81      0.80      0.81       892\n",
      "           6       0.93      0.88      0.91       958\n",
      "           7       0.88      0.89      0.89      1028\n",
      "           8       0.80      0.77      0.78       974\n",
      "           9       0.87      0.75      0.80      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 946    0    3    1    3   15    7    4    1    0]\n",
      " [   0 1074    3    2    1    4    3    0   48    0]\n",
      " [  13   18  882   15    5    9   22   14   51    3]\n",
      " [   5    4   33  859    2   37    2   17   44    7]\n",
      " [   2    4   22    0  888    3    6    7    4   46]\n",
      " [  33    9   12   69   26  717   13    2    6    5]\n",
      " [  26    3   49    0   10   15  845    0   10    0]\n",
      " [   3    9   21    3   24    4    0  916   10   38]\n",
      " [  13   14   20   47   23   71   11   11  751   13]\n",
      " [  14    6   10   10  118   10    0   68   19  754]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['5' '0' '4' ... '5' '0' '5']\n",
      "probabilities: (59700, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (325, 784) (325,)\n",
      "updated train set: (325, 784) (325,) unique(labels): [20 19 37 33 37 42 32 31 36 38] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59675, 784) (59675,)\n",
      "\n",
      "Train set: (325, 784) y: (325,)\n",
      "Val   set: (59675, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 16.516 s \n",
      "\n",
      "Accuracy rate for 86.460000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       980\n",
      "           1       0.95      0.95      0.95      1135\n",
      "           2       0.83      0.87      0.85      1032\n",
      "           3       0.87      0.85      0.86      1010\n",
      "           4       0.80      0.91      0.85       982\n",
      "           5       0.81      0.80      0.81       892\n",
      "           6       0.91      0.91      0.91       958\n",
      "           7       0.88      0.88      0.88      1028\n",
      "           8       0.82      0.76      0.79       974\n",
      "           9       0.85      0.75      0.80      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 937    0    7    1    2   19   10    3    1    0]\n",
      " [   0 1075    3    2    1    5    3    0   46    0]\n",
      " [  15   13  894   16    5    9   21   11   44    4]\n",
      " [   7    3   37  859    1   37    6   17   31   12]\n",
      " [   1    4   24    0  889    2    5    3    4   50]\n",
      " [  29   11   11   57   26  714   29    2    7    6]\n",
      " [  18    4   40    0    6    7  874    0    9    0]\n",
      " [   3    7   21    2   31    7    0  903    8   46]\n",
      " [  19   14   24   39   22   65   15   17  743   16]\n",
      " [  13    5   13   11  124   12    0   65    8  758]]\n",
      "--------------------------------\n",
      "val predicted: (59675,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59675, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (325, 784) (325,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [23 20 38 39 37 47 33 34 39 40] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 17.881 s \n",
      "\n",
      "Accuracy rate for 87.160000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       980\n",
      "           1       0.95      0.95      0.95      1135\n",
      "           2       0.84      0.85      0.85      1032\n",
      "           3       0.87      0.86      0.87      1010\n",
      "           4       0.83      0.90      0.86       982\n",
      "           5       0.83      0.83      0.83       892\n",
      "           6       0.91      0.91      0.91       958\n",
      "           7       0.90      0.87      0.88      1028\n",
      "           8       0.82      0.79      0.81       974\n",
      "           9       0.84      0.78      0.81      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 948    0    4    2    1    9   13    2    1    0]\n",
      " [   0 1073    2    3    1    5    4    0   47    0]\n",
      " [  20   12  882   17    6    9   22    9   48    7]\n",
      " [   4    1   29  872    3   42    3   13   32   11]\n",
      " [   4    3   22    0  881    1    6    4    6   55]\n",
      " [  20   11   10   54   19  736   23    2    9    8]\n",
      " [  19    4   42    0    4   10  870    0    9    0]\n",
      " [   3    6   22    6   29    8    0  895    8   51]\n",
      " [  17   13   22   32   19   60   15   14  769   13]\n",
      " [  13    5   12   16   98   12    0   56    7  790]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59650, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [23 22 44 42 39 49 35 36 44 41] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 18.819 s \n",
      "\n",
      "Accuracy rate for 87.740000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94       980\n",
      "           1       0.95      0.96      0.95      1135\n",
      "           2       0.84      0.88      0.86      1032\n",
      "           3       0.88      0.85      0.87      1010\n",
      "           4       0.84      0.89      0.87       982\n",
      "           5       0.82      0.84      0.83       892\n",
      "           6       0.92      0.92      0.92       958\n",
      "           7       0.89      0.88      0.89      1028\n",
      "           8       0.85      0.78      0.82       974\n",
      "           9       0.85      0.79      0.82      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 944    0    4    2    1   12   14    2    1    0]\n",
      " [   0 1086    5    3    0    5    3    0   33    0]\n",
      " [  18    9  910   18    6    9   18    9   31    4]\n",
      " [   6    1   37  858    1   46    3   17   33    8]\n",
      " [   3    3   23    0  875    2    6    6    6   58]\n",
      " [  13   15    8   44   25  747   23    2    8    7]\n",
      " [  18    4   33    0    4    9  884    0    6    0]\n",
      " [   3    9   23    4   22    5    0  908    7   47]\n",
      " [  18   14   28   28   13   62   14   17  763   17]\n",
      " [  12    4   10   15   91   14    0   54   10  799]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59625, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [25 23 44 46 40 51 37 38 49 47] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 20.401 s \n",
      "\n",
      "Accuracy rate for 87.870000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       980\n",
      "           1       0.94      0.95      0.95      1135\n",
      "           2       0.84      0.88      0.86      1032\n",
      "           3       0.84      0.87      0.85      1010\n",
      "           4       0.86      0.90      0.88       982\n",
      "           5       0.85      0.83      0.84       892\n",
      "           6       0.91      0.92      0.92       958\n",
      "           7       0.89      0.89      0.89      1028\n",
      "           8       0.86      0.78      0.82       974\n",
      "           9       0.88      0.80      0.83      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 940    0    5    1    1   10   21    2    0    0]\n",
      " [   0 1082    6    8    0    4    3    0   32    0]\n",
      " [  15   12  903   16   11   11   20   12   28    4]\n",
      " [   7    2   34  875    2   44    3   13   21    9]\n",
      " [   3    3   24    2  879    2    6   11    7   45]\n",
      " [  20   12    9   49   20  741   21    1   12    7]\n",
      " [  18    3   36    1    4    7  883    0    6    0]\n",
      " [   1    8   19   16   17    3    1  916    6   41]\n",
      " [  12   17   30   59   15   43   13   14  764    7]\n",
      " [  11    6   12   16   73   11    0   66   10  804]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59600, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (425, 784) (425,)\n",
      "updated train set: (425, 784) (425,) unique(labels): [26 26 45 52 41 54 39 41 51 50] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59575, 784) (59575,)\n",
      "\n",
      "Train set: (425, 784) y: (425,)\n",
      "Val   set: (59575, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 21.273 s \n",
      "\n",
      "Accuracy rate for 88.160000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       980\n",
      "           1       0.94      0.96      0.95      1135\n",
      "           2       0.85      0.88      0.86      1032\n",
      "           3       0.85      0.88      0.87      1010\n",
      "           4       0.87      0.88      0.87       982\n",
      "           5       0.85      0.84      0.84       892\n",
      "           6       0.91      0.93      0.92       958\n",
      "           7       0.87      0.89      0.88      1028\n",
      "           8       0.88      0.79      0.83       974\n",
      "           9       0.87      0.80      0.83      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 942    0    6    1    0    9   19    2    1    0]\n",
      " [   0 1084    6   11    0    4    3    0   27    0]\n",
      " [  16   10  907   16   12    9   21   11   28    2]\n",
      " [   3    3   33  892    0   41    2   13   15    8]\n",
      " [   3    4   24    2  864    2    6   20    4   53]\n",
      " [  16   11   11   47   21  751   17    1   11    6]\n",
      " [  14    3   31    0    6   10  887    1    6    0]\n",
      " [   1   13   18   13   16    5    1  911    6   44]\n",
      " [  12   17   25   54   15   42   15   13  772    9]\n",
      " [   9    5   11   13   64   15    0   78    8  806]]\n",
      "--------------------------------\n",
      "val predicted: (59575,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59575, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (425, 784) (425,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [26 26 47 55 43 59 40 43 59 52] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 22.218 s \n",
      "\n",
      "Accuracy rate for 88.240000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       980\n",
      "           1       0.94      0.95      0.95      1135\n",
      "           2       0.85      0.88      0.87      1032\n",
      "           3       0.86      0.88      0.87      1010\n",
      "           4       0.86      0.88      0.87       982\n",
      "           5       0.83      0.84      0.83       892\n",
      "           6       0.92      0.93      0.92       958\n",
      "           7       0.87      0.89      0.88      1028\n",
      "           8       0.87      0.80      0.83       974\n",
      "           9       0.87      0.81      0.84      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 943    0    4    2    0   10   17    2    2    0]\n",
      " [   0 1083   10   10    0    4    3    1   24    0]\n",
      " [  13   12  910   13   15    8   16   10   33    2]\n",
      " [   0    2   27  889    1   51    2   14   17    7]\n",
      " [   3    3   21    3  861    5    6   18    6   56]\n",
      " [  16   11    9   42   23  745   17    2   19    8]\n",
      " [  15    3   33    0    5    8  889    1    4    0]\n",
      " [   2   14   18   12   17    6    1  914    5   39]\n",
      " [   9   15   27   51   16   48   13   12  777    6]\n",
      " [  10    7    8   17   60   14    1   72    7  813]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59550,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59550, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (475, 784) (475,)\n",
      "updated train set: (475, 784) (475,) unique(labels): [28 28 47 60 44 63 41 49 61 54] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59525, 784) (59525,)\n",
      "\n",
      "Train set: (475, 784) y: (475,)\n",
      "Val   set: (59525, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 23.657 s \n",
      "\n",
      "Accuracy rate for 88.420000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       980\n",
      "           1       0.95      0.96      0.95      1135\n",
      "           2       0.86      0.86      0.86      1032\n",
      "           3       0.83      0.89      0.86      1010\n",
      "           4       0.87      0.90      0.88       982\n",
      "           5       0.83      0.84      0.84       892\n",
      "           6       0.93      0.93      0.93       958\n",
      "           7       0.88      0.89      0.88      1028\n",
      "           8       0.88      0.79      0.83       974\n",
      "           9       0.87      0.81      0.84      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 951    0    3    1    0    7   15    2    1    0]\n",
      " [   0 1091    6    8    0    3    3    1   23    0]\n",
      " [  16   16  891   19   14    7   19   16   33    1]\n",
      " [   1    3   27  894    2   52    1   13   10    7]\n",
      " [   3    2   18    2  879    4    4   19    4   47]\n",
      " [  17    7   10   51   13  749   16    0   19   10]\n",
      " [  14    4   29    1    6   10  889    0    5    0]\n",
      " [   1   12   16   15   15    4    0  913    5   47]\n",
      " [   9   12   25   62   15   48   13   13  766   11]\n",
      " [  11    6    6   20   61   14    0   64    8  819]]\n",
      "--------------------------------\n",
      "val predicted: (59525,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59525, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (475, 784) (475,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [30 29 48 63 46 67 43 50 65 59] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 25.054 s \n",
      "\n",
      "Accuracy rate for 88.130000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       980\n",
      "           1       0.94      0.96      0.95      1135\n",
      "           2       0.87      0.85      0.86      1032\n",
      "           3       0.82      0.88      0.85      1010\n",
      "           4       0.89      0.90      0.89       982\n",
      "           5       0.83      0.84      0.83       892\n",
      "           6       0.92      0.94      0.93       958\n",
      "           7       0.88      0.88      0.88      1028\n",
      "           8       0.86      0.78      0.82       974\n",
      "           9       0.86      0.82      0.84      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 936    0    6    1    0   20   13    1    2    1]\n",
      " [   0 1093    3    7    0    2    3    1   26    0]\n",
      " [  21   18  881   19   12    6   19   16   38    2]\n",
      " [   4    3   23  890    3   49    5   12   14    7]\n",
      " [   3    2   18    1  879    3    4   13    5   54]\n",
      " [  23    8    7   55   11  745   16    0   17   10]\n",
      " [  11    4   26    1    3   10  899    0    4    0]\n",
      " [   5   10   17   18   16    5    0  900    5   52]\n",
      " [   8   15   26   68   15   45   14   16  761    6]\n",
      " [  12    6    6   19   54   12    0   59   12  829]]\n",
      "--------------------------------\n",
      "final active learning accuracies [48.209999999999994, 59.870000000000005, 70.07, 73.88, 79.62, 80.99, 82.69999999999999, 83.2, 84.13000000000001, 84.61999999999999, 85.53, 86.32, 86.46000000000001, 87.16000000000001, 87.74, 87.87, 88.16000000000001, 88.24, 88.42, 88.13]\n",
      "saved Active-learning-experiment-9.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', '.ipynb_checkpoints', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 10, using model = SvmModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
      "\n",
      "initial random chosen samples (10,)\n",
      "initial train set: (10, 784) (10,) unique(labels): [0 3 0 2 0 0 1 2 0 2] [1 3 6 7 9]\n",
      "val set: (59990, 784) (59990,) (10,)\n",
      "\n",
      "Train set: (10, 784) y: (10,)\n",
      "Val   set: (59990, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.577 s \n",
      "\n",
      "Accuracy rate for 24.410000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       980\n",
      "           1       0.18      0.98      0.31      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.29      0.32      0.31      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.72      0.38      0.49       958\n",
      "           7       0.31      0.27      0.29      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.26      0.37      0.30      1009\n",
      "\n",
      "    accuracy                           0.24     10000\n",
      "   macro avg       0.18      0.23      0.17     10000\n",
      "weighted avg       0.18      0.24      0.17     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[   0  676    0  159    0    0   43   83    0   19]\n",
      " [   0 1108    0    1    0    0    0    2    0   24]\n",
      " [   0  822    0   71    0    0   43   40    0   56]\n",
      " [   0  584    0  327    0    0    4   34    0   61]\n",
      " [   0  516    0   88    0    0   21   60    0  297]\n",
      " [   0  502    0  166    0    0   23   67    0  134]\n",
      " [   0   96    0  122    0    0  360  158    0  222]\n",
      " [   0  598    0   23    0    0    0  274    0  133]\n",
      " [   0  720    0   58    0    0    5   59    0  132]\n",
      " [   0  423    0  103    0    0    0  111    0  372]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59990,) ['7' '1' '3' ... '7' '6' '1']\n",
      "probabilities: (59990, 5) \n",
      " [3 0 4 ... 3 4 0]\n",
      "trainset before (10, 784) (10,)\n",
      "trainset after (20, 784) (20,)\n",
      "updated train set: (20, 784) (20,) unique(labels): [0 5 1 4 0 2 1 3 1 3] [1 2 3 5 6 7 8 9]\n",
      "val set: (59980, 784) (59980,)\n",
      "\n",
      "Train set: (20, 784) y: (20,)\n",
      "Val   set: (59980, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 1.108 s \n",
      "\n",
      "Accuracy rate for 39.120000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       980\n",
      "           1       0.50      0.95      0.66      1135\n",
      "           2       0.20      0.05      0.08      1032\n",
      "           3       0.37      0.84      0.52      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.16      0.34      0.22       892\n",
      "           6       0.75      0.33      0.46       958\n",
      "           7       0.63      0.64      0.64      1028\n",
      "           8       0.54      0.03      0.06       974\n",
      "           9       0.32      0.62      0.42      1009\n",
      "\n",
      "    accuracy                           0.39     10000\n",
      "   macro avg       0.35      0.38      0.31     10000\n",
      "weighted avg       0.35      0.39      0.31     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[   0   34   24  165    0  648   21   72    0   16]\n",
      " [   0 1075    1    4    0    1    0    0    0   54]\n",
      " [   0  397   52  321    0  137   40   56    3   26]\n",
      " [   0   67    5  850    0   30    5   15    0   38]\n",
      " [   0   76    7   65    0  188   11   31    3  601]\n",
      " [   0  114    3  268    0  302   25   24    8  148]\n",
      " [   0  112  160   68    0   47  319   37    0  215]\n",
      " [   0   87    9   66    0  104    0  661    7   94]\n",
      " [   0  152    0  402    0  205    3   37   29  146]\n",
      " [   0   19    0   64    0  181    0  117    4  624]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59980,) ['3' '5' '3' ... '5' '6' '5']\n",
      "probabilities: (59980, 8) \n",
      " [2 5 2 ... 2 5 5]\n",
      "trainset before (20, 784) (20,)\n",
      "trainset after (30, 784) (30,)\n",
      "updated train set: (30, 784) (30,) unique(labels): [3 5 2 4 1 2 1 6 2 4] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59970, 784) (59970,)\n",
      "\n",
      "Train set: (30, 784) y: (30,)\n",
      "Val   set: (59970, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 1.655 s \n",
      "\n",
      "Accuracy rate for 51.550000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.85      0.74       980\n",
      "           1       0.61      0.92      0.74      1135\n",
      "           2       0.56      0.32      0.41      1032\n",
      "           3       0.47      0.82      0.60      1010\n",
      "           4       0.32      0.04      0.07       982\n",
      "           5       0.75      0.22      0.34       892\n",
      "           6       0.83      0.28      0.42       958\n",
      "           7       0.49      0.86      0.63      1028\n",
      "           8       0.67      0.14      0.24       974\n",
      "           9       0.30      0.58      0.40      1009\n",
      "\n",
      "    accuracy                           0.52     10000\n",
      "   macro avg       0.57      0.50      0.46     10000\n",
      "weighted avg       0.56      0.52      0.46     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 835   10   11   33    0    6   20   52    1   12]\n",
      " [   0 1045    1    2    0    0    0    1    1   85]\n",
      " [  64  237  334  175    0    1   13  170   11   27]\n",
      " [   9   37   13  829    2    4    3   36    0   77]\n",
      " [ 143   50   28   23   36    8    8  123   19  544]\n",
      " [  34  133    8  266   35  194    9   54   19  140]\n",
      " [ 101   71  188   40    4    3  270   73    0  208]\n",
      " [  26   41    7    1    6    0    0  885    8   54]\n",
      " [  20   69    3  385    2   21    2  111  141  220]\n",
      " [  54    7    1   21   27   20    0  283   10  586]]\n",
      "--------------------------------\n",
      "val predicted: (59970,) ['7' '0' '0' ... '5' '6' '8']\n",
      "probabilities: (59970, 10) \n",
      " [7 0 5 ... 3 7 1]\n",
      "trainset before (30, 784) (30,)\n",
      "trainset after (40, 784) (40,)\n",
      "updated train set: (40, 784) (40,) unique(labels): [3 7 3 6 1 3 2 7 3 5] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59960, 784) (59960,)\n",
      "\n",
      "Train set: (40, 784) y: (40,)\n",
      "Val   set: (59960, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.183 s \n",
      "\n",
      "Accuracy rate for 58.150000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.83      0.74       980\n",
      "           1       0.68      0.99      0.80      1135\n",
      "           2       0.68      0.45      0.54      1032\n",
      "           3       0.51      0.76      0.61      1010\n",
      "           4       0.42      0.03      0.06       982\n",
      "           5       0.62      0.34      0.44       892\n",
      "           6       0.81      0.45      0.58       958\n",
      "           7       0.44      0.89      0.59      1028\n",
      "           8       0.66      0.48      0.56       974\n",
      "           9       0.46      0.49      0.48      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.60      0.57      0.54     10000\n",
      "weighted avg       0.60      0.58      0.55     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 809    3    7   15    0   49   29   44   23    1]\n",
      " [   0 1123    3    1    0    0    4    0    1    3]\n",
      " [  62  133  468  146    0   19   23  134   43    4]\n",
      " [   6   61   20  769    1   29    3   58   40   23]\n",
      " [ 131   54   17   25   30   35   23  256   11  400]\n",
      " [  20  103   13  250    9  307   16   51   93   30]\n",
      " [  92   47  112  110    0    7  434  113   12   31]\n",
      " [  22   42    7    5    6    2    0  912    1   31]\n",
      " [  16   77   32  167    0   20    2  137  469   54]\n",
      " [  54   14    8   17   25   28    0  354   15  494]]\n",
      "--------------------------------\n",
      "val predicted: (59960,) ['7' '0' '0' ... '5' '6' '1']\n",
      "probabilities: (59960, 10) \n",
      " [7 0 0 ... 9 3 7]\n",
      "trainset before (40, 784) (40,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [4 7 6 6 2 5 3 8 3 6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.715 s \n",
      "\n",
      "Accuracy rate for 64.190000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       980\n",
      "           1       0.75      0.99      0.85      1135\n",
      "           2       0.61      0.71      0.65      1032\n",
      "           3       0.57      0.75      0.65      1010\n",
      "           4       0.69      0.25      0.37       982\n",
      "           5       0.57      0.49      0.53       892\n",
      "           6       0.89      0.46      0.61       958\n",
      "           7       0.53      0.86      0.66      1028\n",
      "           8       0.76      0.43      0.55       974\n",
      "           9       0.48      0.50      0.49      1009\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.67      0.63      0.62     10000\n",
      "weighted avg       0.67      0.64      0.62     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 868    3   13   15    0   23   18   28   12    0]\n",
      " [   0 1122    4    1    0    0    2    0    1    5]\n",
      " [  45   64  728   79    3   23    5   62   20    3]\n",
      " [   5   43   40  762    3   48    3   50   33   23]\n",
      " [  43   23   33   23  246  102   15  156    6  335]\n",
      " [  15   88   12  233   20  437   12   21   43   11]\n",
      " [  37   36  262   65    4   23  441   23    6   61]\n",
      " [  10   36   13    6   19    7    0  889    2   46]\n",
      " [  14   68   80  132    8   56    1  127  420   68]\n",
      " [  31   11   16   14   56   52    0  313   10  506]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['5' '0' '0' ... '5' '6' '1']\n",
      "probabilities: (59950, 10) \n",
      " [5 0 0 ... 5 6 7]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (60, 784) (60,)\n",
      "updated train set: (60, 784) (60,) unique(labels): [4 7 9 6 2 7 4 9 4 8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59940, 784) (59940,)\n",
      "\n",
      "Train set: (60, 784) y: (60,)\n",
      "Val   set: (59940, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.253 s \n",
      "\n",
      "Accuracy rate for 67.330000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       980\n",
      "           1       0.77      0.99      0.87      1135\n",
      "           2       0.64      0.73      0.68      1032\n",
      "           3       0.62      0.66      0.64      1010\n",
      "           4       0.73      0.21      0.33       982\n",
      "           5       0.50      0.61      0.55       892\n",
      "           6       0.92      0.69      0.79       958\n",
      "           7       0.59      0.87      0.70      1028\n",
      "           8       0.82      0.50      0.62       974\n",
      "           9       0.53      0.56      0.54      1009\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.69      0.67      0.66     10000\n",
      "weighted avg       0.70      0.67      0.66     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 827    3   19    6    0  102   10    6    7    0]\n",
      " [   0 1120    3    1    0    1    6    0    1    3]\n",
      " [  35   55  754   71    0   32    8   52   23    2]\n",
      " [   5   35   41  670    3  154    0   39   38   25]\n",
      " [  41   15   64   27  211   93   19  152    5  355]\n",
      " [  14   91   22  162   14  545    6   14   15    9]\n",
      " [  24   27  161   21    2   50  658    8    4    3]\n",
      " [  10   21   19    7   13    3    0  897    0   58]\n",
      " [  13   72   78  101    1   75    6   86  485   57]\n",
      " [  34   10   23   12   45   31    0  278   10  566]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59940,) ['5' '0' '0' ... '5' '6' '8']\n",
      "probabilities: (59940, 10) \n",
      " [5 0 0 ... 5 6 5]\n",
      "trainset before (60, 784) (60,)\n",
      "trainset after (70, 784) (70,)\n",
      "updated train set: (70, 784) (70,) unique(labels): [ 4  7 10  7  4  7  4  9  9  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59930, 784) (59930,)\n",
      "\n",
      "Train set: (70, 784) y: (70,)\n",
      "Val   set: (59930, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.790 s \n",
      "\n",
      "Accuracy rate for 72.460000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86       980\n",
      "           1       0.82      0.98      0.89      1135\n",
      "           2       0.65      0.81      0.72      1032\n",
      "           3       0.66      0.73      0.69      1010\n",
      "           4       0.74      0.51      0.61       982\n",
      "           5       0.56      0.60      0.58       892\n",
      "           6       0.93      0.68      0.79       958\n",
      "           7       0.71      0.85      0.77      1028\n",
      "           8       0.83      0.59      0.69       974\n",
      "           9       0.57      0.61      0.59      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.72      0.72     10000\n",
      "weighted avg       0.74      0.72      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 799    2   40   10    0  111    9    2    5    2]\n",
      " [   0 1117    4    3    0    0    6    0    2    3]\n",
      " [  25   20  841   46    2   24    9   33   27    5]\n",
      " [   5   20   44  733    2  127    0   26   43   10]\n",
      " [   3   11   65   17  504   20   20   55    2  285]\n",
      " [  10   82   23  176   15  537    5   15   20    9]\n",
      " [  15   26  183   19    1   47  654    3    4    6]\n",
      " [   2   21   21   16   18    3    0  877    0   70]\n",
      " [  17   57   59   69   10   68    4   54  572   64]\n",
      " [  13   11   18   14  128   23    0  178   12  612]]\n",
      "--------------------------------\n",
      "val predicted: (59930,) ['5' '0' '5' ... '5' '6' '8']\n",
      "probabilities: (59930, 10) \n",
      " [5 0 5 ... 5 6 8]\n",
      "trainset before (70, 784) (70,)\n",
      "trainset after (80, 784) (80,)\n",
      "updated train set: (80, 784) (80,) unique(labels): [ 5  8 11  9  4  8  5  9 10 11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59920, 784) (59920,)\n",
      "\n",
      "Train set: (80, 784) y: (80,)\n",
      "Val   set: (59920, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.318 s \n",
      "\n",
      "Accuracy rate for 73.940000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       980\n",
      "           1       0.84      0.99      0.91      1135\n",
      "           2       0.71      0.86      0.78      1032\n",
      "           3       0.70      0.80      0.75      1010\n",
      "           4       0.74      0.46      0.56       982\n",
      "           5       0.62      0.57      0.60       892\n",
      "           6       0.91      0.67      0.77       958\n",
      "           7       0.75      0.84      0.79      1028\n",
      "           8       0.81      0.62      0.70       974\n",
      "           9       0.55      0.64      0.59      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.73      0.73     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 870    1   15   10    0   72    4    0    7    1]\n",
      " [   0 1118    4    3    0    0    7    0    1    2]\n",
      " [  21   10  885   35    3   24    7   27   16    4]\n",
      " [   9   12   40  812    2   54    2   19   52    8]\n",
      " [   9   11   35   15  447   31   23   39    4  368]\n",
      " [  30   79   19  185    9  509    9    7   41    4]\n",
      " [  52   13  171   15    1   45  643    4    9    5]\n",
      " [   8   17   19   14   17   11    1  865    3   73]\n",
      " [  37   61   49   53    6   47    9   42  604   66]\n",
      " [  27    8   11   18  121   22    0  151   10  641]]\n",
      "--------------------------------\n",
      "val predicted: (59920,) ['5' '0' '3' ... '5' '6' '8']\n",
      "probabilities: (59920, 10) \n",
      " [5 0 5 ... 5 6 8]\n",
      "trainset before (80, 784) (80,)\n",
      "trainset after (90, 784) (90,)\n",
      "updated train set: (90, 784) (90,) unique(labels): [ 5  8 11 11  5 10  7 10 11 12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59910, 784) (59910,)\n",
      "\n",
      "Train set: (90, 784) y: (90,)\n",
      "Val   set: (59910, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.864 s \n",
      "\n",
      "Accuracy rate for 78.060000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       980\n",
      "           1       0.88      0.99      0.93      1135\n",
      "           2       0.78      0.85      0.82      1032\n",
      "           3       0.73      0.87      0.79      1010\n",
      "           4       0.71      0.67      0.69       982\n",
      "           5       0.64      0.63      0.63       892\n",
      "           6       0.91      0.78      0.84       958\n",
      "           7       0.82      0.87      0.85      1028\n",
      "           8       0.86      0.62      0.72       974\n",
      "           9       0.62      0.61      0.62      1009\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.78      0.78      0.77     10000\n",
      "weighted avg       0.78      0.78      0.78     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 855    0   16    7    1   94    3    0    4    0]\n",
      " [   0 1118    3    3    0    0    6    0    2    3]\n",
      " [  22    8  877   30    7   34   11   22   13    8]\n",
      " [  10    9   30  875    3   33    2   15   25    8]\n",
      " [   6    8   18    3  655   21   18    7    2  244]\n",
      " [  22   43   13  174    8  563   17    4   41    7]\n",
      " [  37    7  108   13    2   40  743    4    0    4]\n",
      " [   4   18   17   14   24    5    0  894    0   52]\n",
      " [  31   51   30   62   10   79   16   33  607   55]\n",
      " [  22    5    7   12  209   15    0  107   13  619]]\n",
      "--------------------------------\n",
      "val predicted: (59910,) ['3' '0' '9' ... '5' '6' '5']\n",
      "probabilities: (59910, 10) \n",
      " [3 0 9 ... 5 6 5]\n",
      "trainset before (90, 784) (90,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 5  8 12 11  7 12  9 11 12 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.344 s \n",
      "\n",
      "Accuracy rate for 78.570000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       980\n",
      "           1       0.90      0.99      0.94      1135\n",
      "           2       0.73      0.84      0.78      1032\n",
      "           3       0.78      0.87      0.82      1010\n",
      "           4       0.67      0.63      0.65       982\n",
      "           5       0.68      0.73      0.70       892\n",
      "           6       0.90      0.83      0.86       958\n",
      "           7       0.80      0.84      0.82      1028\n",
      "           8       0.88      0.63      0.73       974\n",
      "           9       0.64      0.61      0.62      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.78      0.78     10000\n",
      "weighted avg       0.79      0.79      0.78     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 845    0   25    9    1   93    2    0    5    0]\n",
      " [   0 1119    3    4    0    1    5    0    1    2]\n",
      " [  18    8  866   24    2   26   14   45   24    5]\n",
      " [   6    9   33  876    4   36    5   16   20    5]\n",
      " [   2    5   72    2  622    6   18   28    3  224]\n",
      " [  21   28   15  123   15  647   23    2   15    3]\n",
      " [  12    6   94    6   15   28  791    3    1    2]\n",
      " [   5   15   22   16   34   12    1  867    0   56]\n",
      " [  25   47   43   54   16   82   17   30  612   48]\n",
      " [  21    8   13   13  222   18    0   91   11  612]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59900,) ['5' '0' '9' ... '5' '6' '5']\n",
      "probabilities: (59900, 10) \n",
      " [5 0 2 ... 5 6 5]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (110, 784) (110,)\n",
      "updated train set: (110, 784) (110,) unique(labels): [ 6  8 14 13  8 12  9 14 13 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59890, 784) (59890,)\n",
      "\n",
      "Train set: (110, 784) y: (110,)\n",
      "Val   set: (59890, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.817 s \n",
      "\n",
      "Accuracy rate for 79.010000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86       980\n",
      "           1       0.90      0.98      0.94      1135\n",
      "           2       0.70      0.81      0.75      1032\n",
      "           3       0.75      0.88      0.81      1010\n",
      "           4       0.68      0.70      0.69       982\n",
      "           5       0.70      0.71      0.70       892\n",
      "           6       0.91      0.82      0.86       958\n",
      "           7       0.81      0.86      0.83      1028\n",
      "           8       0.89      0.64      0.75       974\n",
      "           9       0.70      0.62      0.66      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 832    1   38   11    1   93    1    0    3    0]\n",
      " [   0 1109    2    6    0    1    5    9    1    2]\n",
      " [  35    7  836   29    4   26   14   49   27    5]\n",
      " [   5    6   30  892    4   27    4   16   18    8]\n",
      " [   1    5   86   16  684    2   13   17    1  157]\n",
      " [  23   31   12  138   15  630   23    3   16    1]\n",
      " [  14    7   99    7   15   26  786    3    1    0]\n",
      " [   4    8   20   12   36   14    1  881    0   52]\n",
      " [  16   47   47   64   16   73   12   29  627   43]\n",
      " [  19    7   18   18  224   14    1   77    7  624]]\n",
      "--------------------------------\n",
      "val predicted: (59890,) ['5' '0' '3' ... '5' '6' '5']\n",
      "probabilities: (59890, 10) \n",
      " [5 0 3 ... 5 6 5]\n",
      "trainset before (110, 784) (110,)\n",
      "trainset after (120, 784) (120,)\n",
      "updated train set: (120, 784) (120,) unique(labels): [ 8 10 17 13 10 12  9 14 13 14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59880, 784) (59880,)\n",
      "\n",
      "Train set: (120, 784) y: (120,)\n",
      "Val   set: (59880, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.249 s \n",
      "\n",
      "Accuracy rate for 78.680000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87       980\n",
      "           1       0.89      0.98      0.93      1135\n",
      "           2       0.64      0.82      0.72      1032\n",
      "           3       0.78      0.87      0.82      1010\n",
      "           4       0.69      0.64      0.66       982\n",
      "           5       0.75      0.68      0.72       892\n",
      "           6       0.92      0.78      0.85       958\n",
      "           7       0.84      0.85      0.84      1028\n",
      "           8       0.89      0.63      0.74       974\n",
      "           9       0.68      0.66      0.67      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.78      0.78     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 889    0   13    5    3   65    3    1    1    0]\n",
      " [   0 1114    2    4    0    0    3    7    1    4]\n",
      " [  34   10  850   26    6   22   13   38   30    3]\n",
      " [  24   12   23  881    3   21    4   16   18    8]\n",
      " [   1    4  134   16  627    0    6   13    1  180]\n",
      " [  40   25   37  118   18  611   21    3   15    4]\n",
      " [  20    8  127    6   21   23  748    4    1    0]\n",
      " [   4   24   18    8   26    3    0  871    1   73]\n",
      " [  29   48   79   50   20   58   14   24  612   40]\n",
      " [  17    8   35   15  184   13    0   64    8  665]]\n",
      "--------------------------------\n",
      "val predicted: (59880,) ['5' '0' '3' ... '5' '6' '5']\n",
      "probabilities: (59880, 10) \n",
      " [5 0 3 ... 5 6 5]\n",
      "trainset before (120, 784) (120,)\n",
      "trainset after (130, 784) (130,)\n",
      "updated train set: (130, 784) (130,) unique(labels): [ 8 10 19 15 11 14 10 15 14 14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59870, 784) (59870,)\n",
      "\n",
      "Train set: (130, 784) y: (130,)\n",
      "Val   set: (59870, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.873 s \n",
      "\n",
      "Accuracy rate for 79.800000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       980\n",
      "           1       0.89      0.98      0.93      1135\n",
      "           2       0.63      0.87      0.73      1032\n",
      "           3       0.78      0.89      0.83      1010\n",
      "           4       0.71      0.69      0.70       982\n",
      "           5       0.77      0.71      0.74       892\n",
      "           6       0.93      0.76      0.84       958\n",
      "           7       0.84      0.86      0.85      1028\n",
      "           8       0.92      0.64      0.76       974\n",
      "           9       0.74      0.64      0.68      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.81      0.79      0.79     10000\n",
      "weighted avg       0.81      0.80      0.80     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 881    0   15   10    2   67    5    0    0    0]\n",
      " [   0 1112    5    3    0    0    1    7    2    5]\n",
      " [  28    7  899   16    4   17   16   24   18    3]\n",
      " [   8   11   33  894    4   22    1   14   15    8]\n",
      " [   1    5  144   15  674    2    9   11    3  118]\n",
      " [  34   26   30  120   20  632   18    2    4    6]\n",
      " [  21    6  155    3   18   22  729    3    1    0]\n",
      " [   4   21   26    7   25    3    0  889    0   53]\n",
      " [  26   47   79   56   17   50    8   29  625   37]\n",
      " [  17    9   39   16  184   11    0   80    8  645]]\n",
      "--------------------------------\n",
      "val predicted: (59870,) ['5' '0' '2' ... '5' '6' '8']\n",
      "probabilities: (59870, 10) \n",
      " [5 0 2 ... 5 6 8]\n",
      "trainset before (130, 784) (130,)\n",
      "trainset after (140, 784) (140,)\n",
      "updated train set: (140, 784) (140,) unique(labels): [ 8 10 21 15 12 17 11 17 15 14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59860, 784) (59860,)\n",
      "\n",
      "Train set: (140, 784) y: (140,)\n",
      "Val   set: (59860, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 7.349 s \n",
      "\n",
      "Accuracy rate for 80.790000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       980\n",
      "           1       0.90      0.98      0.94      1135\n",
      "           2       0.65      0.89      0.75      1032\n",
      "           3       0.83      0.87      0.85      1010\n",
      "           4       0.71      0.75      0.73       982\n",
      "           5       0.76      0.78      0.77       892\n",
      "           6       0.93      0.76      0.84       958\n",
      "           7       0.84      0.87      0.85      1028\n",
      "           8       0.92      0.66      0.77       974\n",
      "           9       0.75      0.61      0.67      1009\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.82      0.80      0.80     10000\n",
      "weighted avg       0.82      0.81      0.81     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 858    0   30    5    2   74    7    3    0    1]\n",
      " [   0 1115    5    3    0    0    1    5    1    5]\n",
      " [  21    7  919   15    3    7   10   26   21    3]\n",
      " [   9   10   33  877    4   31    4   18   16    8]\n",
      " [   1    5  113   10  735    0    8   23    4   83]\n",
      " [  27   29   33   68   14  694   18    2    3    4]\n",
      " [  21    6  153    3   15   23  729    6    2    0]\n",
      " [   3   20   19    7   23    6    0  891    2   57]\n",
      " [  20   42   69   53   16   62   10   16  644   42]\n",
      " [  17    5   36   13  223   13    0   77    8  617]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59860,) ['5' '0' '2' ... '5' '6' '8']\n",
      "probabilities: (59860, 10) \n",
      " [5 0 2 ... 5 6 8]\n",
      "trainset before (140, 784) (140,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [10 10 21 17 14 18 11 17 15 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 7.829 s \n",
      "\n",
      "Accuracy rate for 81.540000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       980\n",
      "           1       0.91      0.98      0.95      1135\n",
      "           2       0.66      0.89      0.76      1032\n",
      "           3       0.81      0.87      0.84      1010\n",
      "           4       0.78      0.75      0.77       982\n",
      "           5       0.75      0.77      0.76       892\n",
      "           6       0.93      0.75      0.83       958\n",
      "           7       0.87      0.82      0.84      1028\n",
      "           8       0.91      0.67      0.77       974\n",
      "           9       0.74      0.74      0.74      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.81      0.81     10000\n",
      "weighted avg       0.83      0.82      0.82     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 866    0   34    4    1   69    4    2    0    0]\n",
      " [   0 1117    4    5    0    1    0    5    1    2]\n",
      " [  11    7  923   14    5   12   11   22   21    6]\n",
      " [   4    8   39  881    1   27    4   17   15   14]\n",
      " [   1    3   97   16  735    1    8   21    4   96]\n",
      " [  31   18   30   86    9  685   21    1    5    6]\n",
      " [  37    5  147    4   21   20  717    5    2    0]\n",
      " [   2   18   22    2   19   19    0  838    2  106]\n",
      " [  16   40   70   58   18   68   10   15  648   31]\n",
      " [   9    6   37   15  130   15    0   42   11  744]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['5' '0' '2' ... '5' '6' '8']\n",
      "probabilities: (59850, 10) \n",
      " [5 0 2 ... 5 6 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (160, 784) (160,)\n",
      "updated train set: (160, 784) (160,) unique(labels): [10 11 21 18 14 19 12 18 18 19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59840, 784) (59840,)\n",
      "\n",
      "Train set: (160, 784) y: (160,)\n",
      "Val   set: (59840, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 8.432 s \n",
      "\n",
      "Accuracy rate for 82.210000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       980\n",
      "           1       0.91      0.98      0.94      1135\n",
      "           2       0.69      0.88      0.77      1032\n",
      "           3       0.82      0.88      0.85      1010\n",
      "           4       0.80      0.74      0.77       982\n",
      "           5       0.74      0.77      0.75       892\n",
      "           6       0.92      0.78      0.84       958\n",
      "           7       0.86      0.84      0.85      1028\n",
      "           8       0.91      0.67      0.77       974\n",
      "           9       0.74      0.78      0.76      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.83      0.82      0.82     10000\n",
      "weighted avg       0.83      0.82      0.82     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 861    0   34    4    1   74    3    1    1    1]\n",
      " [   0 1108   11    4    0    1    2    7    1    1]\n",
      " [  11    6  910   17    3   12   14   30   18   11]\n",
      " [   4    9   31  891    2   25    3   14   16   15]\n",
      " [   1    4   88   10  722    3   10   15    4  125]\n",
      " [  28   19   24   93    9  684   23    1    8    3]\n",
      " [  28    4  121    3   22   24  744    5    6    1]\n",
      " [   2   16   25    2   16   15    0  863    2   87]\n",
      " [  15   42   56   49   16   78    7   21  654   36]\n",
      " [  11    6   22   13  111   11    0   46    5  784]]\n",
      "--------------------------------\n",
      "val predicted: (59840,) ['5' '0' '2' ... '5' '6' '5']\n",
      "probabilities: (59840, 10) \n",
      " [5 0 2 ... 5 6 8]\n",
      "trainset before (160, 784) (160,)\n",
      "trainset after (170, 784) (170,)\n",
      "updated train set: (170, 784) (170,) unique(labels): [10 11 22 19 16 19 13 19 21 20] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59830, 784) (59830,)\n",
      "\n",
      "Train set: (170, 784) y: (170,)\n",
      "Val   set: (59830, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 8.987 s \n",
      "\n",
      "Accuracy rate for 82.080000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88       980\n",
      "           1       0.92      0.98      0.95      1135\n",
      "           2       0.69      0.88      0.77      1032\n",
      "           3       0.80      0.88      0.84      1010\n",
      "           4       0.78      0.77      0.78       982\n",
      "           5       0.75      0.75      0.75       892\n",
      "           6       0.92      0.78      0.85       958\n",
      "           7       0.85      0.83      0.84      1028\n",
      "           8       0.90      0.68      0.77       974\n",
      "           9       0.76      0.74      0.75      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.83      0.82      0.82     10000\n",
      "weighted avg       0.83      0.82      0.82     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 856    0   33    5    1   78    2    3    1    1]\n",
      " [   0 1107    9    3    0    1    2   11    1    1]\n",
      " [  15    5  903   19    3   16   16   21   26    8]\n",
      " [   6    8   29  892    3   22    3   16   18   13]\n",
      " [   1    2   87   17  759    1   10   18    3   84]\n",
      " [  29   18   24   98   12  672   22    1   13    3]\n",
      " [  30    4  115    3   23   21  751    5    6    0]\n",
      " [   3   12   22    3   14   15    0  856    1  102]\n",
      " [  16   46   55   54   20   65    6   22  661   29]\n",
      " [  12    5   25   17  133    8    0   51    7  751]]\n",
      "--------------------------------\n",
      "val predicted: (59830,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59830, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (170, 784) (170,)\n",
      "trainset after (180, 784) (180,)\n",
      "updated train set: (180, 784) (180,) unique(labels): [14 11 22 19 16 19 14 20 22 23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59820, 784) (59820,)\n",
      "\n",
      "Train set: (180, 784) y: (180,)\n",
      "Val   set: (59820, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 9.408 s \n",
      "\n",
      "Accuracy rate for 83.180000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91       980\n",
      "           1       0.92      0.97      0.94      1135\n",
      "           2       0.72      0.87      0.79      1032\n",
      "           3       0.83      0.88      0.85      1010\n",
      "           4       0.80      0.79      0.79       982\n",
      "           5       0.79      0.75      0.77       892\n",
      "           6       0.92      0.80      0.86       958\n",
      "           7       0.86      0.82      0.84      1028\n",
      "           8       0.90      0.66      0.77       974\n",
      "           9       0.75      0.77      0.76      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 927    1    8    3    1   32    1    4    1    2]\n",
      " [   0 1105    8    3    0    1    2   11    4    1]\n",
      " [  21    5  900   18    4   14   18   22   24    6]\n",
      " [   6    8   27  893    3   25    4   15   15   14]\n",
      " [   1    2   84    5  778    3   10   17    2   80]\n",
      " [  30   19   27   91   12  673   21    1   11    7]\n",
      " [  32    5   95    3   23   19  771    5    5    0]\n",
      " [   3   11   22    2   10    9    0  846    1  124]\n",
      " [  19   44   56   53   22   71   11   27  647   24]\n",
      " [  15    5   28   11  124    8    0   34    6  778]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59820,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59820, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (180, 784) (180,)\n",
      "trainset after (190, 784) (190,)\n",
      "updated train set: (190, 784) (190,) unique(labels): [14 11 23 20 19 19 16 22 23 23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59810, 784) (59810,)\n",
      "\n",
      "Train set: (190, 784) y: (190,)\n",
      "Val   set: (59810, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.000 s \n",
      "\n",
      "Accuracy rate for 83.360000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       980\n",
      "           1       0.92      0.97      0.94      1135\n",
      "           2       0.73      0.88      0.80      1032\n",
      "           3       0.82      0.88      0.85      1010\n",
      "           4       0.81      0.83      0.82       982\n",
      "           5       0.79      0.74      0.77       892\n",
      "           6       0.91      0.80      0.85       958\n",
      "           7       0.84      0.82      0.83      1028\n",
      "           8       0.90      0.68      0.77       974\n",
      "           9       0.76      0.77      0.76      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 915    1   16    4    0   33    2    8    1    0]\n",
      " [   0 1104   10    3    0    1    2   10    4    1]\n",
      " [  17    6  904   14    4   10   25   17   28    7]\n",
      " [   4    8   33  890    2   27    4   16   14   12]\n",
      " [   0    2   61    4  812    3   12   21    3   64]\n",
      " [  30   19   26   96   13  664   21    3   12    8]\n",
      " [  33    4   88    4   23   19  767   16    4    0]\n",
      " [   3   11   22    2   12    4    0  847    1  126]\n",
      " [  17   42   50   56   20   69   11   27  659   23]\n",
      " [  12    5   24   15  119    9    0   45    6  774]]\n",
      "--------------------------------\n",
      "val predicted: (59810,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59810, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (190, 784) (190,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [16 12 24 24 20 19 17 22 23 23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.447 s \n",
      "\n",
      "Accuracy rate for 83.130000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90       980\n",
      "           1       0.92      0.97      0.95      1135\n",
      "           2       0.73      0.86      0.79      1032\n",
      "           3       0.81      0.89      0.84      1010\n",
      "           4       0.81      0.84      0.82       982\n",
      "           5       0.80      0.72      0.76       892\n",
      "           6       0.89      0.81      0.85       958\n",
      "           7       0.84      0.82      0.83      1028\n",
      "           8       0.91      0.67      0.77       974\n",
      "           9       0.77      0.77      0.77      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 915    0   24    6    0   26    3    4    1    1]\n",
      " [   0 1103   10    3    0    0    3   14    1    1]\n",
      " [  31    9  884    8    6   10   34   17   28    5]\n",
      " [   7    6   36  895    1   23    7   15   11    9]\n",
      " [   2    3   54    4  822    4   10   20    3   60]\n",
      " [  33   18   36   93   15  646   24    4   15    8]\n",
      " [  45    4   78    5   19   17  773   14    3    0]\n",
      " [   4   12   20    1   11    5    1  848    1  125]\n",
      " [  14   37   43   81   16   65   15   26  651   26]\n",
      " [  10    5   24   15  122    7    0   46    4  776]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59800, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (210, 784) (210,)\n",
      "updated train set: (210, 784) (210,) unique(labels): [17 12 25 24 22 20 17 24 23 26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59790, 784) (59790,)\n",
      "\n",
      "Train set: (210, 784) y: (210,)\n",
      "Val   set: (59790, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 21\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.890 s \n",
      "\n",
      "Accuracy rate for 82.500000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       980\n",
      "           1       0.91      0.97      0.94      1135\n",
      "           2       0.73      0.84      0.78      1032\n",
      "           3       0.81      0.87      0.84      1010\n",
      "           4       0.79      0.84      0.81       982\n",
      "           5       0.80      0.73      0.77       892\n",
      "           6       0.89      0.81      0.85       958\n",
      "           7       0.85      0.81      0.83      1028\n",
      "           8       0.91      0.65      0.76       974\n",
      "           9       0.74      0.77      0.75      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.83      0.82      0.82     10000\n",
      "weighted avg       0.83      0.82      0.82     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 913    0   25    5    0   30    3    2    1    1]\n",
      " [   0 1099   14    3    0    1    3   14    1    0]\n",
      " [  30   17  872    7    6    7   37   16   32    8]\n",
      " [  13    5   37  879    2   30    7   14    9   14]\n",
      " [   2    3   52    3  822    3    9   24    3   61]\n",
      " [  35   19   35   93   11  654   24    1   13    7]\n",
      " [  50    3   81    2   23   14  773   10    2    0]\n",
      " [   3   13   20    2   22    2    1  831    1  133]\n",
      " [  16   36   43   79   23   63   14   20  634   46]\n",
      " [  11    7   20    9  136   11    0   40    2  773]]\n",
      "--------------------------------\n",
      "val predicted: (59790,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59790, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (210, 784) (210,)\n",
      "trainset after (220, 784) (220,)\n",
      "updated train set: (220, 784) (220,) unique(labels): [17 12 25 24 23 24 17 26 25 27] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59780, 784) (59780,)\n",
      "\n",
      "Train set: (220, 784) y: (220,)\n",
      "Val   set: (59780, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 22\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 11.393 s \n",
      "\n",
      "Accuracy rate for 83.240000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       980\n",
      "           1       0.92      0.97      0.94      1135\n",
      "           2       0.73      0.84      0.78      1032\n",
      "           3       0.83      0.87      0.85      1010\n",
      "           4       0.80      0.84      0.82       982\n",
      "           5       0.79      0.77      0.78       892\n",
      "           6       0.90      0.80      0.85       958\n",
      "           7       0.86      0.83      0.84      1028\n",
      "           8       0.91      0.68      0.78       974\n",
      "           9       0.75      0.78      0.76      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 915    0   28    5    0   26    2    2    1    1]\n",
      " [   0 1097   12    4    0    2    1   17    2    0]\n",
      " [  30   18  867    9    6    9   35   19   32    7]\n",
      " [  10    4   37  880    1   36    4   13   10   15]\n",
      " [   2    3   53    1  825    5    9   22    3   59]\n",
      " [  29   11   29   85    7  684   18    1   13   15]\n",
      " [  52    3   79    2   24   18  765   13    2    0]\n",
      " [   2   12   18    2   20    2    0  850    1  121]\n",
      " [  17   35   41   64   18   69   12   22  658   38]\n",
      " [  10    7   22   12  130   10    0   35    0  783]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59780,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59780, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (220, 784) (220,)\n",
      "trainset after (230, 784) (230,)\n",
      "updated train set: (230, 784) (230,) unique(labels): [17 13 27 24 23 26 18 28 26 28] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59770, 784) (59770,)\n",
      "\n",
      "Train set: (230, 784) y: (230,)\n",
      "Val   set: (59770, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 23\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 11.890 s \n",
      "\n",
      "Accuracy rate for 84.030000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       980\n",
      "           1       0.92      0.99      0.95      1135\n",
      "           2       0.76      0.87      0.81      1032\n",
      "           3       0.84      0.88      0.86      1010\n",
      "           4       0.81      0.83      0.82       982\n",
      "           5       0.78      0.78      0.78       892\n",
      "           6       0.92      0.82      0.87       958\n",
      "           7       0.87      0.82      0.85      1028\n",
      "           8       0.92      0.66      0.77       974\n",
      "           9       0.76      0.79      0.77      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 909    0   29    5    0   28    4    2    1    2]\n",
      " [   0 1120    4    4    0    2    1    2    2    0]\n",
      " [  26   18  895    7    3    7   27   17   28    4]\n",
      " [   6    5   38  887    2   37    4   13    4   14]\n",
      " [   2    3   54    1  817    6   10   25    2   62]\n",
      " [  26   13   27   69    7  697   17    2   15   19]\n",
      " [  51    4   55    2   20   27  787    9    3    0]\n",
      " [   1   13   18    3   18    5    0  847    3  120]\n",
      " [  16   37   40   66   18   80   10   24  647   36]\n",
      " [   7    7   19   12  124    9    0   33    1  797]]\n",
      "--------------------------------\n",
      "val predicted: (59770,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59770, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (230, 784) (230,)\n",
      "trainset after (240, 784) (240,)\n",
      "updated train set: (240, 784) (240,) unique(labels): [17 13 28 25 25 26 20 29 27 30] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59760, 784) (59760,)\n",
      "\n",
      "Train set: (240, 784) y: (240,)\n",
      "Val   set: (59760, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 24\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.316 s \n",
      "\n",
      "Accuracy rate for 84.840000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       980\n",
      "           1       0.92      0.99      0.95      1135\n",
      "           2       0.76      0.86      0.81      1032\n",
      "           3       0.84      0.89      0.87      1010\n",
      "           4       0.82      0.85      0.84       982\n",
      "           5       0.81      0.78      0.79       892\n",
      "           6       0.91      0.86      0.88       958\n",
      "           7       0.87      0.84      0.86      1028\n",
      "           8       0.92      0.66      0.77       974\n",
      "           9       0.76      0.80      0.78      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 913    0   32    4    0   25    4    1    1    0]\n",
      " [   0 1121    3    3    0    0    3    2    2    1]\n",
      " [  24   21  886   10    5    9   27   19   26    5]\n",
      " [   3    5   34  900    2   29    2   14    2   19]\n",
      " [   2    3   39    1  839    6   11   20    3   58]\n",
      " [  26   12   26   71    6  694   18    2   16   21]\n",
      " [  34    4   50    3   10   19  821   13    4    0]\n",
      " [   3   15   18    2   20    2    1  864    2  101]\n",
      " [  16   28   52   66   21   64   13   22  643   49]\n",
      " [   9    6   19    9  121   10    0   32    0  803]]\n",
      "--------------------------------\n",
      "val predicted: (59760,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59760, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (240, 784) (240,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [17 13 28 26 26 27 20 32 28 33] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 25\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.727 s \n",
      "\n",
      "Accuracy rate for 85.200000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       980\n",
      "           1       0.93      0.98      0.95      1135\n",
      "           2       0.77      0.85      0.81      1032\n",
      "           3       0.84      0.89      0.87      1010\n",
      "           4       0.82      0.82      0.82       982\n",
      "           5       0.82      0.78      0.80       892\n",
      "           6       0.91      0.86      0.89       958\n",
      "           7       0.87      0.90      0.88      1028\n",
      "           8       0.92      0.68      0.78       974\n",
      "           9       0.77      0.79      0.78      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 911    0   31    5    0   25    4    2    1    1]\n",
      " [   0 1116    5    3    0    0    3    5    2    1]\n",
      " [  24   20  882   12    6    8   27   21   28    4]\n",
      " [   3    5   29  897    2   30    2   15    7   20]\n",
      " [   2    3   42    2  806    5   11   21    2   88]\n",
      " [  26    9   27   70    8  700   16    3   12   21]\n",
      " [  35    4   50    4   10   19  823   10    3    0]\n",
      " [   3   11   15    2   17    2    1  924    1   52]\n",
      " [  16   28   49   60   20   52   13   21  664   51]\n",
      " [   9    7   19    8  117   10    0   40    2  797]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (260, 784) (260,)\n",
      "updated train set: (260, 784) (260,) unique(labels): [18 14 29 28 26 29 21 32 29 34] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59740, 784) (59740,)\n",
      "\n",
      "Train set: (260, 784) y: (260,)\n",
      "Val   set: (59740, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 26\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 13.328 s \n",
      "\n",
      "Accuracy rate for 85.170000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92       980\n",
      "           1       0.91      0.98      0.95      1135\n",
      "           2       0.76      0.85      0.80      1032\n",
      "           3       0.84      0.89      0.86      1010\n",
      "           4       0.81      0.82      0.82       982\n",
      "           5       0.84      0.79      0.81       892\n",
      "           6       0.92      0.85      0.88       958\n",
      "           7       0.87      0.89      0.88      1028\n",
      "           8       0.92      0.68      0.78       974\n",
      "           9       0.77      0.79      0.78      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 915    0   30    5    0   19    4    3    4    0]\n",
      " [   0 1114    4    4    0    0    3    6    3    1]\n",
      " [  21   28  876   19    6    8   20   21   29    4]\n",
      " [   4    5   30  895    1   31    1   15    7   21]\n",
      " [   1    4   41    2  805    3   13   19    2   92]\n",
      " [  21   10   25   64   10  709   19    2   10   22]\n",
      " [  31    3   57   10   11   15  818   10    3    0]\n",
      " [   3   18   14    1   19    1    1  916    1   54]\n",
      " [  12   29   54   61   20   49   13   24  667   45]\n",
      " [   8    7   15    8  116   13    0   38    2  802]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59740,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59740, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (260, 784) (260,)\n",
      "trainset after (270, 784) (270,)\n",
      "updated train set: (270, 784) (270,) unique(labels): [18 15 30 28 27 32 22 32 30 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59730, 784) (59730,)\n",
      "\n",
      "Train set: (270, 784) y: (270,)\n",
      "Val   set: (59730, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 27\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 13.884 s \n",
      "\n",
      "Accuracy rate for 85.240000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92       980\n",
      "           1       0.92      0.99      0.95      1135\n",
      "           2       0.77      0.86      0.81      1032\n",
      "           3       0.83      0.88      0.86      1010\n",
      "           4       0.80      0.82      0.81       982\n",
      "           5       0.83      0.80      0.81       892\n",
      "           6       0.93      0.85      0.89       958\n",
      "           7       0.89      0.89      0.89      1028\n",
      "           8       0.92      0.69      0.79       974\n",
      "           9       0.76      0.79      0.78      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 912    0   29    6    0   24    4    3    2    0]\n",
      " [   0 1118    6    3    0    3    2    1    1    1]\n",
      " [  23   24  883   24    4    8   17   18   26    5]\n",
      " [   3    5   30  892    1   31    1   13   11   23]\n",
      " [   1    5   40    5  805    1    9   17    2   97]\n",
      " [  22    7   26   66   11  710   21    2   11   16]\n",
      " [  29    3   51    6   25   17  818    7    2    0]\n",
      " [   3   21   14    2   12    2    0  918    1   55]\n",
      " [  11   29   54   59   22   52   11   17  671   48]\n",
      " [   9    7   13   11  126    9    0   34    3  797]]\n",
      "--------------------------------\n",
      "val predicted: (59730,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59730, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (270, 784) (270,)\n",
      "trainset after (280, 784) (280,)\n",
      "updated train set: (280, 784) (280,) unique(labels): [20 15 30 29 30 33 22 34 31 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59720, 784) (59720,)\n",
      "\n",
      "Train set: (280, 784) y: (280,)\n",
      "Val   set: (59720, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 28\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 14.275 s \n",
      "\n",
      "Accuracy rate for 85.100000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       980\n",
      "           1       0.92      0.98      0.95      1135\n",
      "           2       0.77      0.84      0.80      1032\n",
      "           3       0.84      0.87      0.86      1010\n",
      "           4       0.79      0.84      0.81       982\n",
      "           5       0.83      0.80      0.82       892\n",
      "           6       0.93      0.84      0.88       958\n",
      "           7       0.88      0.89      0.88      1028\n",
      "           8       0.91      0.72      0.80       974\n",
      "           9       0.77      0.77      0.77      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 919    0   25    7    0   23    2    3    1    0]\n",
      " [   0 1117    5    4    0    2    3    1    2    1]\n",
      " [  28   23  862   26    5    8   20   21   34    5]\n",
      " [   5    4   31  883    1   34    0   16   14   22]\n",
      " [   1    5   34    5  825    1    9   16    2   84]\n",
      " [  17    7   25   65   10  718   18    4   13   15]\n",
      " [  42    3   55    4   27   20  800    7    0    0]\n",
      " [   3   22   15    2   17    3    0  913    1   52]\n",
      " [  13   21   47   50   21   46   10   19  697   50]\n",
      " [  10    6   15    8  141   10    0   40    3  776]]\n",
      "--------------------------------\n",
      "val predicted: (59720,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59720, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (280, 784) (280,)\n",
      "trainset after (290, 784) (290,)\n",
      "updated train set: (290, 784) (290,) unique(labels): [20 15 31 30 33 33 23 34 33 38] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59710, 784) (59710,)\n",
      "\n",
      "Train set: (290, 784) y: (290,)\n",
      "Val   set: (59710, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 29\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 14.836 s \n",
      "\n",
      "Accuracy rate for 85.330000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       980\n",
      "           1       0.93      0.98      0.95      1135\n",
      "           2       0.77      0.84      0.81      1032\n",
      "           3       0.83      0.88      0.85      1010\n",
      "           4       0.80      0.85      0.82       982\n",
      "           5       0.84      0.79      0.81       892\n",
      "           6       0.92      0.85      0.88       958\n",
      "           7       0.88      0.87      0.88      1028\n",
      "           8       0.92      0.71      0.80       974\n",
      "           9       0.77      0.79      0.78      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 922    0   21    7    0   22    2    4    2    0]\n",
      " [   0 1116    6    4    0    3    3    1    1    1]\n",
      " [  27   23  868   29    7    7   18   21   28    4]\n",
      " [   4    4   29  887    2   32    4   15   11   22]\n",
      " [   2    4   31    6  833    1    8   16    3   78]\n",
      " [  18    7   25   75   10  706   18    5   10   18]\n",
      " [  41    3   54    3   23   14  811    6    3    0]\n",
      " [   3   21   19    2   18    3    0  899    1   62]\n",
      " [  12   20   51   44   24   46   13   18  693   53]\n",
      " [   9    6   17   10  121   10    0   35    3  798]]\n",
      "--------------------------------\n",
      "val predicted: (59710,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59710, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (290, 784) (290,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [21 15 31 30 36 36 23 36 33 39] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 30\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.255 s \n",
      "\n",
      "Accuracy rate for 85.010000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.78      0.84      0.81      1032\n",
      "           3       0.83      0.88      0.85      1010\n",
      "           4       0.78      0.86      0.82       982\n",
      "           5       0.82      0.79      0.81       892\n",
      "           6       0.92      0.85      0.89       958\n",
      "           7       0.87      0.87      0.87      1028\n",
      "           8       0.92      0.70      0.80       974\n",
      "           9       0.77      0.77      0.77      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 903    0   27    7    0   37    2    3    1    0]\n",
      " [   0 1116    6    4    0    3    3    1    1    1]\n",
      " [  27   22  869   26    9    7   17   22   26    7]\n",
      " [   3    4   32  885    0   33    4   19   10   20]\n",
      " [   2    4   23    4  845    1   10   15    2   76]\n",
      " [  16    4   30   76   11  706   18    4   12   15]\n",
      " [  40    3   49    3   27   12  814    8    2    0]\n",
      " [   1   14   18    2   22    2    0  899    0   70]\n",
      " [  15   20   50   45   34   49   13   18  683   47]\n",
      " [  10    6   16   10  130    8    0   45    3  781]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59700, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (310, 784) (310,)\n",
      "updated train set: (310, 784) (310,) unique(labels): [22 15 33 31 37 38 23 38 33 40] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59690, 784) (59690,)\n",
      "\n",
      "Train set: (310, 784) y: (310,)\n",
      "Val   set: (59690, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 31\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.709 s \n",
      "\n",
      "Accuracy rate for 85.570000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.77      0.86      0.81      1032\n",
      "           3       0.84      0.88      0.86      1010\n",
      "           4       0.78      0.88      0.83       982\n",
      "           5       0.84      0.80      0.82       892\n",
      "           6       0.93      0.85      0.89       958\n",
      "           7       0.87      0.90      0.88      1028\n",
      "           8       0.92      0.69      0.79       974\n",
      "           9       0.80      0.76      0.78      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.86      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 906    0   35    8    3   23    2    1    1    1]\n",
      " [   0 1116    5    4    1    2    3    1    2    1]\n",
      " [  21   20  890   17   13    6   15   21   24    5]\n",
      " [   3    5   38  886    0   29    3   17    9   20]\n",
      " [   1    4   24    3  868    1    7   13    2   59]\n",
      " [  16    4   29   68   12  714   18    3   14   14]\n",
      " [  40    3   53    4   29   11  811    5    2    0]\n",
      " [   1   14   17    1   14    2    0  924    0   55]\n",
      " [  12   19   58   50   32   51   14   23  675   40]\n",
      " [  12    6   13   10  135    7    0   57    2  767]]\n",
      "--------------------------------\n",
      "val predicted: (59690,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59690, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (310, 784) (310,)\n",
      "trainset after (320, 784) (320,)\n",
      "updated train set: (320, 784) (320,) unique(labels): [23 16 33 34 37 38 24 40 33 42] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59680, 784) (59680,)\n",
      "\n",
      "Train set: (320, 784) y: (320,)\n",
      "Val   set: (59680, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 32\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 16.425 s \n",
      "\n",
      "Accuracy rate for 85.910000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.80      0.84      0.82      1032\n",
      "           3       0.83      0.88      0.85      1010\n",
      "           4       0.80      0.88      0.84       982\n",
      "           5       0.85      0.79      0.82       892\n",
      "           6       0.92      0.89      0.90       958\n",
      "           7       0.87      0.89      0.88      1028\n",
      "           8       0.93      0.70      0.80       974\n",
      "           9       0.78      0.78      0.78      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 911    0   26    9    2   26    4    1    0    1]\n",
      " [   0 1115    4    7    1    2    3    1    2    0]\n",
      " [  19   19  869   24   14    7   21   27   24    8]\n",
      " [   5    6   34  887    0   27    3   18    8   22]\n",
      " [   1    4   19    4  867    1   12   14    2   58]\n",
      " [  17    3   29   72   13  709   17    3   12   17]\n",
      " [  34    3   31    4   18   11  849    6    2    0]\n",
      " [   2   16   12    2   15    2    0  917    0   62]\n",
      " [  12   17   55   45   30   51   14   20  681   49]\n",
      " [  13    6   11   15  122    3    0   51    2  786]]\n",
      "--------------------------------\n",
      "val predicted: (59680,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59680, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (320, 784) (320,)\n",
      "trainset after (330, 784) (330,)\n",
      "updated train set: (330, 784) (330,) unique(labels): [23 16 34 35 37 40 24 42 35 44] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59670, 784) (59670,)\n",
      "\n",
      "Train set: (330, 784) y: (330,)\n",
      "Val   set: (59670, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 33\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 17.019 s \n",
      "\n",
      "Accuracy rate for 85.910000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       980\n",
      "           1       0.93      0.98      0.96      1135\n",
      "           2       0.79      0.85      0.82      1032\n",
      "           3       0.84      0.88      0.86      1010\n",
      "           4       0.80      0.89      0.84       982\n",
      "           5       0.84      0.80      0.82       892\n",
      "           6       0.92      0.88      0.90       958\n",
      "           7       0.86      0.90      0.88      1028\n",
      "           8       0.91      0.70      0.79       974\n",
      "           9       0.79      0.77      0.78      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 914    0   25    8    2   25    4    2    0    0]\n",
      " [   0 1114    4    6    1    2    3    1    4    0]\n",
      " [  19   20  875   21   12    6   18   22   30    9]\n",
      " [   3    6   32  888    1   29    3   14   11   23]\n",
      " [   1    4   19    2  871    1   12   17    2   53]\n",
      " [  15    5   26   69   12  718   17    3   13   14]\n",
      " [  33    3   44    3   17   13  839    4    2    0]\n",
      " [   2   18   12    1   13    3    0  921    1   57]\n",
      " [  10   17   57   42   27   52   13   29  678   49]\n",
      " [  12    6   10   11  128    7    1   60    1  773]]\n",
      "--------------------------------\n",
      "val predicted: (59670,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59670, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (330, 784) (330,)\n",
      "trainset after (340, 784) (340,)\n",
      "updated train set: (340, 784) (340,) unique(labels): [24 16 34 35 38 41 24 42 37 49] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59660, 784) (59660,)\n",
      "\n",
      "Train set: (340, 784) y: (340,)\n",
      "Val   set: (59660, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 34\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 17.564 s \n",
      "\n",
      "Accuracy rate for 86.400000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.79      0.85      0.82      1032\n",
      "           3       0.84      0.87      0.85      1010\n",
      "           4       0.84      0.89      0.87       982\n",
      "           5       0.83      0.80      0.82       892\n",
      "           6       0.92      0.87      0.90       958\n",
      "           7       0.88      0.88      0.88      1028\n",
      "           8       0.92      0.71      0.80       974\n",
      "           9       0.79      0.83      0.81      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 913    0   27    8    2   25    4    1    0    0]\n",
      " [   0 1114    5    4    1    2    3    1    5    0]\n",
      " [  19   19  878   21   13    4   19   22   27   10]\n",
      " [   3    5   32  877    1   38    3   15   13   23]\n",
      " [   1    3   22    2  874    0   10   13    1   56]\n",
      " [  19    5   24   73   11  712   18    3   13   14]\n",
      " [  31    3   46    2   18   14  837    4    3    0]\n",
      " [   4   17   14    1   12    2    0  906    2   70]\n",
      " [  15   13   47   51   23   52   14   21  693   45]\n",
      " [  13    6   12   11   82    6    1   42    0  836]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59660,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59660, 10) \n",
      " [5 0 4 ... 5 6 9]\n",
      "trainset before (340, 784) (340,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [26 17 35 37 39 41 25 43 38 49] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 35\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 17.957 s \n",
      "\n",
      "Accuracy rate for 86.540000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.80      0.83      0.82      1032\n",
      "           3       0.84      0.87      0.86      1010\n",
      "           4       0.84      0.88      0.86       982\n",
      "           5       0.85      0.80      0.83       892\n",
      "           6       0.91      0.88      0.89       958\n",
      "           7       0.88      0.89      0.88      1028\n",
      "           8       0.92      0.73      0.81       974\n",
      "           9       0.80      0.82      0.81      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.87      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 923    0   27    5    1   18    5    1    0    0]\n",
      " [   0 1112    4    5    1    2    4    0    6    1]\n",
      " [  20   18  858   28   15    4   30   23   28    8]\n",
      " [   3    4   33  883    2   30    2   16   14   23]\n",
      " [   2    3   21    2  868    0   11   14    1   60]\n",
      " [  17    5   24   72   13  717   20    3    9   12]\n",
      " [  38    3   41    0   12   15  843    3    3    0]\n",
      " [   4   16   14    1    9    3    1  912    2   66]\n",
      " [  16   12   36   46   25   52   13   24  707   43]\n",
      " [  13    6   14   11   82    4    0   46    2  831]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59650, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (360, 784) (360,)\n",
      "updated train set: (360, 784) (360,) unique(labels): [26 18 35 38 41 43 27 43 40 49] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59640, 784) (59640,)\n",
      "\n",
      "Train set: (360, 784) y: (360,)\n",
      "Val   set: (59640, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 36\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 18.688 s \n",
      "\n",
      "Accuracy rate for 86.780000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.82      0.82      0.82      1032\n",
      "           3       0.84      0.87      0.86      1010\n",
      "           4       0.84      0.89      0.87       982\n",
      "           5       0.84      0.80      0.82       892\n",
      "           6       0.91      0.90      0.91       958\n",
      "           7       0.88      0.89      0.88      1028\n",
      "           8       0.91      0.73      0.81       974\n",
      "           9       0.80      0.82      0.81      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 928    0   23    5    1   19    3    1    0    0]\n",
      " [   0 1115    2    4    1    3    2    1    6    1]\n",
      " [  20   22  845   38   17    6   28   21   27    8]\n",
      " [   3    4   36  882    2   28    2   16   14   23]\n",
      " [   2    3   13    1  878    0   10   15    0   60]\n",
      " [  15    7   19   66   12  718   23    3   16   13]\n",
      " [  31    3   30    1   16   13  859    3    2    0]\n",
      " [   4   17   13    1   10    3    1  911    2   66]\n",
      " [  17   11   32   43   28   55   12   24  711   41]\n",
      " [  12    6   13   11   81    7    0   46    2  831]]\n",
      "--------------------------------\n",
      "val predicted: (59640,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59640, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (360, 784) (360,)\n",
      "trainset after (370, 784) (370,)\n",
      "updated train set: (370, 784) (370,) unique(labels): [27 18 36 39 43 45 28 44 40 50] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59630, 784) (59630,)\n",
      "\n",
      "Train set: (370, 784) y: (370,)\n",
      "Val   set: (59630, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 37\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 19.018 s \n",
      "\n",
      "Accuracy rate for 87.020000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.83      0.82      0.83      1032\n",
      "           3       0.85      0.89      0.87      1010\n",
      "           4       0.84      0.90      0.87       982\n",
      "           5       0.84      0.81      0.82       892\n",
      "           6       0.91      0.89      0.90       958\n",
      "           7       0.87      0.89      0.88      1028\n",
      "           8       0.91      0.74      0.82       974\n",
      "           9       0.81      0.83      0.82      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 931    0   21    5    1   18    3    1    0    0]\n",
      " [   0 1114    2    4    2    3    2    1    7    0]\n",
      " [  19   22  845   31   17    8   29   27   25    9]\n",
      " [   2    4   30  896    2   24    2   16   13   21]\n",
      " [   3    3   13    1  884    1   11   15    0   51]\n",
      " [  18    6   18   62   15  720   23    2   18   10]\n",
      " [  29    3   33    1   17   21  850    2    2    0]\n",
      " [   4   17   11    2   12    3    1  911    2   65]\n",
      " [  15   10   29   44   28   54   14   22  718   40]\n",
      " [  14    6   12    8   80    7    0   47    2  833]]\n",
      "--------------------------------\n",
      "val predicted: (59630,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59630, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (370, 784) (370,)\n",
      "trainset after (380, 784) (380,)\n",
      "updated train set: (380, 784) (380,) unique(labels): [27 20 37 41 44 48 28 45 40 50] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59620, 784) (59620,)\n",
      "\n",
      "Train set: (380, 784) y: (380,)\n",
      "Val   set: (59620, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 38\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 19.473 s \n",
      "\n",
      "Accuracy rate for 87.180000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.83      0.83      0.83      1032\n",
      "           3       0.84      0.90      0.87      1010\n",
      "           4       0.83      0.90      0.86       982\n",
      "           5       0.84      0.82      0.83       892\n",
      "           6       0.91      0.88      0.90       958\n",
      "           7       0.89      0.88      0.88      1028\n",
      "           8       0.92      0.74      0.82       974\n",
      "           9       0.81      0.83      0.82      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 930    0   21    5    1   19    3    1    0    0]\n",
      " [   0 1115    3    4    2    2    2    0    7    0]\n",
      " [  19   17  853   30   18    6   27   27   25   10]\n",
      " [   1    5   28  908    2   26    2   13   11   14]\n",
      " [   3    4   13    1  882    2   11   14    0   52]\n",
      " [  16    3   16   60   14  731   22    2   16   12]\n",
      " [  27    3   38    2   17   22  845    3    1    0]\n",
      " [   4   20   12    5   16    4    1  904    2   60]\n",
      " [  14   10   31   52   25   54   12   16  716   44]\n",
      " [  14    6   12   13   82    7    0   40    1  834]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59620,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59620, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (380, 784) (380,)\n",
      "trainset after (390, 784) (390,)\n",
      "updated train set: (390, 784) (390,) unique(labels): [27 20 37 42 45 49 28 46 45 51] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59610, 784) (59610,)\n",
      "\n",
      "Train set: (390, 784) y: (390,)\n",
      "Val   set: (59610, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 39\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 20.068 s \n",
      "\n",
      "Accuracy rate for 87.410000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.85      0.83      0.84      1032\n",
      "           3       0.85      0.90      0.87      1010\n",
      "           4       0.83      0.91      0.87       982\n",
      "           5       0.85      0.82      0.83       892\n",
      "           6       0.91      0.88      0.90       958\n",
      "           7       0.88      0.88      0.88      1028\n",
      "           8       0.91      0.76      0.83       974\n",
      "           9       0.82      0.82      0.82      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 927    0   24    5    1   19    3    1    0    0]\n",
      " [   0 1116    2    4    2    2    3    0    6    0]\n",
      " [  18   17  857   29   17    7   24   25   26   12]\n",
      " [   1    5   29  905    2   27    2   14   12   13]\n",
      " [   3    4    8    1  891    1   12   12    0   50]\n",
      " [  17    3   13   55   14  729   21    2   24   14]\n",
      " [  27    3   37    2   16   20  846    3    4    0]\n",
      " [   4   20   12    5   14    3    1  903    3   63]\n",
      " [  12   10   20   51   26   48   14   20  740   33]\n",
      " [  13    6    9   12   87    6    0   47    2  827]]\n",
      "--------------------------------\n",
      "val predicted: (59610,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59610, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (390, 784) (390,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [27 21 37 43 48 50 29 48 46 51] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 40\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 20.345 s \n",
      "\n",
      "Accuracy rate for 87.330000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       980\n",
      "           1       0.94      0.99      0.96      1135\n",
      "           2       0.85      0.83      0.84      1032\n",
      "           3       0.84      0.90      0.87      1010\n",
      "           4       0.82      0.91      0.87       982\n",
      "           5       0.84      0.82      0.83       892\n",
      "           6       0.92      0.89      0.90       958\n",
      "           7       0.89      0.88      0.88      1028\n",
      "           8       0.91      0.74      0.82       974\n",
      "           9       0.83      0.81      0.82      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 926    0   23    5    1   19    5    1    0    0]\n",
      " [   0 1118    2    3    2    1    4    0    5    0]\n",
      " [  19   16  860   28   21   10   22   20   25   11]\n",
      " [   1    4   27  911    2   25    2   14   11   13]\n",
      " [   3    5    9    1  897    2    9   12    0   44]\n",
      " [  16    3   12   61   13  728   21    2   25   11]\n",
      " [  24    3   35    2   17   21  850    2    4    0]\n",
      " [   4   21   12    5   14    4    1  908    4   55]\n",
      " [  14   18   24   55   28   51   12   17  721   34]\n",
      " [  13    7   11   14   95    7    0   48    0  814]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59600, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (410, 784) (410,)\n",
      "updated train set: (410, 784) (410,) unique(labels): [27 21 38 44 48 53 31 48 48 52] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59590, 784) (59590,)\n",
      "\n",
      "Train set: (410, 784) y: (410,)\n",
      "Val   set: (59590, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 41\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 20.907 s \n",
      "\n",
      "Accuracy rate for 87.720000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       980\n",
      "           1       0.94      0.99      0.96      1135\n",
      "           2       0.85      0.84      0.84      1032\n",
      "           3       0.85      0.90      0.87      1010\n",
      "           4       0.83      0.91      0.87       982\n",
      "           5       0.85      0.83      0.84       892\n",
      "           6       0.92      0.90      0.91       958\n",
      "           7       0.89      0.88      0.89      1028\n",
      "           8       0.91      0.76      0.83       974\n",
      "           9       0.83      0.80      0.81      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 925    0   23    8    1   15    6    1    0    1]\n",
      " [   0 1118    2    4    2    1    4    0    4    0]\n",
      " [  20   13  866   26   20    7   23   21   26   10]\n",
      " [   2    5   29  913    2   22    2   14    8   13]\n",
      " [   3    5    9    2  896    2   11   10    0   44]\n",
      " [  18    2   12   56   11  739   19    2   23   10]\n",
      " [  18    3   30    2   17   21  860    2    5    0]\n",
      " [   3   21   10    5   16    3    1  909    4   56]\n",
      " [  10   16   25   49   22   53    9   17  736   37]\n",
      " [  14    7   14   14   97    8    0   45    0  810]]\n",
      "--------------------------------\n",
      "val predicted: (59590,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59590, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (410, 784) (410,)\n",
      "trainset after (420, 784) (420,)\n",
      "updated train set: (420, 784) (420,) unique(labels): [27 21 39 44 48 55 32 49 52 53] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59580, 784) (59580,)\n",
      "\n",
      "Train set: (420, 784) y: (420,)\n",
      "Val   set: (59580, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 42\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 21.525 s \n",
      "\n",
      "Accuracy rate for 87.800000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.84      0.84      0.84      1032\n",
      "           3       0.86      0.89      0.87      1010\n",
      "           4       0.84      0.92      0.87       982\n",
      "           5       0.83      0.83      0.83       892\n",
      "           6       0.92      0.90      0.91       958\n",
      "           7       0.89      0.88      0.88      1028\n",
      "           8       0.90      0.77      0.83       974\n",
      "           9       0.84      0.81      0.82      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 921    0   25    7    1   18    6    2    0    0]\n",
      " [   0 1117    2    4    2    3    2    0    5    0]\n",
      " [  19   12  868   26   21    8   24   21   29    4]\n",
      " [   2    3   29  900    2   32    1   13   14   14]\n",
      " [   3    5    9    1  899    4   10   11    0   40]\n",
      " [  20    2   13   49    8  741   20    4   23   12]\n",
      " [  19    3   30    1   16   19  866    1    3    0]\n",
      " [   3   22   13    5   16    5    1  904    4   55]\n",
      " [  11   17   26   42   20   54   15   13  751   25]\n",
      " [  12    7   16   15   89    7    0   46    4  813]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59580,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59580, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (420, 784) (420,)\n",
      "trainset after (430, 784) (430,)\n",
      "updated train set: (430, 784) (430,) unique(labels): [28 21 40 45 48 56 33 51 53 55] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59570, 784) (59570,)\n",
      "\n",
      "Train set: (430, 784) y: (430,)\n",
      "Val   set: (59570, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 43\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 22.094 s \n",
      "\n",
      "Accuracy rate for 87.900000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.85      0.83      0.84      1032\n",
      "           3       0.85      0.90      0.87      1010\n",
      "           4       0.83      0.92      0.87       982\n",
      "           5       0.84      0.83      0.84       892\n",
      "           6       0.92      0.90      0.91       958\n",
      "           7       0.89      0.89      0.89      1028\n",
      "           8       0.90      0.77      0.83       974\n",
      "           9       0.85      0.81      0.83      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 923    0   26    6    2   15    5    3    0    0]\n",
      " [   0 1117    2    4    2    3    2    0    5    0]\n",
      " [  21   13  860   36   20    7   23   20   28    4]\n",
      " [   2    3   23  911    3   28    1   12   13   14]\n",
      " [   3    5    8    3  899    3   11   11    0   39]\n",
      " [  16    3   15   48    9  742   22    3   25    9]\n",
      " [  26    3   24    2   19   18  860    1    5    0]\n",
      " [   1   21   13    4   17    5    1  910    4   52]\n",
      " [  10   18   25   48   20   54   13   15  749   22]\n",
      " [  11    7   11   16   87    7    1   46    4  819]]\n",
      "--------------------------------\n",
      "val predicted: (59570,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59570, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (430, 784) (430,)\n",
      "trainset after (440, 784) (440,)\n",
      "updated train set: (440, 784) (440,) unique(labels): [29 21 40 45 49 58 34 53 55 56] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59560, 784) (59560,)\n",
      "\n",
      "Train set: (440, 784) y: (440,)\n",
      "Val   set: (59560, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 44\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 22.686 s \n",
      "\n",
      "Accuracy rate for 88.100000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.86      0.83      0.85      1032\n",
      "           3       0.85      0.90      0.87      1010\n",
      "           4       0.83      0.92      0.87       982\n",
      "           5       0.84      0.84      0.84       892\n",
      "           6       0.92      0.90      0.91       958\n",
      "           7       0.90      0.89      0.90      1028\n",
      "           8       0.90      0.77      0.83       974\n",
      "           9       0.85      0.81      0.83      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 930    0   20    5    2   15    5    3    0    0]\n",
      " [   0 1117    2    4    1    3    2    0    5    1]\n",
      " [  22   11  858   38   22    8   24   18   27    4]\n",
      " [   2    2   23  910    4   29    1   11   14   14]\n",
      " [   3    5   12    3  899    3    8    9    0   40]\n",
      " [  13    3   14   48    6  748   24    3   26    7]\n",
      " [  26    3   27    1   18   19  860    0    4    0]\n",
      " [   1   23   12    3   12    4    1  916    3   53]\n",
      " [  10   19   19   47   20   54   12   16  754   23]\n",
      " [  10    7   11   16   96    7    1   40    3  818]]\n",
      "--------------------------------\n",
      "val predicted: (59560,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59560, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (440, 784) (440,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [29 23 41 46 50 59 37 53 55 57] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 45\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 23.086 s \n",
      "\n",
      "Accuracy rate for 88.410000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       980\n",
      "           1       0.94      0.99      0.96      1135\n",
      "           2       0.86      0.84      0.85      1032\n",
      "           3       0.85      0.90      0.87      1010\n",
      "           4       0.84      0.92      0.88       982\n",
      "           5       0.85      0.84      0.84       892\n",
      "           6       0.92      0.91      0.92       958\n",
      "           7       0.90      0.88      0.89      1028\n",
      "           8       0.91      0.78      0.84       974\n",
      "           9       0.85      0.81      0.83      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 933    0   19    6    2   15    2    3    0    0]\n",
      " [   0 1118    2    3    2    3    2    0    5    0]\n",
      " [  21   13  867   33   20    9   19   19   26    5]\n",
      " [   2    2   24  911    4   29    2    9   12   15]\n",
      " [   3    2   14    3  906    3    5   12    0   34]\n",
      " [  12    4   14   49    6  750   24    3   23    7]\n",
      " [  22    3   25    1   18   16  869    0    4    0]\n",
      " [   1   22   12    3   16    3    1  908    3   59]\n",
      " [  10   18   18   46   18   50   16   17  759   22]\n",
      " [   9    7   11   18   91    8    1   39    5  820]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59550, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (460, 784) (460,)\n",
      "updated train set: (460, 784) (460,) unique(labels): [29 23 43 46 50 60 40 54 56 59] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59540, 784) (59540,)\n",
      "\n",
      "Train set: (460, 784) y: (460,)\n",
      "Val   set: (59540, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 46\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 23.462 s \n",
      "\n",
      "Accuracy rate for 88.220000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       980\n",
      "           1       0.94      0.99      0.96      1135\n",
      "           2       0.87      0.84      0.85      1032\n",
      "           3       0.86      0.89      0.88      1010\n",
      "           4       0.84      0.92      0.88       982\n",
      "           5       0.83      0.83      0.83       892\n",
      "           6       0.92      0.91      0.92       958\n",
      "           7       0.89      0.89      0.89      1028\n",
      "           8       0.91      0.77      0.83       974\n",
      "           9       0.85      0.82      0.83      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 932    0   18    5    2   16    3    3    1    0]\n",
      " [   0 1118    2    3    2    5    1    0    4    0]\n",
      " [  22   14  866   30   21    8   21   17   28    5]\n",
      " [   1    2   26  903    4   38    2   11   10   13]\n",
      " [   3    2   12    3  906    2    5   12    0   37]\n",
      " [  17    4   17   47    7  741   24    3   22   10]\n",
      " [  16    3   21    1   23   19  870    1    4    0]\n",
      " [   1   24    8    2   15    5    0  910    3   60]\n",
      " [   9   18   18   44   19   55   15   19  751   26]\n",
      " [   9    7    9   15   86    6    1   47    4  825]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59540,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59540, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (460, 784) (460,)\n",
      "trainset after (470, 784) (470,)\n",
      "updated train set: (470, 784) (470,) unique(labels): [30 24 43 46 50 62 42 54 58 61] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59530, 784) (59530,)\n",
      "\n",
      "Train set: (470, 784) y: (470,)\n",
      "Val   set: (59530, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 47\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 23.950 s \n",
      "\n",
      "Accuracy rate for 88.430000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       980\n",
      "           1       0.94      0.99      0.96      1135\n",
      "           2       0.88      0.83      0.85      1032\n",
      "           3       0.85      0.90      0.87      1010\n",
      "           4       0.84      0.92      0.88       982\n",
      "           5       0.84      0.83      0.83       892\n",
      "           6       0.91      0.91      0.91       958\n",
      "           7       0.90      0.89      0.89      1028\n",
      "           8       0.91      0.78      0.84       974\n",
      "           9       0.86      0.83      0.84      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 940    0   18    5    2    7    4    2    1    1]\n",
      " [   0 1118    2    3    2    4    3    0    3    0]\n",
      " [  25   12  852   31   21   10   29   16   30    6]\n",
      " [   1    1   25  906    4   38    3   12    9   11]\n",
      " [   3    2   10    3  908    3    5   12    1   35]\n",
      " [  18    4   12   49    7  743   25    3   22    9]\n",
      " [  20    1   19    1   24   16  874    0    3    0]\n",
      " [   0   21    8    4   18    5    0  914    3   55]\n",
      " [   9   21   15   43   19   56   16   18  755   22]\n",
      " [  10    6   10   17   80    7    1   42    3  833]]\n",
      "--------------------------------\n",
      "val predicted: (59530,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59530, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (470, 784) (470,)\n",
      "trainset after (480, 784) (480,)\n",
      "updated train set: (480, 784) (480,) unique(labels): [30 26 44 46 51 65 42 56 58 62] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59520, 784) (59520,)\n",
      "\n",
      "Train set: (480, 784) y: (480,)\n",
      "Val   set: (59520, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 48\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 24.427 s \n",
      "\n",
      "Accuracy rate for 88.380000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       980\n",
      "           1       0.94      0.99      0.96      1135\n",
      "           2       0.86      0.84      0.85      1032\n",
      "           3       0.86      0.89      0.88      1010\n",
      "           4       0.84      0.93      0.88       982\n",
      "           5       0.83      0.83      0.83       892\n",
      "           6       0.92      0.91      0.91       958\n",
      "           7       0.91      0.89      0.90      1028\n",
      "           8       0.91      0.76      0.83       974\n",
      "           9       0.86      0.82      0.84      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 942    0   16    4    2    8    4    2    1    1]\n",
      " [   0 1120    3    3    2    2    3    0    2    0]\n",
      " [  27   15  862   32   17   13   21   15   25    5]\n",
      " [   3    3   23  903    4   40    3   10    8   13]\n",
      " [   3    2   11    3  914    4    5    7    1   32]\n",
      " [  18    4   10   45    9  743   26    2   26    9]\n",
      " [  21    2   21    1   22   18  869    1    3    0]\n",
      " [   1   17   12    3   20    5    0  913    3   54]\n",
      " [   9   22   27   42   20   57   15   15  740   27]\n",
      " [  12    8   13   17   79    6    1   38    3  832]]\n",
      "--------------------------------\n",
      "val predicted: (59520,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59520, 10) \n",
      " [5 0 4 ... 5 6 9]\n",
      "trainset before (480, 784) (480,)\n",
      "trainset after (490, 784) (490,)\n",
      "updated train set: (490, 784) (490,) unique(labels): [32 27 45 47 52 65 43 56 58 65] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59510, 784) (59510,)\n",
      "\n",
      "Train set: (490, 784) y: (490,)\n",
      "Val   set: (59510, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 49\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 24.577 s \n",
      "\n",
      "Accuracy rate for 88.310000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       980\n",
      "           1       0.94      0.99      0.96      1135\n",
      "           2       0.87      0.84      0.85      1032\n",
      "           3       0.86      0.89      0.88      1010\n",
      "           4       0.83      0.93      0.88       982\n",
      "           5       0.83      0.83      0.83       892\n",
      "           6       0.91      0.90      0.91       958\n",
      "           7       0.91      0.89      0.90      1028\n",
      "           8       0.91      0.75      0.82       974\n",
      "           9       0.86      0.83      0.84      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 942    0   11    3    2   11    7    2    1    1]\n",
      " [   0 1121    2    4    2    2    2    0    2    0]\n",
      " [  24   15  867   27   20   11   23   15   25    5]\n",
      " [   4    3   22  903    4   40    3   12    8   11]\n",
      " [   4    1    8    1  914    4    7    6    1   36]\n",
      " [  22    5   12   45   10  736   27    2   25    8]\n",
      " [  22    3   26    1   23   14  865    1    3    0]\n",
      " [   2   16   13    1   22    5    0  912    3   54]\n",
      " [  11   24   26   47   21   54   16   18  732   25]\n",
      " [  11    7   11   16   83    5    1   34    2  839]]\n",
      "--------------------------------\n",
      "val predicted: (59510,) ['5' '0' '4' ... '5' '6' '0']\n",
      "probabilities: (59510, 10) \n",
      " [5 0 4 ... 5 6 5]\n",
      "trainset before (490, 784) (490,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [32 27 45 51 53 66 44 58 59 65] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 50\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 25.237 s \n",
      "\n",
      "Accuracy rate for 88.600000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94       980\n",
      "           1       0.94      0.99      0.96      1135\n",
      "           2       0.87      0.84      0.85      1032\n",
      "           3       0.86      0.90      0.88      1010\n",
      "           4       0.83      0.93      0.88       982\n",
      "           5       0.85      0.83      0.84       892\n",
      "           6       0.92      0.91      0.91       958\n",
      "           7       0.91      0.89      0.90      1028\n",
      "           8       0.91      0.76      0.83       974\n",
      "           9       0.86      0.83      0.84      1009\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.88      0.88     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 941    0   11    3    2   12    7    2    1    1]\n",
      " [   0 1122    2    3    2    2    2    0    2    0]\n",
      " [  24   15  869   24   22   11   23   14   25    5]\n",
      " [   4    3   23  913    4   30    2   11    8   12]\n",
      " [   3    1    9    1  914    3    6    6    3   36]\n",
      " [  14    5   12   58    9  739   24    2   21    8]\n",
      " [  21    3   25    2   16   14  873    1    3    0]\n",
      " [   2   15   13    4   21    5    0  915    4   49]\n",
      " [  12   25   27   39   19   53   15   18  741   25]\n",
      " [  10    7   11   15   88    5    1   35    4  833]]\n",
      "--------------------------------\n",
      "final active learning accuracies [24.41, 39.12, 51.55, 58.15, 64.19, 67.33, 72.46000000000001, 73.94, 78.06, 78.57, 79.01, 78.68, 79.80000000000001, 80.78999999999999, 81.54, 82.21000000000001, 82.08, 83.17999999999999, 83.36, 83.13000000000001, 82.5, 83.24000000000001, 84.03, 84.84, 85.2, 85.17, 85.24000000000001, 85.1, 85.33, 85.00999999999999, 85.57000000000001, 85.91, 85.91, 86.4, 86.53999999999999, 86.78, 87.02, 87.18, 87.41, 87.33, 87.72, 87.8, 87.9, 88.1, 88.41, 88.22, 88.42999999999999, 88.38000000000001, 88.31, 88.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved Active-learning-experiment-10.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', '.ipynb_checkpoints', 'LICENSE', '.git']\n",
      "{\n",
      "  \"SvmModel\": {\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          24.41,\n",
      "          39.12,\n",
      "          51.55,\n",
      "          58.15,\n",
      "          64.19,\n",
      "          67.33,\n",
      "          72.46000000000001,\n",
      "          73.94,\n",
      "          78.06,\n",
      "          78.57,\n",
      "          79.01,\n",
      "          78.68,\n",
      "          79.80000000000001,\n",
      "          80.78999999999999,\n",
      "          81.54,\n",
      "          82.21000000000001,\n",
      "          82.08,\n",
      "          83.17999999999999,\n",
      "          83.36,\n",
      "          83.13000000000001,\n",
      "          82.5,\n",
      "          83.24000000000001,\n",
      "          84.03,\n",
      "          84.84,\n",
      "          85.2,\n",
      "          85.17,\n",
      "          85.24000000000001,\n",
      "          85.1,\n",
      "          85.33,\n",
      "          85.00999999999999,\n",
      "          85.57000000000001,\n",
      "          85.91,\n",
      "          85.91,\n",
      "          86.4,\n",
      "          86.53999999999999,\n",
      "          86.78,\n",
      "          87.02,\n",
      "          87.18,\n",
      "          87.41,\n",
      "          87.33,\n",
      "          87.72,\n",
      "          87.8,\n",
      "          87.9,\n",
      "          88.1,\n",
      "          88.41,\n",
      "          88.22,\n",
      "          88.42999999999999,\n",
      "          88.38000000000001,\n",
      "          88.31,\n",
      "          88.6\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          76.8,\n",
      "          83.96000000000001,\n",
      "          87.08,\n",
      "          88.94\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          48.209999999999994,\n",
      "          59.870000000000005,\n",
      "          70.07,\n",
      "          73.88,\n",
      "          79.62,\n",
      "          80.99,\n",
      "          82.69999999999999,\n",
      "          83.2,\n",
      "          84.13000000000001,\n",
      "          84.61999999999999,\n",
      "          85.53,\n",
      "          86.32,\n",
      "          86.46000000000001,\n",
      "          87.16000000000001,\n",
      "          87.74,\n",
      "          87.87,\n",
      "          88.16000000000001,\n",
      "          88.24,\n",
      "          88.42,\n",
      "          88.13\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          82.87,\n",
      "          87.59\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          59.74,\n",
      "          70.57,\n",
      "          79.12,\n",
      "          83.25,\n",
      "          84.19,\n",
      "          86.44,\n",
      "          87.3,\n",
      "          87.81,\n",
      "          87.58,\n",
      "          88.63\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          30.12,\n",
      "          41.54,\n",
      "          51.15,\n",
      "          59.5,\n",
      "          64.64999999999999,\n",
      "          65.02,\n",
      "          66.7,\n",
      "          68.81,\n",
      "          70.28,\n",
      "          73.48,\n",
      "          73.83,\n",
      "          76.64,\n",
      "          76.83,\n",
      "          77.68,\n",
      "          77.38000000000001,\n",
      "          77.77,\n",
      "          79.17,\n",
      "          79.59,\n",
      "          80.86,\n",
      "          80.89,\n",
      "          81.24,\n",
      "          81.47999999999999,\n",
      "          82.23,\n",
      "          82.8,\n",
      "          82.96,\n",
      "          83.00999999999999,\n",
      "          83.64,\n",
      "          83.72,\n",
      "          83.35000000000001,\n",
      "          83.41,\n",
      "          83.69,\n",
      "          83.67999999999999,\n",
      "          84.23,\n",
      "          84.26,\n",
      "          84.48,\n",
      "          84.98,\n",
      "          85.38,\n",
      "          85.39,\n",
      "          85.63,\n",
      "          85.74000000000001,\n",
      "          86.17,\n",
      "          86.28,\n",
      "          86.38,\n",
      "          86.57000000000001,\n",
      "          86.42,\n",
      "          86.56,\n",
      "          86.38,\n",
      "          86.37,\n",
      "          86.44,\n",
      "          86.53999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.53999999999999,\n",
      "          80.67,\n",
      "          84.16,\n",
      "          86.61999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          55.489999999999995,\n",
      "          64.21,\n",
      "          71.63000000000001,\n",
      "          74.95,\n",
      "          76.49000000000001,\n",
      "          80.08999999999999,\n",
      "          82.11,\n",
      "          82.25,\n",
      "          82.65,\n",
      "          83.3,\n",
      "          84.02,\n",
      "          85.05,\n",
      "          85.15,\n",
      "          85.67,\n",
      "          86.18,\n",
      "          86.83999999999999,\n",
      "          87.41,\n",
      "          87.63,\n",
      "          87.82,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.15,\n",
      "          86.91\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          67.52,\n",
      "          75.52,\n",
      "          80.19,\n",
      "          84.26,\n",
      "          85.77,\n",
      "          86.16,\n",
      "          86.58,\n",
      "          86.65,\n",
      "          87.18,\n",
      "          87.09\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 11, using model = SvmModel, selection_function = EntropySelection, k = 250, iteration = 0.\n",
      "\n",
      "initial random chosen samples (250,)\n",
      "initial train set: (250, 784) (250,) unique(labels): [17 33 31 25 25 27 22 26 18 26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,) (250,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 11.570 s \n",
      "\n",
      "Accuracy rate for 84.730000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       980\n",
      "           1       0.89      0.98      0.93      1135\n",
      "           2       0.85      0.83      0.84      1032\n",
      "           3       0.83      0.84      0.83      1010\n",
      "           4       0.81      0.84      0.83       982\n",
      "           5       0.74      0.83      0.78       892\n",
      "           6       0.89      0.90      0.89       958\n",
      "           7       0.88      0.85      0.86      1028\n",
      "           8       0.91      0.65      0.76       974\n",
      "           9       0.79      0.80      0.79      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.84     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 919    0    3    1    2   39    8    7    1    0]\n",
      " [   0 1109    3    4    0    3    4    0   11    1]\n",
      " [  27   28  860   17   12   18   19   24   12   15]\n",
      " [   7   20   27  846    2   56    8   15   19   10]\n",
      " [   2   13    5    0  829    4   19    5    0  105]\n",
      " [  14   10    4   78    8  736   22    2   11    7]\n",
      " [  13    9   27    2   19   21  863    4    0    0]\n",
      " [   2   29   25    6   23    3    1  872    5   62]\n",
      " [  17   24   34   46   46  105   30   20  635   17]\n",
      " [  18    6   18   21   79   11    1   45    6  804]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 6 5]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [ 36  33 103  47  46  43  40  54  41  57] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 22.730 s \n",
      "\n",
      "Accuracy rate for 84.640000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       980\n",
      "           1       0.94      0.96      0.95      1135\n",
      "           2       0.86      0.89      0.87      1032\n",
      "           3       0.79      0.83      0.81      1010\n",
      "           4       0.81      0.83      0.82       982\n",
      "           5       0.70      0.72      0.71       892\n",
      "           6       0.91      0.88      0.89       958\n",
      "           7       0.90      0.90      0.90      1028\n",
      "           8       0.85      0.64      0.73       974\n",
      "           9       0.79      0.82      0.81      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.85      0.85      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 936    1    7    1    2   13   16    3    1    0]\n",
      " [   0 1095   11   13    1    2    2    2    8    1]\n",
      " [  26   11  917   14   15    8   14   11   14    2]\n",
      " [  15    1   29  841    2   62   10   20   25    5]\n",
      " [   1    5   10   10  815    4    6    5    3  123]\n",
      " [  36   15    8  113    3  641   15    7   39   15]\n",
      " [  15    5   34    3   42   18  839    0    2    0]\n",
      " [   2    9   27    5   11    1    0  928    1   44]\n",
      " [  17   23   26   49   16  161   16   16  622   28]\n",
      " [  11    4    1   14   95    3    1   34   16  830]]\n",
      "--------------------------------\n",
      "final active learning accuracies [84.73, 84.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved Active-learning-experiment-11.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', '.ipynb_checkpoints', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 12, using model = SvmModel, selection_function = EntropySelection, k = 125, iteration = 0.\n",
      "\n",
      "initial random chosen samples (125,)\n",
      "initial train set: (125, 784) (125,) unique(labels): [15 22 16 13 15  8  9 11  5 11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,) (125,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.884 s \n",
      "\n",
      "Accuracy rate for 74.170000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87       980\n",
      "           1       0.81      0.98      0.89      1135\n",
      "           2       0.84      0.75      0.79      1032\n",
      "           3       0.59      0.74      0.66      1010\n",
      "           4       0.62      0.89      0.73       982\n",
      "           5       0.53      0.40      0.46       892\n",
      "           6       0.90      0.88      0.89       958\n",
      "           7       0.80      0.78      0.79      1028\n",
      "           8       0.89      0.37      0.52       974\n",
      "           9       0.70      0.68      0.69      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.73      0.73     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 874    1    7    3    6   69   18    1    0    1]\n",
      " [   0 1113    4    3    5    0    4    0    6    0]\n",
      " [  12   87  773   28   31   16   13   41   28    3]\n",
      " [  13   28   19  751   10  135    3   23    8   20]\n",
      " [   3    9   12    0  872    0    4    6    0   76]\n",
      " [  57   21   15  257   93  354   22   20    3   50]\n",
      " [  35   12   43    0   15   12  839    0    0    2]\n",
      " [   5   28    9    4   96    1    0  797    0   88]\n",
      " [  26   66   37  218   51   75   25   65  359   52]\n",
      " [  14   14    3   16  234    2    0   40    1  685]]\n",
      "--------------------------------\n",
      "val predicted: (59875,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59875, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (125, 784) (125,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [16 24 27 16 16 26 14 12 86 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.533 s \n",
      "\n",
      "Accuracy rate for 79.150000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       980\n",
      "           1       0.87      0.94      0.91      1135\n",
      "           2       0.83      0.76      0.79      1032\n",
      "           3       0.77      0.75      0.76      1010\n",
      "           4       0.66      0.87      0.75       982\n",
      "           5       0.68      0.63      0.65       892\n",
      "           6       0.88      0.85      0.86       958\n",
      "           7       0.89      0.76      0.82      1028\n",
      "           8       0.72      0.74      0.73       974\n",
      "           9       0.76      0.67      0.71      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 892    1    8    1    3   36   33    1    3    2]\n",
      " [   0 1072    4    1    4    2    1    3   48    0]\n",
      " [  16   48  789   18   34   26   22    9   68    2]\n",
      " [  10   14   56  757    9  105    2   21   29    7]\n",
      " [   4    2    7    0  851    5   15    3   20   75]\n",
      " [  36   18   19  105   44  559   31    4   64   12]\n",
      " [  21   19   29    1   11   43  817    0   14    3]\n",
      " [   7   15   14    6   85    5    0  779   16  101]\n",
      " [  21   27   25   78   22   39    9   14  724   15]\n",
      " [  11   12    4   17  224    8    2   38   18  675]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [24 24 32 39 17 72 16 37 90 24] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.701 s \n",
      "\n",
      "Accuracy rate for 79.420000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82       980\n",
      "           1       0.88      0.93      0.91      1135\n",
      "           2       0.81      0.72      0.76      1032\n",
      "           3       0.73      0.83      0.78      1010\n",
      "           4       0.79      0.86      0.82       982\n",
      "           5       0.67      0.55      0.61       892\n",
      "           6       0.89      0.85      0.87       958\n",
      "           7       0.83      0.86      0.84      1028\n",
      "           8       0.74      0.74      0.74       974\n",
      "           9       0.81      0.67      0.73      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 877    0   11    5    0   54   26    1    3    3]\n",
      " [   0 1058   21   12    0    5    1    1   37    0]\n",
      " [  43   67  744   19   16   24   20   16   75    8]\n",
      " [  39    8   35  837    2   42    2   18   24    3]\n",
      " [   1    4   13    1  841   18   18   16   15   55]\n",
      " [ 108   12   11  160   13  491   20    3   64   10]\n",
      " [  16    8   46    1   15   46  813    1   11    1]\n",
      " [   5   16   17    4   26    8    0  882   11   59]\n",
      " [  51   15   17   76   13   28    8   21  720   25]\n",
      " [  15    9    1   26  144   14    1  101   19  679]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59625, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [26 59 43 45 34 80 20 50 93 50] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 21.467 s \n",
      "\n",
      "Accuracy rate for 80.080000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81       980\n",
      "           1       0.88      0.99      0.93      1135\n",
      "           2       0.83      0.69      0.75      1032\n",
      "           3       0.76      0.83      0.80      1010\n",
      "           4       0.81      0.87      0.84       982\n",
      "           5       0.70      0.56      0.62       892\n",
      "           6       0.90      0.84      0.87       958\n",
      "           7       0.81      0.87      0.84      1028\n",
      "           8       0.75      0.76      0.76       974\n",
      "           9       0.78      0.67      0.72      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.80      0.79     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 864    0   13    5    1   60   31    1    3    2]\n",
      " [   0 1119    4    2    1    3    0    0    6    0]\n",
      " [  41   82  711   30   19   21   25   17   78    8]\n",
      " [  40    4   23  839    2   32    4   19   40    7]\n",
      " [   1    6    6    9  850   19    8   19   11   53]\n",
      " [ 115    5   13  137    6  503   14    3   72   24]\n",
      " [  19    7   48    1   24   41  804    3    9    2]\n",
      " [   4   19   17    2   12    5    1  897    2   69]\n",
      " [  49   25   14   49    9   28    7   18  745   30]\n",
      " [  12   10    3   25  121    6    0  130   26  676]]\n",
      "--------------------------------\n",
      "final active learning accuracies [74.17, 79.14999999999999, 79.42, 80.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved Active-learning-experiment-12.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', '.ipynb_checkpoints', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 13, using model = SvmModel, selection_function = EntropySelection, k = 50, iteration = 0.\n",
      "\n",
      "initial random chosen samples (50,)\n",
      "initial train set: (50, 784) (50,) unique(labels): [ 3  6  5  4  7  5  3  3 10  4] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,) (50,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.714 s \n",
      "\n",
      "Accuracy rate for 68.250000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.57      0.71       980\n",
      "           1       0.72      0.88      0.79      1135\n",
      "           2       0.69      0.69      0.69      1032\n",
      "           3       0.83      0.64      0.72      1010\n",
      "           4       0.55      0.84      0.67       982\n",
      "           5       0.58      0.67      0.62       892\n",
      "           6       0.78      0.56      0.66       958\n",
      "           7       0.85      0.73      0.79      1028\n",
      "           8       0.60      0.80      0.69       974\n",
      "           9       0.50      0.41      0.45      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.71      0.68      0.68     10000\n",
      "weighted avg       0.71      0.68      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[563   2  14   0   6 261  39   2  33  60]\n",
      " [  0 999  33   3   0   0   4   0  93   3]\n",
      " [  5  52 716  82  26  14  16   5  92  24]\n",
      " [  0  80  52 646   3  71  13   8 120  17]\n",
      " [  0  29  12   0 820   4  14   4   9  90]\n",
      " [ 11  59  17  30  35 599  41   8  62  30]\n",
      " [ 14  12 136   1 185  15 540   0  11  44]\n",
      " [  1  75  14   3  37   2   0 751  27 118]\n",
      " [  2  39  32  10  18  47  20   6 776  24]\n",
      " [  1  44  10   4 350  15   3 101  66 415]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['5' '0' '9' ... '5' '6' '5']\n",
      "probabilities: (59950, 10) \n",
      " [3 0 4 ... 8 6 5]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [12  6  5 17  7 18 13  4 11  7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.284 s \n",
      "\n",
      "Accuracy rate for 69.560000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.71      0.80       980\n",
      "           1       0.83      0.84      0.84      1135\n",
      "           2       0.78      0.60      0.68      1032\n",
      "           3       0.59      0.67      0.63      1010\n",
      "           4       0.65      0.80      0.71       982\n",
      "           5       0.53      0.66      0.59       892\n",
      "           6       0.76      0.77      0.77       958\n",
      "           7       0.85      0.66      0.75      1028\n",
      "           8       0.59      0.74      0.66       974\n",
      "           9       0.59      0.48      0.53      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.69      0.69     10000\n",
      "weighted avg       0.71      0.70      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[693   0   4  62   0 133  43   1  34  10]\n",
      " [  0 956  25  29   0  23   8   0  93   1]\n",
      " [  7  32 624 150  15  25  78   2  79  20]\n",
      " [  0  24  14 677   0 149   8   5 113  20]\n",
      " [  7  20  11   1 786  14  27   7  14  95]\n",
      " [  5   6   9 139  18 588  33   8  59  27]\n",
      " [ 23   2  71   6  48  57 741   0   6   4]\n",
      " [  9  61  20  33  22  18   3 682  35 145]\n",
      " [  6  22  23  48  19  82  28   6 722  18]\n",
      " [  6  22   3   5 309  26   2  87  62 487]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['5' '0' '9' ... '5' '6' '5']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 9 ... 5 6 5]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [12  7  8 21 16 21 14 25 12 14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 7.878 s \n",
      "\n",
      "Accuracy rate for 71.760000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.71      0.80       980\n",
      "           1       0.90      0.92      0.91      1135\n",
      "           2       0.80      0.61      0.69      1032\n",
      "           3       0.56      0.67      0.61      1010\n",
      "           4       0.63      0.82      0.71       982\n",
      "           5       0.49      0.68      0.57       892\n",
      "           6       0.84      0.73      0.78       958\n",
      "           7       0.88      0.68      0.77      1028\n",
      "           8       0.66      0.71      0.69       974\n",
      "           9       0.69      0.61      0.65      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.72      0.72     10000\n",
      "weighted avg       0.74      0.72      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 695    0    3    6    5  209   31    2   24    5]\n",
      " [   0 1039   16   51    0   21    2    2    4    0]\n",
      " [   8   30  629  127   35   37   43   13   98   12]\n",
      " [   0   10   18  681    1  152    8    8  111   21]\n",
      " [   4    5    7    0  807    6   11   16    3  123]\n",
      " [   6   10   17  129    9  610   24    7   63   17]\n",
      " [  17    1   58    4  101   67  700    1    9    0]\n",
      " [   5   31   10  134   35   17    0  701   19   76]\n",
      " [   8   19   21   60   25  106   18    3  695   19]\n",
      " [   5   12    3   15  266   19    1   47   22  619]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['5' '0' '9' ... '5' '6' '5']\n",
      "probabilities: (59850, 10) \n",
      " [3 0 9 ... 5 6 5]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [12 11 13 24 16 22 14 31 36 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.136 s \n",
      "\n",
      "Accuracy rate for 70.640000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.71      0.80       980\n",
      "           1       0.88      0.91      0.89      1135\n",
      "           2       0.85      0.61      0.71      1032\n",
      "           3       0.63      0.66      0.64      1010\n",
      "           4       0.57      0.77      0.66       982\n",
      "           5       0.50      0.62      0.55       892\n",
      "           6       0.85      0.70      0.77       958\n",
      "           7       0.86      0.74      0.80      1028\n",
      "           8       0.57      0.81      0.67       974\n",
      "           9       0.64      0.50      0.56      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.73      0.70      0.71     10000\n",
      "weighted avg       0.73      0.71      0.71     10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 696    0    5    5    5  224   34    2    8    1]\n",
      " [   0 1028    1    6    0    7    2   11   79    1]\n",
      " [  11   45  634  111   27   31   38   13  111   11]\n",
      " [   0   11    3  662    2  119    8   12  175   18]\n",
      " [   3    7    4    1  758    9   12   17   10  161]\n",
      " [   6    6   18  116    7  555   12    6  140   26]\n",
      " [  16    2   55    4  108   75  670    0   28    0]\n",
      " [  10   27    7   99   44   11    2  762   11   55]\n",
      " [   5   28    8   29   19   64   10    7  790   14]\n",
      " [   6   12    8   15  358   17    1   51   32  509]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['3' '0' '9' ... '5' '6' '8']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 9 ... 5 6 8]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [13 15 22 26 18 38 17 32 43 26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.644 s \n",
      "\n",
      "Accuracy rate for 70.590000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.72      0.79       980\n",
      "           1       0.91      0.91      0.91      1135\n",
      "           2       0.87      0.66      0.75      1032\n",
      "           3       0.61      0.65      0.63      1010\n",
      "           4       0.60      0.74      0.66       982\n",
      "           5       0.49      0.54      0.51       892\n",
      "           6       0.88      0.75      0.81       958\n",
      "           7       0.85      0.70      0.77      1028\n",
      "           8       0.53      0.81      0.64       974\n",
      "           9       0.63      0.54      0.58      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.73      0.70      0.71     10000\n",
      "weighted avg       0.73      0.71      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 707    0    3   10    8  200   39    1    9    3]\n",
      " [   0 1031    0    7    2    2    4   10   79    0]\n",
      " [  10   28  685   97   19   29   21   21  118    4]\n",
      " [   3   19    8  654    1   91    8   10  194   22]\n",
      " [   1    2   12    5  730   28   11   12   19  162]\n",
      " [  32   16    7   95   11  479    9    7  193   43]\n",
      " [  27    2   53    1   60   71  723    0   21    0]\n",
      " [   7   19    6  151   45   11    1  722   12   54]\n",
      " [  11   13    4   36   23   54    7   10  788   28]\n",
      " [   4    7    6    9  319   10    1   56   57  540]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '9' ... '9' '6' '5']\n",
      "probabilities: (59750, 10) \n",
      " [8 0 9 ... 9 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [17 17 27 29 23 48 18 41 43 37] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.245 s \n",
      "\n",
      "Accuracy rate for 74.490000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81       980\n",
      "           1       0.88      0.91      0.90      1135\n",
      "           2       0.90      0.68      0.77      1032\n",
      "           3       0.70      0.70      0.70      1010\n",
      "           4       0.68      0.74      0.71       982\n",
      "           5       0.53      0.63      0.57       892\n",
      "           6       0.87      0.78      0.82       958\n",
      "           7       0.87      0.74      0.80      1028\n",
      "           8       0.60      0.80      0.68       974\n",
      "           9       0.69      0.67      0.68      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.76      0.74      0.74     10000\n",
      "weighted avg       0.76      0.74      0.75     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 755    0    0   11    1  165   43    1    4    0]\n",
      " [   0 1034    4    8    0    1    2   10   75    1]\n",
      " [  28   44  703   53   13   25   28   31   97   10]\n",
      " [  18   27    4  710    1   87    8    8  132   15]\n",
      " [   4    2   12    5  723   47   17   17   11  144]\n",
      " [  25   21    6   92    2  559    7    3  140   37]\n",
      " [  18    3   40    5   29   91  749    0   23    0]\n",
      " [  12   14   10   81   52    6    0  765   11   77]\n",
      " [  14   23    5   44   22   64    5    5  775   17]\n",
      " [  14    5    1    9  223   10    0   37   34  676]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['3' '0' '9' ... '5' '6' '5']\n",
      "probabilities: (59700, 10) \n",
      " [5 0 9 ... 5 6 5]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [22 21 39 36 27 50 23 44 49 39] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 17.770 s \n",
      "\n",
      "Accuracy rate for 76.310000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80       980\n",
      "           1       0.90      0.92      0.91      1135\n",
      "           2       0.91      0.69      0.79      1032\n",
      "           3       0.72      0.72      0.72      1010\n",
      "           4       0.71      0.76      0.73       982\n",
      "           5       0.55      0.60      0.58       892\n",
      "           6       0.87      0.84      0.85       958\n",
      "           7       0.87      0.81      0.84      1028\n",
      "           8       0.63      0.74      0.68       974\n",
      "           9       0.73      0.69      0.71      1009\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.77      0.76      0.76     10000\n",
      "weighted avg       0.77      0.76      0.76     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 796    0    3    9    3  146   22    1    0    0]\n",
      " [   0 1046    2    8    1    1    5    8   61    3]\n",
      " [  29   51  716   35    8   25   50   35   77    6]\n",
      " [  46    4    9  731    1   69    6    8  119   17]\n",
      " [  11    2    7    7  748   43    9   18   12  125]\n",
      " [  50   19   11  116    2  538    8    4  113   31]\n",
      " [  24    4   21    1   28   69  805    1    5    0]\n",
      " [  11   11    9   47   36    6    0  833   11   64]\n",
      " [  34   24    6   54   26   67   21    6  725   11]\n",
      " [  15    5    2   10  206    7    0   44   27  693]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['5' '0' '9' ... '5' '6' '8']\n",
      "probabilities: (59650, 10) \n",
      " [3 0 9 ... 5 6 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [30 25 47 41 34 53 27 46 56 41] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 20.508 s \n",
      "\n",
      "Accuracy rate for 78.170000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       980\n",
      "           1       0.88      0.92      0.90      1135\n",
      "           2       0.93      0.68      0.79      1032\n",
      "           3       0.75      0.80      0.77      1010\n",
      "           4       0.69      0.80      0.74       982\n",
      "           5       0.61      0.66      0.64       892\n",
      "           6       0.89      0.86      0.88       958\n",
      "           7       0.88      0.81      0.85      1028\n",
      "           8       0.67      0.75      0.71       974\n",
      "           9       0.72      0.66      0.69      1009\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.79      0.78      0.78     10000\n",
      "weighted avg       0.79      0.78      0.78     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 832    0    1    3    3  121   18    1    1    0]\n",
      " [   0 1047    3    9    0    1    4    9   60    2]\n",
      " [  32   68  701   37   11   25   44   23   89    2]\n",
      " [  41    3    5  805    2   66    6   10   53   19]\n",
      " [   2    1    6    5  789   22    9   27   18  103]\n",
      " [  26   23    4  101    3  588    8    4   96   39]\n",
      " [  18    3    7    2   31   63  824    0   10    0]\n",
      " [  14    8   14   29   36    3    0  833   11   80]\n",
      " [  23   30    3   70   22   59   12    3  735   17]\n",
      " [  14    5    6   12  241    9    0   32   27  663]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59600,) ['5' '0' '9' ... '5' '6' '8']\n",
      "probabilities: (59600, 10) \n",
      " [5 0 9 ... 5 6 8]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [41 26 57 42 44 55 28 54 61 42] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 22.800 s \n",
      "\n",
      "Accuracy rate for 77.950000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.81       980\n",
      "           1       0.88      0.92      0.90      1135\n",
      "           2       0.89      0.67      0.76      1032\n",
      "           3       0.76      0.81      0.79      1010\n",
      "           4       0.70      0.87      0.78       982\n",
      "           5       0.58      0.67      0.62       892\n",
      "           6       0.87      0.84      0.85       958\n",
      "           7       0.90      0.79      0.84      1028\n",
      "           8       0.67      0.76      0.71       974\n",
      "           9       0.74      0.67      0.70      1009\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.79      0.78      0.78     10000\n",
      "weighted avg       0.79      0.78      0.78     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 751    0    2    2    1  199   23    1    1    0]\n",
      " [   0 1049    5    8    1    7    4    7   52    2]\n",
      " [  13   71  688   36   13   17   66   14  110    4]\n",
      " [  25    5   10  823    2   64    7    5   55   14]\n",
      " [   2    0   11    1  855   14    1   26    6   66]\n",
      " [  21   23    8   95    5  596    9    2  101   32]\n",
      " [  11    2   20    2   49   64  801    1    8    0]\n",
      " [  11    7   17   28   31    2    0  813    9  110]\n",
      " [  24   26    8   72   15   53   12   10  742   12]\n",
      " [  12    5    6   12  241   13    0   21   22  677]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59550, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [47 29 68 49 53 58 28 56 65 47] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 25.304 s \n",
      "\n",
      "Accuracy rate for 78.780000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.80       980\n",
      "           1       0.89      0.94      0.91      1135\n",
      "           2       0.91      0.71      0.80      1032\n",
      "           3       0.75      0.77      0.76      1010\n",
      "           4       0.76      0.87      0.81       982\n",
      "           5       0.57      0.69      0.62       892\n",
      "           6       0.89      0.84      0.86       958\n",
      "           7       0.91      0.79      0.85      1028\n",
      "           8       0.69      0.72      0.71       974\n",
      "           9       0.73      0.75      0.74      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 749    0    2    3    1  203   21    1    0    0]\n",
      " [   0 1064    4    3    1    8    4    4   45    2]\n",
      " [  12   54  733   21   16   17   52   11  112    4]\n",
      " [  30    6    9  776    2  104    9    8   42   24]\n",
      " [   3    1   11    2  855    5    1   25    9   70]\n",
      " [  27   19    9   97    3  616    6    1   71   43]\n",
      " [  14    1   11    7   42   65  807    2    9    0]\n",
      " [  21    9   15   33   21    1    0  814    8  106]\n",
      " [  32   32    6   87   13   54   11    7  703   29]\n",
      " [  11    5    5   12  165   13    0   22   15  761]]\n",
      "--------------------------------\n",
      "final active learning accuracies [68.25, 69.56, 71.76, 70.64, 70.59, 74.49, 76.31, 78.17, 77.95, 78.78]\n",
      "saved Active-learning-experiment-13.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 14, using model = SvmModel, selection_function = EntropySelection, k = 25, iteration = 0.\n",
      "\n",
      "initial random chosen samples (25,)\n",
      "initial train set: (25, 784) (25,) unique(labels): [3 5 2 2 1 3 3 3 1 2] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59975, 784) (59975,) (25,)\n",
      "\n",
      "Train set: (25, 784) y: (25,)\n",
      "Val   set: (59975, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 1.385 s \n",
      "\n",
      "Accuracy rate for 52.650000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.77      0.63       980\n",
      "           1       0.58      0.94      0.72      1135\n",
      "           2       0.68      0.49      0.57      1032\n",
      "           3       0.72      0.38      0.50      1010\n",
      "           4       0.86      0.14      0.24       982\n",
      "           5       0.31      0.33      0.32       892\n",
      "           6       0.61      0.70      0.65       958\n",
      "           7       0.47      0.77      0.58      1028\n",
      "           8       0.78      0.18      0.30       974\n",
      "           9       0.36      0.48      0.41      1009\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.59      0.52      0.49     10000\n",
      "weighted avg       0.59      0.53      0.50     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 758    2   17    4    0   56  105   19    0   19]\n",
      " [  41 1064    1    1    0   21    2    5    0    0]\n",
      " [  80   95  505   51    0   53  201   17   15   15]\n",
      " [  50  153   75  385    0  210    5  104   20    8]\n",
      " [  72   38    3    8  137   78   45   68    1  532]\n",
      " [ 239   51    3   45    3  293   17  160   15   66]\n",
      " [  89   71   13    0    0   74  671    0    0   40]\n",
      " [   8  121   17    3    0   45    6  792    0   36]\n",
      " [  66  199  106   30    0   87   13  153  179  141]\n",
      " [  23   46    5    8   19   32   32  363    0  481]]\n",
      "--------------------------------\n",
      "val predicted: (59975,) ['7' '0' '4' ... '7' '6' '7']\n",
      "probabilities: (59975, 10) \n",
      " [5 0 0 ... 5 5 5]\n",
      "trainset before (25, 784) (25,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [ 6  5  2  2  2  9 16  3  3  2] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.608 s \n",
      "\n",
      "Accuracy rate for 55.770000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.89      0.79       980\n",
      "           1       0.63      0.93      0.75      1135\n",
      "           2       0.69      0.36      0.47      1032\n",
      "           3       0.68      0.35      0.46      1010\n",
      "           4       0.80      0.25      0.38       982\n",
      "           5       0.32      0.36      0.34       892\n",
      "           6       0.54      0.83      0.65       958\n",
      "           7       0.49      0.77      0.60      1028\n",
      "           8       0.59      0.33      0.43       974\n",
      "           9       0.42      0.44      0.43      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.59      0.55      0.53     10000\n",
      "weighted avg       0.59      0.56      0.53     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 871    1    1    2    1   24   66    9    4    1]\n",
      " [   0 1059    1    1    0   17    2    5   50    0]\n",
      " [  59   81  371   61    3   47  313   12   82    3]\n",
      " [  20  133   59  352    0  308    6  102   23    7]\n",
      " [   9   36    1   10  248   26  148   60    9  435]\n",
      " [ 179   41    3   49    6  319   51  153   39   52]\n",
      " [  33   22   11    0    6   64  798    0    7   17]\n",
      " [   4  102   12    1    3   43   33  789    9   32]\n",
      " [  38  176   75   30    2   95   22  132  324   80]\n",
      " [  12   40    6    8   41   39   52  362    3  446]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59950,) ['7' '0' '4' ... '7' '6' '7']\n",
      "probabilities: (59950, 10) \n",
      " [7 0 6 ... 7 6 7]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (75, 784) (75,)\n",
      "updated train set: (75, 784) (75,) unique(labels): [ 6  5  2  8  2 27 16  3  4  2] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59925, 784) (59925,)\n",
      "\n",
      "Train set: (75, 784) y: (75,)\n",
      "Val   set: (59925, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.956 s \n",
      "\n",
      "Accuracy rate for 58.500000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       980\n",
      "           1       0.81      0.92      0.86      1135\n",
      "           2       0.82      0.35      0.49      1032\n",
      "           3       0.63      0.61      0.62      1010\n",
      "           4       0.82      0.22      0.34       982\n",
      "           5       0.28      0.68      0.40       892\n",
      "           6       0.59      0.74      0.66       958\n",
      "           7       0.58      0.71      0.64      1028\n",
      "           8       0.63      0.41      0.50       974\n",
      "           9       0.43      0.33      0.38      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.64      0.58      0.57     10000\n",
      "weighted avg       0.65      0.58      0.58     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 832    0    1    4    1   80   48    2   12    0]\n",
      " [   0 1046    0    3    0   38    0    4   44    0]\n",
      " [  48   34  357  133    3  156  224    6   69    2]\n",
      " [   2    7   18  614    0  316    2   25   25    1]\n",
      " [   9   22    1   30  212  169  128   40   13  358]\n",
      " [  60   26    0   43    3  611   33   72   35    9]\n",
      " [  31   13    9    1    6  157  710    0   17   14]\n",
      " [   4   81   13    3    2  143   14  733   11   24]\n",
      " [  19   46   30  124    1  259    3   57  398   37]\n",
      " [   9   20    5   22   31  218   43  321    3  337]]\n",
      "--------------------------------\n",
      "val predicted: (59925,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59925, 10) \n",
      " [5 0 6 ... 5 6 8]\n",
      "trainset before (75, 784) (75,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 6  5  3  8 12 29 16  4  9  8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.248 s \n",
      "\n",
      "Accuracy rate for 67.900000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85       980\n",
      "           1       0.87      0.91      0.89      1135\n",
      "           2       0.79      0.42      0.55      1032\n",
      "           3       0.72      0.61      0.66      1010\n",
      "           4       0.81      0.59      0.68       982\n",
      "           5       0.38      0.66      0.49       892\n",
      "           6       0.71      0.65      0.68       958\n",
      "           7       0.80      0.75      0.77      1028\n",
      "           8       0.48      0.67      0.56       974\n",
      "           9       0.66      0.69      0.68      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.71      0.68      0.68     10000\n",
      "weighted avg       0.72      0.68      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 809    0    7    6    2   80   35    0   37    4]\n",
      " [   0 1029    1    3    0   40    0    1   61    0]\n",
      " [  35   22  436   93   18  107  145    7  162    7]\n",
      " [   4   10   32  618    0  264    4   13   59    6]\n",
      " [   5    7    1    9  575   68   35   10   29  243]\n",
      " [  17   14    0   44   16  591    7   16  176   11]\n",
      " [  31    9   20    2   42  119  618    0  105   12]\n",
      " [   1   41   33    0   12   72    4  769   53   43]\n",
      " [   9   39   19   77    6  126    1   21  650   26]\n",
      " [   5   12    2    9   42   69   18  130   27  695]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['8' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59900, 10) \n",
      " [8 0 4 ... 5 6 8]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (125, 784) (125,)\n",
      "updated train set: (125, 784) (125,) unique(labels): [ 7 10  5  8 17 31 19  7 12  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.322 s \n",
      "\n",
      "Accuracy rate for 68.630000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       980\n",
      "           1       0.78      0.96      0.87      1135\n",
      "           2       0.76      0.42      0.54      1032\n",
      "           3       0.77      0.61      0.68      1010\n",
      "           4       0.76      0.69      0.72       982\n",
      "           5       0.44      0.68      0.54       892\n",
      "           6       0.68      0.69      0.69       958\n",
      "           7       0.73      0.70      0.71      1028\n",
      "           8       0.56      0.61      0.58       974\n",
      "           9       0.65      0.62      0.64      1009\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.70      0.68      0.68     10000\n",
      "weighted avg       0.70      0.69      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 827    1    3    3    0   83   48    1   14    0]\n",
      " [   0 1095    1    1    0   15    0    9   14    0]\n",
      " [  37   95  436   73   29   61  163   13  115   10]\n",
      " [  17   16   41  614    1  231   10   36   40    4]\n",
      " [   1    8    0    0  674   21   49   19   12  198]\n",
      " [  47   14    1   33   16  608   11   12  142    8]\n",
      " [  39    8    3    1    6  121  664    0  113    3]\n",
      " [   2   64   61    1   27   60   10  720   15   68]\n",
      " [  12   77   21   66    9  126    1   22  595   45]\n",
      " [   3   18    6    7  120   42   15  156   12  630]]\n",
      "--------------------------------\n",
      "val predicted: (59875,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59875, 10) \n",
      " [5 0 5 ... 5 6 8]\n",
      "trainset before (125, 784) (125,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [ 7 10 24 10 17 31 20  8 14  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 7.523 s \n",
      "\n",
      "Accuracy rate for 72.320000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       980\n",
      "           1       0.82      0.96      0.88      1135\n",
      "           2       0.79      0.67      0.72      1032\n",
      "           3       0.75      0.62      0.68      1010\n",
      "           4       0.78      0.69      0.73       982\n",
      "           5       0.49      0.64      0.56       892\n",
      "           6       0.75      0.73      0.74       958\n",
      "           7       0.77      0.76      0.76      1028\n",
      "           8       0.58      0.65      0.62       974\n",
      "           9       0.68      0.63      0.65      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.72     10000\n",
      "weighted avg       0.73      0.72      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 814    0   14   10    0   82   48    1   11    0]\n",
      " [   0 1090    0    5    0    9    3   10   18    0]\n",
      " [  27   63  689   23   25   27   99   11   60    8]\n",
      " [   7    7   74  627    0  202   11   28   48    6]\n",
      " [   1    7    5    9  678   20   39   21    8  194]\n",
      " [  41   17    0   39   14  575   12    9  177    8]\n",
      " [  29    8    6    1    3   96  704    0  109    2]\n",
      " [   2   60   61    2   18   45    9  782    6   43]\n",
      " [   8   63   20   96    8   82    4   19  637   37]\n",
      " [   3   19    7   22  118   40   11  136   17  636]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59850,) ['5' '0' '6' ... '5' '6' '8']\n",
      "probabilities: (59850, 10) \n",
      " [5 0 5 ... 5 6 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (175, 784) (175,)\n",
      "updated train set: (175, 784) (175,) unique(labels): [ 9 11 30 12 20 32 20 10 22  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59825, 784) (59825,)\n",
      "\n",
      "Train set: (175, 784) y: (175,)\n",
      "Val   set: (59825, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 9.048 s \n",
      "\n",
      "Accuracy rate for 72.370000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       980\n",
      "           1       0.85      0.93      0.89      1135\n",
      "           2       0.85      0.68      0.75      1032\n",
      "           3       0.79      0.55      0.65      1010\n",
      "           4       0.67      0.70      0.69       982\n",
      "           5       0.49      0.67      0.57       892\n",
      "           6       0.78      0.73      0.75       958\n",
      "           7       0.82      0.73      0.77      1028\n",
      "           8       0.59      0.79      0.68       974\n",
      "           9       0.70      0.60      0.64      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.72     10000\n",
      "weighted avg       0.74      0.72      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 820    0    9    4    0  115   28    2    2    0]\n",
      " [   0 1057    0    2    1   10    3    5   57    0]\n",
      " [  17   78  697   29   25   28   76   20   60    2]\n",
      " [  33   10   60  559    1  235   13   25   73    1]\n",
      " [   5    4    7   15  689   19   42   15    9  177]\n",
      " [  64   10    2   19   31  597   10   12  140    7]\n",
      " [  46    5    6    2    9   60  695    0  134    1]\n",
      " [  10   51   31    4   44   69    5  755    4   55]\n",
      " [  21   14    2   67   15   45    4   19  766   21]\n",
      " [   7   10    8   11  207   34   12   72   46  602]]\n",
      "--------------------------------\n",
      "val predicted: (59825,) ['5' '0' '4' ... '8' '6' '8']\n",
      "probabilities: (59825, 10) \n",
      " [5 0 5 ... 8 6 8]\n",
      "trainset before (175, 784) (175,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [10 11 37 18 21 33 20 11 29 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.093 s \n",
      "\n",
      "Accuracy rate for 72.080000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84       980\n",
      "           1       0.87      0.94      0.91      1135\n",
      "           2       0.81      0.74      0.77      1032\n",
      "           3       0.62      0.46      0.53      1010\n",
      "           4       0.65      0.71      0.68       982\n",
      "           5       0.52      0.76      0.62       892\n",
      "           6       0.80      0.73      0.76       958\n",
      "           7       0.82      0.69      0.75      1028\n",
      "           8       0.61      0.81      0.70       974\n",
      "           9       0.71      0.53      0.60      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.72     10000\n",
      "weighted avg       0.73      0.72      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 806    0   23    4    0  109   34    2    2    0]\n",
      " [   0 1067    2    5    4   12    2    6   37    0]\n",
      " [   7   56  761   22   15   32   52   12   75    0]\n",
      " [  37    9   63  466    1  237   12   25  159    1]\n",
      " [   2    4   15   33  693   20   39    9   12  155]\n",
      " [  34   12    6   28   25  679   13    5   89    1]\n",
      " [  24    5   29    4   21   89  699    0   86    1]\n",
      " [  12   44   26   47   59   62    5  711    4   58]\n",
      " [   8   15    9   72   19   37    4   10  793    7]\n",
      " [   8    8   10   70  228   26   10   82   34  533]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['5' '0' '3' ... '5' '6' '8']\n",
      "probabilities: (59800, 10) \n",
      " [5 0 5 ... 5 6 8]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (225, 784) (225,)\n",
      "updated train set: (225, 784) (225,) unique(labels): [12 11 41 22 27 34 22 12 30 14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59775, 784) (59775,)\n",
      "\n",
      "Train set: (225, 784) y: (225,)\n",
      "Val   set: (59775, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 11.671 s \n",
      "\n",
      "Accuracy rate for 72.490000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81       980\n",
      "           1       0.88      0.93      0.90      1135\n",
      "           2       0.82      0.71      0.76      1032\n",
      "           3       0.62      0.52      0.57      1010\n",
      "           4       0.71      0.73      0.72       982\n",
      "           5       0.54      0.74      0.63       892\n",
      "           6       0.83      0.74      0.78       958\n",
      "           7       0.85      0.67      0.75      1028\n",
      "           8       0.59      0.81      0.68       974\n",
      "           9       0.67      0.60      0.63      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.72     10000\n",
      "weighted avg       0.74      0.72      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 774    1   12    3    0  158   29    1    2    0]\n",
      " [   0 1056    1   30    1    8    0    6   33    0]\n",
      " [  10   51  733   12   12   27   74    7  102    4]\n",
      " [  53    7   33  529    2  194    8   29  152    3]\n",
      " [   1    3   24   16  714    5   14    7    8  190]\n",
      " [  42    9    4   30   18  657   11    2  116    3]\n",
      " [  21    2   41    6   22   63  708    1   93    1]\n",
      " [   3   47   26   81   46   40    2  684    3   96]\n",
      " [  20   16    8   68   15   39    5    9  786    8]\n",
      " [   8    8   16   73  182   15    3   60   36  608]]\n",
      "--------------------------------\n",
      "val predicted: (59775,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59775, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (225, 784) (225,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [12 16 43 22 27 39 26 13 37 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.588 s \n",
      "\n",
      "Accuracy rate for 71.940000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       980\n",
      "           1       0.86      0.95      0.90      1135\n",
      "           2       0.75      0.71      0.73      1032\n",
      "           3       0.63      0.61      0.62      1010\n",
      "           4       0.72      0.73      0.72       982\n",
      "           5       0.53      0.66      0.59       892\n",
      "           6       0.86      0.70      0.77       958\n",
      "           7       0.85      0.66      0.74      1028\n",
      "           8       0.60      0.74      0.66       974\n",
      "           9       0.65      0.60      0.63      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.72     10000\n",
      "weighted avg       0.73      0.72      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 782    1   24    1    0  161    9    1    1    0]\n",
      " [   0 1083    4   18    0    4    0    1   25    0]\n",
      " [  12   62  736   17   13   24   62    8   95    3]\n",
      " [  53   12   27  614    3  188    9   24   76    4]\n",
      " [   1    2   23   12  713   10    7    7   15  192]\n",
      " [  48   18    4   38   18  593   10    4  155    4]\n",
      " [  18    2  114    1   15   49  666    1   90    2]\n",
      " [   3   54   26   86   45   25    1  676    6  106]\n",
      " [  23   20    9  100   10   51    9   13  724   15]\n",
      " [   9   10   17   90  173   14    1   60   28  607]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "val predicted: (59750,) ['8' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (275, 784) (275,)\n",
      "updated train set: (275, 784) (275,) unique(labels): [12 17 45 27 28 42 26 19 40 19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59725, 784) (59725,)\n",
      "\n",
      "Train set: (275, 784) y: (275,)\n",
      "Val   set: (59725, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 13.824 s \n",
      "\n",
      "Accuracy rate for 73.110000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81       980\n",
      "           1       0.87      0.96      0.91      1135\n",
      "           2       0.75      0.68      0.71      1032\n",
      "           3       0.61      0.61      0.61      1010\n",
      "           4       0.68      0.80      0.74       982\n",
      "           5       0.56      0.72      0.63       892\n",
      "           6       0.86      0.70      0.77       958\n",
      "           7       0.81      0.75      0.77      1028\n",
      "           8       0.67      0.75      0.71       974\n",
      "           9       0.74      0.51      0.60      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.73      0.73     10000\n",
      "weighted avg       0.74      0.73      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 787    0   19    5    2  152   10    1    4    0]\n",
      " [   0 1084    6   16    1    8    0    0   19    1]\n",
      " [  16   96  701   20   17   19   67   11   83    2]\n",
      " [  63    9   22  621    3  191   11   31   58    1]\n",
      " [   1    1   18   22  787   12    9    6   15  111]\n",
      " [  53    8    7   51   15  646    9    2   98    3]\n",
      " [  19    3  111    7   31   52  674    1   59    1]\n",
      " [   1   31   22  100   48    7    0  766    4   49]\n",
      " [  25   15   12   89    9   50    5   28  733    8]\n",
      " [   8    6   21   83  238    9    1  103   28  512]]\n",
      "--------------------------------\n",
      "val predicted: (59725,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59725, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (275, 784) (275,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [18 20 48 33 28 42 28 21 41 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.216 s \n",
      "\n",
      "Accuracy rate for 75.180000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       980\n",
      "           1       0.87      0.96      0.91      1135\n",
      "           2       0.80      0.67      0.73      1032\n",
      "           3       0.65      0.67      0.66      1010\n",
      "           4       0.71      0.79      0.75       982\n",
      "           5       0.61      0.72      0.66       892\n",
      "           6       0.87      0.73      0.79       958\n",
      "           7       0.82      0.74      0.78      1028\n",
      "           8       0.69      0.74      0.71       974\n",
      "           9       0.72      0.60      0.65      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.75      0.75     10000\n",
      "weighted avg       0.76      0.75      0.75     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 862    0    2    5    2   99    8    1    1    0]\n",
      " [   0 1088    3   21    0    6    0    1   14    2]\n",
      " [  32   94  688   33   16   11   71    7   79    1]\n",
      " [  61    4   24  681    1  158    2   33   46    0]\n",
      " [   3    2   10   10  774   10   10    7   14  142]\n",
      " [  52    6    6   49   13  643   10    8   98    7]\n",
      " [  26    3   82    5   33   53  701    1   53    1]\n",
      " [   5   27   23  103   32    7    0  760    3   68]\n",
      " [  26   19    9   89    9   54    7   28  718   15]\n",
      " [   9    8   16   56  207   10    1   78   21  603]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59700, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (325, 784) (325,)\n",
      "updated train set: (325, 784) (325,) unique(labels): [20 20 51 35 29 47 30 25 45 23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59675, 784) (59675,)\n",
      "\n",
      "Train set: (325, 784) y: (325,)\n",
      "Val   set: (59675, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 16.271 s \n",
      "\n",
      "Accuracy rate for 76.250000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.84       980\n",
      "           1       0.87      0.95      0.91      1135\n",
      "           2       0.85      0.68      0.75      1032\n",
      "           3       0.66      0.70      0.68      1010\n",
      "           4       0.74      0.79      0.76       982\n",
      "           5       0.62      0.71      0.66       892\n",
      "           6       0.88      0.77      0.82       958\n",
      "           7       0.87      0.71      0.78      1028\n",
      "           8       0.67      0.74      0.70       974\n",
      "           9       0.72      0.68      0.70      1009\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.77      0.76      0.76     10000\n",
      "weighted avg       0.77      0.76      0.76     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 864    0    1    3    1   97    9    1    2    2]\n",
      " [   0 1082    3   25    0    8    0    1   15    1]\n",
      " [  39   98  700   36   12   13   59    9   65    1]\n",
      " [  68    3   20  704    2  127    2   22   59    3]\n",
      " [   1    2    9   10  777   15    8    4   16  140]\n",
      " [  51    8    2   53   18  630   10    6  102   12]\n",
      " [  27    3   51   12   24   36  737    1   66    1]\n",
      " [   3   28   24  105   33   16    1  727    5   86]\n",
      " [  25   21    7   84    7   64    8   15  721   22]\n",
      " [  11    5    9   34  183   10    0   47   27  683]]\n",
      "--------------------------------\n",
      "val predicted: (59675,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59675, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (325, 784) (325,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [23 20 55 38 34 50 34 26 46 24] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 17.692 s \n",
      "\n",
      "Accuracy rate for 75.600000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.80       980\n",
      "           1       0.86      0.95      0.90      1135\n",
      "           2       0.79      0.67      0.73      1032\n",
      "           3       0.70      0.62      0.66      1010\n",
      "           4       0.74      0.78      0.76       982\n",
      "           5       0.59      0.68      0.63       892\n",
      "           6       0.89      0.83      0.86       958\n",
      "           7       0.88      0.73      0.80      1028\n",
      "           8       0.68      0.75      0.71       974\n",
      "           9       0.71      0.66      0.68      1009\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.75      0.75     10000\n",
      "weighted avg       0.76      0.76      0.76     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 854    0    0    3    1  109    8    1    1    3]\n",
      " [   0 1082    3   24    0   11    0    1   13    1]\n",
      " [  47  108  690   27   14   13   57    7   68    1]\n",
      " [ 107    3   33  630    2  160    5   15   51    4]\n",
      " [   7    2   12   16  762   10    9    7   15  142]\n",
      " [  59   10    7   42   17  605   12    5  125   10]\n",
      " [  27    3   54    2   16   21  797    1   37    0]\n",
      " [   5   26   42   76   24   13    0  748    4   90]\n",
      " [  25   20   13   60    7   80    8   13  730   18]\n",
      " [  14    6   15   26  191   11    0   55   29  662]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59650, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [25 22 57 39 37 52 37 28 49 29] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 19.142 s \n",
      "\n",
      "Accuracy rate for 76.790000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78       980\n",
      "           1       0.82      0.96      0.88      1135\n",
      "           2       0.84      0.68      0.75      1032\n",
      "           3       0.70      0.67      0.68      1010\n",
      "           4       0.82      0.79      0.80       982\n",
      "           5       0.62      0.64      0.63       892\n",
      "           6       0.91      0.82      0.87       958\n",
      "           7       0.89      0.70      0.78      1028\n",
      "           8       0.71      0.74      0.72       974\n",
      "           9       0.71      0.78      0.74      1009\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.76      0.76     10000\n",
      "weighted avg       0.77      0.77      0.77     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 844    0    1   10    2  114    6    1    1    1]\n",
      " [   0 1089    1   18    0   12    1    0   13    1]\n",
      " [  44  145  700   18   14   13   43    8   45    2]\n",
      " [ 116   10   37  674    1  114    3   17   34    4]\n",
      " [   4    2   11   14  778    9    9    8   13  134]\n",
      " [  73   11    3   56   19  573    9    6  124   18]\n",
      " [  51    3   39    7   20   13  789    1   35    0]\n",
      " [   4   26   27   79   12    8    0  721    7  144]\n",
      " [  35   42    9   61    5   60    6   15  721   20]\n",
      " [  14    6    7   25  101    7    0   37   22  790]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['0' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59625, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [26 23 61 43 39 55 37 30 56 30] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 20.456 s \n",
      "\n",
      "Accuracy rate for 77.430000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79       980\n",
      "           1       0.83      0.95      0.88      1135\n",
      "           2       0.86      0.70      0.77      1032\n",
      "           3       0.68      0.71      0.70      1010\n",
      "           4       0.84      0.76      0.80       982\n",
      "           5       0.64      0.67      0.66       892\n",
      "           6       0.91      0.84      0.87       958\n",
      "           7       0.90      0.73      0.81      1028\n",
      "           8       0.71      0.74      0.73       974\n",
      "           9       0.69      0.76      0.72      1009\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.78      0.77      0.77     10000\n",
      "weighted avg       0.78      0.77      0.77     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 843    0    4    7    1  113    7    2    3    0]\n",
      " [   1 1079    2   23    0    9    1    0   19    1]\n",
      " [  33  134  719   22   12   10   47    8   45    2]\n",
      " [ 105   10   24  717    2   92    2   12   41    5]\n",
      " [   4    2   12   26  745    7    8    6   14  158]\n",
      " [  60   12    3   60   21  602    8    3  102   21]\n",
      " [  47    3   32   11   16   13  801    1   34    0]\n",
      " [   4   27   28   62    8   10    0  752    8  129]\n",
      " [  38   32    9   60    3   72    6    9  722   23]\n",
      " [   9    7    7   60   79   11    0   46   27  763]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59600, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (425, 784) (425,)\n",
      "updated train set: (425, 784) (425,) unique(labels): [28 33 61 44 40 58 41 31 58 31] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59575, 784) (59575,)\n",
      "\n",
      "Train set: (425, 784) y: (425,)\n",
      "Val   set: (59575, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 21.376 s \n",
      "\n",
      "Accuracy rate for 77.560000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78       980\n",
      "           1       0.84      0.96      0.90      1135\n",
      "           2       0.86      0.69      0.76      1032\n",
      "           3       0.69      0.69      0.69      1010\n",
      "           4       0.84      0.76      0.80       982\n",
      "           5       0.65      0.68      0.66       892\n",
      "           6       0.91      0.85      0.88       958\n",
      "           7       0.89      0.75      0.82      1028\n",
      "           8       0.69      0.74      0.72       974\n",
      "           9       0.70      0.74      0.72      1009\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.78      0.77      0.77     10000\n",
      "weighted avg       0.78      0.78      0.78     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 842    0    6    6    1  117    6    1    1    0]\n",
      " [   0 1087    3   13    0    7    1    0   23    1]\n",
      " [  39  118  710   27   12    8   47   10   59    2]\n",
      " [ 131    6   22  699    2   81    2   15   48    4]\n",
      " [   6    3   12   21  750    9    5    7   19  150]\n",
      " [  62   12    3   61   19  606    9    3   97   20]\n",
      " [  42    3   31   10   14   11  817    1   29    0]\n",
      " [   3   27   30   52   11    9    0  774    8  114]\n",
      " [  48   28    5   57    3   72    6    8  721   26]\n",
      " [  10    6    8   60   79   11    0   49   36  750]]\n",
      "--------------------------------\n",
      "val predicted: (59575,) ['5' '0' '3' ... '5' '6' '8']\n",
      "probabilities: (59575, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (425, 784) (425,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [28 33 72 45 40 63 42 34 61 32] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 22.624 s \n",
      "\n",
      "Accuracy rate for 77.450000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.77       980\n",
      "           1       0.85      0.96      0.90      1135\n",
      "           2       0.81      0.69      0.74      1032\n",
      "           3       0.72      0.68      0.70      1010\n",
      "           4       0.85      0.75      0.80       982\n",
      "           5       0.64      0.70      0.67       892\n",
      "           6       0.92      0.84      0.88       958\n",
      "           7       0.90      0.77      0.83      1028\n",
      "           8       0.68      0.78      0.72       974\n",
      "           9       0.71      0.73      0.72      1009\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.78      0.77      0.77     10000\n",
      "weighted avg       0.78      0.77      0.77     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 826    0    7    5    1  130    7    1    3    0]\n",
      " [   0 1084    3   12    0    6    1    0   28    1]\n",
      " [  39  114  707   29    9   11   45    7   70    1]\n",
      " [ 124    9   22  683    1  101    1   16   49    4]\n",
      " [   8    2   27   15  736    9    4    7   24  150]\n",
      " [  54   12    4   47   18  626    8    3  102   18]\n",
      " [  49    3   41    6   13   17  802    1   26    0]\n",
      " [   6   26   36   30   10   10    0  788   11  111]\n",
      " [  35   23   14   57    3   59    4    6  755   18]\n",
      " [  14    8   10   59   76   12    0   50   42  738]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59550,) ['5' '0' '3' ... '5' '6' '3']\n",
      "probabilities: (59550, 10) \n",
      " [5 0 3 ... 5 6 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (475, 784) (475,)\n",
      "updated train set: (475, 784) (475,) unique(labels): [28 33 77 46 45 68 44 38 62 34] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59525, 784) (59525,)\n",
      "\n",
      "Train set: (475, 784) y: (475,)\n",
      "Val   set: (59525, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 23.900 s \n",
      "\n",
      "Accuracy rate for 78.300000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79       980\n",
      "           1       0.85      0.96      0.90      1135\n",
      "           2       0.87      0.68      0.76      1032\n",
      "           3       0.78      0.69      0.73      1010\n",
      "           4       0.88      0.74      0.81       982\n",
      "           5       0.64      0.69      0.67       892\n",
      "           6       0.91      0.88      0.89       958\n",
      "           7       0.88      0.79      0.83      1028\n",
      "           8       0.66      0.77      0.71       974\n",
      "           9       0.69      0.77      0.73      1009\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.79      0.78      0.78     10000\n",
      "weighted avg       0.79      0.78      0.78     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 827    0    8    6    1  125    9    1    3    0]\n",
      " [   0 1084    4   12    0    7    1    0   26    1]\n",
      " [  36  107  703   27   10   12   52    8   76    1]\n",
      " [ 124    8   16  693    1   95    4   14   49    6]\n",
      " [   5    2   19    7  731    8    5   11   26  168]\n",
      " [  54   15    4   46   17  618   11    1  110   16]\n",
      " [  25    3   12    8   15   17  843    1   33    1]\n",
      " [   4   24   31   10    6    7    0  807   11  128]\n",
      " [  32   25    9   60    2   65    6    6  748   21]\n",
      " [  15    8    4   22   51   12    0   70   51  776]]\n",
      "--------------------------------\n",
      "val predicted: (59525,) ['5' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59525, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (475, 784) (475,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [28 33 81 49 51 72 46 39 65 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 25.163 s \n",
      "\n",
      "Accuracy rate for 78.860000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79       980\n",
      "           1       0.87      0.96      0.91      1135\n",
      "           2       0.85      0.69      0.76      1032\n",
      "           3       0.79      0.72      0.76      1010\n",
      "           4       0.89      0.75      0.81       982\n",
      "           5       0.66      0.71      0.68       892\n",
      "           6       0.90      0.87      0.88       958\n",
      "           7       0.88      0.75      0.81      1028\n",
      "           8       0.68      0.78      0.73       974\n",
      "           9       0.68      0.78      0.73      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 827    0   12    5    2  118   12    1    3    0]\n",
      " [   0 1084    5   13    0    4    3    0   25    1]\n",
      " [  37   94  716   15   10   11   58    9   81    1]\n",
      " [ 112    5   24  727    1   70    4   16   47    4]\n",
      " [   5    3   20   11  739   11    4    7   14  168]\n",
      " [  52   14    2   44   15  632    9    5  108   11]\n",
      " [  26    3   14    8   17   24  835    1   30    0]\n",
      " [   2   18   32   14    3   16    0  771    7  165]\n",
      " [  28   18    9   55    4   62    7    7  763   21]\n",
      " [  12    5    9   23   42   14    0   61   51  792]]\n",
      "--------------------------------\n",
      "final active learning accuracies [52.65, 55.769999999999996, 58.5, 67.9, 68.63, 72.32, 72.37, 72.08, 72.49, 71.94, 73.11, 75.18, 76.25, 75.6, 76.79, 77.42999999999999, 77.56, 77.45, 78.3, 78.86]\n",
      "saved Active-learning-experiment-14.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 15, using model = SvmModel, selection_function = EntropySelection, k = 10, iteration = 0.\n",
      "\n",
      "initial random chosen samples (10,)\n",
      "initial train set: (10, 784) (10,) unique(labels): [2 1 0 1 0 1 1 1 2 1] [0 1 3 5 6 7 8 9]\n",
      "val set: (59990, 784) (59990,) (10,)\n",
      "\n",
      "Train set: (10, 784) y: (10,)\n",
      "Val   set: (59990, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.590 s \n",
      "\n",
      "Accuracy rate for 34.220000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.56      0.46       980\n",
      "           1       0.68      0.70      0.69      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.19      0.25      0.21      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.10      0.09      0.10       892\n",
      "           6       0.41      0.66      0.51       958\n",
      "           7       0.29      0.29      0.29      1028\n",
      "           8       0.30      0.51      0.38       974\n",
      "           9       0.32      0.32      0.32      1009\n",
      "\n",
      "    accuracy                           0.34     10000\n",
      "   macro avg       0.27      0.34      0.29     10000\n",
      "weighted avg       0.27      0.34      0.30     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[553   2   0 123   0   9 235  40  13   5]\n",
      " [  0 789   0   8   0 258   7   8  32  33]\n",
      " [186 102   0 191   0   8 425  28  87   5]\n",
      " [252  15   0 252   0  46  96  62 272  15]\n",
      " [127  66   0 103   0 150  34 230 103 169]\n",
      " [ 80  66   0 285   0  84  62  23 182 110]\n",
      " [ 93  41   0  40   0  82 632  14  28  28]\n",
      " [ 24  47   0  27   0  32   7 293 313 285]\n",
      " [ 53  36   0 228   0  70  18  29 500  40]\n",
      " [ 38   4   0  84   0 122  14 297 131 319]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59990,) ['8' '0' '7' ... '8' '0' '9']\n",
      "probabilities: (59990, 8) \n",
      " [5 6 0 ... 0 0 6]\n",
      "trainset before (10, 784) (10,)\n",
      "trainset after (20, 784) (20,)\n",
      "updated train set: (20, 784) (20,) unique(labels): [4 1 0 3 0 1 1 1 6 3] [0 1 3 5 6 7 8 9]\n",
      "val set: (59980, 784) (59980,)\n",
      "\n",
      "Train set: (20, 784) y: (20,)\n",
      "Val   set: (59980, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 1.108 s \n",
      "\n",
      "Accuracy rate for 36.500000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.88      0.51       980\n",
      "           1       0.73      0.47      0.58      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.31      0.44      0.37      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.17      0.07      0.10       892\n",
      "           6       0.90      0.37      0.52       958\n",
      "           7       0.32      0.32      0.32      1028\n",
      "           8       0.62      0.55      0.58       974\n",
      "           9       0.19      0.53      0.28      1009\n",
      "\n",
      "    accuracy                           0.36     10000\n",
      "   macro avg       0.36      0.36      0.33     10000\n",
      "weighted avg       0.37      0.36      0.33     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[858   2   0  33   0   3   1  26   1  56]\n",
      " [ 24 539   0   3   0  50   1   2   7 509]\n",
      " [576  62   0 168   0   2  33  29  88  74]\n",
      " [221   3   0 448   0  23   0  63  25 227]\n",
      " [144  26   0 118   0  58   1 235  42 358]\n",
      " [ 77  35   0 315   0  62   1  23  92 287]\n",
      " [373  27   0  36   0  52 353   4  12 101]\n",
      " [ 17  22   0  18   0   9   0 325  14 623]\n",
      " [ 43  17   0 210   0  40   1  32 532  99]\n",
      " [ 24   2   0  79   0  59   0 272  40 533]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59980,) ['9' '0' '7' ... '8' '0' '9']\n",
      "probabilities: (59980, 8) \n",
      " [2 0 2 ... 6 0 6]\n",
      "trainset before (20, 784) (20,)\n",
      "trainset after (30, 784) (30,)\n",
      "updated train set: (30, 784) (30,) unique(labels): [7 1 2 6 0 1 1 1 8 3] [0 1 2 3 5 6 7 8 9]\n",
      "val set: (59970, 784) (59970,)\n",
      "\n",
      "Train set: (30, 784) y: (30,)\n",
      "Val   set: (59970, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 1.590 s \n",
      "\n",
      "Accuracy rate for 41.500000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.92      0.69       980\n",
      "           1       0.62      0.48      0.54      1135\n",
      "           2       0.53      0.08      0.15      1032\n",
      "           3       0.51      0.57      0.54      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.17      0.08      0.11       892\n",
      "           6       0.92      0.47      0.63       958\n",
      "           7       0.30      0.30      0.30      1028\n",
      "           8       0.50      0.68      0.58       974\n",
      "           9       0.19      0.55      0.28      1009\n",
      "\n",
      "    accuracy                           0.41     10000\n",
      "   macro avg       0.43      0.41      0.38     10000\n",
      "weighted avg       0.43      0.41      0.38     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[897   2   2   5   0   2   0  12  16  44]\n",
      " [  1 543   0   1   0  79   2   1   6 502]\n",
      " [243 174  87  52   0   4  36  41 316  79]\n",
      " [ 17   1  35 576   0  26   0  88  48 219]\n",
      " [129  32  15  49   0  57   1 232  67 400]\n",
      " [ 75  35   2 283   0  70   0  31 116 280]\n",
      " [173  35  18  37   0  60 454   3  45 133]\n",
      " [ 22  23   1   1   0   9   0 304  15 653]\n",
      " [ 16  21   3  88   0  41   0  43 662 100]\n",
      " [ 52   3   1  39   0  56   0 274  27 557]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59970,) ['9' '0' '7' ... '8' '0' '9']\n",
      "probabilities: (59970, 9) \n",
      " [3 0 0 ... 7 0 7]\n",
      "trainset before (30, 784) (30,)\n",
      "trainset after (40, 784) (40,)\n",
      "updated train set: (40, 784) (40,) unique(labels): [ 7  1  2 16  0  1  1  1  8  3] [0 1 2 3 5 6 7 8 9]\n",
      "val set: (59960, 784) (59960,)\n",
      "\n",
      "Train set: (40, 784) y: (40,)\n",
      "Val   set: (59960, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 1.907 s \n",
      "\n",
      "Accuracy rate for 41.700000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.93      0.69       980\n",
      "           1       0.62      0.48      0.54      1135\n",
      "           2       0.64      0.05      0.10      1032\n",
      "           3       0.53      0.69      0.60      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.17      0.08      0.11       892\n",
      "           6       0.92      0.47      0.62       958\n",
      "           7       0.27      0.20      0.23      1028\n",
      "           8       0.51      0.70      0.59       974\n",
      "           9       0.18      0.56      0.27      1009\n",
      "\n",
      "    accuracy                           0.42     10000\n",
      "   macro avg       0.44      0.42      0.38     10000\n",
      "weighted avg       0.44      0.42      0.38     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[909   3   0   2   0   2   0   2  17  45]\n",
      " [  1 543   0   2   0  79   2   0   6 502]\n",
      " [257 181  54  85   0   4  37   4 316  94]\n",
      " [ 14   2   2 696   0  23   0  17  41 215]\n",
      " [124  32  14  63   0  55   1 220  73 400]\n",
      " [ 75  37   0 293   0  68   0  25 114 280]\n",
      " [178  38  13  38   0  58 450   1  45 137]\n",
      " [ 15  23   0   3   0  10   0 210  16 751]\n",
      " [ 15  20   2  91   0  41   0  27 679  99]\n",
      " [ 53   2   0  37   0  54   0 274  28 561]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59960,) ['9' '0' '7' ... '8' '0' '9']\n",
      "probabilities: (59960, 9) \n",
      " [3 0 0 ... 7 0 7]\n",
      "trainset before (40, 784) (40,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [ 7  1  8 20  0  1  1  1  8  3] [0 1 2 3 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.332 s \n",
      "\n",
      "Accuracy rate for 43.050000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.92      0.70       980\n",
      "           1       0.67      0.48      0.56      1135\n",
      "           2       0.64      0.16      0.26      1032\n",
      "           3       0.46      0.75      0.57      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.18      0.08      0.11       892\n",
      "           6       0.94      0.45      0.61       958\n",
      "           7       0.27      0.20      0.23      1028\n",
      "           8       0.57      0.67      0.62       974\n",
      "           9       0.19      0.56      0.29      1009\n",
      "\n",
      "    accuracy                           0.43     10000\n",
      "   macro avg       0.45      0.43      0.39     10000\n",
      "weighted avg       0.45      0.43      0.40     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[899   1  20  13   0   2   0   2  15  28]\n",
      " [  1 550   0   3   0  79   2   0   6 494]\n",
      " [200 150 165 255   0   4  23   4 165  66]\n",
      " [  5   1  10 761   0  24   0  14  29 166]\n",
      " [130  26  20  71   0  54   1 215  69 396]\n",
      " [ 84  32   3 297   0  69   0  27 116 264]\n",
      " [185  17  32 103   0  55 431   1  46  88]\n",
      " [ 15  26   1   6   0  10   0 210  13 747]\n",
      " [ 13  17   5 118   0  43   0  25 654  99]\n",
      " [ 52   2   0  34   0  54   0 274  27 566]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59950,) ['9' '0' '7' ... '8' '0' '9']\n",
      "probabilities: (59950, 9) \n",
      " [3 0 3 ... 7 0 7]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (60, 784) (60,)\n",
      "updated train set: (60, 784) (60,) unique(labels): [ 7  1  8 20  0  1  1  5  8  9] [0 1 2 3 5 6 7 8 9]\n",
      "val set: (59940, 784) (59940,)\n",
      "\n",
      "Train set: (60, 784) y: (60,)\n",
      "Val   set: (59940, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.866 s \n",
      "\n",
      "Accuracy rate for 46.930000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.71       980\n",
      "           1       0.65      0.47      0.55      1135\n",
      "           2       0.67      0.16      0.25      1032\n",
      "           3       0.44      0.77      0.56      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.20      0.08      0.11       892\n",
      "           6       0.94      0.44      0.60       958\n",
      "           7       0.54      0.47      0.50      1028\n",
      "           8       0.59      0.69      0.64       974\n",
      "           9       0.24      0.68      0.36      1009\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.49      0.47      0.43     10000\n",
      "weighted avg       0.49      0.47      0.43     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[888   1  19  12   0   2   0  24  15  19]\n",
      " [  1 531   0   2   0  50   2   0   5 544]\n",
      " [201 148 161 252   0   3  25   4 163  75]\n",
      " [ 18   1  10 782   0  27   0   9  36 127]\n",
      " [ 65  27  12 120   0  51   1 134  46 526]\n",
      " [ 98  34   0 308   0  70   0  72 119 191]\n",
      " [184  15  33 100   0  47 423   2  46 108]\n",
      " [  6  38   0   9   0  11   0 484  14 466]\n",
      " [ 11  15   5 125   0  43   0  18 671  86]\n",
      " [ 33   2   0  75   0  48   0 147  21 683]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59940,) ['9' '0' '3' ... '8' '0' '9']\n",
      "probabilities: (59940, 9) \n",
      " [8 0 3 ... 7 0 8]\n",
      "trainset before (60, 784) (60,)\n",
      "trainset after (70, 784) (70,)\n",
      "updated train set: (70, 784) (70,) unique(labels): [11  1  8 20  5  1  1  5  8 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59930, 784) (59930,)\n",
      "\n",
      "Train set: (70, 784) y: (70,)\n",
      "Val   set: (59930, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.410 s \n",
      "\n",
      "Accuracy rate for 50.620000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.97      0.75       980\n",
      "           1       0.70      0.47      0.56      1135\n",
      "           2       0.81      0.18      0.29      1032\n",
      "           3       0.54      0.71      0.61      1010\n",
      "           4       0.68      0.30      0.42       982\n",
      "           5       0.36      0.07      0.11       892\n",
      "           6       0.95      0.43      0.59       958\n",
      "           7       0.77      0.39      0.52      1028\n",
      "           8       0.65      0.67      0.66       974\n",
      "           9       0.24      0.85      0.38      1009\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.63      0.50      0.49     10000\n",
      "weighted avg       0.63      0.51      0.49     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[954   0   3   3   0   1   0   3   6  10]\n",
      " [  1 534   0   1   0   3   2   0   4 590]\n",
      " [193 129 183 200   4   1  21   2 131 168]\n",
      " [ 21   0  10 714   1  14   0   1  24 225]\n",
      " [ 18  13   5   6 294   6   1  20  23 596]\n",
      " [148  31   1 265   5  58   0  52 114 218]\n",
      " [200   3  20  35  53  38 413   1  34 161]\n",
      " [  4  35   0   1   6   6   0 399  12 565]\n",
      " [ 13  12   4  83   4  25   0   4 653 176]\n",
      " [ 20   2   0   8  66   9   0  39   5 860]]\n",
      "--------------------------------\n",
      "val predicted: (59930,) ['9' '0' '4' ... '8' '0' '9']\n",
      "probabilities: (59930, 10) \n",
      " [9 0 3 ... 8 0 9]\n",
      "trainset before (70, 784) (70,)\n",
      "trainset after (80, 784) (80,)\n",
      "updated train set: (80, 784) (80,) unique(labels): [11  1  8 20  5  1 11  5  8 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59920, 784) (59920,)\n",
      "\n",
      "Train set: (80, 784) y: (80,)\n",
      "Val   set: (59920, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.830 s \n",
      "\n",
      "Accuracy rate for 51.130000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.97      0.77       980\n",
      "           1       0.70      0.47      0.56      1135\n",
      "           2       0.81      0.18      0.29      1032\n",
      "           3       0.54      0.71      0.61      1010\n",
      "           4       0.67      0.30      0.41       982\n",
      "           5       0.36      0.07      0.11       892\n",
      "           6       0.97      0.49      0.65       958\n",
      "           7       0.76      0.39      0.51      1028\n",
      "           8       0.66      0.67      0.66       974\n",
      "           9       0.24      0.85      0.37      1009\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.63      0.51      0.50     10000\n",
      "weighted avg       0.64      0.51      0.50     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[954   0   3   3   0   1   0   3   6  10]\n",
      " [  1 534   0   1   0   3   2   0   4 590]\n",
      " [203 134 183 202   6   1   3   2 129 169]\n",
      " [ 20   0  10 715   1  14   0   1  24 225]\n",
      " [ 14  13   5   6 294   6   5  21  23 595]\n",
      " [146  31   1 264   5  58   1  52 114 220]\n",
      " [139   3  20  32  54  38 465   1  26 180]\n",
      " [  4  35   0   1   6   6   0 398  12 566]\n",
      " [ 13  12   4  84   4  25   0   5 652 175]\n",
      " [ 19   2   0   8  66   9   1  39   5 860]]\n",
      "--------------------------------\n",
      "val predicted: (59920,) ['9' '0' '4' ... '8' '6' '9']\n",
      "probabilities: (59920, 10) \n",
      " [9 0 4 ... 9 0 9]\n",
      "trainset before (80, 784) (80,)\n",
      "trainset after (90, 784) (90,)\n",
      "updated train set: (90, 784) (90,) unique(labels): [11  1 13 20  8  1 13  5  8 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59910, 784) (59910,)\n",
      "\n",
      "Train set: (90, 784) y: (90,)\n",
      "Val   set: (59910, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.317 s \n",
      "\n",
      "Accuracy rate for 55.740000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83       980\n",
      "           1       0.75      0.47      0.58      1135\n",
      "           2       0.66      0.49      0.56      1032\n",
      "           3       0.57      0.70      0.63      1010\n",
      "           4       0.60      0.45      0.52       982\n",
      "           5       0.36      0.06      0.11       892\n",
      "           6       0.92      0.62      0.74       958\n",
      "           7       0.82      0.38      0.52      1028\n",
      "           8       0.73      0.66      0.69       974\n",
      "           9       0.25      0.78      0.38      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.64      0.55      0.55     10000\n",
      "weighted avg       0.64      0.56      0.56     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[925   0  19   2   2   1  15   3   5   8]\n",
      " [  0 532   2   1   0   3   4   0   4 589]\n",
      " [ 81  97 504 148  27   1  20   2  66  86]\n",
      " [ 16   0  39 706   6  14   2   1  22 204]\n",
      " [  2  10  24   4 444   3   6   8  14 467]\n",
      " [129  17  48 261  32  55   3  46 108 193]\n",
      " [ 69   2  92  36  23  40 590   1  11  94]\n",
      " [  4  35   6   1  27   6   1 391   7 550]\n",
      " [  9  11  31  79  10  23   0   4 641 166]\n",
      " [ 10   2   1   5 170   8   1  21   5 786]]\n",
      "--------------------------------\n",
      "val predicted: (59910,) ['9' '0' '4' ... '8' '6' '9']\n",
      "probabilities: (59910, 10) \n",
      " [9 0 4 ... 9 6 9]\n",
      "trainset before (90, 784) (90,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [12  1 13 20  8  4 19  5  8 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.702 s \n",
      "\n",
      "Accuracy rate for 57.090000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83       980\n",
      "           1       0.79      0.47      0.59      1135\n",
      "           2       0.72      0.46      0.56      1032\n",
      "           3       0.60      0.69      0.64      1010\n",
      "           4       0.64      0.43      0.51       982\n",
      "           5       0.22      0.17      0.19       892\n",
      "           6       0.67      0.85      0.75       958\n",
      "           7       0.85      0.34      0.48      1028\n",
      "           8       0.75      0.63      0.68       974\n",
      "           9       0.30      0.75      0.43      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.63      0.57      0.57     10000\n",
      "weighted avg       0.64      0.57      0.57     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[911   0  10   1   1  13  36   1   3   4]\n",
      " [  0 530   2   3   0 272  10   0   4 314]\n",
      " [100  75 471 140  27  17 108   1  54  39]\n",
      " [  8   0  33 693   2  74  13   1  22 164]\n",
      " [  4  10  21   3 420  23  78   4  12 407]\n",
      " [120   9  31 214  13 155  74  30  94 152]\n",
      " [ 30   2  54  19   3  12 818   0   2  18]\n",
      " [  8  35   6   1  15  69  19 348   7 520]\n",
      " [ 14   9  28  78   8  57  43   4 609 124]\n",
      " [ 12   2   1   5 164  25  20  21   5 754]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59900,) ['9' '0' '4' ... '8' '6' '9']\n",
      "probabilities: (59900, 10) \n",
      " [9 0 4 ... 9 6 9]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (110, 784) (110,)\n",
      "updated train set: (110, 784) (110,) unique(labels): [12  1 13 23  8  7 19  5 12 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59890, 784) (59890,)\n",
      "\n",
      "Train set: (110, 784) y: (110,)\n",
      "Val   set: (59890, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.130 s \n",
      "\n",
      "Accuracy rate for 56.840000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87       980\n",
      "           1       0.83      0.43      0.57      1135\n",
      "           2       0.83      0.41      0.55      1032\n",
      "           3       0.55      0.75      0.64      1010\n",
      "           4       0.67      0.36      0.47       982\n",
      "           5       0.19      0.34      0.24       892\n",
      "           6       0.80      0.81      0.81       958\n",
      "           7       0.89      0.28      0.43      1028\n",
      "           8       0.58      0.75      0.65       974\n",
      "           9       0.37      0.65      0.47      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.65      0.57      0.57     10000\n",
      "weighted avg       0.66      0.57      0.57     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[902   0   8   6   2  22  31   0   6   3]\n",
      " [  0 493   0  35   0 458   4   0   8 137]\n",
      " [ 83  57 424 129  20  58  70   1 167  23]\n",
      " [  5   0  24 760   1 105   4   1  28  82]\n",
      " [  4   6  13  87 358 160  45   4  35 270]\n",
      " [ 51   1   4 192   2 299  19   6 233  85]\n",
      " [ 26   2  24  44   3  71 777   0   6   5]\n",
      " [  5  25   0   9   9 205   2 287  31 455]\n",
      " [  7   5  15  79   1  70   7   3 733  54]\n",
      " [ 12   2   0  36 139 116   9  19  25 651]]\n",
      "--------------------------------\n",
      "val predicted: (59890,) ['9' '0' '4' ... '8' '6' '8']\n",
      "probabilities: (59890, 10) \n",
      " [9 0 4 ... 8 6 8]\n",
      "trainset before (110, 784) (110,)\n",
      "trainset after (120, 784) (120,)\n",
      "updated train set: (120, 784) (120,) unique(labels): [12  1 15 23 12  7 20  5 12 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59880, 784) (59880,)\n",
      "\n",
      "Train set: (120, 784) y: (120,)\n",
      "Val   set: (59880, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.602 s \n",
      "\n",
      "Accuracy rate for 61.220000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       980\n",
      "           1       0.86      0.43      0.58      1135\n",
      "           2       0.76      0.49      0.60      1032\n",
      "           3       0.55      0.75      0.63      1010\n",
      "           4       0.90      0.55      0.69       982\n",
      "           5       0.22      0.32      0.26       892\n",
      "           6       0.76      0.84      0.80       958\n",
      "           7       0.93      0.26      0.41      1028\n",
      "           8       0.64      0.73      0.68       974\n",
      "           9       0.44      0.86      0.58      1009\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.69      0.61      0.61     10000\n",
      "weighted avg       0.70      0.61      0.61     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[889   0  15   5   2  19  42   0   5   3]\n",
      " [  0 491   4  88   0 489   5   0   6  52]\n",
      " [ 48  45 505 120  17  36  90   1 140  30]\n",
      " [  3   0  31 754   1 108  11   1  31  70]\n",
      " [  0   3  17  67 542  87  39   1   8 218]\n",
      " [ 53   1  13 202   3 288  44   6 187  95]\n",
      " [ 16   2  44  24   5  59 805   0   2   1]\n",
      " [  3  18   6   8   4 121   9 269  11 579]\n",
      " [  6   6  24  80   3  60  13   4 713  65]\n",
      " [  8   2   3  21  23  65   3   7  11 866]]\n",
      "--------------------------------\n",
      "val predicted: (59880,) ['9' '0' '4' ... '9' '6' '9']\n",
      "probabilities: (59880, 10) \n",
      " [9 0 4 ... 9 6 9]\n",
      "trainset before (120, 784) (120,)\n",
      "trainset after (130, 784) (130,)\n",
      "updated train set: (130, 784) (130,) unique(labels): [13  1 15 23 13 14 21  5 12 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59870, 784) (59870,)\n",
      "\n",
      "Train set: (130, 784) y: (130,)\n",
      "Val   set: (59870, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.152 s \n",
      "\n",
      "Accuracy rate for 62.030000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       980\n",
      "           1       0.87      0.41      0.56      1135\n",
      "           2       0.81      0.46      0.59      1032\n",
      "           3       0.60      0.74      0.66      1010\n",
      "           4       0.88      0.55      0.68       982\n",
      "           5       0.26      0.49      0.34       892\n",
      "           6       0.74      0.88      0.80       958\n",
      "           7       0.95      0.26      0.41      1028\n",
      "           8       0.65      0.72      0.69       974\n",
      "           9       0.46      0.83      0.59      1009\n",
      "\n",
      "    accuracy                           0.62     10000\n",
      "   macro avg       0.71      0.62      0.62     10000\n",
      "weighted avg       0.72      0.62      0.62     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[873   0   8   2   2  32  49   0   8   6]\n",
      " [  0 470   4  75   0 550   7   0   6  23]\n",
      " [ 71  41 478 109  20  34 111   1 140  27]\n",
      " [  8   0  29 748   1 115  12   1  31  65]\n",
      " [  0   1  17  42 539 152  43   1   7 180]\n",
      " [ 35   0   4 163   3 439  39   0 159  50]\n",
      " [  8   2  24  10  10  57 845   0   2   0]\n",
      " [  3  18   5   9   9 123  11 269  10 571]\n",
      " [ 11   4  19  74   3  73  21   4 705  60]\n",
      " [  6   2   2  16  26  96   4   8  12 837]]\n",
      "--------------------------------\n",
      "val predicted: (59870,) ['9' '0' '4' ... '9' '6' '9']\n",
      "probabilities: (59870, 10) \n",
      " [9 0 4 ... 9 6 9]\n",
      "trainset before (130, 784) (130,)\n",
      "trainset after (140, 784) (140,)\n",
      "updated train set: (140, 784) (140,) unique(labels): [14  1 15 23 15 15 21  6 17 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59860, 784) (59860,)\n",
      "\n",
      "Train set: (140, 784) y: (140,)\n",
      "Val   set: (59860, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.421 s \n",
      "\n",
      "Accuracy rate for 62.830000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87       980\n",
      "           1       0.88      0.41      0.56      1135\n",
      "           2       0.82      0.45      0.58      1032\n",
      "           3       0.61      0.72      0.66      1010\n",
      "           4       0.82      0.64      0.72       982\n",
      "           5       0.26      0.50      0.34       892\n",
      "           6       0.75      0.88      0.81       958\n",
      "           7       0.93      0.31      0.46      1028\n",
      "           8       0.61      0.77      0.68       974\n",
      "           9       0.50      0.77      0.60      1009\n",
      "\n",
      "    accuracy                           0.63     10000\n",
      "   macro avg       0.70      0.63      0.63     10000\n",
      "weighted avg       0.71      0.63      0.63     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[870   0   9   1   1  36  48   0  12   3]\n",
      " [  0 467   3  61   0 566   8   0  18  12]\n",
      " [ 70  41 460 100  22  26 119   2 170  22]\n",
      " [ 12   0  28 724  20 111   9   1  35  70]\n",
      " [  2   0  11  29 629 144  31   1  31 104]\n",
      " [ 53   0   7 162   0 445  36   4 148  37]\n",
      " [ 11   2  24   8   9  56 843   0   5   0]\n",
      " [  4  15   3  10  38 120   3 317  31 487]\n",
      " [  3   2  12  71   4  56  22   5 751  48]\n",
      " [  6   2   1  14  44 128   3  11  23 777]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59860,) ['9' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59860, 10) \n",
      " [9 0 4 ... 5 6 8]\n",
      "trainset before (140, 784) (140,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [14  1 19 24 15 16 21 10 17 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 7.074 s \n",
      "\n",
      "Accuracy rate for 62.030000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       980\n",
      "           1       0.87      0.40      0.55      1135\n",
      "           2       0.82      0.46      0.59      1032\n",
      "           3       0.58      0.72      0.64      1010\n",
      "           4       0.83      0.62      0.71       982\n",
      "           5       0.25      0.50      0.34       892\n",
      "           6       0.78      0.86      0.81       958\n",
      "           7       0.90      0.33      0.48      1028\n",
      "           8       0.60      0.74      0.66       974\n",
      "           9       0.50      0.76      0.60      1009\n",
      "\n",
      "    accuracy                           0.62     10000\n",
      "   macro avg       0.70      0.62      0.62     10000\n",
      "weighted avg       0.71      0.62      0.62     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[858   0  13   2   0  44  45   4  12   2]\n",
      " [  0 450   1 112   0 540   9   0  12  11]\n",
      " [ 62  46 471 115  18  36  85   3 176  20]\n",
      " [ 13   0  25 725  18 121   7   0  40  61]\n",
      " [  2   0   8  35 604 174  31   6  25  97]\n",
      " [ 40   0   7 148   1 448  34   7 171  36]\n",
      " [ 10   2  36   9   8  67 821   0   5   0]\n",
      " [  3  15   3   8  37 122   4 339  21 476]\n",
      " [  3   1  12  87   4  64  20   6 725  52]\n",
      " [  6   2   1  11  36 156   3  11  21 762]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['9' '0' '4' ... '5' '2' '8']\n",
      "probabilities: (59850, 10) \n",
      " [9 0 4 ... 5 2 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (160, 784) (160,)\n",
      "updated train set: (160, 784) (160,) unique(labels): [14  1 20 24 16 18 21 11 19 16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59840, 784) (59840,)\n",
      "\n",
      "Train set: (160, 784) y: (160,)\n",
      "Val   set: (59840, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 7.448 s \n",
      "\n",
      "Accuracy rate for 62.210000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87       980\n",
      "           1       0.89      0.39      0.55      1135\n",
      "           2       0.83      0.48      0.61      1032\n",
      "           3       0.65      0.71      0.68      1010\n",
      "           4       0.76      0.72      0.74       982\n",
      "           5       0.25      0.53      0.34       892\n",
      "           6       0.81      0.83      0.82       958\n",
      "           7       0.90      0.39      0.54      1028\n",
      "           8       0.52      0.78      0.62       974\n",
      "           9       0.50      0.57      0.53      1009\n",
      "\n",
      "    accuracy                           0.62     10000\n",
      "   macro avg       0.70      0.63      0.63     10000\n",
      "weighted avg       0.71      0.62      0.63     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[849   0  14   2   0  45  40  17   6   7]\n",
      " [  0 447   2  48   0 457   4   0 173   4]\n",
      " [ 51  33 498  94  25  34  81   3 200  13]\n",
      " [ 12   0  22 721  17 121   5   0  53  59]\n",
      " [  2   0   6  16 709 147  14   3  20  65]\n",
      " [ 31   1   2 122   3 470  27  10 181  45]\n",
      " [  9   2  28   5  12  91 798   0  10   3]\n",
      " [  3  16  19   6  45 153   1 398  46 341]\n",
      " [  2   0   8  81   4  70  11   4 760  34]\n",
      " [  4   2   1  18 113 263   2   9  26 571]]\n",
      "--------------------------------\n",
      "val predicted: (59840,) ['9' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59840, 10) \n",
      " [9 0 4 ... 5 2 8]\n",
      "trainset before (160, 784) (160,)\n",
      "trainset after (170, 784) (170,)\n",
      "updated train set: (170, 784) (170,) unique(labels): [14  1 23 26 17 19 21 12 21 16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59830, 784) (59830,)\n",
      "\n",
      "Train set: (170, 784) y: (170,)\n",
      "Val   set: (59830, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 7.939 s \n",
      "\n",
      "Accuracy rate for 63.280000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       980\n",
      "           1       0.90      0.39      0.54      1135\n",
      "           2       0.81      0.60      0.69      1032\n",
      "           3       0.57      0.74      0.65      1010\n",
      "           4       0.77      0.70      0.73       982\n",
      "           5       0.26      0.52      0.34       892\n",
      "           6       0.85      0.81      0.83       958\n",
      "           7       0.90      0.44      0.59      1028\n",
      "           8       0.55      0.76      0.64       974\n",
      "           9       0.53      0.54      0.53      1009\n",
      "\n",
      "    accuracy                           0.63     10000\n",
      "   macro avg       0.71      0.64      0.64     10000\n",
      "weighted avg       0.71      0.63      0.64     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[844   0  21   2   0  48  40  14   6   5]\n",
      " [  0 438   1  91   0 430   3   0 167   5]\n",
      " [ 12  32 622 150  35  28  48   3  93   9]\n",
      " [  8   0  28 751  17 109   5   0  45  47]\n",
      " [  1   0   6  23 691 162  12   2  27  58]\n",
      " [ 28   0   7 151   6 463  23  10 169  35]\n",
      " [ 11   2  32   7  16  77 777   0  35   1]\n",
      " [  3  15  34  10  39 148   1 454  32 292]\n",
      " [  1   0  11 110   4  58   4   9 744  33]\n",
      " [  5   2   3  16  92 289   2  12  44 544]]\n",
      "--------------------------------\n",
      "val predicted: (59830,) ['9' '0' '4' ... '5' '2' '8']\n",
      "probabilities: (59830, 10) \n",
      " [9 0 4 ... 5 2 8]\n",
      "trainset before (170, 784) (170,)\n",
      "trainset after (180, 784) (180,)\n",
      "updated train set: (180, 784) (180,) unique(labels): [15  1 24 26 19 19 23 12 24 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59820, 784) (59820,)\n",
      "\n",
      "Train set: (180, 784) y: (180,)\n",
      "Val   set: (59820, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 8.553 s \n",
      "\n",
      "Accuracy rate for 63.540000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       980\n",
      "           1       0.90      0.39      0.54      1135\n",
      "           2       0.81      0.63      0.71      1032\n",
      "           3       0.60      0.74      0.66      1010\n",
      "           4       0.74      0.72      0.73       982\n",
      "           5       0.26      0.51      0.35       892\n",
      "           6       0.86      0.84      0.85       958\n",
      "           7       0.89      0.43      0.58      1028\n",
      "           8       0.54      0.80      0.65       974\n",
      "           9       0.50      0.47      0.48      1009\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.70      0.64      0.64     10000\n",
      "weighted avg       0.71      0.64      0.64     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[849   0  26   2   0  41  37  14   6   5]\n",
      " [  0 438   3  75   0 468   3   0 146   2]\n",
      " [ 14  31 655 143  37  29  35   3  75  10]\n",
      " [  5   0  37 749  16 108   5   1  48  41]\n",
      " [  1   0   5  24 705 141   8   4  38  56]\n",
      " [ 27   0  10 150  10 459  32   8 167  29]\n",
      " [ 15   2  26   5  34  53 804   0  18   1]\n",
      " [  0  15  35   7  40 144   1 438  38 310]\n",
      " [  4   0  10  82   5  50   8  10 783  22]\n",
      " [  5   2   1  12 109 269   2  13 122 474]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59820,) ['8' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59820, 10) \n",
      " [9 0 4 ... 5 6 8]\n",
      "trainset before (180, 784) (180,)\n",
      "trainset after (190, 784) (190,)\n",
      "updated train set: (190, 784) (190,) unique(labels): [18  1 24 26 19 20 23 15 25 19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59810, 784) (59810,)\n",
      "\n",
      "Train set: (190, 784) y: (190,)\n",
      "Val   set: (59810, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 8.827 s \n",
      "\n",
      "Accuracy rate for 65.230000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88       980\n",
      "           1       0.90      0.38      0.54      1135\n",
      "           2       0.82      0.62      0.71      1032\n",
      "           3       0.60      0.75      0.67      1010\n",
      "           4       0.78      0.69      0.73       982\n",
      "           5       0.26      0.50      0.34       892\n",
      "           6       0.87      0.83      0.85       958\n",
      "           7       0.83      0.62      0.71      1028\n",
      "           8       0.57      0.79      0.66       974\n",
      "           9       0.56      0.50      0.53      1009\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.71      0.66      0.66     10000\n",
      "weighted avg       0.72      0.65      0.66     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[839   0  16   1   0  44  29  30   5  16]\n",
      " [  0 435   3  74   0 506   3   0 113   1]\n",
      " [ 16  32 645 145  36  37  36   7  65  13]\n",
      " [  5   0  39 759   2 113   7   7  37  41]\n",
      " [  1   0   5  18 679 138   7   7  62  65]\n",
      " [ 36   0  12 166   6 448  25  26 140  33]\n",
      " [ 13   2  23   5  35  57 799   0  22   2]\n",
      " [  3  15  33   6  21  87   1 638  20 204]\n",
      " [  2   0   9  88   4  58   8  13 773  19]\n",
      " [  4   2   1   6  83 236   2  37 130 508]]\n",
      "--------------------------------\n",
      "val predicted: (59810,) ['9' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59810, 10) \n",
      " [9 0 4 ... 5 6 8]\n",
      "trainset before (190, 784) (190,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [22  2 25 27 19 20 24 16 26 19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 9.378 s \n",
      "\n",
      "Accuracy rate for 66.370000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       980\n",
      "           1       0.89      0.38      0.53      1135\n",
      "           2       0.77      0.71      0.74      1032\n",
      "           3       0.58      0.76      0.66      1010\n",
      "           4       0.79      0.68      0.73       982\n",
      "           5       0.27      0.48      0.35       892\n",
      "           6       0.90      0.82      0.86       958\n",
      "           7       0.82      0.65      0.73      1028\n",
      "           8       0.60      0.77      0.67       974\n",
      "           9       0.59      0.51      0.55      1009\n",
      "\n",
      "    accuracy                           0.66     10000\n",
      "   macro avg       0.71      0.67      0.67     10000\n",
      "weighted avg       0.72      0.66      0.67     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[884   0  14   1   0  36   9  22   7   7]\n",
      " [  0 434  42  74   0 470   3   0 111   1]\n",
      " [ 17  11 732 122  32  19  30   7  53   9]\n",
      " [  3   3  60 766   2  99   5   7  29  36]\n",
      " [  1   4   4  15 670 132   8  16  71  61]\n",
      " [ 46   0  14 215   8 431  24  21 104  29]\n",
      " [ 24   2  29   5  39  53 783   0  23   0]\n",
      " [  5  29  40   3  11  56   1 672  19 192]\n",
      " [  7   3  10 105   4  55   6  15 748  21]\n",
      " [  8   3   2   7  87 232   0  63  90 517]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['9' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59800, 10) \n",
      " [9 0 4 ... 5 6 8]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (210, 784) (210,)\n",
      "updated train set: (210, 784) (210,) unique(labels): [22  3 27 27 20 21 26 19 26 19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59790, 784) (59790,)\n",
      "\n",
      "Train set: (210, 784) y: (210,)\n",
      "Val   set: (59790, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 21\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 9.970 s \n",
      "\n",
      "Accuracy rate for 68.420000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       980\n",
      "           1       0.85      0.40      0.54      1135\n",
      "           2       0.56      0.77      0.65      1032\n",
      "           3       0.63      0.74      0.68      1010\n",
      "           4       0.83      0.70      0.76       982\n",
      "           5       0.34      0.48      0.40       892\n",
      "           6       0.89      0.81      0.85       958\n",
      "           7       0.76      0.81      0.79      1028\n",
      "           8       0.66      0.76      0.71       974\n",
      "           9       0.71      0.49      0.58      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.71      0.69      0.68     10000\n",
      "weighted avg       0.72      0.68      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[885   0  11   2   0  37  14  12  11   8]\n",
      " [  0 452 369  22   0 236   3   7  46   0]\n",
      " [ 15  10 799  93  17   9  27  14  41   7]\n",
      " [  4   3  79 747   3  87   7  19  28  33]\n",
      " [  0   6   8   8 689 121  11  26  48  65]\n",
      " [ 45   1  21 215   8 424  24  25 104  25]\n",
      " [ 28   2  70   3  27  41 773   0  13   1]\n",
      " [  3  50  39   2   7  26   1 836   9  55]\n",
      " [  7   2  21  95   6  51   4  36 741  11]\n",
      " [  9   5   3   6  74 218   0 118  80 496]]\n",
      "--------------------------------\n",
      "val predicted: (59790,) ['9' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59790, 10) \n",
      " [9 0 4 ... 5 6 8]\n",
      "trainset before (210, 784) (210,)\n",
      "trainset after (220, 784) (220,)\n",
      "updated train set: (220, 784) (220,) unique(labels): [22  3 27 27 23 22 26 22 27 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59780, 784) (59780,)\n",
      "\n",
      "Train set: (220, 784) y: (220,)\n",
      "Val   set: (59780, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 22\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.203 s \n",
      "\n",
      "Accuracy rate for 69.950000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       980\n",
      "           1       0.93      0.34      0.50      1135\n",
      "           2       0.57      0.79      0.66      1032\n",
      "           3       0.65      0.73      0.69      1010\n",
      "           4       0.83      0.75      0.79       982\n",
      "           5       0.38      0.45      0.41       892\n",
      "           6       0.90      0.80      0.85       958\n",
      "           7       0.79      0.84      0.81      1028\n",
      "           8       0.62      0.78      0.69       974\n",
      "           9       0.73      0.62      0.67      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.73      0.70      0.70     10000\n",
      "weighted avg       0.73      0.70      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[890   0   9   3   2  27  15  18  11   5]\n",
      " [  0 386 376  14   0 222   3  18 115   1]\n",
      " [ 15   7 812  69  20  11  27  15  50   6]\n",
      " [  6   1  76 742   3  82   9  25  39  27]\n",
      " [  2   2   6   7 740  50  12  12  43 108]\n",
      " [ 47   0  22 213  11 404  18  30 119  28]\n",
      " [ 30   2  67   4  29  37 768   1  19   1]\n",
      " [  4  16  37   1  15  37   2 866   9  41]\n",
      " [  4   0  21  87  10  43   3  33 759  14]\n",
      " [ 13   1   6   7  65 144   0  81  64 628]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59780,) ['9' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59780, 10) \n",
      " [9 0 4 ... 5 6 9]\n",
      "trainset before (220, 784) (220,)\n",
      "trainset after (230, 784) (230,)\n",
      "updated train set: (230, 784) (230,) unique(labels): [22 12 27 27 24 22 26 22 27 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59770, 784) (59770,)\n",
      "\n",
      "Train set: (230, 784) y: (230,)\n",
      "Val   set: (59770, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 23\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.532 s \n",
      "\n",
      "Accuracy rate for 69.550000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       980\n",
      "           1       0.91      0.32      0.47      1135\n",
      "           2       0.56      0.78      0.65      1032\n",
      "           3       0.65      0.74      0.69      1010\n",
      "           4       0.82      0.76      0.79       982\n",
      "           5       0.38      0.45      0.41       892\n",
      "           6       0.90      0.79      0.84       958\n",
      "           7       0.79      0.84      0.81      1028\n",
      "           8       0.61      0.78      0.68       974\n",
      "           9       0.73      0.62      0.67      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.72      0.70      0.69     10000\n",
      "weighted avg       0.73      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[890   0   9   3   2  26  16  18  11   5]\n",
      " [  0 364 396  12   0 223   3  18 118   1]\n",
      " [ 15  13 803  69  28  11  26  14  47   6]\n",
      " [  6   1  75 743   2  82   9  25  40  27]\n",
      " [  0   3   7   7 742  47  11  11  47 107]\n",
      " [ 47   0  22 213  14 401  17  30 120  28]\n",
      " [ 30   1  67   4  35  38 761   1  20   1]\n",
      " [  4  15  38   1  15  37   1 867   9  41]\n",
      " [  5   1  23  87   8  43   3  33 757  14]\n",
      " [ 12   1   5   7  60 143   0  84  70 627]]\n",
      "--------------------------------\n",
      "val predicted: (59770,) ['9' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59770, 10) \n",
      " [9 0 4 ... 5 6 9]\n",
      "trainset before (230, 784) (230,)\n",
      "trainset after (240, 784) (240,)\n",
      "updated train set: (240, 784) (240,) unique(labels): [22 12 31 27 25 22 28 23 29 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59760, 784) (59760,)\n",
      "\n",
      "Train set: (240, 784) y: (240,)\n",
      "Val   set: (59760, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 24\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 10.917 s \n",
      "\n",
      "Accuracy rate for 69.820000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       980\n",
      "           1       0.93      0.28      0.43      1135\n",
      "           2       0.61      0.83      0.70      1032\n",
      "           3       0.69      0.71      0.70      1010\n",
      "           4       0.84      0.75      0.79       982\n",
      "           5       0.38      0.42      0.40       892\n",
      "           6       0.85      0.84      0.84       958\n",
      "           7       0.79      0.85      0.82      1028\n",
      "           8       0.54      0.80      0.65       974\n",
      "           9       0.73      0.64      0.68      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.73      0.70      0.69     10000\n",
      "weighted avg       0.73      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[880   1   8   2   1  25  29  17  11   6]\n",
      " [  0 313 291   4   3 223   8   8 285   0]\n",
      " [ 18   1 853  22  25   6  46  16  40   5]\n",
      " [  9   0  84 722   2  81  11  24  49  28]\n",
      " [  1   3   9   1 734  49  10  17  46 112]\n",
      " [ 44   0  16 222  12 375  29  24 142  28]\n",
      " [ 20   2  60   3  28  22 801   1  19   2]\n",
      " [  4  16  41   1   8  30   2 876   8  42]\n",
      " [  6   0  34  68   9  25   4  33 782  13]\n",
      " [ 13   1   5   5  50 142   0  92  55 646]]\n",
      "--------------------------------\n",
      "val predicted: (59760,) ['9' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59760, 10) \n",
      " [9 0 4 ... 5 6 9]\n",
      "trainset before (240, 784) (240,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [25 13 32 27 26 25 28 24 29 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 25\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 11.419 s \n",
      "\n",
      "Accuracy rate for 74.800000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       980\n",
      "           1       0.92      0.69      0.79      1135\n",
      "           2       0.68      0.84      0.75      1032\n",
      "           3       0.69      0.71      0.70      1010\n",
      "           4       0.85      0.77      0.81       982\n",
      "           5       0.50      0.44      0.47       892\n",
      "           6       0.87      0.83      0.85       958\n",
      "           7       0.78      0.84      0.81      1028\n",
      "           8       0.62      0.79      0.69       974\n",
      "           9       0.74      0.64      0.69      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.75      0.74     10000\n",
      "weighted avg       0.76      0.75      0.75     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[885   0  11   2   0  18  29  13  10  12]\n",
      " [  0 788 159   5   0  13   5   7 158   0]\n",
      " [ 18   4 867  17  21   9  38  16  36   6]\n",
      " [ 11   9  82 722   1  77  11  26  50  21]\n",
      " [  2   2   7   2 758  51   8  15  42  95]\n",
      " [ 48   5  17 223   9 390  24  28 121  27]\n",
      " [ 21   2  64   3  33  22 794   1  16   2]\n",
      " [  3  37  32   0   8  30   1 861  10  46]\n",
      " [  5   4  39  71   8  30   3  28 772  14]\n",
      " [ 16   4   5   5  54 138   0 104  40 643]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59750, 10) \n",
      " [9 0 4 ... 5 6 9]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (260, 784) (260,)\n",
      "updated train set: (260, 784) (260,) unique(labels): [25 13 34 31 26 27 28 25 30 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59740, 784) (59740,)\n",
      "\n",
      "Train set: (260, 784) y: (260,)\n",
      "Val   set: (59740, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 26\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.014 s \n",
      "\n",
      "Accuracy rate for 75.440000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       980\n",
      "           1       0.94      0.66      0.77      1135\n",
      "           2       0.70      0.85      0.77      1032\n",
      "           3       0.69      0.80      0.74      1010\n",
      "           4       0.86      0.76      0.81       982\n",
      "           5       0.58      0.46      0.51       892\n",
      "           6       0.88      0.82      0.85       958\n",
      "           7       0.74      0.86      0.80      1028\n",
      "           8       0.61      0.79      0.69       974\n",
      "           9       0.74      0.62      0.67      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.76      0.75      0.75     10000\n",
      "weighted avg       0.77      0.75      0.75     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[884   0  10   1   0  19  29  14  10  13]\n",
      " [  0 748 144   7   0  42   5  15 174   0]\n",
      " [ 17   3 874  20  19   8  30  13  41   7]\n",
      " [  6   4  58 810   1  33   7  26  47  18]\n",
      " [  2   2  10   4 751  34   8  29  46  96]\n",
      " [ 45   0  14 232   8 410  24  26 109  24]\n",
      " [ 22   2  65   3  33  26 788   0  17   2]\n",
      " [  2  34  28   2   5  17   0 887   9  44]\n",
      " [  7   3  45  71   9  21   3  30 771  14]\n",
      " [ 17   4   4  18  49  91   0 160  45 621]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59740,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59740, 10) \n",
      " [5 0 4 ... 5 6 9]\n",
      "trainset before (260, 784) (260,)\n",
      "trainset after (270, 784) (270,)\n",
      "updated train set: (270, 784) (270,) unique(labels): [25 13 34 32 29 28 31 25 31 22] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59730, 784) (59730,)\n",
      "\n",
      "Train set: (270, 784) y: (270,)\n",
      "Val   set: (59730, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 27\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.580 s \n",
      "\n",
      "Accuracy rate for 74.930000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89       980\n",
      "           1       0.95      0.64      0.77      1135\n",
      "           2       0.69      0.84      0.76      1032\n",
      "           3       0.71      0.79      0.75      1010\n",
      "           4       0.80      0.74      0.77       982\n",
      "           5       0.59      0.47      0.52       892\n",
      "           6       0.86      0.81      0.83       958\n",
      "           7       0.76      0.86      0.81      1028\n",
      "           8       0.60      0.79      0.69       974\n",
      "           9       0.73      0.64      0.68      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.76      0.75      0.75     10000\n",
      "weighted avg       0.76      0.75      0.75     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[885   0   9   1   0  18  34  11  11  11]\n",
      " [  0 730 145   2   5  59   5  13 176   0]\n",
      " [ 19   4 864  20  21  13  35  12  38   6]\n",
      " [ 12   1  73 796   1  40   7  26  38  16]\n",
      " [  2   1  11   8 722  20  16  28  39 135]\n",
      " [ 50   0  21 198  10 416  24  26 129  18]\n",
      " [ 26   2  50   7  44  35 775   0  19   0]\n",
      " [  2  28  30   0  15   8   2 886  10  47]\n",
      " [  6   2  47  61  12  29   4  31 774   8]\n",
      " [ 17   4   3  27  67  67   0 128  51 645]]\n",
      "--------------------------------\n",
      "val predicted: (59730,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59730, 10) \n",
      " [5 0 4 ... 5 6 9]\n",
      "trainset before (270, 784) (270,)\n",
      "trainset after (280, 784) (280,)\n",
      "updated train set: (280, 784) (280,) unique(labels): [25 15 34 34 30 28 31 26 34 23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59720, 784) (59720,)\n",
      "\n",
      "Train set: (280, 784) y: (280,)\n",
      "Val   set: (59720, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 28\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 12.768 s \n",
      "\n",
      "Accuracy rate for 76.360000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       980\n",
      "           1       0.94      0.82      0.88      1135\n",
      "           2       0.78      0.83      0.80      1032\n",
      "           3       0.71      0.80      0.75      1010\n",
      "           4       0.80      0.70      0.74       982\n",
      "           5       0.66      0.50      0.57       892\n",
      "           6       0.86      0.80      0.83       958\n",
      "           7       0.76      0.84      0.80      1028\n",
      "           8       0.61      0.79      0.68       974\n",
      "           9       0.67      0.63      0.65      1009\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.77      0.76      0.76     10000\n",
      "weighted avg       0.77      0.76      0.76     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[878   1   9   4   0  17  34  17  11   9]\n",
      " [  0 934  21   3   1  23   5   1 147   0]\n",
      " [ 17   3 854  26  21  11  36  18  41   5]\n",
      " [  7   4  64 808   1  39   8  28  33  18]\n",
      " [  2   3   8   5 684  21  14  25  51 169]\n",
      " [ 53   0  23 184  14 446  21  18 115  18]\n",
      " [ 28   2  47   3  52  36 771   1  18   0]\n",
      " [  4  37  20   2   9  13   1 859  11  72]\n",
      " [  7   5  45  67  11  25   4  26 765  19]\n",
      " [ 16   4   4  36  65  48   0 131  68 637]]\n",
      "--------------------------------\n",
      "val predicted: (59720,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59720, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (280, 784) (280,)\n",
      "trainset after (290, 784) (290,)\n",
      "updated train set: (290, 784) (290,) unique(labels): [25 17 37 35 30 30 31 27 34 24] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59710, 784) (59710,)\n",
      "\n",
      "Train set: (290, 784) y: (290,)\n",
      "Val   set: (59710, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 29\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 13.606 s \n",
      "\n",
      "Accuracy rate for 77.230000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       980\n",
      "           1       0.92      0.90      0.91      1135\n",
      "           2       0.80      0.82      0.81      1032\n",
      "           3       0.70      0.81      0.75      1010\n",
      "           4       0.81      0.69      0.74       982\n",
      "           5       0.69      0.52      0.59       892\n",
      "           6       0.88      0.81      0.84       958\n",
      "           7       0.74      0.82      0.78      1028\n",
      "           8       0.64      0.79      0.71       974\n",
      "           9       0.67      0.62      0.64      1009\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.77      0.77     10000\n",
      "weighted avg       0.78      0.77      0.77     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 879    0    8    5    0   19   35   15   11    8]\n",
      " [   0 1027   13    6    1   13    3    1   71    0]\n",
      " [  17    8  850   43   13    7   24   19   48    3]\n",
      " [   7    7   58  817    1   42    8   26   32   12]\n",
      " [   3    4    9    7  673   20   14   20   50  182]\n",
      " [  54    1   17  173   15  461   18   20  119   14]\n",
      " [  25    2   46    4   54   35  772    1   19    0]\n",
      " [   5   51   21    7   11    5    1  846    8   73]\n",
      " [   6    8   33   80   11   26    4   22  774   10]\n",
      " [  16    8    2   26   56   40    0  167   70  624]]\n",
      "--------------------------------\n",
      "val predicted: (59710,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59710, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (290, 784) (290,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [25 17 38 36 31 32 33 28 36 24] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 30\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 14.258 s \n",
      "\n",
      "Accuracy rate for 76.910000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       980\n",
      "           1       0.92      0.87      0.89      1135\n",
      "           2       0.80      0.81      0.81      1032\n",
      "           3       0.70      0.79      0.74      1010\n",
      "           4       0.78      0.69      0.73       982\n",
      "           5       0.69      0.54      0.61       892\n",
      "           6       0.88      0.81      0.84       958\n",
      "           7       0.77      0.84      0.81      1028\n",
      "           8       0.62      0.79      0.69       974\n",
      "           9       0.69      0.61      0.65      1009\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.77      0.77     10000\n",
      "weighted avg       0.77      0.77      0.77     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[876   0   6   5   0  21  38  16  10   8]\n",
      " [  0 982  11   8   2  10   3   1 118   0]\n",
      " [ 17   9 838  48  19   8  21  19  48   5]\n",
      " [  7   4  64 802   1  55   7  25  33  12]\n",
      " [  3   4   9  11 680  16  15  19  47 178]\n",
      " [ 60   1  19 151  12 485  17  18 117  12]\n",
      " [ 27   1  44   3  46  36 775   0  25   1]\n",
      " [  5  44  22   8  12   4   0 866   8  59]\n",
      " [  7  16  32  76  11  33   3  20 768   8]\n",
      " [ 16   9   3  40  87  32   0 137  66 619]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59700, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (310, 784) (310,)\n",
      "updated train set: (310, 784) (310,) unique(labels): [25 21 39 37 32 33 33 28 36 26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59690, 784) (59690,)\n",
      "\n",
      "Train set: (310, 784) y: (310,)\n",
      "Val   set: (59690, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 31\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 14.710 s \n",
      "\n",
      "Accuracy rate for 75.790000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       980\n",
      "           1       0.92      0.80      0.86      1135\n",
      "           2       0.78      0.81      0.80      1032\n",
      "           3       0.68      0.78      0.73      1010\n",
      "           4       0.79      0.69      0.74       982\n",
      "           5       0.68      0.53      0.59       892\n",
      "           6       0.88      0.79      0.83       958\n",
      "           7       0.80      0.79      0.79      1028\n",
      "           8       0.58      0.79      0.67       974\n",
      "           9       0.66      0.68      0.67      1009\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.75      0.76     10000\n",
      "weighted avg       0.77      0.76      0.76     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[876   0   7   4   0  18  40  15   9  11]\n",
      " [  0 912  17   6   2   7   2   1 188   0]\n",
      " [ 18   6 838  46  20  10  26  14  50   4]\n",
      " [  8   3  68 784   1  62   8  19  35  22]\n",
      " [  3   3  10  11 679  17  13  16  49 181]\n",
      " [ 50   3  17 178  10 469  15  18 115  17]\n",
      " [ 26   2  41   6  66  34 757   0  26   0]\n",
      " [  5  38  28   5  12   4   0 814   8 114]\n",
      " [  6  12  38  70  10  40   3  21 766   8]\n",
      " [ 17   7   4  36  57  31   0 105  68 684]]\n",
      "--------------------------------\n",
      "val predicted: (59690,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59690, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (310, 784) (310,)\n",
      "trainset after (320, 784) (320,)\n",
      "updated train set: (320, 784) (320,) unique(labels): [26 22 39 38 32 36 35 29 37 26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59680, 784) (59680,)\n",
      "\n",
      "Train set: (320, 784) y: (320,)\n",
      "Val   set: (59680, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 32\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.170 s \n",
      "\n",
      "Accuracy rate for 77.340000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       980\n",
      "           1       0.92      0.84      0.88      1135\n",
      "           2       0.82      0.79      0.80      1032\n",
      "           3       0.71      0.81      0.76      1010\n",
      "           4       0.82      0.69      0.75       982\n",
      "           5       0.71      0.56      0.62       892\n",
      "           6       0.88      0.87      0.87       958\n",
      "           7       0.80      0.79      0.80      1028\n",
      "           8       0.60      0.78      0.67       974\n",
      "           9       0.66      0.67      0.66      1009\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.78      0.77      0.77     10000\n",
      "weighted avg       0.78      0.77      0.77     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[894   0   7   3   0  16  32  15   7   6]\n",
      " [  0 950  16   3   2   3   3   0 158   0]\n",
      " [ 20  10 815  56  22   8  38  13  46   4]\n",
      " [  7   4  53 822   1  41   6  18  37  21]\n",
      " [  2   3  12   7 676  23  14  16  47 182]\n",
      " [ 48   4  10 164  12 496  18  14 112  14]\n",
      " [ 23   1  19   9  32  23 834   0  17   0]\n",
      " [  5  36  27   3  11   6   0 813   9 118]\n",
      " [  6  20  31  75  11  39   6  18 759   9]\n",
      " [ 12   7   4  22  57  43   0 106  83 675]]\n",
      "--------------------------------\n",
      "val predicted: (59680,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59680, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (320, 784) (320,)\n",
      "trainset after (330, 784) (330,)\n",
      "updated train set: (330, 784) (330,) unique(labels): [27 23 42 40 33 36 35 29 37 28] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59670, 784) (59670,)\n",
      "\n",
      "Train set: (330, 784) y: (330,)\n",
      "Val   set: (59670, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 33\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 15.662 s \n",
      "\n",
      "Accuracy rate for 77.810000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       980\n",
      "           1       0.92      0.80      0.85      1135\n",
      "           2       0.82      0.78      0.80      1032\n",
      "           3       0.73      0.83      0.78      1010\n",
      "           4       0.81      0.70      0.75       982\n",
      "           5       0.74      0.57      0.64       892\n",
      "           6       0.87      0.88      0.87       958\n",
      "           7       0.81      0.81      0.81      1028\n",
      "           8       0.59      0.77      0.67       974\n",
      "           9       0.68      0.71      0.69      1009\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.78      0.78      0.78     10000\n",
      "weighted avg       0.79      0.78      0.78     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[896   0  11   3   0  15  29  16   6   4]\n",
      " [  0 907  13   6   0   4   3   0 202   0]\n",
      " [ 21  16 804  53  22   7  49  14  42   4]\n",
      " [  6   4  51 836   2  37   6  19  33  16]\n",
      " [  2   2   9   9 685  22  15  14  43 181]\n",
      " [ 51   5  10 134  14 512  19  15 113  19]\n",
      " [ 22   1  12   6  35  23 839   0  20   0]\n",
      " [  5  30  29   3  15   5   0 833   8 100]\n",
      " [  5  17  36  75  11  40   6  17 754  13]\n",
      " [ 13   7   3  13  62  31   0  98  67 715]]\n",
      "--------------------------------\n",
      "val predicted: (59670,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59670, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (330, 784) (330,)\n",
      "trainset after (340, 784) (340,)\n",
      "updated train set: (340, 784) (340,) unique(labels): [28 24 44 40 34 37 37 30 38 28] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59660, 784) (59660,)\n",
      "\n",
      "Train set: (340, 784) y: (340,)\n",
      "Val   set: (59660, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 34\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 16.388 s \n",
      "\n",
      "Accuracy rate for 78.970000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       980\n",
      "           1       0.93      0.87      0.90      1135\n",
      "           2       0.83      0.78      0.81      1032\n",
      "           3       0.73      0.83      0.77      1010\n",
      "           4       0.81      0.71      0.75       982\n",
      "           5       0.74      0.60      0.66       892\n",
      "           6       0.88      0.87      0.87       958\n",
      "           7       0.80      0.82      0.81      1028\n",
      "           8       0.64      0.77      0.70       974\n",
      "           9       0.68      0.71      0.70      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[894   0   7   4   1  22  27  16   6   3]\n",
      " [  0 992  11   4   0   1   4   3 120   0]\n",
      " [ 19  15 809  59  20   4  42  16  44   4]\n",
      " [  7   4  45 837   2  43   6  23  27  16]\n",
      " [  2   4   7   7 693  19  14  14  44 178]\n",
      " [ 38   9  11 142  14 539  17  20  88  14]\n",
      " [ 22   3  10   2  36  29 831   0  25   0]\n",
      " [  5  17  31   2  13   5   0 841   9 105]\n",
      " [  5  15  36  83  12  36   6  24 748   9]\n",
      " [ 13   7   3  13  63  35   0  97  65 713]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59660,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59660, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (340, 784) (340,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [28 25 45 42 34 38 37 31 40 30] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 35\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 16.829 s \n",
      "\n",
      "Accuracy rate for 80.160000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       980\n",
      "           1       0.93      0.90      0.91      1135\n",
      "           2       0.85      0.78      0.82      1032\n",
      "           3       0.73      0.86      0.79      1010\n",
      "           4       0.82      0.70      0.76       982\n",
      "           5       0.77      0.60      0.68       892\n",
      "           6       0.88      0.86      0.87       958\n",
      "           7       0.83      0.84      0.83      1028\n",
      "           8       0.66      0.76      0.71       974\n",
      "           9       0.69      0.77      0.73      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.81      0.80      0.80     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 896    0    5    4    1   22   27   16    5    4]\n",
      " [   0 1020    5    7    0    2    4    0   97    0]\n",
      " [  24   17  808   43   19    8   42   15   52    4]\n",
      " [   6    2   43  864    2   33    6   20   20   14]\n",
      " [   2    3    7    6  688   15   15   11   40  195]\n",
      " [  40   11    9  153   18  537   14   14   78   18]\n",
      " [  22    5   10    7   36   25  826    0   27    0]\n",
      " [   5   14   24    3   10    4    0  859    5  104]\n",
      " [   4   20   34   86   11   32    6   28  744    9]\n",
      " [  15    5    3   15   54   18    0   73   52  774]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59650, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (360, 784) (360,)\n",
      "updated train set: (360, 784) (360,) unique(labels): [31 25 45 44 35 39 37 31 42 31] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59640, 784) (59640,)\n",
      "\n",
      "Train set: (360, 784) y: (360,)\n",
      "Val   set: (59640, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 36\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 17.167 s \n",
      "\n",
      "Accuracy rate for 79.450000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       980\n",
      "           1       0.93      0.91      0.92      1135\n",
      "           2       0.86      0.78      0.82      1032\n",
      "           3       0.72      0.84      0.78      1010\n",
      "           4       0.83      0.70      0.76       982\n",
      "           5       0.74      0.54      0.63       892\n",
      "           6       0.88      0.86      0.87       958\n",
      "           7       0.83      0.81      0.82      1028\n",
      "           8       0.64      0.78      0.70       974\n",
      "           9       0.67      0.77      0.72      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 903    0    6    4    0   23   22   14    3    5]\n",
      " [   0 1030    4    6    0    1    4    0   90    0]\n",
      " [  26   16  803   42   16    6   44   17   59    3]\n",
      " [   8    2   45  848    2   40    4   16   24   21]\n",
      " [   2    2    7    4  684   16   15   10   44  198]\n",
      " [  38   11    9  176   14  484   15   18  102   25]\n",
      " [  21    5   10    6   34   30  823    0   29    0]\n",
      " [   5   13   27    1   12    4    0  837    9  120]\n",
      " [  10   21   24   77   10   31    6   27  760    8]\n",
      " [  10    5    3    9   55   20    0   68   66  773]]\n",
      "--------------------------------\n",
      "val predicted: (59640,) ['5' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59640, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (360, 784) (360,)\n",
      "trainset after (370, 784) (370,)\n",
      "updated train set: (370, 784) (370,) unique(labels): [33 25 48 44 36 42 37 31 42 32] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59630, 784) (59630,)\n",
      "\n",
      "Train set: (370, 784) y: (370,)\n",
      "Val   set: (59630, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 37\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 17.742 s \n",
      "\n",
      "Accuracy rate for 79.650000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       980\n",
      "           1       0.93      0.92      0.92      1135\n",
      "           2       0.84      0.77      0.80      1032\n",
      "           3       0.72      0.84      0.77      1010\n",
      "           4       0.83      0.71      0.77       982\n",
      "           5       0.75      0.57      0.64       892\n",
      "           6       0.88      0.85      0.87       958\n",
      "           7       0.84      0.82      0.83      1028\n",
      "           8       0.66      0.76      0.71       974\n",
      "           9       0.68      0.78      0.73      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 898    0    7    6    2   22   25   14    4    2]\n",
      " [   0 1041    3    6    0    3    4    0   78    0]\n",
      " [  35   21  793   47   14    7   45   14   51    5]\n",
      " [   9    2   48  849    2   39    4   17   21   19]\n",
      " [   2    2    6    4  696   18   16   12   35  191]\n",
      " [  49   12   10  171   10  505    9   17   91   18]\n",
      " [  25    5   11    7   38   24  818    0   30    0]\n",
      " [   4   12   28    2   11    5    0  838    8  120]\n",
      " [  10   22   37   81   12   35    5   25  736   11]\n",
      " [  10    5    6    9   52   19    0   62   55  791]]\n",
      "--------------------------------\n",
      "val predicted: (59630,) ['5' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59630, 10) \n",
      " [5 0 4 ... 9 6 8]\n",
      "trainset before (370, 784) (370,)\n",
      "trainset after (380, 784) (380,)\n",
      "updated train set: (380, 784) (380,) unique(labels): [34 28 49 44 38 42 37 31 42 35] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59620, 784) (59620,)\n",
      "\n",
      "Train set: (380, 784) y: (380,)\n",
      "Val   set: (59620, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 38\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 18.452 s \n",
      "\n",
      "Accuracy rate for 79.330000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       980\n",
      "           1       0.91      0.89      0.90      1135\n",
      "           2       0.85      0.75      0.80      1032\n",
      "           3       0.73      0.84      0.78      1010\n",
      "           4       0.85      0.69      0.76       982\n",
      "           5       0.75      0.56      0.64       892\n",
      "           6       0.88      0.86      0.87       958\n",
      "           7       0.84      0.82      0.83      1028\n",
      "           8       0.66      0.76      0.70       974\n",
      "           9       0.67      0.81      0.73      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 903    0    5    4    2   25   23   13    4    1]\n",
      " [   0 1010    2    6    0    3    3    7  104    0]\n",
      " [  40   18  776   56   17    5   46   15   53    6]\n",
      " [  11    3   43  846    1   40    4   16   21   25]\n",
      " [   2    1    5    6  682   17   15   14   35  205]\n",
      " [  56   15   11  161   11  499   10   14   86   29]\n",
      " [  26    6   12    4   40   23  820    0   27    0]\n",
      " [   5   16   23    2    6    4    0  840    8  124]\n",
      " [  17   32   31   73    8   32    6   24  739   12]\n",
      " [  11    4    4    8   36   19    0   59   50  818]]\n",
      "--------------------------------\n",
      "val predicted: (59620,) ['5' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59620, 10) \n",
      " [5 0 4 ... 9 6 8]\n",
      "trainset before (380, 784) (380,)\n",
      "trainset after (390, 784) (390,)\n",
      "updated train set: (390, 784) (390,) unique(labels): [35 28 50 46 40 44 38 31 42 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59610, 784) (59610,)\n",
      "\n",
      "Train set: (390, 784) y: (390,)\n",
      "Val   set: (59610, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 39\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 18.806 s \n",
      "\n",
      "Accuracy rate for 79.410000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89       980\n",
      "           1       0.91      0.89      0.90      1135\n",
      "           2       0.84      0.77      0.80      1032\n",
      "           3       0.72      0.85      0.78      1010\n",
      "           4       0.85      0.70      0.77       982\n",
      "           5       0.75      0.56      0.64       892\n",
      "           6       0.90      0.86      0.88       958\n",
      "           7       0.82      0.82      0.82      1028\n",
      "           8       0.66      0.75      0.70       974\n",
      "           9       0.67      0.79      0.73      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 891    0    7    4    2   41   19   13    3    0]\n",
      " [   0 1015    4    4    0    3    3    6   99    1]\n",
      " [  36   17  790   40   18   10   41   15   58    7]\n",
      " [   9    5   42  854    1   25    2   20   26   26]\n",
      " [   1    1    6    7  692   19   14   15   33  194]\n",
      " [  40   17    6  193    9  499   11   14   70   33]\n",
      " [  21    5   10    6   46   19  827    0   23    1]\n",
      " [   5   14   30    1    6    4    0  838    6  124]\n",
      " [  19   32   37   74    8   31    5   24  734   10]\n",
      " [  11    5    4    7   34   17    0   72   58  801]]\n",
      "--------------------------------\n",
      "val predicted: (59610,) ['5' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59610, 10) \n",
      " [5 0 4 ... 9 6 8]\n",
      "trainset before (390, 784) (390,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [35 28 50 49 41 45 40 33 43 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 40\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 19.205 s \n",
      "\n",
      "Accuracy rate for 79.310000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       980\n",
      "           1       0.92      0.90      0.91      1135\n",
      "           2       0.86      0.75      0.80      1032\n",
      "           3       0.73      0.87      0.79      1010\n",
      "           4       0.85      0.69      0.77       982\n",
      "           5       0.75      0.58      0.65       892\n",
      "           6       0.88      0.88      0.88       958\n",
      "           7       0.81      0.77      0.79      1028\n",
      "           8       0.68      0.75      0.71       974\n",
      "           9       0.64      0.81      0.72      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 889    0    7    4    1   46   18   11    3    1]\n",
      " [   0 1020    3    6    0    3    4   10   88    1]\n",
      " [  27   15  775   46   22   10   59   14   58    6]\n",
      " [  11    7   25  876    1   24    4   20   18   24]\n",
      " [   1    1    7    7  681   13   13   19   29  211]\n",
      " [  44   13    7  166    6  513   13   15   89   26]\n",
      " [  20    5   12    5   37   16  840    0   22    1]\n",
      " [   5   14   27    4    8    3    0  787    6  174]\n",
      " [  18   29   32   74    8   39    9   22  731   12]\n",
      " [  11    5    2    7   33   17    0   77   38  819]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['5' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59600, 10) \n",
      " [5 0 4 ... 9 6 8]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (410, 784) (410,)\n",
      "updated train set: (410, 784) (410,) unique(labels): [35 28 50 50 41 47 40 36 46 37] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59590, 784) (59590,)\n",
      "\n",
      "Train set: (410, 784) y: (410,)\n",
      "Val   set: (59590, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 41\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 19.655 s \n",
      "\n",
      "Accuracy rate for 78.950000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       980\n",
      "           1       0.93      0.86      0.89      1135\n",
      "           2       0.87      0.75      0.81      1032\n",
      "           3       0.74      0.85      0.79      1010\n",
      "           4       0.86      0.69      0.77       982\n",
      "           5       0.73      0.58      0.65       892\n",
      "           6       0.88      0.87      0.88       958\n",
      "           7       0.79      0.79      0.79      1028\n",
      "           8       0.65      0.75      0.70       974\n",
      "           9       0.65      0.80      0.72      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[884   0   5   4   1  53  17  12   2   2]\n",
      " [  0 977   5   4   0   3   4  16 125   1]\n",
      " [ 26  11 775  40  21  11  57  13  72   6]\n",
      " [ 11   4  30 862   1  29   3  20  26  24]\n",
      " [  1   1   6   5 680  17  11  25  29 207]\n",
      " [ 51  15   8 162   6 517  13  16  83  21]\n",
      " [ 20   5  12   6  36  19 838   0  21   1]\n",
      " [  5  15  21   4   6   4   0 815   5 153]\n",
      " [ 25  24  26  71   7  39   9  23 735  15]\n",
      " [ 10   4   3   5  34  18   0  87  36 812]]\n",
      "--------------------------------\n",
      "val predicted: (59590,) ['5' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59590, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (410, 784) (410,)\n",
      "trainset after (420, 784) (420,)\n",
      "updated train set: (420, 784) (420,) unique(labels): [36 28 52 51 41 50 40 37 48 37] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59580, 784) (59580,)\n",
      "\n",
      "Train set: (420, 784) y: (420,)\n",
      "Val   set: (59580, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 42\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 20.226 s \n",
      "\n",
      "Accuracy rate for 79.330000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       980\n",
      "           1       0.92      0.86      0.89      1135\n",
      "           2       0.87      0.75      0.81      1032\n",
      "           3       0.76      0.85      0.81      1010\n",
      "           4       0.85      0.69      0.76       982\n",
      "           5       0.74      0.58      0.65       892\n",
      "           6       0.88      0.88      0.88       958\n",
      "           7       0.81      0.79      0.80      1028\n",
      "           8       0.65      0.77      0.70       974\n",
      "           9       0.66      0.81      0.73      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[890   0   4   6   1  50  17  10   1   1]\n",
      " [  0 976   4   1   0   3   4  11 135   1]\n",
      " [ 31   8 776  40  19   8  57  11  76   6]\n",
      " [ 13   4  30 862   1  27   4  20  28  21]\n",
      " [  1   1   6   4 679  20  12  22  29 208]\n",
      " [ 59  16   9 146   8 520  12  18  80  24]\n",
      " [ 18   5  14   4  36  13 845   0  22   1]\n",
      " [  4  17  23   2   9   3   0 811   7 152]\n",
      " [ 28  25  24  56   8  38   8  20 754  13]\n",
      " [  9   4   2   7  37  20   0  74  36 820]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59580,) ['5' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59580, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (420, 784) (420,)\n",
      "trainset after (430, 784) (430,)\n",
      "updated train set: (430, 784) (430,) unique(labels): [38 29 55 51 41 51 41 37 48 39] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59570, 784) (59570,)\n",
      "\n",
      "Train set: (430, 784) y: (430,)\n",
      "Val   set: (59570, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 43\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 20.867 s \n",
      "\n",
      "Accuracy rate for 78.780000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       980\n",
      "           1       0.91      0.85      0.88      1135\n",
      "           2       0.84      0.74      0.79      1032\n",
      "           3       0.77      0.84      0.80      1010\n",
      "           4       0.86      0.70      0.77       982\n",
      "           5       0.74      0.59      0.65       892\n",
      "           6       0.87      0.88      0.88       958\n",
      "           7       0.81      0.78      0.80      1028\n",
      "           8       0.64      0.76      0.69       974\n",
      "           9       0.66      0.82      0.73      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[882   0   7   4   1  49  24  10   1   2]\n",
      " [  0 962   5   0   0   2   4   9 152   1]\n",
      " [ 27  10 767  44  19  11  55  13  80   6]\n",
      " [ 16   8  33 849   1  33   4  19  28  19]\n",
      " [  1   0   8   4 684  19  14  23  25 204]\n",
      " [ 72  15  12 142   8 522  11  15  73  22]\n",
      " [ 23   5  16   2  32  14 844   0  20   2]\n",
      " [  4  20  29   3   8   4   0 804   7 149]\n",
      " [ 36  33  29  54   8  35   8  20 739  12]\n",
      " [  7   7   3   7  34  21   1  74  30 825]]\n",
      "--------------------------------\n",
      "val predicted: (59570,) ['5' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59570, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (430, 784) (430,)\n",
      "trainset after (440, 784) (440,)\n",
      "updated train set: (440, 784) (440,) unique(labels): [38 29 55 52 44 56 41 37 49 39] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59560, 784) (59560,)\n",
      "\n",
      "Train set: (440, 784) y: (440,)\n",
      "Val   set: (59560, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 44\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 21.305 s \n",
      "\n",
      "Accuracy rate for 79.050000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       980\n",
      "           1       0.91      0.84      0.88      1135\n",
      "           2       0.85      0.74      0.79      1032\n",
      "           3       0.77      0.85      0.81      1010\n",
      "           4       0.86      0.72      0.78       982\n",
      "           5       0.73      0.59      0.65       892\n",
      "           6       0.88      0.88      0.88       958\n",
      "           7       0.82      0.78      0.80      1028\n",
      "           8       0.63      0.77      0.69       974\n",
      "           9       0.68      0.81      0.74      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[888   0  10   3   1  42  22  10   2   2]\n",
      " [  0 957   5   4   0   4   4   9 151   1]\n",
      " [ 31  10 765  43  22  10  55  13  78   5]\n",
      " [ 14   7  31 857   2  30   3  18  32  16]\n",
      " [  1   1   6   2 708  23  13  19  32 177]\n",
      " [ 79  13   9 134   7 522  11  15  87  15]\n",
      " [ 23   4  16   2  28  18 845   0  20   2]\n",
      " [  4  19  29   5  10   8   0 799   6 148]\n",
      " [ 33  31  28  48  11  36   8  18 749  12]\n",
      " [  6   6   2   8  39  22   1  70  40 815]]\n",
      "--------------------------------\n",
      "val predicted: (59560,) ['5' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59560, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (440, 784) (440,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [39 29 55 53 44 59 41 38 51 41] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 45\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 21.856 s \n",
      "\n",
      "Accuracy rate for 79.110000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       980\n",
      "           1       0.92      0.85      0.88      1135\n",
      "           2       0.85      0.73      0.79      1032\n",
      "           3       0.77      0.85      0.81      1010\n",
      "           4       0.87      0.72      0.78       982\n",
      "           5       0.69      0.59      0.64       892\n",
      "           6       0.88      0.88      0.88       958\n",
      "           7       0.82      0.82      0.82      1028\n",
      "           8       0.63      0.75      0.69       974\n",
      "           9       0.71      0.81      0.76      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[862   0  15   3   1  65  22   9   2   1]\n",
      " [  0 962   4   6   0   4   4  11 143   1]\n",
      " [ 31  12 756  55  22  14  51  13  73   5]\n",
      " [ 16   3  31 859   2  35   2  15  25  22]\n",
      " [  1   1   6   2 703  25  13  19  48 164]\n",
      " [ 91  11   7 115   6 530  13  17  84  18]\n",
      " [ 24   5  16   1  27  18 847   0  19   1]\n",
      " [  5  20  27   8   8   8   0 843   5 104]\n",
      " [ 39  31  30  52  10  43   6  18 733  12]\n",
      " [  9   4   1   8  33  22   1  83  32 816]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['5' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59550, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (460, 784) (460,)\n",
      "updated train set: (460, 784) (460,) unique(labels): [39 30 55 54 44 63 42 38 53 42] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59540, 784) (59540,)\n",
      "\n",
      "Train set: (460, 784) y: (460,)\n",
      "Val   set: (59540, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 46\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 22.378 s \n",
      "\n",
      "Accuracy rate for 79.630000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85       980\n",
      "           1       0.92      0.86      0.89      1135\n",
      "           2       0.85      0.73      0.78      1032\n",
      "           3       0.79      0.85      0.82      1010\n",
      "           4       0.86      0.71      0.78       982\n",
      "           5       0.71      0.64      0.68       892\n",
      "           6       0.88      0.89      0.88       958\n",
      "           7       0.84      0.82      0.83      1028\n",
      "           8       0.64      0.77      0.70       974\n",
      "           9       0.70      0.80      0.75      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[862   0  15   2   1  61  23  12   3   1]\n",
      " [  0 972   4   7   0   4   4   4 139   1]\n",
      " [ 32  12 750  59  21  18  54  12  70   4]\n",
      " [ 18   4  29 858   1  34   5  12  33  16]\n",
      " [  1   1   6   2 698  26   9  16  40 183]\n",
      " [ 79  11   5  93   9 575  15  10  80  15]\n",
      " [ 21   4  14   2  30  18 849   0  18   2]\n",
      " [  4  22  26   8   8   8   0 838   6 108]\n",
      " [ 34  27  30  42  10  48   7  17 749  10]\n",
      " [  8   6   2   7  33  18   1  81  41 812]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59540,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59540, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (460, 784) (460,)\n",
      "trainset after (470, 784) (470,)\n",
      "updated train set: (470, 784) (470,) unique(labels): [39 30 57 55 45 65 43 40 54 42] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59530, 784) (59530,)\n",
      "\n",
      "Train set: (470, 784) y: (470,)\n",
      "Val   set: (59530, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 47\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 22.958 s \n",
      "\n",
      "Accuracy rate for 79.600000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       980\n",
      "           1       0.92      0.86      0.89      1135\n",
      "           2       0.84      0.73      0.78      1032\n",
      "           3       0.81      0.84      0.83      1010\n",
      "           4       0.86      0.71      0.78       982\n",
      "           5       0.70      0.66      0.68       892\n",
      "           6       0.88      0.88      0.88       958\n",
      "           7       0.80      0.84      0.82      1028\n",
      "           8       0.64      0.76      0.70       974\n",
      "           9       0.72      0.78      0.75      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[863   0  15   6   0  64  19   7   3   3]\n",
      " [  0 976   5   6   0   5   5   2 136   0]\n",
      " [ 36  12 750  53  24  17  54  18  65   3]\n",
      " [ 18   2  33 852   1  45   3  19  25  12]\n",
      " [  1   1   4   2 700  21  14  18  38 183]\n",
      " [ 81  10   7  80   9 587  10  17  78  13]\n",
      " [ 24   3  12   2  30  21 846   0  19   1]\n",
      " [  5  23  30   2   6  11   0 859   7  85]\n",
      " [ 34  24  31  39  12  54   7  21 744   8]\n",
      " [  9   6   2   8  32  19   0 109  41 783]]\n",
      "--------------------------------\n",
      "val predicted: (59530,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59530, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (470, 784) (470,)\n",
      "trainset after (480, 784) (480,)\n",
      "updated train set: (480, 784) (480,) unique(labels): [39 31 59 56 46 65 46 41 55 42] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59520, 784) (59520,)\n",
      "\n",
      "Train set: (480, 784) y: (480,)\n",
      "Val   set: (59520, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 48\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 23.495 s \n",
      "\n",
      "Accuracy rate for 79.730000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       980\n",
      "           1       0.91      0.86      0.89      1135\n",
      "           2       0.84      0.73      0.78      1032\n",
      "           3       0.82      0.84      0.83      1010\n",
      "           4       0.88      0.71      0.79       982\n",
      "           5       0.71      0.66      0.68       892\n",
      "           6       0.89      0.89      0.89       958\n",
      "           7       0.81      0.81      0.81      1028\n",
      "           8       0.65      0.78      0.70       974\n",
      "           9       0.70      0.79      0.74      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[866   0  15   4   0  63  16   8   4   4]\n",
      " [  0 975   7   4   0   6   4   7 131   1]\n",
      " [ 38  13 753  52  19  16  53  14  70   4]\n",
      " [ 20   4  34 851   1  41   4  16  26  13]\n",
      " [  1   1   4   2 701  18  12  16  39 188]\n",
      " [ 85   9   6  77   7 591  11  13  80  13]\n",
      " [ 23   5  12   2  26  22 851   0  16   1]\n",
      " [  5  23  38   2   6   9   0 836   7 102]\n",
      " [ 31  31  22  37   9  52   7  21 756   8]\n",
      " [  9   7   1   9  28  20   0 100  42 793]]\n",
      "--------------------------------\n",
      "val predicted: (59520,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59520, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (480, 784) (480,)\n",
      "trainset after (490, 784) (490,)\n",
      "updated train set: (490, 784) (490,) unique(labels): [40 31 62 57 46 66 47 42 56 43] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59510, 784) (59510,)\n",
      "\n",
      "Train set: (490, 784) y: (490,)\n",
      "Val   set: (59510, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 49\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 23.922 s \n",
      "\n",
      "Accuracy rate for 80.130000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       980\n",
      "           1       0.92      0.86      0.89      1135\n",
      "           2       0.87      0.73      0.79      1032\n",
      "           3       0.81      0.84      0.82      1010\n",
      "           4       0.88      0.70      0.78       982\n",
      "           5       0.70      0.69      0.70       892\n",
      "           6       0.89      0.89      0.89       958\n",
      "           7       0.82      0.83      0.83      1028\n",
      "           8       0.65      0.78      0.71       974\n",
      "           9       0.71      0.79      0.75      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.81      0.80      0.80     10000\n",
      "weighted avg       0.81      0.80      0.80     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[861   0  15   2   0  70  19   6   3   4]\n",
      " [  0 976   4   4   0   6   4   9 131   1]\n",
      " [ 39  12 753  53  19  14  52  12  75   3]\n",
      " [ 21   4  33 846   1  43   4  18  29  11]\n",
      " [  1   1   4   8 688  20  12  18  44 186]\n",
      " [ 72   9   5  79   8 614  12  13  64  16]\n",
      " [ 21   5   9   2  24  24 857   0  15   1]\n",
      " [  4  21  28   7   7   9   0 858   5  89]\n",
      " [ 33  30  17  37   7  58   7  16 760   9]\n",
      " [ 10   6   2   8  24  15   0  99  45 800]]\n",
      "--------------------------------\n",
      "val predicted: (59510,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59510, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (490, 784) (490,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [41 31 62 59 47 67 48 43 58 44] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 50\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 24.391 s \n",
      "\n",
      "Accuracy rate for 80.130000 \n",
      "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       980\n",
      "           1       0.92      0.86      0.89      1135\n",
      "           2       0.87      0.74      0.80      1032\n",
      "           3       0.81      0.85      0.83      1010\n",
      "           4       0.87      0.73      0.79       982\n",
      "           5       0.70      0.67      0.69       892\n",
      "           6       0.89      0.89      0.89       958\n",
      "           7       0.81      0.82      0.82      1028\n",
      "           8       0.65      0.78      0.71       974\n",
      "           9       0.71      0.78      0.75      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.81      0.80      0.80     10000\n",
      "weighted avg       0.81      0.80      0.80     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[864   0  13   2   0  68  19   9   3   2]\n",
      " [  0 976   7   3   0   4   4   8 133   0]\n",
      " [ 39  16 761  47  20  16  49  13  70   1]\n",
      " [ 19   3  31 854   1  39   4  18  31  10]\n",
      " [  1   1   5   8 712  19  10  19  33 174]\n",
      " [ 80   8   7  72   6 601  12  15  73  18]\n",
      " [ 21   2  10   2  31  23 850   0  18   1]\n",
      " [  3  21  28   7   7  10   0 844   5 103]\n",
      " [ 30  24  15  48   8  55   8  16 761   9]\n",
      " [  9   6   1   8  29  18   0  96  52 790]]\n",
      "--------------------------------\n",
      "final active learning accuracies [34.22, 36.5, 41.5, 41.699999999999996, 43.05, 46.93, 50.62, 51.129999999999995, 55.74, 57.089999999999996, 56.84, 61.22, 62.029999999999994, 62.83, 62.029999999999994, 62.21, 63.28, 63.54, 65.23, 66.36999999999999, 68.42, 69.95, 69.55, 69.82000000000001, 74.8, 75.44, 74.92999999999999, 76.36, 77.23, 76.91, 75.79, 77.34, 77.81, 78.97, 80.16, 79.45, 79.65, 79.33, 79.41, 79.31, 78.95, 79.33, 78.78, 79.05, 79.11, 79.63, 79.60000000000001, 79.73, 80.13, 80.13]\n",
      "saved Active-learning-experiment-15.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'README.md', 'Active-learning-experiment-9.pkl', '.~Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "{\n",
      "  \"SvmModel\": {\n",
      "    \"EntropySelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          34.22,\n",
      "          36.5,\n",
      "          41.5,\n",
      "          41.699999999999996,\n",
      "          43.05,\n",
      "          46.93,\n",
      "          50.62,\n",
      "          51.129999999999995,\n",
      "          55.74,\n",
      "          57.089999999999996,\n",
      "          56.84,\n",
      "          61.22,\n",
      "          62.029999999999994,\n",
      "          62.83,\n",
      "          62.029999999999994,\n",
      "          62.21,\n",
      "          63.28,\n",
      "          63.54,\n",
      "          65.23,\n",
      "          66.36999999999999,\n",
      "          68.42,\n",
      "          69.95,\n",
      "          69.55,\n",
      "          69.82000000000001,\n",
      "          74.8,\n",
      "          75.44,\n",
      "          74.92999999999999,\n",
      "          76.36,\n",
      "          77.23,\n",
      "          76.91,\n",
      "          75.79,\n",
      "          77.34,\n",
      "          77.81,\n",
      "          78.97,\n",
      "          80.16,\n",
      "          79.45,\n",
      "          79.65,\n",
      "          79.33,\n",
      "          79.41,\n",
      "          79.31,\n",
      "          78.95,\n",
      "          79.33,\n",
      "          78.78,\n",
      "          79.05,\n",
      "          79.11,\n",
      "          79.63,\n",
      "          79.60000000000001,\n",
      "          79.73,\n",
      "          80.13,\n",
      "          80.13\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.17,\n",
      "          79.14999999999999,\n",
      "          79.42,\n",
      "          80.08\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          52.65,\n",
      "          55.769999999999996,\n",
      "          58.5,\n",
      "          67.9,\n",
      "          68.63,\n",
      "          72.32,\n",
      "          72.37,\n",
      "          72.08,\n",
      "          72.49,\n",
      "          71.94,\n",
      "          73.11,\n",
      "          75.18,\n",
      "          76.25,\n",
      "          75.6,\n",
      "          76.79,\n",
      "          77.42999999999999,\n",
      "          77.56,\n",
      "          77.45,\n",
      "          78.3,\n",
      "          78.86\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.73,\n",
      "          84.64\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          68.25,\n",
      "          69.56,\n",
      "          71.76,\n",
      "          70.64,\n",
      "          70.59,\n",
      "          74.49,\n",
      "          76.31,\n",
      "          78.17,\n",
      "          77.95,\n",
      "          78.78\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          24.41,\n",
      "          39.12,\n",
      "          51.55,\n",
      "          58.15,\n",
      "          64.19,\n",
      "          67.33,\n",
      "          72.46000000000001,\n",
      "          73.94,\n",
      "          78.06,\n",
      "          78.57,\n",
      "          79.01,\n",
      "          78.68,\n",
      "          79.80000000000001,\n",
      "          80.78999999999999,\n",
      "          81.54,\n",
      "          82.21000000000001,\n",
      "          82.08,\n",
      "          83.17999999999999,\n",
      "          83.36,\n",
      "          83.13000000000001,\n",
      "          82.5,\n",
      "          83.24000000000001,\n",
      "          84.03,\n",
      "          84.84,\n",
      "          85.2,\n",
      "          85.17,\n",
      "          85.24000000000001,\n",
      "          85.1,\n",
      "          85.33,\n",
      "          85.00999999999999,\n",
      "          85.57000000000001,\n",
      "          85.91,\n",
      "          85.91,\n",
      "          86.4,\n",
      "          86.53999999999999,\n",
      "          86.78,\n",
      "          87.02,\n",
      "          87.18,\n",
      "          87.41,\n",
      "          87.33,\n",
      "          87.72,\n",
      "          87.8,\n",
      "          87.9,\n",
      "          88.1,\n",
      "          88.41,\n",
      "          88.22,\n",
      "          88.42999999999999,\n",
      "          88.38000000000001,\n",
      "          88.31,\n",
      "          88.6\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          76.8,\n",
      "          83.96000000000001,\n",
      "          87.08,\n",
      "          88.94\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          48.209999999999994,\n",
      "          59.870000000000005,\n",
      "          70.07,\n",
      "          73.88,\n",
      "          79.62,\n",
      "          80.99,\n",
      "          82.69999999999999,\n",
      "          83.2,\n",
      "          84.13000000000001,\n",
      "          84.61999999999999,\n",
      "          85.53,\n",
      "          86.32,\n",
      "          86.46000000000001,\n",
      "          87.16000000000001,\n",
      "          87.74,\n",
      "          87.87,\n",
      "          88.16000000000001,\n",
      "          88.24,\n",
      "          88.42,\n",
      "          88.13\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          82.87,\n",
      "          87.59\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          59.74,\n",
      "          70.57,\n",
      "          79.12,\n",
      "          83.25,\n",
      "          84.19,\n",
      "          86.44,\n",
      "          87.3,\n",
      "          87.81,\n",
      "          87.58,\n",
      "          88.63\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          30.12,\n",
      "          41.54,\n",
      "          51.15,\n",
      "          59.5,\n",
      "          64.64999999999999,\n",
      "          65.02,\n",
      "          66.7,\n",
      "          68.81,\n",
      "          70.28,\n",
      "          73.48,\n",
      "          73.83,\n",
      "          76.64,\n",
      "          76.83,\n",
      "          77.68,\n",
      "          77.38000000000001,\n",
      "          77.77,\n",
      "          79.17,\n",
      "          79.59,\n",
      "          80.86,\n",
      "          80.89,\n",
      "          81.24,\n",
      "          81.47999999999999,\n",
      "          82.23,\n",
      "          82.8,\n",
      "          82.96,\n",
      "          83.00999999999999,\n",
      "          83.64,\n",
      "          83.72,\n",
      "          83.35000000000001,\n",
      "          83.41,\n",
      "          83.69,\n",
      "          83.67999999999999,\n",
      "          84.23,\n",
      "          84.26,\n",
      "          84.48,\n",
      "          84.98,\n",
      "          85.38,\n",
      "          85.39,\n",
      "          85.63,\n",
      "          85.74000000000001,\n",
      "          86.17,\n",
      "          86.28,\n",
      "          86.38,\n",
      "          86.57000000000001,\n",
      "          86.42,\n",
      "          86.56,\n",
      "          86.38,\n",
      "          86.37,\n",
      "          86.44,\n",
      "          86.53999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.53999999999999,\n",
      "          80.67,\n",
      "          84.16,\n",
      "          86.61999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          55.489999999999995,\n",
      "          64.21,\n",
      "          71.63000000000001,\n",
      "          74.95,\n",
      "          76.49000000000001,\n",
      "          80.08999999999999,\n",
      "          82.11,\n",
      "          82.25,\n",
      "          82.65,\n",
      "          83.3,\n",
      "          84.02,\n",
      "          85.05,\n",
      "          85.15,\n",
      "          85.67,\n",
      "          86.18,\n",
      "          86.83999999999999,\n",
      "          87.41,\n",
      "          87.63,\n",
      "          87.82,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.15,\n",
      "          86.91\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          67.52,\n",
      "          75.52,\n",
      "          80.19,\n",
      "          84.26,\n",
      "          85.77,\n",
      "          86.16,\n",
      "          86.58,\n",
      "          86.65,\n",
      "          87.18,\n",
      "          87.09\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 16, using model = RfModel, selection_function = RandomSelection, k = 250, iteration = 0.\n",
      "\n",
      "initial random chosen samples (250,)\n",
      "initial train set: (250, 784) (250,) unique(labels): [25 26 26 30 23 17 34 28 16 25] [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59750, 784) (59750,) (250,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.056 s \n",
      "\n",
      "Accuracy rate for 79.440000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.69      0.78       980\n",
      "           1       0.86      0.99      0.92      1135\n",
      "           2       0.84      0.84      0.84      1032\n",
      "           3       0.64      0.91      0.75      1010\n",
      "           4       0.84      0.81      0.82       982\n",
      "           5       0.71      0.52      0.60       892\n",
      "           6       0.72      0.94      0.82       958\n",
      "           7       0.88      0.86      0.87      1028\n",
      "           8       0.92      0.53      0.67       974\n",
      "           9       0.77      0.79      0.78      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.81      0.79      0.78     10000\n",
      "weighted avg       0.81      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 674    0   20   37    1  154   82    9    2    1]\n",
      " [   0 1120    2    7    0    0    4    1    1    0]\n",
      " [  13   20  872   32   17    0   47   22    4    5]\n",
      " [   4    6   27  922    1    7    7   10    7   19]\n",
      " [   2   14    1    5  795    0   75    4    1   85]\n",
      " [   8   24    6  239   15  464   53   15   21   47]\n",
      " [  24    4    9    1    7    9  902    1    1    0]\n",
      " [   2   55   39    5   13    0    3  880    3   28]\n",
      " [   9   45   56  176    9   19   74   12  516   58]\n",
      " [   6   17   12   26   91    4    8   44    2  799]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [54 51 47 62 47 41 54 56 38 50] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.767 s \n",
      "\n",
      "Accuracy rate for 87.520000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       980\n",
      "           1       0.91      0.99      0.95      1135\n",
      "           2       0.93      0.83      0.88      1032\n",
      "           3       0.74      0.93      0.82      1010\n",
      "           4       0.89      0.88      0.89       982\n",
      "           5       0.90      0.71      0.80       892\n",
      "           6       0.87      0.93      0.90       958\n",
      "           7       0.91      0.90      0.91      1028\n",
      "           8       0.92      0.73      0.81       974\n",
      "           9       0.82      0.87      0.84      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.87      0.87     10000\n",
      "weighted avg       0.88      0.88      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 929    1    2   10    1   13   17    2    2    3]\n",
      " [   0 1118    3    2    0    1    5    1    5    0]\n",
      " [  20   17  858   34   15    1   29   29   19   10]\n",
      " [   3    6   16  938    0   10    2   12   13   10]\n",
      " [   1    9    1    0  866    0   28    2    2   73]\n",
      " [  12   18    0  144    8  636   22    4   13   35]\n",
      " [  26    5    5    3   10   16  890    0    3    0]\n",
      " [   3   35   20    0    6    2    2  930    2   28]\n",
      " [   8   10   16  124   14   19   24   15  707   37]\n",
      " [   7   11    5   20   48    7    4   24    3  880]]\n",
      "--------------------------------\n",
      "final active learning accuracies [79.44, 87.52]\n",
      "saved Active-learning-experiment-16.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 17, using model = RfModel, selection_function = RandomSelection, k = 125, iteration = 0.\n",
      "\n",
      "initial random chosen samples (125,)\n",
      "initial train set: (125, 784) (125,) unique(labels): [17 12 13 14 14  5 17 10 10 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,) (125,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.472 s \n",
      "\n",
      "Accuracy rate for 75.480000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       980\n",
      "           1       0.76      0.97      0.85      1135\n",
      "           2       0.71      0.72      0.72      1032\n",
      "           3       0.63      0.88      0.73      1010\n",
      "           4       0.68      0.84      0.75       982\n",
      "           5       0.98      0.22      0.36       892\n",
      "           6       0.79      0.89      0.84       958\n",
      "           7       0.91      0.79      0.84      1028\n",
      "           8       0.86      0.56      0.68       974\n",
      "           9       0.69      0.66      0.68      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.78      0.75      0.73     10000\n",
      "weighted avg       0.78      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 918    2    3    1    3    0   44    4    1    4]\n",
      " [   0 1104   11    7    0    0    2    2    9    0]\n",
      " [  41   95  748   54   12    0   36   12   33    1]\n",
      " [   7   14   37  887    5    2    8   12   14   24]\n",
      " [   2   12   22    2  821    0   35    4    1   83]\n",
      " [  58   75   13  266  100  197   68   21   22   72]\n",
      " [  13   16   53    1   15    0  854    3    1    2]\n",
      " [   3   44  106    3   19    0    2  808    1   42]\n",
      " [  28   76   24  167   33    1   26    3  544   72]\n",
      " [  17   18   33   26  206    0    9   23   10  667]]\n",
      "--------------------------------\n",
      "val predicted: (59875,) ['5' '0' '4' ... '5' '6' '2']\n",
      "probabilities: (59875, 10) \n",
      " [5 0 4 ... 5 6 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (125, 784) (125,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [31 27 25 24 25 21 31 16 23 27] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.990 s \n",
      "\n",
      "Accuracy rate for 83.130000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       980\n",
      "           1       0.79      0.98      0.88      1135\n",
      "           2       0.80      0.73      0.77      1032\n",
      "           3       0.81      0.84      0.82      1010\n",
      "           4       0.84      0.79      0.82       982\n",
      "           5       0.92      0.64      0.75       892\n",
      "           6       0.86      0.94      0.90       958\n",
      "           7       0.91      0.80      0.85      1028\n",
      "           8       0.85      0.74      0.79       974\n",
      "           9       0.73      0.84      0.78      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 954    1    3    0    0    1   17    2    2    0]\n",
      " [   0 1114    6    5    0    0    4    1    5    0]\n",
      " [  30   84  756   43    9    2   33   14   54    7]\n",
      " [  11   17   30  844    1   23    5   11   35   33]\n",
      " [   4   12   16    0  779    1   27    5    2  136]\n",
      " [  32   57    9   75   33  569   38   17    9   53]\n",
      " [  21    5    8    0   13    3  905    3    0    0]\n",
      " [   6   52   76    1   12    2    1  822    5   51]\n",
      " [  23   48   29   63   10   14   22    5  721   39]\n",
      " [  14   17   11    8   68    3    6   19   14  849]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '2']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 6 2]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [41 45 40 38 35 34 40 26 35 41] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.336 s \n",
      "\n",
      "Accuracy rate for 85.790000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       980\n",
      "           1       0.81      0.99      0.89      1135\n",
      "           2       0.86      0.78      0.82      1032\n",
      "           3       0.82      0.86      0.84      1010\n",
      "           4       0.89      0.81      0.85       982\n",
      "           5       0.89      0.75      0.81       892\n",
      "           6       0.89      0.93      0.91       958\n",
      "           7       0.93      0.82      0.88      1028\n",
      "           8       0.87      0.77      0.81       974\n",
      "           9       0.76      0.88      0.81      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 947    1    2    2    0    4   17    1    5    1]\n",
      " [   0 1121    3    3    0    1    4    0    3    0]\n",
      " [  22   81  801   28   11    2   20   16   44    7]\n",
      " [   4   19   22  872    1   21    2   13   34   22]\n",
      " [   2   15    5    0  797    3   20    2    4  134]\n",
      " [  16   39    8   80   15  667   27    5    6   29]\n",
      " [  17    7    9    0   14   16  894    0    1    0]\n",
      " [   3   43   55    3   14    2    1  848    4   55]\n",
      " [  16   40   24   62    3   26   15    4  748   36]\n",
      " [   9   14    3   12   43    9    4   18   13  884]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59625, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [53 60 51 47 50 44 51 41 51 52] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.693 s \n",
      "\n",
      "Accuracy rate for 87.780000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       980\n",
      "           1       0.85      0.98      0.91      1135\n",
      "           2       0.87      0.80      0.84      1032\n",
      "           3       0.87      0.84      0.86      1010\n",
      "           4       0.88      0.87      0.88       982\n",
      "           5       0.91      0.80      0.85       892\n",
      "           6       0.89      0.94      0.91       958\n",
      "           7       0.94      0.84      0.89      1028\n",
      "           8       0.85      0.83      0.84       974\n",
      "           9       0.81      0.89      0.85      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 947    1    3    1    3    4   14    1    6    0]\n",
      " [   0 1115    7    2    1    0    4    0    6    0]\n",
      " [  19   57  828   21   14    0   23   19   45    6]\n",
      " [   6   13   21  851    2   30    4   15   46   22]\n",
      " [   1   14    4    0  858    2   14    0    5   84]\n",
      " [  21   27    6   49   12  712   30    6   11   18]\n",
      " [  11    5    5    1   23   11  899    0    3    0]\n",
      " [   1   44   55    1    6    0    1  866    7   47]\n",
      " [  10   22   17   36    8   19   16    5  808   33]\n",
      " [   7   13    3   12   46    5    3   12   14  894]]\n",
      "--------------------------------\n",
      "final active learning accuracies [75.48, 83.13000000000001, 85.79, 87.78]\n",
      "saved Active-learning-experiment-17.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 18, using model = RfModel, selection_function = RandomSelection, k = 50, iteration = 0.\n",
      "\n",
      "initial random chosen samples (50,)\n",
      "initial train set: (50, 784) (50,) unique(labels): [7 5 5 7 2 5 3 8 4 4] [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59950, 784) (59950,) (50,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.960 s \n",
      "\n",
      "Accuracy rate for 58.270000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.95      0.80       980\n",
      "           1       0.74      0.93      0.82      1135\n",
      "           2       0.85      0.55      0.67      1032\n",
      "           3       0.57      0.82      0.67      1010\n",
      "           4       0.63      0.05      0.09       982\n",
      "           5       0.57      0.37      0.45       892\n",
      "           6       0.86      0.41      0.56       958\n",
      "           7       0.36      0.92      0.51      1028\n",
      "           8       0.84      0.33      0.48       974\n",
      "           9       0.42      0.39      0.41      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.65      0.57      0.55     10000\n",
      "weighted avg       0.65      0.58      0.55     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 930    2    0    4    0   35    1    7    1    0]\n",
      " [   0 1055    7    8    0    0    0   63    2    0]\n",
      " [  86  103  570   62    0    2   18  126   41   24]\n",
      " [  47   16    1  832    0   33    5   70    4    2]\n",
      " [   9   22    8   33   47    5   18  416    3  421]\n",
      " [  87   44    2  186    0  333   10  220    4    6]\n",
      " [ 124   32   64   16   28   88  397  158    2   49]\n",
      " [  18   39    9    2    0    0    0  942    0   18]\n",
      " [  25  102    5  255    0   72   14  156  325   20]\n",
      " [  19   13    2   68    0   14    0  494    3  396]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['5' '0' '7' ... '5' '0' '7']\n",
      "probabilities: (59950, 10) \n",
      " [5 0 7 ... 5 0 7]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [12 11  8 14  8 12  7 13  9  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.311 s \n",
      "\n",
      "Accuracy rate for 71.760000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       980\n",
      "           1       0.76      0.98      0.85      1135\n",
      "           2       0.91      0.52      0.66      1032\n",
      "           3       0.70      0.83      0.76      1010\n",
      "           4       0.71      0.67      0.69       982\n",
      "           5       0.50      0.67      0.58       892\n",
      "           6       0.83      0.60      0.69       958\n",
      "           7       0.61      0.89      0.73      1028\n",
      "           8       0.80      0.56      0.66       974\n",
      "           9       0.78      0.46      0.58      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.71      0.71     10000\n",
      "weighted avg       0.74      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 932    0    0    6    0   27   11    4    0    0]\n",
      " [   0 1109    1    7    0    0    2    3   13    0]\n",
      " [  81  137  537   65   21    6   36   76   68    5]\n",
      " [   8   13    4  834    1   91    9   33   16    1]\n",
      " [   1   25    2    7  661   79   33   81   15   78]\n",
      " [  40   42    2  122   16  600   15   46    5    4]\n",
      " [  61   39   22   12  123   98  571   28    3    1]\n",
      " [  10   41   14    3    8    3    0  918    4   27]\n",
      " [  15   48    3  116    4  155    9   60  550   14]\n",
      " [  15   14    2   15  100  133    4  250   12  464]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '4' ... '5' '0' '7']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 4 ... 5 0 7]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [16 15 16 18 13 14  9 18 18 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.614 s \n",
      "\n",
      "Accuracy rate for 79.640000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       980\n",
      "           1       0.85      0.94      0.89      1135\n",
      "           2       0.79      0.77      0.78      1032\n",
      "           3       0.80      0.80      0.80      1010\n",
      "           4       0.77      0.79      0.78       982\n",
      "           5       0.69      0.62      0.65       892\n",
      "           6       0.89      0.65      0.75       958\n",
      "           7       0.72      0.90      0.80      1028\n",
      "           8       0.82      0.81      0.81       974\n",
      "           9       0.83      0.69      0.76      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.80      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 932    0    3    1    1   16   16    3    8    0]\n",
      " [   0 1067   49    6    1    0    2    6    4    0]\n",
      " [  49   52  792   22   17    3    9   45   39    4]\n",
      " [  10   12   23  808    0   80    3   33   34    7]\n",
      " [   3   14   11    0  775   17   18   36   20   88]\n",
      " [  29   28   21  123   16  550   20   52   33   20]\n",
      " [  79   17   59    3   94   50  624   19   12    1]\n",
      " [   7   33   20    0   21    1    0  928    4   14]\n",
      " [  18   20   23   32    5   41    6   30  787   12]\n",
      " [  14   10    6   10   71   37    3  133   24  701]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['3' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59850, 10) \n",
      " [3 0 4 ... 5 0 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [24 23 22 19 21 19 12 20 19 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.919 s \n",
      "\n",
      "Accuracy rate for 82.540000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88       980\n",
      "           1       0.82      0.98      0.90      1135\n",
      "           2       0.81      0.81      0.81      1032\n",
      "           3       0.86      0.76      0.81      1010\n",
      "           4       0.79      0.79      0.79       982\n",
      "           5       0.75      0.71      0.73       892\n",
      "           6       0.95      0.72      0.82       958\n",
      "           7       0.85      0.89      0.87      1028\n",
      "           8       0.90      0.75      0.82       974\n",
      "           9       0.76      0.83      0.80      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.82      0.82     10000\n",
      "weighted avg       0.83      0.83      0.82     10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 953    1    2    0    0   15    6    1    2    0]\n",
      " [   0 1115   11    3    0    0    2    3    1    0]\n",
      " [  40   59  838   13   16    2    7   27   21    9]\n",
      " [  27   12   40  766    0  100    1   24   26   14]\n",
      " [   4   16   12    0  779    3    7   12    5  144]\n",
      " [  47   31   11   70   34  629    7   21    9   33]\n",
      " [  77   20   60    0   69   36  693    2    1    0]\n",
      " [   7   41   24    0   14    2    1  912    1   26]\n",
      " [  14   44   31   31   16   47    4   20  729   38]\n",
      " [  11   13   10    4   60    8    0   51   12  840]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['3' '0' '4' ... '5' '6' '2']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 4 ... 5 6 2]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [35 28 23 24 25 21 14 27 26 27] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.939 s \n",
      "\n",
      "Accuracy rate for 83.820000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86       980\n",
      "           1       0.85      0.98      0.91      1135\n",
      "           2       0.87      0.76      0.81      1032\n",
      "           3       0.88      0.77      0.82      1010\n",
      "           4       0.86      0.77      0.81       982\n",
      "           5       0.84      0.71      0.77       892\n",
      "           6       0.94      0.77      0.85       958\n",
      "           7       0.85      0.90      0.87      1028\n",
      "           8       0.87      0.82      0.85       974\n",
      "           9       0.74      0.89      0.81      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.85      0.83      0.84     10000\n",
      "weighted avg       0.85      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 962    1    1    0    1    4    5    1    4    1]\n",
      " [   0 1117    9    2    0    0    2    2    3    0]\n",
      " [  62   58  783   13   12    1   10   35   48   10]\n",
      " [  31   16   24  779    0   77    2   28   33   20]\n",
      " [   8   11   14    0  755    1   10   11    6  166]\n",
      " [  53   27    3   72   20  634   12   25   10   36]\n",
      " [ 100   19   32    0   43   18  736    6    3    1]\n",
      " [   4   31   21    0    8    2    0  924    3   35]\n",
      " [  27   24    9   19   10   20    4   16  799   46]\n",
      " [  20    8    4    4   30    1    0   41    8  893]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '5' '0' '7']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 0 7]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [42 33 30 32 26 25 25 28 29 30] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.114 s \n",
      "\n",
      "Accuracy rate for 83.980000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       980\n",
      "           1       0.87      0.99      0.92      1135\n",
      "           2       0.88      0.77      0.82      1032\n",
      "           3       0.79      0.82      0.80      1010\n",
      "           4       0.89      0.78      0.83       982\n",
      "           5       0.85      0.62      0.72       892\n",
      "           6       0.85      0.89      0.87       958\n",
      "           7       0.88      0.88      0.88      1028\n",
      "           8       0.89      0.76      0.82       974\n",
      "           9       0.73      0.90      0.81      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 938    1    1    0    0    4   33    1    1    1]\n",
      " [   0 1118    5    1    0    1    4    3    3    0]\n",
      " [  44   49  793   22   14    0   23   27   50   10]\n",
      " [  24   12   23  825    0   54    5   19   22   26]\n",
      " [   4   13    9    0  767    2   25    8    2  152]\n",
      " [  51   15    4  150   12  552   31   20   10   47]\n",
      " [  53    7   25    1   14    8  849    1    0    0]\n",
      " [   8   32   19    0   12    3    1  905    1   47]\n",
      " [  17   29   13   40   11   27   23   19  741   54]\n",
      " [  16    8    6    6   27    0    7   26    3  910]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['3' '0' '4' ... '5' '6' '2']\n",
      "probabilities: (59700, 10) \n",
      " [3 0 4 ... 5 6 2]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [48 37 35 36 30 29 31 33 34 37] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.240 s \n",
      "\n",
      "Accuracy rate for 84.630000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       980\n",
      "           1       0.88      0.98      0.93      1135\n",
      "           2       0.90      0.76      0.82      1032\n",
      "           3       0.82      0.81      0.81      1010\n",
      "           4       0.92      0.73      0.81       982\n",
      "           5       0.84      0.67      0.75       892\n",
      "           6       0.87      0.93      0.90       958\n",
      "           7       0.90      0.89      0.89      1028\n",
      "           8       0.86      0.80      0.83       974\n",
      "           9       0.70      0.91      0.79      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.84      0.84     10000\n",
      "weighted avg       0.85      0.85      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 942    1    1    0    0    4   27    1    4    0]\n",
      " [   0 1115    6    3    0    3    2    2    4    0]\n",
      " [  40   60  782   24   11    0   22   23   56   14]\n",
      " [  19    5   22  814    1   64    6   16   38   25]\n",
      " [   2   11   11    0  717    4   25    5    6  201]\n",
      " [  45   13    3  117    7  600   25   15   11   56]\n",
      " [  37    7    6    1   13    6  887    1    0    0]\n",
      " [   8   29   18    1   10    2    0  910    2   48]\n",
      " [  12   19   14   25    6   26   18   17  780   57]\n",
      " [  14    8    5    7   18    3    5   25    8  916]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['3' '0' '4' ... '9' '6' '7']\n",
      "probabilities: (59650, 10) \n",
      " [3 0 4 ... 9 6 7]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [55 38 43 44 36 30 34 36 40 44] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.414 s \n",
      "\n",
      "Accuracy rate for 84.890000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91       980\n",
      "           1       0.89      0.98      0.93      1135\n",
      "           2       0.90      0.78      0.84      1032\n",
      "           3       0.79      0.86      0.82      1010\n",
      "           4       0.92      0.72      0.81       982\n",
      "           5       0.90      0.61      0.73       892\n",
      "           6       0.89      0.92      0.90       958\n",
      "           7       0.92      0.87      0.89      1028\n",
      "           8       0.86      0.81      0.83       974\n",
      "           9       0.67      0.92      0.78      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.84      0.84     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 966    1    1    0    0    2    7    1    1    1]\n",
      " [   0 1115    7    5    0    0    3    1    4    0]\n",
      " [  24   50  810   20    9    0   20   22   63   14]\n",
      " [  21    3   25  865    0   30    3   16   30   17]\n",
      " [   2   10   10    0  706    1   24    4    4  221]\n",
      " [  47   14    3  148    8  543   28    8   16   77]\n",
      " [  36    6    9    1   14   11  878    0    3    0]\n",
      " [   9   29   18    0    6    2    0  892    3   69]\n",
      " [  17   17   14   39    8   14   15   11  785   54]\n",
      " [  12    6    6   12   15    1    5   16    7  929]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['3' '0' '4' ... '9' '6' '2']\n",
      "probabilities: (59600, 10) \n",
      " [3 0 4 ... 9 6 2]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [62 47 48 48 39 33 40 39 45 49] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.503 s \n",
      "\n",
      "Accuracy rate for 85.770000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       980\n",
      "           1       0.88      0.99      0.93      1135\n",
      "           2       0.90      0.81      0.85      1032\n",
      "           3       0.79      0.88      0.83      1010\n",
      "           4       0.93      0.72      0.81       982\n",
      "           5       0.91      0.61      0.73       892\n",
      "           6       0.89      0.93      0.91       958\n",
      "           7       0.92      0.88      0.90      1028\n",
      "           8       0.88      0.81      0.84       974\n",
      "           9       0.70      0.92      0.79      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.85      0.85     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 959    1    1    0    0    2   13    1    2    1]\n",
      " [   0 1122    5    2    0    0    2    1    3    0]\n",
      " [  32   42  835   26    9    0   12   20   46   10]\n",
      " [  10    6   26  887    0   27    1   15   27   11]\n",
      " [   1   12   11    0  710    3   32    3    4  206]\n",
      " [  34   22    6  156   10  542   24   10   16   72]\n",
      " [  32    8    4    2   10    6  894    0    2    0]\n",
      " [   5   27   21    2    7    2    0  905    3   56]\n",
      " [  12   22   14   37    7   13   19   10  793   47]\n",
      " [  12    8    7   12   13    0    5   15    7  930]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['3' '0' '4' ... '9' '6' '2']\n",
      "probabilities: (59550, 10) \n",
      " [3 0 4 ... 9 6 2]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [64 52 57 53 48 36 45 41 49 55] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.678 s \n",
      "\n",
      "Accuracy rate for 86.590000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       980\n",
      "           1       0.91      0.98      0.95      1135\n",
      "           2       0.87      0.88      0.88      1032\n",
      "           3       0.81      0.88      0.84      1010\n",
      "           4       0.90      0.75      0.82       982\n",
      "           5       0.91      0.63      0.74       892\n",
      "           6       0.91      0.92      0.91       958\n",
      "           7       0.93      0.87      0.90      1028\n",
      "           8       0.90      0.81      0.85       974\n",
      "           9       0.70      0.92      0.80      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.87      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 949    1    2    2    0    7   16    1    2    0]\n",
      " [   0 1117    7    3    0    0    3    1    4    0]\n",
      " [  19   14  910   14   11    0   11   15   30    8]\n",
      " [  10    7   32  888    1   23    2   13   20   14]\n",
      " [   1   10   16    0  736    1   20    2    4  192]\n",
      " [  28   20    9  144   13  560   20   11   18   69]\n",
      " [  32    5    9    2   18    8  882    0    2    0]\n",
      " [   4   26   28    1    9    3    0  893    3   61]\n",
      " [   8   20   24   33   14   13   12   10  791   49]\n",
      " [   9    8    8   11   15    0    4   14    7  933]]\n",
      "--------------------------------\n",
      "final active learning accuracies [58.269999999999996, 71.76, 79.64, 82.54, 83.82, 83.98, 84.63000000000001, 84.89, 85.77, 86.59]\n",
      "saved Active-learning-experiment-18.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 19, using model = RfModel, selection_function = RandomSelection, k = 25, iteration = 0.\n",
      "\n",
      "initial random chosen samples (25,)\n",
      "initial train set: (25, 784) (25,) unique(labels): [2 1 2 5 0 2 4 2 2 5] [0 1 2 3 5 6 7 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59975, 784) (59975,) (25,)\n",
      "\n",
      "Train set: (25, 784) y: (25,)\n",
      "Val   set: (59975, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.384 s \n",
      "\n",
      "Accuracy rate for 35.360000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.16      0.26       980\n",
      "           1       0.82      0.36      0.50      1135\n",
      "           2       0.95      0.22      0.36      1032\n",
      "           3       0.36      0.86      0.51      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.19      0.05      0.08       892\n",
      "           6       0.43      0.61      0.50       958\n",
      "           7       0.45      0.27      0.33      1028\n",
      "           8       0.63      0.07      0.13       974\n",
      "           9       0.21      0.91      0.34      1009\n",
      "\n",
      "    accuracy                           0.35     10000\n",
      "   macro avg       0.48      0.35      0.30     10000\n",
      "weighted avg       0.49      0.35      0.31     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[153   0   5 118   0  97 500   0   0 107]\n",
      " [  0 403   0 155   0   0   1 267   1 308]\n",
      " [  7  69 232 242   0  11 141  19   6 305]\n",
      " [  1   0   4 869   0   6   5  26   1  98]\n",
      " [  0   1   0  12   0  21  56   0   3 889]\n",
      " [ 18   1   0 452   0  42  23   9  17 330]\n",
      " [ 15   2   0  65   0  12 581   0   0 283]\n",
      " [  0  10   2  36   0   4   1 273  11 691]\n",
      " [  0   4   0 408   0   9  28  11  68 446]\n",
      " [  1   1   0  46   0  14  23   8   1 915]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59975,) ['3' '6' '9' ... '9' '6' '9']\n",
      "probabilities: (59975, 9) \n",
      " [3 5 8 ... 8 5 8]\n",
      "trainset before (25, 784) (25,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [ 5  3  6 10  2  4  5  5  3  7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.977 s \n",
      "\n",
      "Accuracy rate for 60.410000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       980\n",
      "           1       0.85      0.86      0.86      1135\n",
      "           2       0.63      0.69      0.66      1032\n",
      "           3       0.39      0.93      0.55      1010\n",
      "           4       0.92      0.02      0.05       982\n",
      "           5       0.71      0.30      0.42       892\n",
      "           6       0.79      0.67      0.73       958\n",
      "           7       0.81      0.60      0.69      1028\n",
      "           8       0.91      0.23      0.37       974\n",
      "           9       0.38      0.83      0.52      1009\n",
      "\n",
      "    accuracy                           0.60     10000\n",
      "   macro avg       0.73      0.60      0.57     10000\n",
      "weighted avg       0.73      0.60      0.58     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[808   0   1 134   0   5  25   0   0   7]\n",
      " [  0 974  71  20   0   0   1  65   0   4]\n",
      " [ 40  50 710 159   0  10  26  15   3  19]\n",
      " [  0   5  17 942   0  11   1  11   0  23]\n",
      " [  1   8  29  42  23  13  77   5   1 783]\n",
      " [  9  34  17 485   0 265   8  12  12  50]\n",
      " [ 15   6 118  80   0  48 645   0   0  46]\n",
      " [ 15  23  66  60   0   6   1 618   1 238]\n",
      " [  8  38  93 411   0   6  16  11 223 168]\n",
      " [ 17   5   8  93   2   9  14  24   4 833]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['3' '0' '5' ... '3' '0' '8']\n",
      "probabilities: (59950, 10) \n",
      " [3 0 5 ... 3 0 8]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (75, 784) (75,)\n",
      "updated train set: (75, 784) (75,) unique(labels): [ 7  5  7 12  6  6  7  8  5 12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59925, 784) (59925,)\n",
      "\n",
      "Train set: (75, 784) y: (75,)\n",
      "Val   set: (59925, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.158 s \n",
      "\n",
      "Accuracy rate for 67.990000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       980\n",
      "           1       0.82      0.93      0.88      1135\n",
      "           2       0.80      0.66      0.72      1032\n",
      "           3       0.46      0.90      0.61      1010\n",
      "           4       0.87      0.31      0.46       982\n",
      "           5       0.68      0.40      0.50       892\n",
      "           6       0.80      0.70      0.75       958\n",
      "           7       0.93      0.76      0.84      1028\n",
      "           8       0.77      0.37      0.50       974\n",
      "           9       0.46      0.88      0.61      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.74      0.67      0.67     10000\n",
      "weighted avg       0.74      0.68      0.67     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 796    1    2  106    0   10   60    0    1    4]\n",
      " [   0 1060   35    7    0    2    1    6   22    2]\n",
      " [  65   64  676  131   12    9   18   17   21   19]\n",
      " [   1   14    9  914    0   23    6    6    9   28]\n",
      " [   2   10    5    6  307    4   30    2   15  601]\n",
      " [  32   25    5  421    1  355   11    1    6   35]\n",
      " [  27   22   44   47    7   92  666    0    0   53]\n",
      " [   5   23   28    8    1    6    1  781   23  152]\n",
      " [  26   60   37  322    1   12   21    8  358  129]\n",
      " [  10    7    3   32   24    7   14   19    7  886]]\n",
      "--------------------------------\n",
      "val predicted: (59925,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59925, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (75, 784) (75,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 9  6 10 15 12  7  9 12  7 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.350 s \n",
      "\n",
      "Accuracy rate for 74.920000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80       980\n",
      "           1       0.84      0.93      0.88      1135\n",
      "           2       0.80      0.71      0.75      1032\n",
      "           3       0.54      0.90      0.68      1010\n",
      "           4       0.79      0.71      0.75       982\n",
      "           5       0.67      0.48      0.56       892\n",
      "           6       0.86      0.77      0.81       958\n",
      "           7       0.80      0.86      0.83      1028\n",
      "           8       0.86      0.51      0.64       974\n",
      "           9       0.67      0.78      0.72      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.77      0.74      0.74     10000\n",
      "weighted avg       0.77      0.75      0.75     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 765    1   25   43    0   30   64   40    7    5]\n",
      " [   0 1057   38    7    1    4    1    0   26    1]\n",
      " [  48   56  729   87   26    9    5   42   22    8]\n",
      " [   0   17    8  906    1   35    2   15    7   19]\n",
      " [   1   12    6    8  700    8   11   12    4  220]\n",
      " [  33   25    5  328   16  429   13   18    4   21]\n",
      " [  25   15   39   15   21   87  740    9    1    6]\n",
      " [   0   24   30    4   10    1    1  889    5   64]\n",
      " [  46   49   20  246   11   23   21   28  493   37]\n",
      " [  10    9    7   24  105   11    3   52    4  784]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 4 ... 5 0 8]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (125, 784) (125,)\n",
      "updated train set: (125, 784) (125,) unique(labels): [13  8 13 18 12  9 10 17 11 14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.464 s \n",
      "\n",
      "Accuracy rate for 78.180000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       980\n",
      "           1       0.85      0.93      0.89      1135\n",
      "           2       0.76      0.75      0.75      1032\n",
      "           3       0.59      0.89      0.71      1010\n",
      "           4       0.88      0.69      0.77       982\n",
      "           5       0.83      0.50      0.62       892\n",
      "           6       0.91      0.80      0.85       958\n",
      "           7       0.80      0.86      0.83      1028\n",
      "           8       0.85      0.64      0.73       974\n",
      "           9       0.70      0.76      0.72      1009\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.80      0.78      0.78     10000\n",
      "weighted avg       0.80      0.78      0.78     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 931    0    8   17    0    0   16    2    6    0]\n",
      " [   0 1051   53    6    0    3    2    0   20    0]\n",
      " [  53   52  773   60    8    2    9   33   40    2]\n",
      " [   7   22   12  900    1   28    1   21    9    9]\n",
      " [   5   10   17   12  679    5   12   25    6  211]\n",
      " [  44   18    9  310    6  445   16   17   10   17]\n",
      " [  44   11   68    5    9   38  767    7    3    6]\n",
      " [   3   28   35    5    3    0    1  881    4   68]\n",
      " [  16   33   23  191    2   14   16   30  627   22]\n",
      " [  14   14   21   30   66    4    1   83   12  764]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59875,) ['3' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59875, 10) \n",
      " [3 0 4 ... 5 0 8]\n",
      "trainset before (125, 784) (125,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [14 15 15 19 15 13 10 19 15 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.610 s \n",
      "\n",
      "Accuracy rate for 80.600000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       980\n",
      "           1       0.78      0.96      0.86      1135\n",
      "           2       0.83      0.75      0.78      1032\n",
      "           3       0.73      0.86      0.79      1010\n",
      "           4       0.80      0.77      0.79       982\n",
      "           5       0.79      0.63      0.70       892\n",
      "           6       0.90      0.77      0.83       958\n",
      "           7       0.80      0.88      0.84      1028\n",
      "           8       0.86      0.77      0.81       974\n",
      "           9       0.75      0.73      0.74      1009\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.81      0.80      0.80     10000\n",
      "weighted avg       0.81      0.81      0.80     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 882    2    7    6    0   14   35   13   19    2]\n",
      " [   0 1086   31    5    0    1    1    0   11    0]\n",
      " [  47   82  770   34    7    4    6   44   36    2]\n",
      " [   7   39   12  870    1   35    0   26   15    5]\n",
      " [   2   17   11    1  760    6   10   24    7  144]\n",
      " [  24   32    5  184   12  566   14   22   14   19]\n",
      " [  36   30   42    3   27   65  733    8   10    4]\n",
      " [   2   39   27    4    5    0    1  902    2   46]\n",
      " [  14   52   14   62   10   17   12   19  751   23]\n",
      " [  12   15   12   16  129    8    2   68    7  740]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59850, 10) \n",
      " [5 0 4 ... 5 0 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (175, 784) (175,)\n",
      "updated train set: (175, 784) (175,) unique(labels): [20 15 19 21 19 16 12 21 15 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59825, 784) (59825,)\n",
      "\n",
      "Train set: (175, 784) y: (175,)\n",
      "Val   set: (59825, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.690 s \n",
      "\n",
      "Accuracy rate for 81.700000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       980\n",
      "           1       0.81      0.95      0.87      1135\n",
      "           2       0.78      0.79      0.79      1032\n",
      "           3       0.76      0.84      0.80      1010\n",
      "           4       0.76      0.84      0.80       982\n",
      "           5       0.83      0.66      0.74       892\n",
      "           6       0.92      0.77      0.83       958\n",
      "           7       0.85      0.87      0.86      1028\n",
      "           8       0.90      0.76      0.82       974\n",
      "           9       0.80      0.72      0.75      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.81      0.81     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 920    0    6    6    0    4   16    9   19    0]\n",
      " [   0 1077   47    4    0    0    2    0    5    0]\n",
      " [  54   61  813   24    9    3    6   32   28    2]\n",
      " [   9   39   18  850    2   52    2   23   12    3]\n",
      " [   4   12   12    0  826    3   10    8    3  104]\n",
      " [  34   24    6  164   18  590   16   17   10   13]\n",
      " [  47   24   58    2   45   38  735    3    4    2]\n",
      " [   4   35   44    3   11    0    0  895    1   35]\n",
      " [  18   47   20   54   15   18   16   18  741   27]\n",
      " [  23   13   12   18  162    4    0   50    4  723]]\n",
      "--------------------------------\n",
      "val predicted: (59825,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59825, 10) \n",
      " [5 0 4 ... 5 0 8]\n",
      "trainset before (175, 784) (175,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [23 18 21 21 22 21 14 22 19 19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.812 s \n",
      "\n",
      "Accuracy rate for 81.970000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       980\n",
      "           1       0.80      0.95      0.87      1135\n",
      "           2       0.86      0.75      0.80      1032\n",
      "           3       0.81      0.79      0.80      1010\n",
      "           4       0.71      0.86      0.78       982\n",
      "           5       0.77      0.75      0.76       892\n",
      "           6       0.93      0.81      0.86       958\n",
      "           7       0.87      0.87      0.87      1028\n",
      "           8       0.81      0.80      0.81       974\n",
      "           9       0.81      0.67      0.74      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 909    1    7    1    4   16    6    4   31    1]\n",
      " [   0 1077   18    2    1    3    2    0   32    0]\n",
      " [  40   79  769   19   15    4   12   33   59    2]\n",
      " [   9   39   14  797    2   91    4   21   28    5]\n",
      " [   1   17    8    0  844    4    7    7    7   87]\n",
      " [  21   22    5  120   19  667   17    9    9    3]\n",
      " [  40   23   17    0   54   44  772    0    8    0]\n",
      " [   5   35   32    1   11    1    0  897    8   38]\n",
      " [  13   44   11   29   13   25   11   19  784   25]\n",
      " [  14   12    9   14  220   15    0   42    2  681]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59800, 10) \n",
      " [5 0 4 ... 5 0 8]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (225, 784) (225,)\n",
      "updated train set: (225, 784) (225,) unique(labels): [24 22 25 25 25 21 16 26 20 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59775, 784) (59775,)\n",
      "\n",
      "Train set: (225, 784) y: (225,)\n",
      "Val   set: (59775, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.861 s \n",
      "\n",
      "Accuracy rate for 82.430000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       980\n",
      "           1       0.80      0.97      0.88      1135\n",
      "           2       0.83      0.78      0.81      1032\n",
      "           3       0.78      0.82      0.80      1010\n",
      "           4       0.76      0.85      0.80       982\n",
      "           5       0.83      0.68      0.75       892\n",
      "           6       0.91      0.82      0.87       958\n",
      "           7       0.85      0.86      0.86      1028\n",
      "           8       0.82      0.79      0.81       974\n",
      "           9       0.79      0.72      0.75      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.83      0.82      0.82     10000\n",
      "weighted avg       0.83      0.82      0.82     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 901    1   16    1    1    4   22    7   24    3]\n",
      " [   0 1097   13    3    0    1    2    0   19    0]\n",
      " [  29   74  803   14   11    2    9   33   55    2]\n",
      " [   9   33   23  830    2   57    1   21   24   10]\n",
      " [   1   13   12    0  834    2    9   12    9   90]\n",
      " [  22   32    9  153   23  605   16    7   17    8]\n",
      " [  35   23   21    1   46   28  787    1   15    1]\n",
      " [   4   40   37    6    6    2    0  885    3   45]\n",
      " [  16   37   15   36   12   12   14   26  773   33]\n",
      " [  11   14   14   16  168   12    1   44    1  728]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59775,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59775, 10) \n",
      " [5 0 4 ... 5 0 8]\n",
      "trainset before (225, 784) (225,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [25 27 25 31 28 23 16 28 23 24] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.971 s \n",
      "\n",
      "Accuracy rate for 83.530000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       980\n",
      "           1       0.80      0.97      0.88      1135\n",
      "           2       0.86      0.75      0.80      1032\n",
      "           3       0.76      0.89      0.82      1010\n",
      "           4       0.78      0.85      0.81       982\n",
      "           5       0.85      0.70      0.76       892\n",
      "           6       0.93      0.82      0.87       958\n",
      "           7       0.91      0.85      0.88      1028\n",
      "           8       0.83      0.82      0.83       974\n",
      "           9       0.80      0.77      0.79      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.84      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 891    1   17    7    1   12   15    2   33    1]\n",
      " [   0 1100   12    4    0    1    1    0   17    0]\n",
      " [  36   87  770   24   11    1    9   30   62    2]\n",
      " [   5   20   15  896    3   41    1   15    9    5]\n",
      " [   3   15    8    3  834    3   11    5    8   92]\n",
      " [  14   31    9  163   13  620   15    6   15    6]\n",
      " [  35   24   19    3   41   36  787    0   12    1]\n",
      " [   2   46   31    6    6    2    0  877    6   52]\n",
      " [  10   32    7   50   15   10    6   10  802   32]\n",
      " [  12   15   12   19  142    7    1   23    2  776]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 0 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (275, 784) (275,)\n",
      "updated train set: (275, 784) (275,) unique(labels): [27 30 25 35 29 30 16 32 25 26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59725, 784) (59725,)\n",
      "\n",
      "Train set: (275, 784) y: (275,)\n",
      "Val   set: (59725, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.054 s \n",
      "\n",
      "Accuracy rate for 84.900000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       980\n",
      "           1       0.82      0.97      0.89      1135\n",
      "           2       0.88      0.74      0.80      1032\n",
      "           3       0.83      0.88      0.85      1010\n",
      "           4       0.81      0.86      0.83       982\n",
      "           5       0.82      0.79      0.80       892\n",
      "           6       0.95      0.80      0.87       958\n",
      "           7       0.89      0.87      0.88      1028\n",
      "           8       0.84      0.82      0.83       974\n",
      "           9       0.81      0.81      0.81      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 926    1    7    2    0   12    8    1   22    1]\n",
      " [   0 1105   10    3    0    2    2    0   13    0]\n",
      " [  31   78  765   21   15    4    9   34   71    4]\n",
      " [   5   22   10  884    1   50    0   18   13    7]\n",
      " [   5   13    6    1  840    3    9    5    7   93]\n",
      " [  15   34    6   92    9  703    9    7    7   10]\n",
      " [  42   22   21    2   51   40  765    1   14    0]\n",
      " [   2   39   28    3    8    2    0  892    6   48]\n",
      " [  16   26    7   41   12   25    6   11  796   34]\n",
      " [   8   15    9   15   96   16    1   33    2  814]]\n",
      "--------------------------------\n",
      "val predicted: (59725,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59725, 10) \n",
      " [5 0 4 ... 5 0 8]\n",
      "trainset before (275, 784) (275,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [29 33 26 39 31 34 20 34 26 28] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.160 s \n",
      "\n",
      "Accuracy rate for 84.940000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       980\n",
      "           1       0.80      0.98      0.88      1135\n",
      "           2       0.90      0.75      0.82      1032\n",
      "           3       0.81      0.86      0.83      1010\n",
      "           4       0.80      0.86      0.83       982\n",
      "           5       0.80      0.80      0.80       892\n",
      "           6       0.92      0.82      0.87       958\n",
      "           7       0.90      0.87      0.89      1028\n",
      "           8       0.87      0.79      0.83       974\n",
      "           9       0.82      0.79      0.81      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 921    1    6    1    0   23   12    1   15    0]\n",
      " [   0 1116    1    3    0    3    1    0   11    0]\n",
      " [  26   93  769   32   14    5   13   24   53    3]\n",
      " [   7   24   12  870    1   54    2   16   12   12]\n",
      " [   3   12    5    2  849    3   14    5    7   82]\n",
      " [  11   26    3   98   14  715   11    4    4    6]\n",
      " [  33   23   21    2   47   39  787    1    5    0]\n",
      " [   3   45   25    3    8    1    1  895    2   45]\n",
      " [  10   38    3   54   14   30   13   14  772   26]\n",
      " [   6   14    9   14  114   18    1   30    3  800]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59700, 10) \n",
      " [5 0 4 ... 5 0 8]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (325, 784) (325,)\n",
      "updated train set: (325, 784) (325,) unique(labels): [30 36 26 43 32 37 24 39 26 32] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59675, 784) (59675,)\n",
      "\n",
      "Train set: (325, 784) y: (325,)\n",
      "Val   set: (59675, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.200 s \n",
      "\n",
      "Accuracy rate for 85.240000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91       980\n",
      "           1       0.83      0.98      0.90      1135\n",
      "           2       0.91      0.72      0.80      1032\n",
      "           3       0.81      0.86      0.84      1010\n",
      "           4       0.87      0.84      0.85       982\n",
      "           5       0.77      0.83      0.80       892\n",
      "           6       0.91      0.85      0.88       958\n",
      "           7       0.92      0.87      0.89      1028\n",
      "           8       0.84      0.80      0.82       974\n",
      "           9       0.79      0.85      0.82      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 889    1    6    2    0   51   13    2   16    0]\n",
      " [   0 1114    0    3    0    4    2    0   12    0]\n",
      " [  34   88  738   32   16    7   15   28   69    5]\n",
      " [   5   18   11  871    1   61    1   15   11   16]\n",
      " [   0    9    7    0  821    3   19    3    9  111]\n",
      " [   9   21    3   83    8  741   11    4    7    5]\n",
      " [  34   16   11    1   28   42  815    3    8    0]\n",
      " [   0   36   22    4    4    1    0  899    8   54]\n",
      " [   7   28    6   51    7   32   16    8  779   40]\n",
      " [   6   15    9   22   60   16    2   19    3  857]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59675,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59675, 10) \n",
      " [5 0 4 ... 5 0 8]\n",
      "trainset before (325, 784) (325,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [32 37 28 48 36 41 25 39 28 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.284 s \n",
      "\n",
      "Accuracy rate for 85.810000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       980\n",
      "           1       0.84      0.99      0.91      1135\n",
      "           2       0.90      0.74      0.81      1032\n",
      "           3       0.81      0.87      0.84      1010\n",
      "           4       0.85      0.85      0.85       982\n",
      "           5       0.83      0.81      0.82       892\n",
      "           6       0.91      0.85      0.88       958\n",
      "           7       0.93      0.85      0.89      1028\n",
      "           8       0.85      0.80      0.83       974\n",
      "           9       0.77      0.85      0.81      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 935    1    3    1    0   19   12    1    8    0]\n",
      " [   0 1118    1    4    0    2    2    0    8    0]\n",
      " [  29   65  764   36   15    2   19   23   73    6]\n",
      " [   5   21   10  881    2   48    2   12   15   14]\n",
      " [   1    9    6    0  836    1   11    1    6  111]\n",
      " [  10   22    3   94   11  721   11    3    9    8]\n",
      " [  34   19   17    0   29   36  812    3    6    2]\n",
      " [   1   38   29    4    8    2    1  877    6   62]\n",
      " [   8   25    7   50    8   22   20    5  784   45]\n",
      " [   5   14    7   19   79   12    2   15    3  853]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59650, 10) \n",
      " [5 0 4 ... 5 0 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [33 39 34 48 39 43 27 42 31 39] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.413 s \n",
      "\n",
      "Accuracy rate for 85.960000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       980\n",
      "           1       0.84      0.98      0.90      1135\n",
      "           2       0.87      0.76      0.81      1032\n",
      "           3       0.83      0.87      0.85      1010\n",
      "           4       0.85      0.85      0.85       982\n",
      "           5       0.81      0.83      0.82       892\n",
      "           6       0.92      0.82      0.87       958\n",
      "           7       0.94      0.86      0.90      1028\n",
      "           8       0.85      0.80      0.82       974\n",
      "           9       0.79      0.86      0.82      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 929    0    4    1    0   19   11    1   15    0]\n",
      " [   0 1112    3    3    0    3    2    0   12    0]\n",
      " [  32   67  785   28   16    5   10   20   66    3]\n",
      " [   4   19   14  875    2   58    1   11    9   17]\n",
      " [   0    7    8    2  836    1   14    1    8  105]\n",
      " [  11   23    5   74   10  741   11    4    7    6]\n",
      " [  35   20   29    1   35   39  790    0    9    0]\n",
      " [   1   34   38    2    7    3    1  883    4   55]\n",
      " [   5   28    8   49   10   32   15    7  775   45]\n",
      " [   4   13   10   19   62   13    1   15    2  870]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59625, 10) \n",
      " [5 0 4 ... 5 0 8]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [34 44 36 49 44 44 28 42 37 42] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.394 s \n",
      "\n",
      "Accuracy rate for 86.800000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       980\n",
      "           1       0.83      0.98      0.90      1135\n",
      "           2       0.88      0.77      0.82      1032\n",
      "           3       0.85      0.86      0.85      1010\n",
      "           4       0.85      0.87      0.86       982\n",
      "           5       0.81      0.86      0.83       892\n",
      "           6       0.93      0.83      0.88       958\n",
      "           7       0.93      0.85      0.89      1028\n",
      "           8       0.88      0.81      0.85       974\n",
      "           9       0.81      0.87      0.84      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 947    1    4    1    0   14    3    2    8    0]\n",
      " [   0 1115    3    3    0    2    3    0    9    0]\n",
      " [  22   74  799   33   18    7   12   18   46    3]\n",
      " [   4   21   13  865    1   64    1   12   18   11]\n",
      " [   1    9    3    1  850    3   12    2    6   95]\n",
      " [  11   23    3   46   12  769   11    4    6    7]\n",
      " [  32   18   21    1   35   46  799    1    5    0]\n",
      " [   1   38   46    2    7    3    1  869    5   56]\n",
      " [   6   25    7   49    8   33   16    8  793   29]\n",
      " [   7   12    6   17   64   11    1   15    2  874]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59600, 10) \n",
      " [5 0 4 ... 5 0 8]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (425, 784) (425,)\n",
      "updated train set: (425, 784) (425,) unique(labels): [35 48 40 50 45 47 31 45 38 46] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59575, 784) (59575,)\n",
      "\n",
      "Train set: (425, 784) y: (425,)\n",
      "Val   set: (59575, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.527 s \n",
      "\n",
      "Accuracy rate for 87.250000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       980\n",
      "           1       0.86      0.98      0.92      1135\n",
      "           2       0.87      0.81      0.84      1032\n",
      "           3       0.85      0.84      0.85      1010\n",
      "           4       0.86      0.87      0.87       982\n",
      "           5       0.81      0.84      0.83       892\n",
      "           6       0.92      0.87      0.90       958\n",
      "           7       0.94      0.86      0.89      1028\n",
      "           8       0.87      0.83      0.85       974\n",
      "           9       0.82      0.86      0.84      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 941    1    6    0    0   15    9    1    7    0]\n",
      " [   0 1113    7    2    0    2    2    0    9    0]\n",
      " [  17   61  833   24   14    5   13   19   43    3]\n",
      " [   4   15   18  853    2   72    2   12   21   11]\n",
      " [   1    7    7    1  854    2   14    1    6   89]\n",
      " [  10   25    5   57   17  747   12    3   11    5]\n",
      " [  27   15   14    2   24   30  832    3   11    0]\n",
      " [   1   31   44    1   11    2    0  881    5   52]\n",
      " [   5   15   13   53    8   27   16    6  804   27]\n",
      " [   6   13   14   15   60   15    1   16    2  867]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59575,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59575, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (425, 784) (425,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [36 54 43 53 47 47 34 48 40 48] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.515 s \n",
      "\n",
      "Accuracy rate for 87.810000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       980\n",
      "           1       0.86      0.98      0.92      1135\n",
      "           2       0.90      0.81      0.85      1032\n",
      "           3       0.84      0.87      0.85      1010\n",
      "           4       0.86      0.87      0.87       982\n",
      "           5       0.83      0.83      0.83       892\n",
      "           6       0.93      0.87      0.90       958\n",
      "           7       0.93      0.87      0.90      1028\n",
      "           8       0.90      0.82      0.85       974\n",
      "           9       0.82      0.88      0.85      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 943    1    4    1    2   15    4    2    8    0]\n",
      " [   0 1115    3    1    0    2    2    0   12    0]\n",
      " [  17   52  839   33   18    5   12   23   28    5]\n",
      " [   4   15   17  883    1   51    2   17   10   10]\n",
      " [   0    7    5    0  857    2   13    1    7   90]\n",
      " [  10   26    2   59   12  744   14    5   10   10]\n",
      " [  27   15   13    1   26   37  829    1    8    1]\n",
      " [   1   30   36    2    9    2    0  893    7   48]\n",
      " [   4   18    7   60   10   25   16    8  795   31]\n",
      " [   6   14    5   17   56   16    1    9    2  883]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59550, 10) \n",
      " [5 0 4 ... 5 0 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (475, 784) (475,)\n",
      "updated train set: (475, 784) (475,) unique(labels): [39 56 46 55 50 49 35 50 43 52] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59525, 784) (59525,)\n",
      "\n",
      "Train set: (475, 784) y: (475,)\n",
      "Val   set: (59525, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.664 s \n",
      "\n",
      "Accuracy rate for 87.900000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95       980\n",
      "           1       0.87      0.98      0.92      1135\n",
      "           2       0.88      0.82      0.85      1032\n",
      "           3       0.83      0.88      0.85      1010\n",
      "           4       0.87      0.89      0.88       982\n",
      "           5       0.87      0.80      0.83       892\n",
      "           6       0.92      0.86      0.89       958\n",
      "           7       0.93      0.86      0.89      1028\n",
      "           8       0.89      0.83      0.86       974\n",
      "           9       0.83      0.88      0.86      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 951    1    5    1    0    6    5    2    9    0]\n",
      " [   0 1116    3    3    0    2    3    0    8    0]\n",
      " [  23   42  847   30   16    2   15   18   36    3]\n",
      " [   4   17   17  885    2   41    2   18   14   10]\n",
      " [   0    7    6    0  872    1   13    2    7   74]\n",
      " [  13   28    5   82   11  713   15    5   11    9]\n",
      " [  28   15   15    1   31   26  828    1   13    0]\n",
      " [   1   31   48    1   10    1    1  879    5   51]\n",
      " [   7   13   11   50    9   16   18    9  811   30]\n",
      " [   4   14    5   18   55   14    1    8    2  888]]\n",
      "--------------------------------\n",
      "val predicted: (59525,) ['5' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59525, 10) \n",
      " [5 0 4 ... 5 0 8]\n",
      "trainset before (475, 784) (475,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [40 58 47 59 52 52 36 52 46 58] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.671 s \n",
      "\n",
      "Accuracy rate for 87.830000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       980\n",
      "           1       0.87      0.98      0.92      1135\n",
      "           2       0.90      0.81      0.85      1032\n",
      "           3       0.86      0.86      0.86      1010\n",
      "           4       0.86      0.87      0.87       982\n",
      "           5       0.83      0.85      0.84       892\n",
      "           6       0.93      0.86      0.89       958\n",
      "           7       0.93      0.86      0.90      1028\n",
      "           8       0.88      0.83      0.86       974\n",
      "           9       0.81      0.88      0.85      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 940    1    7    0    1   14    7    2    7    1]\n",
      " [   0 1116    2    2    0    2    3    0   10    0]\n",
      " [  23   43  837   30   17    3    9   21   43    6]\n",
      " [   4   17   15  869    2   58    3   17   13   12]\n",
      " [   0    8    8    0  858    2    9    2    7   88]\n",
      " [  11   22    2   53   11  757   14    3   10    9]\n",
      " [  25   15   12    1   35   40  822    0    8    0]\n",
      " [   1   27   39    2   10    1    0  888    4   56]\n",
      " [   8   22    6   41    8   24   19    8  808   30]\n",
      " [   7   14    2   15   54   11    2   13    3  888]]\n",
      "--------------------------------\n",
      "final active learning accuracies [35.36, 60.41, 67.99, 74.92, 78.18, 80.60000000000001, 81.69999999999999, 81.97, 82.43, 83.53, 84.89999999999999, 84.94, 85.24000000000001, 85.81, 85.96000000000001, 86.8, 87.25, 87.81, 87.9, 87.83]\n",
      "saved Active-learning-experiment-19.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 20, using model = RfModel, selection_function = RandomSelection, k = 10, iteration = 0.\n",
      "\n",
      "initial random chosen samples (10,)\n",
      "initial train set: (10, 784) (10,) unique(labels): [1 1 1 1 2 0 0 2 1 1] [0 1 2 3 4 7 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59990, 784) (59990,) (10,)\n",
      "\n",
      "Train set: (10, 784) y: (10,)\n",
      "Val   set: (59990, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.913 s \n",
      "\n",
      "Accuracy rate for 28.470000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.47      0.54       980\n",
      "           1       0.47      0.35      0.40      1135\n",
      "           2       0.36      0.18      0.24      1032\n",
      "           3       0.22      0.12      0.16      1010\n",
      "           4       0.24      0.67      0.35       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.23      0.82      0.36      1028\n",
      "           8       0.17      0.12      0.14       974\n",
      "           9       0.18      0.07      0.10      1009\n",
      "\n",
      "    accuracy                           0.28     10000\n",
      "   macro avg       0.25      0.28      0.23     10000\n",
      "weighted avg       0.26      0.28      0.23     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[465   4  26 216  88   0   0 108  67   6]\n",
      " [  0 397   7   1   0   0   0 632  21  77]\n",
      " [ 96 153 188   4 197   0   0 259 121  14]\n",
      " [ 16  45  47 120  58   0   0 469 241  14]\n",
      " [  8   5  34   4 657   0   0 232   0  42]\n",
      " [ 72  52   5 123 150   0   0 425  61   4]\n",
      " [ 51  67 171  36 389   0   0 149  42  53]\n",
      " [  3   4  13   0 106   0   0 839   0  63]\n",
      " [ 11 109  17  27 476   0   0 183 114  37]\n",
      " [ 10   1  10   5 600   0   0 315   1  67]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59990,) ['7' '0' '7' ... '7' '7' '7']\n",
      "probabilities: (59990, 8) \n",
      " [5 0 5 ... 5 5 5]\n",
      "trainset before (10, 784) (10,)\n",
      "trainset after (20, 784) (20,)\n",
      "updated train set: (20, 784) (20,) unique(labels): [1 2 2 2 3 1 1 2 1 5] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59980, 784) (59980,)\n",
      "\n",
      "Train set: (20, 784) y: (20,)\n",
      "Val   set: (59980, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.563 s \n",
      "\n",
      "Accuracy rate for 35.380000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.33      0.45       980\n",
      "           1       0.56      0.97      0.71      1135\n",
      "           2       0.43      0.21      0.29      1032\n",
      "           3       0.20      0.14      0.16      1010\n",
      "           4       0.28      0.57      0.38       982\n",
      "           5       0.66      0.09      0.15       892\n",
      "           6       0.31      0.23      0.26       958\n",
      "           7       0.51      0.21      0.30      1028\n",
      "           8       0.17      0.03      0.06       974\n",
      "           9       0.22      0.65      0.33      1009\n",
      "\n",
      "    accuracy                           0.35     10000\n",
      "   macro avg       0.41      0.34      0.31     10000\n",
      "weighted avg       0.41      0.35      0.32     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 320   12   15  323   29    5  192   10   12   62]\n",
      " [   0 1097    3    0    0    0    0    6    1   28]\n",
      " [  59  214  220   26  302    2   55   41   38   75]\n",
      " [   6  243   53  141   45   14   92   49   80  287]\n",
      " [  11   12   24    5  560    1    7   44    0  318]\n",
      " [  18  115    4  111   70   76  100   25   12  361]\n",
      " [  13  137   72   65  366    8  217    3   10   67]\n",
      " [   5   24   66    4   94    0    0  220    0  615]\n",
      " [   2  110   37   20  236    9   44    8   32  476]\n",
      " [   9    6   15    8  283    0    4   29    0  655]]\n",
      "--------------------------------\n",
      "val predicted: (59980,) ['9' '0' '4' ... '9' '3' '9']\n",
      "probabilities: (59980, 10) \n",
      " [9 0 4 ... 9 3 9]\n",
      "trainset before (20, 784) (20,)\n",
      "trainset after (30, 784) (30,)\n",
      "updated train set: (30, 784) (30,) unique(labels): [2 3 2 3 3 3 2 2 3 7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59970, 784) (59970,)\n",
      "\n",
      "Train set: (30, 784) y: (30,)\n",
      "Val   set: (59970, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.678 s \n",
      "\n",
      "Accuracy rate for 44.850000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.46      0.55       980\n",
      "           1       0.59      0.99      0.74      1135\n",
      "           2       0.44      0.09      0.15      1032\n",
      "           3       0.32      0.28      0.30      1010\n",
      "           4       0.48      0.21      0.30       982\n",
      "           5       0.66      0.33      0.44       892\n",
      "           6       0.53      0.52      0.52       958\n",
      "           7       0.71      0.18      0.28      1028\n",
      "           8       0.46      0.47      0.46       974\n",
      "           9       0.27      0.89      0.42      1009\n",
      "\n",
      "    accuracy                           0.45     10000\n",
      "   macro avg       0.51      0.44      0.42     10000\n",
      "weighted avg       0.51      0.45      0.42     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 453    1   10  235    2   11  203    2   33   30]\n",
      " [   0 1121    0    2    0    1    1    1    1    8]\n",
      " [  99  206   93   23   16    4  103    6  347  135]\n",
      " [  37  236    8  284    2   57   34    9  114  229]\n",
      " [   9   13   11   14  210    1   17   13    0  694]\n",
      " [  31   94    3  175    8  293   43   18   29  198]\n",
      " [   8   63   44   80  127   43  497    0   14   82]\n",
      " [   6   49   23   18    7   11    0  181    6  727]\n",
      " [  14  107    6   41   22   21   34    5  459  265]\n",
      " [  11    8   11   13   42    3    4   20    3  894]]\n",
      "--------------------------------\n",
      "val predicted: (59970,) ['9' '0' '9' ... '5' '3' '9']\n",
      "probabilities: (59970, 10) \n",
      " [9 0 9 ... 5 3 9]\n",
      "trainset before (30, 784) (30,)\n",
      "trainset after (40, 784) (40,)\n",
      "updated train set: (40, 784) (40,) unique(labels): [2 4 2 5 4 6 4 2 3 8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59960, 784) (59960,)\n",
      "\n",
      "Train set: (40, 784) y: (40,)\n",
      "Val   set: (59960, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.966 s \n",
      "\n",
      "Accuracy rate for 50.710000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.46      0.58       980\n",
      "           1       0.61      0.99      0.75      1135\n",
      "           2       0.53      0.08      0.14      1032\n",
      "           3       0.60      0.34      0.44      1010\n",
      "           4       0.56      0.40      0.47       982\n",
      "           5       0.37      0.65      0.47       892\n",
      "           6       0.69      0.73      0.71       958\n",
      "           7       0.76      0.16      0.26      1028\n",
      "           8       0.66      0.36      0.47       974\n",
      "           9       0.31      0.87      0.46      1009\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.59      0.50      0.47     10000\n",
      "weighted avg       0.59      0.51      0.48     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 447    2   10   57   20  298  113    1    1   31]\n",
      " [   0 1124    0    0    0    4    1    0    0    6]\n",
      " [  87  294   85   85  117   14   56   14  161  119]\n",
      " [   0   72    6  344    3  465   15    4    9   92]\n",
      " [   3   14    4    5  395    0   24   10    0  527]\n",
      " [   2   71    2   37    5  576   40    7    3  149]\n",
      " [   6   79   34    8   25   56  701    0    6   43]\n",
      " [   4   54    4    4   29    0    0  164    2  767]\n",
      " [   3  142   11   27   34  143   67    4  353  190]\n",
      " [   5    5    4    3   75   16    5   11    3  882]]\n",
      "--------------------------------\n",
      "val predicted: (59960,) ['5' '5' '9' ... '5' '4' '9']\n",
      "probabilities: (59960, 10) \n",
      " [5 5 9 ... 5 4 9]\n",
      "trainset before (40, 784) (40,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [2 6 3 7 6 7 5 3 3 8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.967 s \n",
      "\n",
      "Accuracy rate for 58.480000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.39      0.55       980\n",
      "           1       0.64      0.99      0.78      1135\n",
      "           2       0.77      0.38      0.51      1032\n",
      "           3       0.53      0.61      0.57      1010\n",
      "           4       0.55      0.68      0.61       982\n",
      "           5       0.44      0.64      0.53       892\n",
      "           6       0.70      0.77      0.73       958\n",
      "           7       0.79      0.28      0.41      1028\n",
      "           8       0.84      0.34      0.49       974\n",
      "           9       0.40      0.72      0.52      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.66      0.58      0.57     10000\n",
      "weighted avg       0.66      0.58      0.57     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 386    2   22  168    6  222  162    0    3    9]\n",
      " [   0 1128    0    1    0    3    2    0    0    1]\n",
      " [  29  224  389  146   96   11   42   15   54   26]\n",
      " [   0   56    5  621    4  270    7    9    3   35]\n",
      " [   0   15    3    7  669    4   17    5    0  262]\n",
      " [   3   72    2   96   35  574   32   14    2   62]\n",
      " [   0   59   43   31   57   30  736    0    1    1]\n",
      " [   3   55   11    6   84    4    0  286    0  579]\n",
      " [   2  147   18   78   84  151   48    6  334  106]\n",
      " [   2    7   15   15  189   23    5   28    0  725]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59950,) ['5' '0' '4' ... '5' '4' '4']\n",
      "probabilities: (59950, 10) \n",
      " [5 0 4 ... 5 4 4]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (60, 784) (60,)\n",
      "updated train set: (60, 784) (60,) unique(labels): [6 7 4 7 8 7 6 4 3 8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59940, 784) (59940,)\n",
      "\n",
      "Train set: (60, 784) y: (60,)\n",
      "Val   set: (59940, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.254 s \n",
      "\n",
      "Accuracy rate for 61.300000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.72       980\n",
      "           1       0.61      0.99      0.76      1135\n",
      "           2       0.84      0.46      0.59      1032\n",
      "           3       0.69      0.54      0.60      1010\n",
      "           4       0.54      0.77      0.63       982\n",
      "           5       0.52      0.62      0.56       892\n",
      "           6       0.65      0.77      0.70       958\n",
      "           7       0.77      0.29      0.43      1028\n",
      "           8       0.88      0.32      0.47       974\n",
      "           9       0.42      0.64      0.51      1009\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.67      0.61      0.60     10000\n",
      "weighted avg       0.67      0.61      0.60     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 696    2    2   26    3   59  188    0    0    4]\n",
      " [   0 1126    1    2    0    2    2    0    0    2]\n",
      " [  81  235  471   76   48    8   36   21   40   16]\n",
      " [  12   90    7  542    7  280   26    8    3   35]\n",
      " [   9   16    3    2  755    2   25    7    0  163]\n",
      " [  34   85    0   70   52  549   37   10    0   55]\n",
      " [  62   61   21    1   67   12  734    0    0    0]\n",
      " [  17   53   28    2  100    0    0  302    0  526]\n",
      " [  17  161    7   58  119  130   76    8  309   89]\n",
      " [  12    8   20    5  256   21    4   37    0  646]]\n",
      "--------------------------------\n",
      "val predicted: (59940,) ['5' '0' '4' ... '5' '0' '4']\n",
      "probabilities: (59940, 10) \n",
      " [5 0 4 ... 5 0 4]\n",
      "trainset before (60, 784) (60,)\n",
      "trainset after (70, 784) (70,)\n",
      "updated train set: (70, 784) (70,) unique(labels): [ 6  8  5 10  9  8  8  4  3  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59930, 784) (59930,)\n",
      "\n",
      "Train set: (70, 784) y: (70,)\n",
      "Val   set: (59930, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.284 s \n",
      "\n",
      "Accuracy rate for 63.740000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74       980\n",
      "           1       0.66      0.98      0.79      1135\n",
      "           2       0.78      0.57      0.66      1032\n",
      "           3       0.62      0.84      0.72      1010\n",
      "           4       0.55      0.77      0.64       982\n",
      "           5       0.63      0.60      0.62       892\n",
      "           6       0.65      0.77      0.71       958\n",
      "           7       0.80      0.27      0.41      1028\n",
      "           8       0.98      0.21      0.34       974\n",
      "           9       0.44      0.62      0.52      1009\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.69      0.63      0.61     10000\n",
      "weighted avg       0.69      0.64      0.62     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 688    1    6   44    1   78  160    0    0    2]\n",
      " [   0 1110   18    3    0    1    3    0    0    0]\n",
      " [  72  159  585  107   48    5   37   10    2    7]\n",
      " [   6   35   10  853    3   63   10    7    1   22]\n",
      " [   7   15    4    6  753    4   42    4    0  147]\n",
      " [   7   77    1  153   35  535   38    8    1   37]\n",
      " [  69   28   51    8   50   15  737    0    0    0]\n",
      " [  14   70   36   49   74   11    1  282    0  491]\n",
      " [  10  173   20  125  151  110   96    6  201   82]\n",
      " [  10   12   17   21  253   24    8   34    0  630]]\n",
      "--------------------------------\n",
      "val predicted: (59930,) ['5' '0' '4' ... '5' '5' '6']\n",
      "probabilities: (59930, 10) \n",
      " [5 0 4 ... 5 5 6]\n",
      "trainset before (70, 784) (70,)\n",
      "trainset after (80, 784) (80,)\n",
      "updated train set: (80, 784) (80,) unique(labels): [ 7  9  7 10 10 10  8  5  3 11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59920, 784) (59920,)\n",
      "\n",
      "Train set: (80, 784) y: (80,)\n",
      "Val   set: (59920, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.315 s \n",
      "\n",
      "Accuracy rate for 65.480000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78       980\n",
      "           1       0.68      0.98      0.80      1135\n",
      "           2       0.78      0.62      0.69      1032\n",
      "           3       0.71      0.76      0.73      1010\n",
      "           4       0.54      0.77      0.64       982\n",
      "           5       0.60      0.67      0.63       892\n",
      "           6       0.71      0.74      0.73       958\n",
      "           7       0.89      0.35      0.50      1028\n",
      "           8       0.93      0.19      0.32       974\n",
      "           9       0.44      0.66      0.53      1009\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.71      0.65      0.63     10000\n",
      "weighted avg       0.71      0.65      0.64     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 749    1    7   27    1   84  107    2    0    2]\n",
      " [   0 1114   13    3    0    1    2    0    0    2]\n",
      " [  62  135  637   58   51    5   35   26   13   10]\n",
      " [   6   44   14  767    4  135    7    6    1   26]\n",
      " [   7   13    5    3  761    2   37    3    0  151]\n",
      " [   5   86    5   98   35  599   20    2    1   41]\n",
      " [  67   36   54    1   75   13  710    0    0    2]\n",
      " [  19   53   31   15   81    6    2  356    0  465]\n",
      " [  11  152   17   96  145  140   73    2  187  151]\n",
      " [  15    8   30   12  248   18    5    5    0  668]]\n",
      "--------------------------------\n",
      "val predicted: (59920,) ['5' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59920, 10) \n",
      " [5 0 4 ... 5 0 9]\n",
      "trainset before (80, 784) (80,)\n",
      "trainset after (90, 784) (90,)\n",
      "updated train set: (90, 784) (90,) unique(labels): [ 9  9  8 10 10 10 10  6  5 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59910, 784) (59910,)\n",
      "\n",
      "Train set: (90, 784) y: (90,)\n",
      "Val   set: (59910, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.318 s \n",
      "\n",
      "Accuracy rate for 70.150000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       980\n",
      "           1       0.72      0.97      0.82      1135\n",
      "           2       0.79      0.62      0.70      1032\n",
      "           3       0.76      0.75      0.76      1010\n",
      "           4       0.64      0.71      0.67       982\n",
      "           5       0.68      0.69      0.68       892\n",
      "           6       0.70      0.80      0.75       958\n",
      "           7       0.86      0.53      0.65      1028\n",
      "           8       0.94      0.41      0.57       974\n",
      "           9       0.48      0.74      0.58      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.74      0.70      0.70     10000\n",
      "weighted avg       0.74      0.70      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 744    1    6   16    2   69  133    6    1    2]\n",
      " [   0 1096   28    3    0    0    3    0    1    4]\n",
      " [  68  121  644   35   36    4   38   47   20   19]\n",
      " [   8   51   11  761    1  111   13   12    1   41]\n",
      " [   8   11    6    3  695    2   48    2    0  207]\n",
      " [   6   58    6   92   30  617   33    9    2   39]\n",
      " [  45   28   39    0   65   14  766    0    0    1]\n",
      " [  21   44   36    1   31    7    2  541    0  345]\n",
      " [  33  115   10   67   67   74   47    1  403  157]\n",
      " [  21    7   32   17  154   12    7   11    0  748]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59910,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59910, 10) \n",
      " [5 0 4 ... 5 6 9]\n",
      "trainset before (90, 784) (90,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 9 10  9 11 11 11 11  8  6 14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.450 s \n",
      "\n",
      "Accuracy rate for 71.580000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79       980\n",
      "           1       0.75      0.98      0.85      1135\n",
      "           2       0.76      0.62      0.68      1032\n",
      "           3       0.71      0.74      0.73      1010\n",
      "           4       0.66      0.71      0.68       982\n",
      "           5       0.61      0.68      0.64       892\n",
      "           6       0.70      0.82      0.76       958\n",
      "           7       0.90      0.68      0.77      1028\n",
      "           8       0.94      0.45      0.61       974\n",
      "           9       0.53      0.67      0.59      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.71      0.71     10000\n",
      "weighted avg       0.74      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 737    1    6   28    1   58  145    1    0    3]\n",
      " [   0 1112   12    4    0    2    2    0    1    2]\n",
      " [  57  126  643   44   30   12   50   45   16    9]\n",
      " [   5   24    9  752    2  159    9    9    6   35]\n",
      " [   1    8   13    4  694    6   53    1    1  201]\n",
      " [   9   54    7  106   26  610   32    9    2   37]\n",
      " [  37   18   54    1   22   35  790    0    1    0]\n",
      " [  10   47   39    6   20    7    3  699    0  197]\n",
      " [  27   88   17   93   55   93   37    2  443  119]\n",
      " [   9    8   49   17  201   22   13   12    0  678]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['5' '0' '4' ... '5' '5' '9']\n",
      "probabilities: (59900, 10) \n",
      " [5 0 4 ... 5 5 9]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (110, 784) (110,)\n",
      "updated train set: (110, 784) (110,) unique(labels): [11 10 10 13 13 11 12  8  7 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59890, 784) (59890,)\n",
      "\n",
      "Train set: (110, 784) y: (110,)\n",
      "Val   set: (59890, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.384 s \n",
      "\n",
      "Accuracy rate for 74.520000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.81       980\n",
      "           1       0.76      0.96      0.85      1135\n",
      "           2       0.75      0.68      0.71      1032\n",
      "           3       0.70      0.88      0.78      1010\n",
      "           4       0.71      0.78      0.74       982\n",
      "           5       0.79      0.57      0.66       892\n",
      "           6       0.73      0.84      0.78       958\n",
      "           7       0.89      0.66      0.76      1028\n",
      "           8       0.96      0.48      0.64       974\n",
      "           9       0.56      0.77      0.65      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.77      0.74      0.74     10000\n",
      "weighted avg       0.77      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 768    1    4   28    2   31  142    2    0    2]\n",
      " [   0 1087   32   10    0    0    3    0    1    2]\n",
      " [  60  101  701   38   25    1   40   47   12    7]\n",
      " [   9   19    9  893    3   26    8   10    3   30]\n",
      " [   2    8   21    3  770    2   20    2    1  153]\n",
      " [  10   55   10  177   30  504   30   13    2   61]\n",
      " [  36   18   42    2   27   27  806    0    0    0]\n",
      " [  14   47   37    6   34    3    2  680    0  205]\n",
      " [  16   85   34   92   68   36   35    1  470  137]\n",
      " [  11    6   43   22  128    8   11    7    0  773]]\n",
      "--------------------------------\n",
      "val predicted: (59890,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59890, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (110, 784) (110,)\n",
      "trainset after (120, 784) (120,)\n",
      "updated train set: (120, 784) (120,) unique(labels): [11 12 11 14 13 12 13  9  8 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59880, 784) (59880,)\n",
      "\n",
      "Train set: (120, 784) y: (120,)\n",
      "Val   set: (59880, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.621 s \n",
      "\n",
      "Accuracy rate for 75.670000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82       980\n",
      "           1       0.75      0.98      0.85      1135\n",
      "           2       0.78      0.64      0.70      1032\n",
      "           3       0.71      0.88      0.78      1010\n",
      "           4       0.76      0.74      0.75       982\n",
      "           5       0.82      0.58      0.68       892\n",
      "           6       0.73      0.87      0.79       958\n",
      "           7       0.92      0.71      0.81      1028\n",
      "           8       0.89      0.50      0.64       974\n",
      "           9       0.58      0.86      0.69      1009\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.78      0.75      0.75     10000\n",
      "weighted avg       0.78      0.76      0.75     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 750    1    8   24    0   30  160    1    0    6]\n",
      " [   0 1114   11    5    0    0    3    0    0    2]\n",
      " [  48  128  656   52   25    0   29   38   49    7]\n",
      " [   6   23   10  885    2   24    5    6    7   42]\n",
      " [   1   10   18    5  723    1   28    2    1  193]\n",
      " [   9   42    8  159   41  520   31    7    3   72]\n",
      " [  21   21   44    3   19   20  830    0    0    0]\n",
      " [   5   51   30    6   23    0    3  735    1  174]\n",
      " [  16   98   25   93   57   30   38    1  491  125]\n",
      " [   4    6   29   18   67    9    7    6    0  863]]\n",
      "--------------------------------\n",
      "val predicted: (59880,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59880, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (120, 784) (120,)\n",
      "trainset after (130, 784) (130,)\n",
      "updated train set: (130, 784) (130,) unique(labels): [13 13 12 15 15 12 13 11  9 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59870, 784) (59870,)\n",
      "\n",
      "Train set: (130, 784) y: (130,)\n",
      "Val   set: (59870, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.496 s \n",
      "\n",
      "Accuracy rate for 77.110000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       980\n",
      "           1       0.74      0.98      0.85      1135\n",
      "           2       0.80      0.66      0.72      1032\n",
      "           3       0.72      0.86      0.78      1010\n",
      "           4       0.71      0.82      0.76       982\n",
      "           5       0.79      0.59      0.67       892\n",
      "           6       0.78      0.79      0.78       958\n",
      "           7       0.91      0.78      0.84      1028\n",
      "           8       0.95      0.52      0.67       974\n",
      "           9       0.66      0.82      0.73      1009\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.79      0.77      0.76     10000\n",
      "weighted avg       0.79      0.77      0.77     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 825    1    7   11    1   12  109    3    1   10]\n",
      " [   0 1114   12    4    0    0    3    0    0    2]\n",
      " [  58  127  685   43   27    1   19   45   22    5]\n",
      " [  13   30    9  866    4   32    4   11    3   38]\n",
      " [   2    9   19    2  804    3   22    2    0  119]\n",
      " [  19   46    6  161   53  523   22   11    2   49]\n",
      " [  34   23   54    4   61   28  753    0    1    0]\n",
      " [   4   55   31    4   23    2    1  803    0  105]\n",
      " [  24   88   11   96   64   51   24    3  506  107]\n",
      " [   7    6   26   19   96   12    4    7    0  832]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59870,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59870, 10) \n",
      " [3 0 4 ... 5 0 9]\n",
      "trainset before (130, 784) (130,)\n",
      "trainset after (140, 784) (140,)\n",
      "updated train set: (140, 784) (140,) unique(labels): [14 16 12 15 18 12 14 12 10 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59860, 784) (59860,)\n",
      "\n",
      "Train set: (140, 784) y: (140,)\n",
      "Val   set: (59860, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.694 s \n",
      "\n",
      "Accuracy rate for 77.310000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       980\n",
      "           1       0.72      0.98      0.83      1135\n",
      "           2       0.82      0.65      0.72      1032\n",
      "           3       0.73      0.84      0.78      1010\n",
      "           4       0.68      0.84      0.75       982\n",
      "           5       0.81      0.61      0.70       892\n",
      "           6       0.78      0.76      0.77       958\n",
      "           7       0.90      0.78      0.83      1028\n",
      "           8       0.93      0.56      0.70       974\n",
      "           9       0.69      0.79      0.73      1009\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.79      0.77      0.77     10000\n",
      "weighted avg       0.79      0.77      0.77     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 871    1    1    9    0    5   88    4    1    0]\n",
      " [   0 1110   17    3    0    1    3    0    0    1]\n",
      " [  59  120  668   47   29    0   31   41   34    3]\n",
      " [  11   44   11  850    4   45    5   11    5   24]\n",
      " [   2   11    8    3  821    2   17    2    0  116]\n",
      " [  14   56    4  136   52  546   32   15    1   36]\n",
      " [  51   23   44    1   77   30  732    0    0    0]\n",
      " [  12   72   29    2   27    2    1  797    1   85]\n",
      " [  10   85   11   94   71   35   25    2  542   99]\n",
      " [  14   11   19   16  121    9    6   18    1  794]]\n",
      "--------------------------------\n",
      "val predicted: (59860,) ['5' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59860, 10) \n",
      " [5 0 4 ... 5 0 9]\n",
      "trainset before (140, 784) (140,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [15 16 13 16 20 14 16 12 10 18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.567 s \n",
      "\n",
      "Accuracy rate for 77.440000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       980\n",
      "           1       0.73      0.98      0.84      1135\n",
      "           2       0.81      0.67      0.74      1032\n",
      "           3       0.74      0.82      0.78      1010\n",
      "           4       0.65      0.86      0.74       982\n",
      "           5       0.79      0.60      0.68       892\n",
      "           6       0.77      0.81      0.79       958\n",
      "           7       0.91      0.77      0.84      1028\n",
      "           8       0.93      0.54      0.68       974\n",
      "           9       0.71      0.75      0.73      1009\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.79      0.77      0.77     10000\n",
      "weighted avg       0.79      0.77      0.77     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 881    2    2    3    1   13   74    3    0    1]\n",
      " [   0 1107   20    3    0    1    3    0    0    1]\n",
      " [  46  114  693   33   48    3   28   33   30    4]\n",
      " [   6   48   10  832   10   46    9   11    5   33]\n",
      " [   2   13    9    1  848    5   18    2    0   84]\n",
      " [   7   43    2  142   80  537   40    9    3   29]\n",
      " [  50   20   42    0   48   24  774    0    0    0]\n",
      " [  13   65   35    2   40    2    1  795    0   75]\n",
      " [   8   86   14   85   76   39   54    2  522   88]\n",
      " [  13   11   25   17  152   13    6   17    0  755]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['5' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59850, 10) \n",
      " [5 0 4 ... 5 0 9]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (160, 784) (160,)\n",
      "updated train set: (160, 784) (160,) unique(labels): [16 16 14 16 22 15 18 13 11 19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59840, 784) (59840,)\n",
      "\n",
      "Train set: (160, 784) y: (160,)\n",
      "Val   set: (59840, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.732 s \n",
      "\n",
      "Accuracy rate for 77.610000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       980\n",
      "           1       0.74      0.98      0.85      1135\n",
      "           2       0.85      0.63      0.72      1032\n",
      "           3       0.77      0.81      0.79      1010\n",
      "           4       0.61      0.89      0.73       982\n",
      "           5       0.83      0.60      0.70       892\n",
      "           6       0.77      0.83      0.80       958\n",
      "           7       0.89      0.79      0.84      1028\n",
      "           8       0.92      0.57      0.70       974\n",
      "           9       0.71      0.73      0.72      1009\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.79      0.77      0.77     10000\n",
      "weighted avg       0.79      0.78      0.77     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 878    1    1    4    5    4   83    4    0    0]\n",
      " [   0 1111   15    3    1    1    3    0    0    1]\n",
      " [  55  121  649   33   50    2   37   43   40    2]\n",
      " [   8   48   10  822   14   41    8   17    8   34]\n",
      " [   1    9    4    1  874    4   13    0    0   76]\n",
      " [  14   39    2  118   96  536   32   19    3   33]\n",
      " [  51   16   24    0   50   22  795    0    0    0]\n",
      " [   9   66   32    3   35    3    0  811    0   69]\n",
      " [   5   71    8   73  111   21   50    5  551   79]\n",
      " [   9   10   23   11  188   13    6   15    0  734]]\n",
      "--------------------------------\n",
      "val predicted: (59840,) ['3' '0' '4' ... '5' '0' '4']\n",
      "probabilities: (59840, 10) \n",
      " [3 0 4 ... 5 0 4]\n",
      "trainset before (160, 784) (160,)\n",
      "trainset after (170, 784) (170,)\n",
      "updated train set: (170, 784) (170,) unique(labels): [17 18 14 18 23 15 20 14 11 20] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59830, 784) (59830,)\n",
      "\n",
      "Train set: (170, 784) y: (170,)\n",
      "Val   set: (59830, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.900 s \n",
      "\n",
      "Accuracy rate for 78.070000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88       980\n",
      "           1       0.73      0.98      0.84      1135\n",
      "           2       0.86      0.62      0.72      1032\n",
      "           3       0.74      0.85      0.79      1010\n",
      "           4       0.66      0.88      0.76       982\n",
      "           5       0.83      0.58      0.69       892\n",
      "           6       0.77      0.86      0.81       958\n",
      "           7       0.91      0.78      0.84      1028\n",
      "           8       0.91      0.56      0.69       974\n",
      "           9       0.71      0.74      0.73      1009\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.80      0.78      0.77     10000\n",
      "weighted avg       0.80      0.78      0.78     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 884    2    1    2    5    5   79    2    0    0]\n",
      " [   0 1114   13    2    2    0    3    0    0    1]\n",
      " [  44  129  644   33   54    0   41   40   45    2]\n",
      " [   9   46   11  854    5   37    7    9    4   28]\n",
      " [   2    8    5    2  864    3   21    2    0   75]\n",
      " [  16   48    2  147   78  521   32   11    4   33]\n",
      " [  42   18   16    0   35   18  827    0    2    0]\n",
      " [  15   67   29    6   32    1    0  800    0   78]\n",
      " [   8   84    6   84   67   32   59    2  548   84]\n",
      " [  15   10   23   19  161   12    7   11    0  751]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59830,) ['5' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59830, 10) \n",
      " [5 0 4 ... 5 0 9]\n",
      "trainset before (170, 784) (170,)\n",
      "trainset after (180, 784) (180,)\n",
      "updated train set: (180, 784) (180,) unique(labels): [17 20 14 18 23 16 21 17 11 23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59820, 784) (59820,)\n",
      "\n",
      "Train set: (180, 784) y: (180,)\n",
      "Val   set: (59820, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.832 s \n",
      "\n",
      "Accuracy rate for 78.640000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       980\n",
      "           1       0.74      0.98      0.84      1135\n",
      "           2       0.86      0.62      0.72      1032\n",
      "           3       0.76      0.83      0.79      1010\n",
      "           4       0.71      0.84      0.77       982\n",
      "           5       0.80      0.62      0.70       892\n",
      "           6       0.76      0.89      0.82       958\n",
      "           7       0.88      0.83      0.86      1028\n",
      "           8       0.92      0.54      0.68       974\n",
      "           9       0.71      0.75      0.73      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.78      0.78     10000\n",
      "weighted avg       0.80      0.79      0.78     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 894    1    3    3    3    5   67    3    1    0]\n",
      " [   0 1116   13    2    0    1    3    0    0    0]\n",
      " [  47  132  644   29   45    1   48   47   36    3]\n",
      " [  10   46    8  835    4   49   11   13    8   26]\n",
      " [   2    9    7    3  827    5   30    2    0   97]\n",
      " [  15   50    4  126   58  557   41   20    2   19]\n",
      " [  36   23   12    1   20   15  851    0    0    0]\n",
      " [   5   58   26    4   20    2    2  854    1   56]\n",
      " [  12   69   10   82   59   38   59    3  529  113]\n",
      " [   9   10   25   16  135   19   12   26    0  757]]\n",
      "--------------------------------\n",
      "val predicted: (59820,) ['5' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59820, 10) \n",
      " [5 0 4 ... 5 0 9]\n",
      "trainset before (180, 784) (180,)\n",
      "trainset after (190, 784) (190,)\n",
      "updated train set: (190, 784) (190,) unique(labels): [18 21 15 19 23 19 21 19 11 24] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59810, 784) (59810,)\n",
      "\n",
      "Train set: (190, 784) y: (190,)\n",
      "Val   set: (59810, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.821 s \n",
      "\n",
      "Accuracy rate for 78.990000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       980\n",
      "           1       0.75      0.98      0.85      1135\n",
      "           2       0.87      0.65      0.74      1032\n",
      "           3       0.77      0.81      0.79      1010\n",
      "           4       0.71      0.85      0.77       982\n",
      "           5       0.74      0.68      0.71       892\n",
      "           6       0.76      0.88      0.82       958\n",
      "           7       0.88      0.83      0.85      1028\n",
      "           8       0.93      0.55      0.69       974\n",
      "           9       0.73      0.75      0.74      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.78     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 879    1    2    3    3   18   72    2    0    0]\n",
      " [   0 1111   17    2    0    1    3    0    1    0]\n",
      " [  43  113  670   40   48    0   41   42   31    4]\n",
      " [   6   44   11  814    5   77    9   16    5   23]\n",
      " [   2   10    6    2  839    4   24    5    0   90]\n",
      " [  15   48    3  110   48  603   42   17    1    5]\n",
      " [  32   23   11    2   27   20  842    1    0    0]\n",
      " [   4   55   26    2   19    5    1  855    1   60]\n",
      " [   4   77    9   64   65   65   64    3  532   91]\n",
      " [  10    9   19   21  134   21    7   34    0  754]]\n",
      "--------------------------------\n",
      "val predicted: (59810,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59810, 10) \n",
      " [3 0 4 ... 5 0 9]\n",
      "trainset before (190, 784) (190,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [20 22 15 20 24 19 21 20 13 26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.876 s \n",
      "\n",
      "Accuracy rate for 79.330000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       980\n",
      "           1       0.75      0.99      0.85      1135\n",
      "           2       0.88      0.62      0.73      1032\n",
      "           3       0.77      0.83      0.80      1010\n",
      "           4       0.70      0.85      0.77       982\n",
      "           5       0.78      0.65      0.71       892\n",
      "           6       0.81      0.86      0.84       958\n",
      "           7       0.87      0.83      0.85      1028\n",
      "           8       0.94      0.59      0.72       974\n",
      "           9       0.71      0.76      0.73      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.81      0.79      0.79     10000\n",
      "weighted avg       0.81      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 903    1    3    1    4    4   61    2    1    0]\n",
      " [   0 1119    6    3    0    1    3    0    2    1]\n",
      " [  54  131  643   40   53    1   29   50   27    4]\n",
      " [  12   37    8  838    5   58    4   16    3   29]\n",
      " [   3   11    5    4  830    4   21    4    1   99]\n",
      " [  12   42    1  125   67  578   34   17    4   12]\n",
      " [  43   21   12    5   31   19  827    0    0    0]\n",
      " [   3   54   23    4   17    6    0  854    0   67]\n",
      " [  17   72    6   55   55   46   37    5  575  106]\n",
      " [   9   10   22   19  119   21    6   37    0  766]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 4 ... 5 0 9]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (210, 784) (210,)\n",
      "updated train set: (210, 784) (210,) unique(labels): [21 22 15 21 25 20 24 22 13 27] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59790, 784) (59790,)\n",
      "\n",
      "Train set: (210, 784) y: (210,)\n",
      "Val   set: (59790, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 21\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.913 s \n",
      "\n",
      "Accuracy rate for 79.990000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       980\n",
      "           1       0.76      0.98      0.85      1135\n",
      "           2       0.86      0.64      0.74      1032\n",
      "           3       0.78      0.84      0.81      1010\n",
      "           4       0.73      0.84      0.78       982\n",
      "           5       0.76      0.68      0.72       892\n",
      "           6       0.79      0.89      0.84       958\n",
      "           7       0.85      0.85      0.85      1028\n",
      "           8       0.94      0.58      0.72       974\n",
      "           9       0.74      0.75      0.75      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.81      0.80      0.79     10000\n",
      "weighted avg       0.81      0.80      0.80     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 901    1    4    2    3   14   53    2    0    0]\n",
      " [   0 1108   19    3    0    1    3    1    0    0]\n",
      " [  41  123  664   44   43    1   36   50   27    3]\n",
      " [   9   25    9  846    5   67    6   17    3   23]\n",
      " [   4   10    5    2  826    4   29   12    1   89]\n",
      " [  11   48    1   97   60  608   41   15    3    8]\n",
      " [  40   18   13    2   16   19  848    2    0    0]\n",
      " [   3   55   27    3   16    4    0  874    0   46]\n",
      " [  11   68   11   60   36   65   50   11  565   97]\n",
      " [   7   11   16   20  131   15    7   43    0  759]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59790,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59790, 10) \n",
      " [3 0 4 ... 5 0 9]\n",
      "trainset before (210, 784) (210,)\n",
      "trainset after (220, 784) (220,)\n",
      "updated train set: (220, 784) (220,) unique(labels): [22 24 17 21 25 22 25 22 15 27] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59780, 784) (59780,)\n",
      "\n",
      "Train set: (220, 784) y: (220,)\n",
      "Val   set: (59780, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 22\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.956 s \n",
      "\n",
      "Accuracy rate for 80.120000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       980\n",
      "           1       0.76      0.99      0.86      1135\n",
      "           2       0.90      0.64      0.75      1032\n",
      "           3       0.80      0.80      0.80      1010\n",
      "           4       0.74      0.82      0.78       982\n",
      "           5       0.72      0.72      0.72       892\n",
      "           6       0.81      0.88      0.84       958\n",
      "           7       0.88      0.85      0.86      1028\n",
      "           8       0.90      0.61      0.73       974\n",
      "           9       0.73      0.78      0.75      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.81      0.80      0.80     10000\n",
      "weighted avg       0.81      0.80      0.80     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 878    1    3    1    2   45   47    1    2    0]\n",
      " [   0 1120    5    3    0    0    3    0    3    1]\n",
      " [  53  125  663   34   32    3   32   43   44    3]\n",
      " [   8   31   13  813    4   87    5   15    6   28]\n",
      " [   3    9    8    4  809    2   26   12    2  107]\n",
      " [  12   40    1   96   47  641   31   13    4    7]\n",
      " [  44   18    6    3   17   28  841    0    1    0]\n",
      " [   5   54   19    4   16    3    1  872    1   53]\n",
      " [  12   71    6   45   52   64   43    4  590   87]\n",
      " [   9   11   16   16  113   17    8   34    0  785]]\n",
      "--------------------------------\n",
      "val predicted: (59780,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59780, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (220, 784) (220,)\n",
      "trainset after (230, 784) (230,)\n",
      "updated train set: (230, 784) (230,) unique(labels): [24 24 19 22 25 22 25 22 17 30] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59770, 784) (59770,)\n",
      "\n",
      "Train set: (230, 784) y: (230,)\n",
      "Val   set: (59770, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 23\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.020 s \n",
      "\n",
      "Accuracy rate for 82.240000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88       980\n",
      "           1       0.78      0.99      0.87      1135\n",
      "           2       0.90      0.70      0.79      1032\n",
      "           3       0.80      0.82      0.81      1010\n",
      "           4       0.81      0.83      0.82       982\n",
      "           5       0.77      0.73      0.75       892\n",
      "           6       0.83      0.88      0.86       958\n",
      "           7       0.88      0.83      0.86      1028\n",
      "           8       0.93      0.69      0.79       974\n",
      "           9       0.73      0.82      0.77      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.83      0.82      0.82     10000\n",
      "weighted avg       0.83      0.82      0.82     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 894    1    2    2    3   28   47    2    1    0]\n",
      " [   0 1125    0    3    0    0    3    0    3    1]\n",
      " [  51  105  720   35   22    1   21   38   34    5]\n",
      " [   9   29   12  825    2   66    5   16    7   39]\n",
      " [   4   12    4    3  812    3   20    7    1  116]\n",
      " [  16   43    4   96   29  650   32   11    4    7]\n",
      " [  38   18   10    2   16   32  841    1    0    0]\n",
      " [   8   51   25    2   10    2    0  856    2   72]\n",
      " [  13   53    9   51   32   45   29    7  672   63]\n",
      " [   9    9   12   15   76   18   10   31    0  829]]\n",
      "--------------------------------\n",
      "val predicted: (59770,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59770, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (230, 784) (230,)\n",
      "trainset after (240, 784) (240,)\n",
      "updated train set: (240, 784) (240,) unique(labels): [24 27 19 23 25 23 28 22 19 30] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59760, 784) (59760,)\n",
      "\n",
      "Train set: (240, 784) y: (240,)\n",
      "Val   set: (59760, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 24\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.021 s \n",
      "\n",
      "Accuracy rate for 81.910000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89       980\n",
      "           1       0.78      0.99      0.87      1135\n",
      "           2       0.89      0.67      0.76      1032\n",
      "           3       0.79      0.83      0.81      1010\n",
      "           4       0.80      0.80      0.80       982\n",
      "           5       0.74      0.73      0.73       892\n",
      "           6       0.82      0.90      0.86       958\n",
      "           7       0.89      0.83      0.86      1028\n",
      "           8       0.88      0.72      0.79       974\n",
      "           9       0.75      0.81      0.78      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 879    1    2    1    0   48   45    2    2    0]\n",
      " [   0 1119    0    3    0    1    4    0    8    0]\n",
      " [  43  109  688   45   28    1   32   35   48    3]\n",
      " [   8   22   12  839    2   64    3   11   22   27]\n",
      " [   1   12    7    1  785    5   30    6    4  131]\n",
      " [   8   42    5  100   34  647   36    8    7    5]\n",
      " [  26   15   11    1   16   29  858    1    1    0]\n",
      " [   3   53   26    2   10    4    1  858    5   66]\n",
      " [  10   51    7   55   23   56   29    2  704   37]\n",
      " [   9   10   14   11   84   19    9   37    2  814]]\n",
      "--------------------------------\n",
      "val predicted: (59760,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59760, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (240, 784) (240,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [25 27 20 25 26 24 28 23 19 33] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 25\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.072 s \n",
      "\n",
      "Accuracy rate for 82.740000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       980\n",
      "           1       0.79      0.99      0.88      1135\n",
      "           2       0.92      0.68      0.78      1032\n",
      "           3       0.80      0.83      0.81      1010\n",
      "           4       0.81      0.83      0.82       982\n",
      "           5       0.73      0.73      0.73       892\n",
      "           6       0.85      0.89      0.87       958\n",
      "           7       0.90      0.85      0.87      1028\n",
      "           8       0.91      0.73      0.81       974\n",
      "           9       0.75      0.85      0.79      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.82      0.82     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 864    1    2    2    3   63   42    1    2    0]\n",
      " [   0 1118    4    3    0    1    4    0    4    1]\n",
      " [  49  100  702   47   29    3   21   36   39    6]\n",
      " [   8   24   10  841    5   65    5    9   11   32]\n",
      " [   3   12    5    1  813    4   19    6    3  116]\n",
      " [  12   41    4   93   35  650   30    6    6   15]\n",
      " [  27   17    8    3   20   34  848    0    1    0]\n",
      " [   5   52   18    1   11    5    1  870    2   63]\n",
      " [  11   42    5   51   20   50   23    4  715   53]\n",
      " [   8    9    7   15   63   14    9   31    0  853]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (260, 784) (260,)\n",
      "updated train set: (260, 784) (260,) unique(labels): [25 27 21 25 27 27 31 24 19 34] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59740, 784) (59740,)\n",
      "\n",
      "Train set: (260, 784) y: (260,)\n",
      "Val   set: (59740, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 26\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.146 s \n",
      "\n",
      "Accuracy rate for 82.820000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89       980\n",
      "           1       0.78      0.98      0.87      1135\n",
      "           2       0.92      0.70      0.79      1032\n",
      "           3       0.82      0.82      0.82      1010\n",
      "           4       0.85      0.79      0.81       982\n",
      "           5       0.72      0.76      0.74       892\n",
      "           6       0.83      0.90      0.87       958\n",
      "           7       0.90      0.85      0.87      1028\n",
      "           8       0.92      0.69      0.79       974\n",
      "           9       0.73      0.87      0.79      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 882    1    1    0    0   53   37    3    3    0]\n",
      " [   0 1112   10    1    1    1    4    0    5    1]\n",
      " [  44  100  719   37   20    3   31   41   27   10]\n",
      " [   9   29   13  831    2   65    6   13   12   30]\n",
      " [   2   12    2    3  771    5   21   10    3  153]\n",
      " [  12   44    3   75   26  678   34    6    2   12]\n",
      " [  24   17    7    0   12   35  863    0    0    0]\n",
      " [   7   48   17    4    9    3    2  874    4   60]\n",
      " [   5   53    4   47   18   77   32    4  676   58]\n",
      " [   6    9    5   11   53   19    6   22    2  876]]\n",
      "--------------------------------\n",
      "val predicted: (59740,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59740, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (260, 784) (260,)\n",
      "trainset after (270, 784) (270,)\n",
      "updated train set: (270, 784) (270,) unique(labels): [25 28 24 26 27 27 35 24 20 34] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59730, 784) (59730,)\n",
      "\n",
      "Train set: (270, 784) y: (270,)\n",
      "Val   set: (59730, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 27\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.144 s \n",
      "\n",
      "Accuracy rate for 83.210000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       980\n",
      "           1       0.78      0.98      0.87      1135\n",
      "           2       0.91      0.71      0.80      1032\n",
      "           3       0.85      0.82      0.83      1010\n",
      "           4       0.84      0.79      0.82       982\n",
      "           5       0.77      0.79      0.78       892\n",
      "           6       0.80      0.91      0.85       958\n",
      "           7       0.88      0.85      0.87      1028\n",
      "           8       0.91      0.72      0.80       974\n",
      "           9       0.74      0.84      0.78      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 883    1    2    1    0   29   60    2    2    0]\n",
      " [   0 1110    7    3    0    0    3    0   12    0]\n",
      " [  36  101  733   31   19    2   38   38   29    5]\n",
      " [   6   32   17  826    2   62    7   16   13   29]\n",
      " [   2   11    4    1  779    4   18    8    3  152]\n",
      " [  13   35    1   56   26  701   37    8    6    9]\n",
      " [  17   17    7    0   17   30  868    2    0    0]\n",
      " [   7   52   20    2    8    3    0  875    4   57]\n",
      " [   8   48    6   43   16   59   39    5  699   51]\n",
      " [  10    9    6   12   62   16    9   37    1  847]]\n",
      "--------------------------------\n",
      "val predicted: (59730,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59730, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (270, 784) (270,)\n",
      "trainset after (280, 784) (280,)\n",
      "updated train set: (280, 784) (280,) unique(labels): [26 29 24 27 27 29 38 24 21 35] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59720, 784) (59720,)\n",
      "\n",
      "Train set: (280, 784) y: (280,)\n",
      "Val   set: (59720, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 28\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.222 s \n",
      "\n",
      "Accuracy rate for 83.710000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       980\n",
      "           1       0.81      0.98      0.88      1135\n",
      "           2       0.93      0.69      0.79      1032\n",
      "           3       0.85      0.84      0.84      1010\n",
      "           4       0.87      0.79      0.83       982\n",
      "           5       0.75      0.81      0.78       892\n",
      "           6       0.77      0.92      0.84       958\n",
      "           7       0.90      0.85      0.88      1028\n",
      "           8       0.92      0.74      0.82       974\n",
      "           9       0.75      0.84      0.79      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.85      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 877    1    0    1    1   31   66    1    2    0]\n",
      " [   0 1113    4    4    0    3    3    0    8    0]\n",
      " [  39  105  713   38   17    1   50   35   25    9]\n",
      " [   9   18   11  844    0   61   11   11   14   31]\n",
      " [   1   12    2    3  774   10   35    9    3  133]\n",
      " [  11   27    2   50   17  720   44    6    4   11]\n",
      " [  19   12    6    0    8   33  880    0    0    0]\n",
      " [   9   47   19    4    7    7    2  875    2   56]\n",
      " [   7   37    5   37   17   61   38    2  723   47]\n",
      " [   8    9    6   12   50   29   11   30    2  852]]\n",
      "--------------------------------\n",
      "val predicted: (59720,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59720, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (280, 784) (280,)\n",
      "trainset after (290, 784) (290,)\n",
      "updated train set: (290, 784) (290,) unique(labels): [28 30 25 27 27 29 39 25 23 37] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59710, 784) (59710,)\n",
      "\n",
      "Train set: (290, 784) y: (290,)\n",
      "Val   set: (59710, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 29\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.182 s \n",
      "\n",
      "Accuracy rate for 83.380000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       980\n",
      "           1       0.79      0.97      0.87      1135\n",
      "           2       0.93      0.68      0.79      1032\n",
      "           3       0.84      0.81      0.82      1010\n",
      "           4       0.86      0.77      0.81       982\n",
      "           5       0.77      0.78      0.78       892\n",
      "           6       0.80      0.92      0.86       958\n",
      "           7       0.91      0.86      0.88      1028\n",
      "           8       0.89      0.75      0.81       974\n",
      "           9       0.73      0.87      0.79      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 886    1    1    1    2   28   55    4    2    0]\n",
      " [   0 1100    6    6    0    1    3    0   19    0]\n",
      " [  35  117  705   40   17    1   42   38   29    8]\n",
      " [   7   28   13  816    1   69    8   14   20   34]\n",
      " [   0    9    3    2  760    5   24    5    4  170]\n",
      " [  11   34    2   54   25  697   40    8    9   12]\n",
      " [  12   15    3    0   13   33  881    1    0    0]\n",
      " [   8   47   17    3    7    3    0  879    5   59]\n",
      " [   8   38    4   39   16   49   37    4  733   46]\n",
      " [   7   11    5   10   45   18   11   16    5  881]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59710,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59710, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (290, 784) (290,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [28 30 27 28 29 31 40 25 23 39] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 30\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.270 s \n",
      "\n",
      "Accuracy rate for 84.190000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91       980\n",
      "           1       0.82      0.97      0.89      1135\n",
      "           2       0.93      0.70      0.80      1032\n",
      "           3       0.85      0.84      0.84      1010\n",
      "           4       0.86      0.77      0.82       982\n",
      "           5       0.77      0.82      0.79       892\n",
      "           6       0.80      0.92      0.86       958\n",
      "           7       0.91      0.85      0.88      1028\n",
      "           8       0.89      0.76      0.82       974\n",
      "           9       0.74      0.86      0.80      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.85      0.84      0.84     10000\n",
      "weighted avg       0.85      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 894    1    2    0    0   28   49    3    3    0]\n",
      " [   0 1096    4    4    0    2    3    0   25    1]\n",
      " [  38   96  722   44   15    2   44   35   29    7]\n",
      " [   7   16   11  846    2   67   10   11   13   27]\n",
      " [   2   10    3    3  759    6   34    5    5  155]\n",
      " [  12   20    1   49   18  735   32    7    8   10]\n",
      " [  14    9    5    0   15   30  883    1    1    0]\n",
      " [   9   44   18    2    6    5    1  877    3   63]\n",
      " [   5   31    4   37   12   63   37    5  738   42]\n",
      " [   8    9    7    9   51   22   10   21    3  869]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59700, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (310, 784) (310,)\n",
      "updated train set: (310, 784) (310,) unique(labels): [28 32 27 28 30 31 41 27 25 41] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59690, 784) (59690,)\n",
      "\n",
      "Train set: (310, 784) y: (310,)\n",
      "Val   set: (59690, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 31\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.253 s \n",
      "\n",
      "Accuracy rate for 84.610000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       980\n",
      "           1       0.83      0.98      0.90      1135\n",
      "           2       0.92      0.73      0.81      1032\n",
      "           3       0.87      0.83      0.85      1010\n",
      "           4       0.85      0.79      0.82       982\n",
      "           5       0.76      0.82      0.79       892\n",
      "           6       0.81      0.92      0.86       958\n",
      "           7       0.91      0.86      0.89      1028\n",
      "           8       0.91      0.74      0.82       974\n",
      "           9       0.74      0.86      0.80      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.84      0.84     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 888    1    1    1    1   33   53    1    1    0]\n",
      " [   0 1113    4    4    0    1    3    0    9    1]\n",
      " [  35   84  749   39   17    5   42   32   21    8]\n",
      " [   5   20   12  840    1   60   10   14   18   30]\n",
      " [   0   10    4    2  779    2   23    5    4  153]\n",
      " [  10   27    4   42   23  732   30    6    5   13]\n",
      " [  17   11    3    0   11   35  880    0    1    0]\n",
      " [   7   45   18    1    8    6    1  887    1   54]\n",
      " [   1   28    5   34   17   71   45    5  725   43]\n",
      " [   7    9   10    8   55   17    6   21    8  868]]\n",
      "--------------------------------\n",
      "val predicted: (59690,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59690, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (310, 784) (310,)\n",
      "trainset after (320, 784) (320,)\n",
      "updated train set: (320, 784) (320,) unique(labels): [30 34 27 28 33 31 43 27 26 41] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59680, 784) (59680,)\n",
      "\n",
      "Train set: (320, 784) y: (320,)\n",
      "Val   set: (59680, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 32\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.299 s \n",
      "\n",
      "Accuracy rate for 84.650000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       980\n",
      "           1       0.84      0.97      0.90      1135\n",
      "           2       0.90      0.72      0.80      1032\n",
      "           3       0.87      0.83      0.85      1010\n",
      "           4       0.84      0.82      0.83       982\n",
      "           5       0.78      0.82      0.80       892\n",
      "           6       0.80      0.92      0.86       958\n",
      "           7       0.92      0.86      0.89      1028\n",
      "           8       0.90      0.75      0.82       974\n",
      "           9       0.76      0.85      0.80      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.84     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 889    0    1    0    0   29   57    1    3    0]\n",
      " [   0 1100   13    4    0    0    3    1   13    1]\n",
      " [  40   86  745   33   23    4   39   35   22    5]\n",
      " [   7   20   11  835    3   59    5   12   21   37]\n",
      " [   1    8    4    1  810    2   27    2    5  122]\n",
      " [   9   20    3   46   22  731   37    7    6   11]\n",
      " [  14    9    7    0   14   31  880    1    2    0]\n",
      " [   5   41   25    2    8    2    1  887    5   52]\n",
      " [  12   21    8   29   14   65   41    5  730   49]\n",
      " [  10    9    7    7   72   15    8   18    5  858]]\n",
      "--------------------------------\n",
      "val predicted: (59680,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59680, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (320, 784) (320,)\n",
      "trainset after (330, 784) (330,)\n",
      "updated train set: (330, 784) (330,) unique(labels): [32 35 30 28 33 33 44 27 27 41] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59670, 784) (59670,)\n",
      "\n",
      "Train set: (330, 784) y: (330,)\n",
      "Val   set: (59670, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 33\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.299 s \n",
      "\n",
      "Accuracy rate for 84.700000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       980\n",
      "           1       0.82      0.99      0.90      1135\n",
      "           2       0.91      0.69      0.79      1032\n",
      "           3       0.87      0.82      0.85      1010\n",
      "           4       0.85      0.83      0.84       982\n",
      "           5       0.79      0.81      0.80       892\n",
      "           6       0.79      0.92      0.85       958\n",
      "           7       0.90      0.85      0.88      1028\n",
      "           8       0.93      0.77      0.84       974\n",
      "           9       0.77      0.84      0.80      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 905    1    1    0    0   17   52    2    2    0]\n",
      " [   0 1122    2    4    0    1    4    1    1    0]\n",
      " [  47  101  716   29   24    5   49   34   20    7]\n",
      " [   8   20   17  831    2   65    8   15   15   29]\n",
      " [   0    8    2    1  814    4   31    5    5  112]\n",
      " [  10   29    1   46   17  726   36   10    6   11]\n",
      " [  16   13    3    0   14   25  885    0    2    0]\n",
      " [  10   44   27    2    8    4    2  872    1   58]\n",
      " [   4   25    8   32   12   56   42    5  751   39]\n",
      " [   9    9    8    9   69   18   14   20    5  848]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59670,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59670, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (330, 784) (330,)\n",
      "trainset after (340, 784) (340,)\n",
      "updated train set: (340, 784) (340,) unique(labels): [32 37 33 29 34 34 44 29 27 41] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59660, 784) (59660,)\n",
      "\n",
      "Train set: (340, 784) y: (340,)\n",
      "Val   set: (59660, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 34\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.377 s \n",
      "\n",
      "Accuracy rate for 84.990000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       980\n",
      "           1       0.82      0.99      0.90      1135\n",
      "           2       0.92      0.73      0.81      1032\n",
      "           3       0.84      0.83      0.84      1010\n",
      "           4       0.85      0.84      0.84       982\n",
      "           5       0.79      0.80      0.80       892\n",
      "           6       0.82      0.92      0.87       958\n",
      "           7       0.90      0.85      0.88      1028\n",
      "           8       0.92      0.75      0.83       974\n",
      "           9       0.78      0.83      0.81      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 907    1    1    0    0   22   44    3    2    0]\n",
      " [   0 1125    1    2    0    0    3    1    2    1]\n",
      " [  49   92  752   32   24    1   39   30    9    4]\n",
      " [   6   21   14  842    1   55    5   15   22   29]\n",
      " [   5    9    2    4  823    3   21    8    6  101]\n",
      " [  10   26    1   61   18  711   32   11    9   13]\n",
      " [  17   11    3    1   13   24  885    1    3    0]\n",
      " [  12   43   28    5   10    3    0  878    3   46]\n",
      " [   3   27   10   41   11   62   36    4  735   45]\n",
      " [  11   10    8   13   72   15    9   25    5  841]]\n",
      "--------------------------------\n",
      "val predicted: (59660,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59660, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (340, 784) (340,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [32 38 34 30 37 34 45 29 29 42] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 35\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.377 s \n",
      "\n",
      "Accuracy rate for 85.130000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       980\n",
      "           1       0.82      0.99      0.90      1135\n",
      "           2       0.91      0.75      0.82      1032\n",
      "           3       0.85      0.81      0.83      1010\n",
      "           4       0.83      0.88      0.86       982\n",
      "           5       0.77      0.80      0.79       892\n",
      "           6       0.83      0.91      0.87       958\n",
      "           7       0.92      0.85      0.89      1028\n",
      "           8       0.91      0.76      0.83       974\n",
      "           9       0.80      0.82      0.81      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 910    1    2    0    0   25   36    2    4    0]\n",
      " [   0 1120    4    4    0    0    3    0    3    1]\n",
      " [  43   85  771   31   23    2   33   28   12    4]\n",
      " [   7   24   13  814    2   71    8   10   27   34]\n",
      " [   2    9    5    1  868    2   14    1    5   75]\n",
      " [   9   29    2   56   23  712   32    9    7   13]\n",
      " [  19   12    6    0   14   34  868    1    4    0]\n",
      " [  14   41   26    4   12    3    1  875    5   47]\n",
      " [   4   32    6   37   15   53   43    3  743   38]\n",
      " [  10   10    8    7   90   19    7   17    9  832]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59650, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (360, 784) (360,)\n",
      "updated train set: (360, 784) (360,) unique(labels): [32 39 36 31 37 35 45 31 30 44] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59640, 784) (59640,)\n",
      "\n",
      "Train set: (360, 784) y: (360,)\n",
      "Val   set: (59640, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 36\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.444 s \n",
      "\n",
      "Accuracy rate for 85.200000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       980\n",
      "           1       0.84      0.99      0.91      1135\n",
      "           2       0.92      0.76      0.83      1032\n",
      "           3       0.87      0.80      0.84      1010\n",
      "           4       0.83      0.86      0.84       982\n",
      "           5       0.78      0.80      0.79       892\n",
      "           6       0.81      0.92      0.86       958\n",
      "           7       0.92      0.86      0.89      1028\n",
      "           8       0.91      0.77      0.83       974\n",
      "           9       0.78      0.84      0.81      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 905    1    2    0    0   26   40    3    3    0]\n",
      " [   0 1121    4    2    0    1    4    1    2    0]\n",
      " [  47   74  782   24   16    2   39   32   11    5]\n",
      " [   7   19   17  810    2   66   14   15   28   32]\n",
      " [   0   10    1    1  843    1   24    4    3   95]\n",
      " [   9   25    1   54   26  710   32    7    9   19]\n",
      " [  16   12    5    0   12   33  877    0    3    0]\n",
      " [   9   43   21    1   10    5    2  881    5   51]\n",
      " [   6   24   12   31   14   58   39    4  746   40]\n",
      " [  10    9    7    5   91   14    6   15    7  845]]\n",
      "--------------------------------\n",
      "val predicted: (59640,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59640, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (360, 784) (360,)\n",
      "trainset after (370, 784) (370,)\n",
      "updated train set: (370, 784) (370,) unique(labels): [32 40 37 33 37 37 46 31 32 45] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59630, 784) (59630,)\n",
      "\n",
      "Train set: (370, 784) y: (370,)\n",
      "Val   set: (59630, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 37\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.422 s \n",
      "\n",
      "Accuracy rate for 85.730000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       980\n",
      "           1       0.85      0.99      0.91      1135\n",
      "           2       0.91      0.79      0.84      1032\n",
      "           3       0.86      0.84      0.85      1010\n",
      "           4       0.85      0.86      0.86       982\n",
      "           5       0.80      0.81      0.80       892\n",
      "           6       0.80      0.91      0.85       958\n",
      "           7       0.92      0.86      0.89      1028\n",
      "           8       0.92      0.76      0.83       974\n",
      "           9       0.79      0.82      0.81      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 897    1    1    0    0   13   63    1    4    0]\n",
      " [   0 1124    1    3    0    1    3    0    2    1]\n",
      " [  43   66  811   26   14    4   30   27    7    4]\n",
      " [   7   15   22  844    1   59    5   10   21   26]\n",
      " [   1   10    4    1  845    2   21    2    7   89]\n",
      " [   8   25    1   56   18  724   36    6    9    9]\n",
      " [  18   11   10    1   13   34  870    0    1    0]\n",
      " [  13   43   24    5    9    2    1  883    6   42]\n",
      " [   1   20   11   42    6   54   50    3  743   44]\n",
      " [   8    9   11    7   87   17    6   23    9  832]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59630,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59630, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (370, 784) (370,)\n",
      "trainset after (380, 784) (380,)\n",
      "updated train set: (380, 784) (380,) unique(labels): [34 41 38 33 38 38 46 32 34 46] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59620, 784) (59620,)\n",
      "\n",
      "Train set: (380, 784) y: (380,)\n",
      "Val   set: (59620, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 38\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.491 s \n",
      "\n",
      "Accuracy rate for 86.180000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       980\n",
      "           1       0.87      0.99      0.92      1135\n",
      "           2       0.92      0.79      0.85      1032\n",
      "           3       0.88      0.80      0.84      1010\n",
      "           4       0.86      0.86      0.86       982\n",
      "           5       0.77      0.84      0.80       892\n",
      "           6       0.82      0.91      0.86       958\n",
      "           7       0.92      0.87      0.89      1028\n",
      "           8       0.92      0.77      0.84       974\n",
      "           9       0.79      0.85      0.81      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 906    1    0    0    0   22   48    1    2    0]\n",
      " [   0 1123    1    3    0    1    4    1    2    0]\n",
      " [  40   54  811   19   22    2   42   31    8    3]\n",
      " [   7   18   18  813    1   79    6   12   29   27]\n",
      " [   1    9    4    1  848    1   18    3    4   93]\n",
      " [   6   18    2   41   14  747   30    6    9   19]\n",
      " [  18   10    4    0   11   39  873    1    2    0]\n",
      " [  11   35   24    0    7    5    0  890    7   49]\n",
      " [   6   18    9   34    9   58   40    4  754   42]\n",
      " [   8    9    7    8   77   18    8   16    5  853]]\n",
      "--------------------------------\n",
      "val predicted: (59620,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59620, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (380, 784) (380,)\n",
      "trainset after (390, 784) (390,)\n",
      "updated train set: (390, 784) (390,) unique(labels): [35 43 40 33 42 39 46 32 34 46] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59610, 784) (59610,)\n",
      "\n",
      "Train set: (390, 784) y: (390,)\n",
      "Val   set: (59610, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 39\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.482 s \n",
      "\n",
      "Accuracy rate for 86.250000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       980\n",
      "           1       0.86      0.98      0.92      1135\n",
      "           2       0.90      0.80      0.85      1032\n",
      "           3       0.88      0.81      0.84      1010\n",
      "           4       0.83      0.88      0.86       982\n",
      "           5       0.77      0.83      0.80       892\n",
      "           6       0.84      0.89      0.87       958\n",
      "           7       0.92      0.86      0.89      1028\n",
      "           8       0.91      0.78      0.84       974\n",
      "           9       0.83      0.83      0.83      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 921    1    1    0    0   18   35    1    3    0]\n",
      " [   0 1117    6    3    0    1    3    1    4    0]\n",
      " [  37   62  827   19   15    5   24   29    8    6]\n",
      " [  10   18   20  822    3   72    6   13   24   22]\n",
      " [   3    9    5    1  864    2   16    5    5   72]\n",
      " [  11   17    1   51   19  743   29    6    9    6]\n",
      " [  23    9   10    0   19   44  852    0    1    0]\n",
      " [  17   36   24    4   11    5    1  885    9   36]\n",
      " [   6   15   18   29   11   55   40    6  761   33]\n",
      " [   8    8    8    8   94   17    5   20    8  833]]\n",
      "--------------------------------\n",
      "val predicted: (59610,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59610, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (390, 784) (390,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [35 45 40 33 43 41 47 34 34 48] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 40\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.550 s \n",
      "\n",
      "Accuracy rate for 86.080000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       980\n",
      "           1       0.87      0.98      0.92      1135\n",
      "           2       0.89      0.78      0.84      1032\n",
      "           3       0.89      0.80      0.84      1010\n",
      "           4       0.84      0.86      0.85       982\n",
      "           5       0.76      0.84      0.80       892\n",
      "           6       0.83      0.90      0.87       958\n",
      "           7       0.91      0.87      0.89      1028\n",
      "           8       0.92      0.78      0.84       974\n",
      "           9       0.81      0.83      0.82      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 921    1    1    0    0   17   37    1    2    0]\n",
      " [   0 1115    9    2    0    3    3    0    2    1]\n",
      " [  39   63  808   18   22    2   31   37   11    1]\n",
      " [   8   19   20  811    2   86    5   16   20   23]\n",
      " [   3    9    5    0  849    4   15    3    7   87]\n",
      " [   8   15    2   47   12  753   33    6    9    7]\n",
      " [  20    5   10    0   14   43  864    0    2    0]\n",
      " [  13   33   24    5   10    4    0  890   10   39]\n",
      " [   8   18   16   25    7   60   43    5  755   37]\n",
      " [   9    8    8    5   91   15    7   18    6  842]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59600, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (410, 784) (410,)\n",
      "updated train set: (410, 784) (410,) unique(labels): [36 47 41 35 44 42 47 35 34 49] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59590, 784) (59590,)\n",
      "\n",
      "Train set: (410, 784) y: (410,)\n",
      "Val   set: (59590, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 41\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.550 s \n",
      "\n",
      "Accuracy rate for 85.760000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.91       980\n",
      "           1       0.86      0.98      0.92      1135\n",
      "           2       0.89      0.77      0.82      1032\n",
      "           3       0.89      0.81      0.85      1010\n",
      "           4       0.83      0.86      0.85       982\n",
      "           5       0.74      0.86      0.80       892\n",
      "           6       0.84      0.89      0.87       958\n",
      "           7       0.91      0.87      0.89      1028\n",
      "           8       0.93      0.76      0.84       974\n",
      "           9       0.81      0.82      0.81      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 927    1    0    0    0   26   23    1    2    0]\n",
      " [   0 1116    7    3    0    3    3    0    3    0]\n",
      " [  43   73  790   17   20    8   32   37   10    2]\n",
      " [   7   13   25  817    2   85    7   14   17   23]\n",
      " [   3    9    3    0  846    5   22    5    5   84]\n",
      " [   8   12    0   47   11  770   28    6    3    7]\n",
      " [  26    7    7    0   15   48  854    0    1    0]\n",
      " [  16   33   24    0   14    7    0  891    6   37]\n",
      " [   7   18   21   24    9   66   38    5  741   45]\n",
      " [  10    9    9    7  100   18    6   21    5  824]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59590,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59590, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (410, 784) (410,)\n",
      "trainset after (420, 784) (420,)\n",
      "updated train set: (420, 784) (420,) unique(labels): [36 49 42 36 45 44 47 36 34 51] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59580, 784) (59580,)\n",
      "\n",
      "Train set: (420, 784) y: (420,)\n",
      "Val   set: (59580, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 42\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.577 s \n",
      "\n",
      "Accuracy rate for 85.930000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       980\n",
      "           1       0.87      0.99      0.92      1135\n",
      "           2       0.90      0.80      0.84      1032\n",
      "           3       0.88      0.81      0.85      1010\n",
      "           4       0.83      0.87      0.85       982\n",
      "           5       0.75      0.85      0.80       892\n",
      "           6       0.85      0.88      0.86       958\n",
      "           7       0.92      0.85      0.88      1028\n",
      "           8       0.93      0.76      0.84       974\n",
      "           9       0.81      0.82      0.82      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 924    1    1    0    0   21   30    1    2    0]\n",
      " [   0 1120    4    3    0    3    3    0    2    0]\n",
      " [  43   53  822   17   22    6   22   35    9    3]\n",
      " [   7   16   18  823    3   81    7   12   19   24]\n",
      " [   4    9    3    0  859    2   18    5    5   77]\n",
      " [   7   15    2   54    9  757   28    5    6    9]\n",
      " [  25    8   13    0   16   47  846    1    2    0]\n",
      " [  18   42   26    3   16    6    0  871    6   40]\n",
      " [   6   18   17   25   13   69   37    5  744   40]\n",
      " [  13    8   10    8  103   15    8   13    4  827]]\n",
      "--------------------------------\n",
      "val predicted: (59580,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59580, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (420, 784) (420,)\n",
      "trainset after (430, 784) (430,)\n",
      "updated train set: (430, 784) (430,) unique(labels): [36 49 44 37 46 45 49 36 36 52] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59570, 784) (59570,)\n",
      "\n",
      "Train set: (430, 784) y: (430,)\n",
      "Val   set: (59570, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 43\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.600 s \n",
      "\n",
      "Accuracy rate for 86.330000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       980\n",
      "           1       0.87      0.99      0.92      1135\n",
      "           2       0.90      0.80      0.85      1032\n",
      "           3       0.90      0.80      0.85      1010\n",
      "           4       0.86      0.88      0.87       982\n",
      "           5       0.73      0.87      0.79       892\n",
      "           6       0.86      0.88      0.87       958\n",
      "           7       0.92      0.86      0.88      1028\n",
      "           8       0.93      0.78      0.84       974\n",
      "           9       0.81      0.84      0.83      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 917    1    0    0    0   32   26    2    2    0]\n",
      " [   0 1121    3    2    0    4    3    0    2    0]\n",
      " [  37   56  824   16   12   12   21   37   14    3]\n",
      " [   8   19   19  808    1   88    4   14   22   27]\n",
      " [   2    9    3    0  861    4   19    2    4   78]\n",
      " [   9   14    1   42    8  774   26    6    6    6]\n",
      " [  28    6   12    0   18   48  843    1    2    0]\n",
      " [  15   40   22    1   15    7    1  880    6   41]\n",
      " [   3   18   18   20   10   75   28    5  756   41]\n",
      " [  11    9   11    7   77   22    6   14    3  849]]\n",
      "--------------------------------\n",
      "val predicted: (59570,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59570, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (430, 784) (430,)\n",
      "trainset after (440, 784) (440,)\n",
      "updated train set: (440, 784) (440,) unique(labels): [37 50 45 38 48 47 50 37 36 52] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59560, 784) (59560,)\n",
      "\n",
      "Train set: (440, 784) y: (440,)\n",
      "Val   set: (59560, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 44\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.612 s \n",
      "\n",
      "Accuracy rate for 86.520000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92       980\n",
      "           1       0.87      0.98      0.92      1135\n",
      "           2       0.89      0.81      0.85      1032\n",
      "           3       0.87      0.82      0.85      1010\n",
      "           4       0.85      0.88      0.86       982\n",
      "           5       0.76      0.86      0.81       892\n",
      "           6       0.85      0.89      0.87       958\n",
      "           7       0.93      0.86      0.89      1028\n",
      "           8       0.95      0.76      0.85       974\n",
      "           9       0.81      0.84      0.82      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.87      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 922    1    0    0    0   21   33    1    2    0]\n",
      " [   0 1115    8    4    0    1    3    0    3    1]\n",
      " [  43   51  839   17   12   11   19   31    5    4]\n",
      " [   8   14   20  829    2   81    5   13   13   25]\n",
      " [   4    6    5    0  861    2   20    1    3   80]\n",
      " [   6   15    2   48    5  771   30    2    3   10]\n",
      " [  25    9   14    0   15   46  849    0    0    0]\n",
      " [  13   36   28    2   14    6    1  880    4   44]\n",
      " [   4   21   14   38   14   60   37    4  742   40]\n",
      " [  10    9   11   10   91   11    6   11    6  844]]\n",
      "--------------------------------\n",
      "val predicted: (59560,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59560, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (440, 784) (440,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [38 50 46 38 48 50 51 37 39 53] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 45\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.631 s \n",
      "\n",
      "Accuracy rate for 86.940000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       980\n",
      "           1       0.88      0.99      0.93      1135\n",
      "           2       0.92      0.79      0.85      1032\n",
      "           3       0.89      0.81      0.85      1010\n",
      "           4       0.84      0.86      0.85       982\n",
      "           5       0.75      0.88      0.81       892\n",
      "           6       0.86      0.91      0.88       958\n",
      "           7       0.94      0.87      0.90      1028\n",
      "           8       0.93      0.79      0.85       974\n",
      "           9       0.81      0.84      0.83      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 920    1    0    0    0   28   29    1    1    0]\n",
      " [   0 1123    1    2    0    2    4    0    2    1]\n",
      " [  39   49  818   22   21   14   23   30   11    5]\n",
      " [   9   14   12  821    2   86    6   14   26   20]\n",
      " [   3   10    4    0  847    2   20    1    7   88]\n",
      " [   6   15    2   38    9  785   23    3    5    6]\n",
      " [  17   10    7    0   13   42  868    0    1    0]\n",
      " [  14   37   21    1   15    3    1  892    5   39]\n",
      " [   6   13   12   26   14   67   29    4  768   35]\n",
      " [  10    9    8   10   84   18    7    8    3  852]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59550, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (460, 784) (460,)\n",
      "updated train set: (460, 784) (460,) unique(labels): [40 50 49 41 48 50 52 37 39 54] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59540, 784) (59540,)\n",
      "\n",
      "Train set: (460, 784) y: (460,)\n",
      "Val   set: (59540, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 46\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.671 s \n",
      "\n",
      "Accuracy rate for 87.240000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       980\n",
      "           1       0.89      0.98      0.93      1135\n",
      "           2       0.90      0.82      0.86      1032\n",
      "           3       0.87      0.84      0.85      1010\n",
      "           4       0.84      0.88      0.86       982\n",
      "           5       0.78      0.86      0.82       892\n",
      "           6       0.86      0.90      0.88       958\n",
      "           7       0.93      0.87      0.90      1028\n",
      "           8       0.94      0.77      0.85       974\n",
      "           9       0.82      0.85      0.83      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 917    1    0    0    0   29   30    1    2    0]\n",
      " [   0 1113   10    2    0    2    3    2    3    0]\n",
      " [  29   47  848   17   16    8   25   33    4    5]\n",
      " [   7   10   18  846    2   64    2   16   21   24]\n",
      " [   3    8    4    0  863    2   21    2    5   74]\n",
      " [   5   13    2   49   14  767   26    3    2   11]\n",
      " [  20    8    5    0   20   40  863    1    1    0]\n",
      " [   8   32   22    3   14    4    1  898    7   39]\n",
      " [   3   13   20   48   13   50   31    4  753   39]\n",
      " [  11    8    9   12   82   13    5    8    5  856]]\n",
      "--------------------------------\n",
      "val predicted: (59540,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59540, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (460, 784) (460,)\n",
      "trainset after (470, 784) (470,)\n",
      "updated train set: (470, 784) (470,) unique(labels): [40 51 49 43 49 54 52 38 39 55] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59530, 784) (59530,)\n",
      "\n",
      "Train set: (470, 784) y: (470,)\n",
      "Val   set: (59530, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 47\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.669 s \n",
      "\n",
      "Accuracy rate for 87.260000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       980\n",
      "           1       0.87      0.98      0.92      1135\n",
      "           2       0.91      0.81      0.86      1032\n",
      "           3       0.87      0.85      0.86      1010\n",
      "           4       0.86      0.87      0.86       982\n",
      "           5       0.77      0.88      0.82       892\n",
      "           6       0.88      0.89      0.88       958\n",
      "           7       0.93      0.87      0.90      1028\n",
      "           8       0.93      0.78      0.85       974\n",
      "           9       0.82      0.86      0.84      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 917    1    0    0    0   32   27    1    2    0]\n",
      " [   0 1113    9    4    0    3    3    1    2    0]\n",
      " [  31   56  832   27   15    7   18   34    8    4]\n",
      " [   7   12   16  860    2   63    1   13   19   17]\n",
      " [   2   12    4    0  853    4   16    2    5   84]\n",
      " [   6   14    2   36   10  787   20    2    5   10]\n",
      " [  24    7    5    1   17   49  854    0    1    0]\n",
      " [  16   35   24    2   11    6    1  890    6   37]\n",
      " [   6   17   10   49   11   56   29    4  756   36]\n",
      " [  10    8    9   11   75   14    4    7    7  864]]\n",
      "--------------------------------\n",
      "val predicted: (59530,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59530, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (470, 784) (470,)\n",
      "trainset after (480, 784) (480,)\n",
      "updated train set: (480, 784) (480,) unique(labels): [40 54 49 43 51 55 52 40 40 56] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59520, 784) (59520,)\n",
      "\n",
      "Train set: (480, 784) y: (480,)\n",
      "Val   set: (59520, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 48\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.745 s \n",
      "\n",
      "Accuracy rate for 87.850000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       980\n",
      "           1       0.89      0.99      0.93      1135\n",
      "           2       0.92      0.83      0.87      1032\n",
      "           3       0.89      0.85      0.87      1010\n",
      "           4       0.86      0.88      0.87       982\n",
      "           5       0.78      0.88      0.83       892\n",
      "           6       0.88      0.90      0.89       958\n",
      "           7       0.94      0.87      0.91      1028\n",
      "           8       0.94      0.78      0.85       974\n",
      "           9       0.81      0.86      0.83      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 918    1    1    0    0   27   29    2    2    0]\n",
      " [   0 1120    4    3    0    2    4    0    1    1]\n",
      " [  31   46  855   19   17    5   18   27    9    5]\n",
      " [   7    9   18  858    3   56    2   11   14   32]\n",
      " [   3   11    3    0  867    3   15    0    4   76]\n",
      " [   7   15    4   34    9  786   18    4    2   13]\n",
      " [  18    7    4    0   18   48  863    0    0    0]\n",
      " [  11   33   23    0   12    4    0  895    9   41]\n",
      " [   5   14   15   38   11   65   27    4  755   40]\n",
      " [  11    8    6    9   74   16    4    6    7  868]]\n",
      "--------------------------------\n",
      "val predicted: (59520,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59520, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (480, 784) (480,)\n",
      "trainset after (490, 784) (490,)\n",
      "updated train set: (490, 784) (490,) unique(labels): [41 55 51 44 51 56 53 41 41 57] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59510, 784) (59510,)\n",
      "\n",
      "Train set: (490, 784) y: (490,)\n",
      "Val   set: (59510, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 49\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.743 s \n",
      "\n",
      "Accuracy rate for 87.910000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       980\n",
      "           1       0.89      0.99      0.94      1135\n",
      "           2       0.92      0.82      0.87      1032\n",
      "           3       0.90      0.84      0.87      1010\n",
      "           4       0.85      0.89      0.87       982\n",
      "           5       0.76      0.90      0.83       892\n",
      "           6       0.88      0.89      0.88       958\n",
      "           7       0.94      0.87      0.91      1028\n",
      "           8       0.93      0.80      0.86       974\n",
      "           9       0.83      0.85      0.84      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 923    1    1    0    0   27   25    1    2    0]\n",
      " [   0 1119    7    3    0    3    3    0    0    0]\n",
      " [  34   46  848   15   17    9   19   29   11    4]\n",
      " [   7   10   17  848    4   73    4   12   19   16]\n",
      " [   2    5    3    0  875    4   15    1    6   71]\n",
      " [   5   11    1   32    7  801   18    3    4   10]\n",
      " [  27    6    5    0   17   54  848    0    1    0]\n",
      " [  11   30   24    0   15    3    1  897    9   38]\n",
      " [   4   17   11   39   11   55   25    4  776   32]\n",
      " [  11    9    8    5   81   20    2    7   10  856]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59510,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59510, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (490, 784) (490,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [45 55 51 44 52 59 55 41 41 57] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 50\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.773 s \n",
      "\n",
      "Accuracy rate for 87.520000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       980\n",
      "           1       0.88      0.98      0.93      1135\n",
      "           2       0.91      0.81      0.86      1032\n",
      "           3       0.91      0.84      0.87      1010\n",
      "           4       0.87      0.88      0.87       982\n",
      "           5       0.74      0.89      0.81       892\n",
      "           6       0.89      0.89      0.89       958\n",
      "           7       0.93      0.87      0.90      1028\n",
      "           8       0.94      0.77      0.85       974\n",
      "           9       0.82      0.87      0.84      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.87      0.87     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 930    1    0    0    0   29   17    1    2    0]\n",
      " [   0 1116    8    2    0    4    3    0    1    1]\n",
      " [  34   51  841   14   16   14   18   30    8    6]\n",
      " [   6   10   18  845    3   78    3   13   18   16]\n",
      " [   1    8    4    0  860    4   19    3    5   78]\n",
      " [   7   12    2   27   10  797   19    3    3   12]\n",
      " [  26   10    4    1   17   51  849    0    0    0]\n",
      " [  13   33   25    1   12    4    0  890    8   42]\n",
      " [   4   20   11   33    8   75   27    4  749   43]\n",
      " [  10   10    7    4   65   21    4    9    4  875]]\n",
      "--------------------------------\n",
      "final active learning accuracies [28.470000000000002, 35.38, 44.85, 50.71, 58.48, 61.3, 63.739999999999995, 65.48, 70.15, 71.58, 74.52, 75.67, 77.11, 77.31, 77.44, 77.61, 78.07, 78.64, 78.99000000000001, 79.33, 79.99000000000001, 80.12, 82.24000000000001, 81.91000000000001, 82.74000000000001, 82.82000000000001, 83.21, 83.71, 83.38, 84.19, 84.61, 84.65, 84.7, 84.99, 85.13, 85.2, 85.72999999999999, 86.18, 86.25, 86.08, 85.76, 85.92999999999999, 86.33, 86.52, 86.94, 87.24, 87.26, 87.85, 87.91, 87.52]\n",
      "saved Active-learning-experiment-20.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "{\n",
      "  \"RfModel\": {\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          28.470000000000002,\n",
      "          35.38,\n",
      "          44.85,\n",
      "          50.71,\n",
      "          58.48,\n",
      "          61.3,\n",
      "          63.739999999999995,\n",
      "          65.48,\n",
      "          70.15,\n",
      "          71.58,\n",
      "          74.52,\n",
      "          75.67,\n",
      "          77.11,\n",
      "          77.31,\n",
      "          77.44,\n",
      "          77.61,\n",
      "          78.07,\n",
      "          78.64,\n",
      "          78.99000000000001,\n",
      "          79.33,\n",
      "          79.99000000000001,\n",
      "          80.12,\n",
      "          82.24000000000001,\n",
      "          81.91000000000001,\n",
      "          82.74000000000001,\n",
      "          82.82000000000001,\n",
      "          83.21,\n",
      "          83.71,\n",
      "          83.38,\n",
      "          84.19,\n",
      "          84.61,\n",
      "          84.65,\n",
      "          84.7,\n",
      "          84.99,\n",
      "          85.13,\n",
      "          85.2,\n",
      "          85.72999999999999,\n",
      "          86.18,\n",
      "          86.25,\n",
      "          86.08,\n",
      "          85.76,\n",
      "          85.92999999999999,\n",
      "          86.33,\n",
      "          86.52,\n",
      "          86.94,\n",
      "          87.24,\n",
      "          87.26,\n",
      "          87.85,\n",
      "          87.91,\n",
      "          87.52\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          75.48,\n",
      "          83.13000000000001,\n",
      "          85.79,\n",
      "          87.78\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          35.36,\n",
      "          60.41,\n",
      "          67.99,\n",
      "          74.92,\n",
      "          78.18,\n",
      "          80.60000000000001,\n",
      "          81.69999999999999,\n",
      "          81.97,\n",
      "          82.43,\n",
      "          83.53,\n",
      "          84.89999999999999,\n",
      "          84.94,\n",
      "          85.24000000000001,\n",
      "          85.81,\n",
      "          85.96000000000001,\n",
      "          86.8,\n",
      "          87.25,\n",
      "          87.81,\n",
      "          87.9,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          79.44,\n",
      "          87.52\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          58.269999999999996,\n",
      "          71.76,\n",
      "          79.64,\n",
      "          82.54,\n",
      "          83.82,\n",
      "          83.98,\n",
      "          84.63000000000001,\n",
      "          84.89,\n",
      "          85.77,\n",
      "          86.59\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"SvmModel\": {\n",
      "    \"EntropySelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          34.22,\n",
      "          36.5,\n",
      "          41.5,\n",
      "          41.699999999999996,\n",
      "          43.05,\n",
      "          46.93,\n",
      "          50.62,\n",
      "          51.129999999999995,\n",
      "          55.74,\n",
      "          57.089999999999996,\n",
      "          56.84,\n",
      "          61.22,\n",
      "          62.029999999999994,\n",
      "          62.83,\n",
      "          62.029999999999994,\n",
      "          62.21,\n",
      "          63.28,\n",
      "          63.54,\n",
      "          65.23,\n",
      "          66.36999999999999,\n",
      "          68.42,\n",
      "          69.95,\n",
      "          69.55,\n",
      "          69.82000000000001,\n",
      "          74.8,\n",
      "          75.44,\n",
      "          74.92999999999999,\n",
      "          76.36,\n",
      "          77.23,\n",
      "          76.91,\n",
      "          75.79,\n",
      "          77.34,\n",
      "          77.81,\n",
      "          78.97,\n",
      "          80.16,\n",
      "          79.45,\n",
      "          79.65,\n",
      "          79.33,\n",
      "          79.41,\n",
      "          79.31,\n",
      "          78.95,\n",
      "          79.33,\n",
      "          78.78,\n",
      "          79.05,\n",
      "          79.11,\n",
      "          79.63,\n",
      "          79.60000000000001,\n",
      "          79.73,\n",
      "          80.13,\n",
      "          80.13\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.17,\n",
      "          79.14999999999999,\n",
      "          79.42,\n",
      "          80.08\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          52.65,\n",
      "          55.769999999999996,\n",
      "          58.5,\n",
      "          67.9,\n",
      "          68.63,\n",
      "          72.32,\n",
      "          72.37,\n",
      "          72.08,\n",
      "          72.49,\n",
      "          71.94,\n",
      "          73.11,\n",
      "          75.18,\n",
      "          76.25,\n",
      "          75.6,\n",
      "          76.79,\n",
      "          77.42999999999999,\n",
      "          77.56,\n",
      "          77.45,\n",
      "          78.3,\n",
      "          78.86\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.73,\n",
      "          84.64\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          68.25,\n",
      "          69.56,\n",
      "          71.76,\n",
      "          70.64,\n",
      "          70.59,\n",
      "          74.49,\n",
      "          76.31,\n",
      "          78.17,\n",
      "          77.95,\n",
      "          78.78\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          24.41,\n",
      "          39.12,\n",
      "          51.55,\n",
      "          58.15,\n",
      "          64.19,\n",
      "          67.33,\n",
      "          72.46000000000001,\n",
      "          73.94,\n",
      "          78.06,\n",
      "          78.57,\n",
      "          79.01,\n",
      "          78.68,\n",
      "          79.80000000000001,\n",
      "          80.78999999999999,\n",
      "          81.54,\n",
      "          82.21000000000001,\n",
      "          82.08,\n",
      "          83.17999999999999,\n",
      "          83.36,\n",
      "          83.13000000000001,\n",
      "          82.5,\n",
      "          83.24000000000001,\n",
      "          84.03,\n",
      "          84.84,\n",
      "          85.2,\n",
      "          85.17,\n",
      "          85.24000000000001,\n",
      "          85.1,\n",
      "          85.33,\n",
      "          85.00999999999999,\n",
      "          85.57000000000001,\n",
      "          85.91,\n",
      "          85.91,\n",
      "          86.4,\n",
      "          86.53999999999999,\n",
      "          86.78,\n",
      "          87.02,\n",
      "          87.18,\n",
      "          87.41,\n",
      "          87.33,\n",
      "          87.72,\n",
      "          87.8,\n",
      "          87.9,\n",
      "          88.1,\n",
      "          88.41,\n",
      "          88.22,\n",
      "          88.42999999999999,\n",
      "          88.38000000000001,\n",
      "          88.31,\n",
      "          88.6\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          76.8,\n",
      "          83.96000000000001,\n",
      "          87.08,\n",
      "          88.94\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          48.209999999999994,\n",
      "          59.870000000000005,\n",
      "          70.07,\n",
      "          73.88,\n",
      "          79.62,\n",
      "          80.99,\n",
      "          82.69999999999999,\n",
      "          83.2,\n",
      "          84.13000000000001,\n",
      "          84.61999999999999,\n",
      "          85.53,\n",
      "          86.32,\n",
      "          86.46000000000001,\n",
      "          87.16000000000001,\n",
      "          87.74,\n",
      "          87.87,\n",
      "          88.16000000000001,\n",
      "          88.24,\n",
      "          88.42,\n",
      "          88.13\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          82.87,\n",
      "          87.59\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          59.74,\n",
      "          70.57,\n",
      "          79.12,\n",
      "          83.25,\n",
      "          84.19,\n",
      "          86.44,\n",
      "          87.3,\n",
      "          87.81,\n",
      "          87.58,\n",
      "          88.63\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          30.12,\n",
      "          41.54,\n",
      "          51.15,\n",
      "          59.5,\n",
      "          64.64999999999999,\n",
      "          65.02,\n",
      "          66.7,\n",
      "          68.81,\n",
      "          70.28,\n",
      "          73.48,\n",
      "          73.83,\n",
      "          76.64,\n",
      "          76.83,\n",
      "          77.68,\n",
      "          77.38000000000001,\n",
      "          77.77,\n",
      "          79.17,\n",
      "          79.59,\n",
      "          80.86,\n",
      "          80.89,\n",
      "          81.24,\n",
      "          81.47999999999999,\n",
      "          82.23,\n",
      "          82.8,\n",
      "          82.96,\n",
      "          83.00999999999999,\n",
      "          83.64,\n",
      "          83.72,\n",
      "          83.35000000000001,\n",
      "          83.41,\n",
      "          83.69,\n",
      "          83.67999999999999,\n",
      "          84.23,\n",
      "          84.26,\n",
      "          84.48,\n",
      "          84.98,\n",
      "          85.38,\n",
      "          85.39,\n",
      "          85.63,\n",
      "          85.74000000000001,\n",
      "          86.17,\n",
      "          86.28,\n",
      "          86.38,\n",
      "          86.57000000000001,\n",
      "          86.42,\n",
      "          86.56,\n",
      "          86.38,\n",
      "          86.37,\n",
      "          86.44,\n",
      "          86.53999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.53999999999999,\n",
      "          80.67,\n",
      "          84.16,\n",
      "          86.61999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          55.489999999999995,\n",
      "          64.21,\n",
      "          71.63000000000001,\n",
      "          74.95,\n",
      "          76.49000000000001,\n",
      "          80.08999999999999,\n",
      "          82.11,\n",
      "          82.25,\n",
      "          82.65,\n",
      "          83.3,\n",
      "          84.02,\n",
      "          85.05,\n",
      "          85.15,\n",
      "          85.67,\n",
      "          86.18,\n",
      "          86.83999999999999,\n",
      "          87.41,\n",
      "          87.63,\n",
      "          87.82,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.15,\n",
      "          86.91\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          67.52,\n",
      "          75.52,\n",
      "          80.19,\n",
      "          84.26,\n",
      "          85.77,\n",
      "          86.16,\n",
      "          86.58,\n",
      "          86.65,\n",
      "          87.18,\n",
      "          87.09\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 21, using model = RfModel, selection_function = MarginSamplingSelection, k = 250, iteration = 0.\n",
      "\n",
      "initial random chosen samples (250,)\n",
      "initial train set: (250, 784) (250,) unique(labels): [15 33 29 21 29 28 32 21 19 23] [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59750, 784) (59750,) (250,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.001 s \n",
      "\n",
      "Accuracy rate for 80.640000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.87       980\n",
      "           1       0.86      0.90      0.88      1135\n",
      "           2       0.70      0.84      0.76      1032\n",
      "           3       0.90      0.71      0.79      1010\n",
      "           4       0.71      0.83      0.76       982\n",
      "           5       0.73      0.84      0.78       892\n",
      "           6       0.72      0.92      0.81       958\n",
      "           7       0.90      0.85      0.87      1028\n",
      "           8       0.95      0.65      0.77       974\n",
      "           9       0.80      0.70      0.75      1009\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.82      0.81      0.81     10000\n",
      "weighted avg       0.82      0.81      0.81     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 799    1   27    0    4   43  102    1    3    0]\n",
      " [   0 1018  102    2    1    1    7    1    3    0]\n",
      " [   8   38  863   15   31    4   42   26    2    3]\n",
      " [   7    9   71  720    6  136   17   16   14   14]\n",
      " [   0    7    6    1  814    1   53    4    0   96]\n",
      " [   6   24   18   17   15  748   55    2    6    1]\n",
      " [  19    7   14    0   20   12  886    0    0    0]\n",
      " [   3   28   45    5   38    3    3  871    1   31]\n",
      " [   3   41   76   33   33   52   55   10  636   35]\n",
      " [   3   16    4    9  187   21   13   41    6  709]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '2']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 6 2]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [48 38 51 60 56 48 38 31 69 61] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.978 s \n",
      "\n",
      "Accuracy rate for 89.200000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       980\n",
      "           1       0.94      0.96      0.95      1135\n",
      "           2       0.89      0.86      0.88      1032\n",
      "           3       0.84      0.91      0.88      1010\n",
      "           4       0.90      0.86      0.88       982\n",
      "           5       0.94      0.78      0.85       892\n",
      "           6       0.95      0.88      0.91       958\n",
      "           7       0.97      0.83      0.90      1028\n",
      "           8       0.82      0.91      0.86       974\n",
      "           9       0.79      0.92      0.85      1009\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.90      0.89      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 964    0    0    0    0    3    4    3    5    1]\n",
      " [   0 1092   17    4    1    1    2    2   15    1]\n",
      " [  22   12  892   20   12    2    8   10   39   15]\n",
      " [   4    1   12  923    3   12    0    6   34   15]\n",
      " [   1    5    5    0  847    1   13    0   13   97]\n",
      " [  16   10    6  103    6  693    8    2   28   20]\n",
      " [  25    5   26    2   32   13  840    0   15    0]\n",
      " [   4   19   32    6   16    2    0  857   19   73]\n",
      " [   4    9    4   29   10    7    4    3  882   22]\n",
      " [   8    6    5   12   19    3    1    4   21  930]]\n",
      "--------------------------------\n",
      "final active learning accuracies [80.64, 89.2]\n",
      "saved Active-learning-experiment-21.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 22, using model = RfModel, selection_function = MarginSamplingSelection, k = 125, iteration = 0.\n",
      "\n",
      "initial random chosen samples (125,)\n",
      "initial train set: (125, 784) (125,) unique(labels): [20 10 11 11 13 17 15 12  6 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,) (125,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.523 s \n",
      "\n",
      "Accuracy rate for 73.390000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88       980\n",
      "           1       0.82      0.97      0.89      1135\n",
      "           2       0.78      0.65      0.71      1032\n",
      "           3       0.69      0.61      0.65      1010\n",
      "           4       0.64      0.73      0.68       982\n",
      "           5       0.55      0.71      0.62       892\n",
      "           6       0.79      0.84      0.82       958\n",
      "           7       0.86      0.78      0.82      1028\n",
      "           8       0.84      0.47      0.61       974\n",
      "           9       0.61      0.56      0.59      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.73      0.73     10000\n",
      "weighted avg       0.74      0.73      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 963    2    1    0    1    3    8    1    1    0]\n",
      " [   0 1100   15    2    1    4    2    0    9    2]\n",
      " [  52   61  675   35   35   15   95    8   55    1]\n",
      " [  38   30   29  612    4  229    7    9   16   36]\n",
      " [   3   13   10    2  717    8   33    2    0  194]\n",
      " [  57   29    1   98   24  637   22   17    1    6]\n",
      " [  37   10   13    5   55   33  805    0    0    0]\n",
      " [   7   37   68    7   17    6    0  800    4   82]\n",
      " [  32   44   31  114   31  166   43   13  462   38]\n",
      " [  16    9   24    7  238   60    2   84    1  568]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59875,) ['5' '0' '4' ... '5' '0' '5']\n",
      "probabilities: (59875, 10) \n",
      " [5 0 4 ... 5 0 5]\n",
      "trainset before (125, 784) (125,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [23 15 27 31 22 27 24 18 39 24] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.298 s \n",
      "\n",
      "Accuracy rate for 86.380000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       980\n",
      "           1       0.93      0.98      0.95      1135\n",
      "           2       0.85      0.84      0.84      1032\n",
      "           3       0.79      0.89      0.84      1010\n",
      "           4       0.81      0.88      0.84       982\n",
      "           5       0.91      0.72      0.80       892\n",
      "           6       0.89      0.87      0.88       958\n",
      "           7       0.95      0.82      0.88      1028\n",
      "           8       0.81      0.86      0.84       974\n",
      "           9       0.83      0.79      0.81      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 948    1    5    3    0    3   12    1    7    0]\n",
      " [   0 1107    7    9    0    1    4    0    6    1]\n",
      " [  29    8  864   16   21    1   25   11   56    1]\n",
      " [   7    1   29  903    2   20    5   11   24    8]\n",
      " [   3    1    6    3  860    0   16    0   12   81]\n",
      " [  21   19    7  133    7  642   25    3   31    4]\n",
      " [  25    3   16    4   44    9  834    0   22    1]\n",
      " [   9   22   60   13   16    2    0  842    4   60]\n",
      " [   7   16   15   44    6   22    9    5  841    9]\n",
      " [  11    7   12   19  102    4    3   17   37  797]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [27 21 40 39 40 47 34 33 51 43] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.644 s \n",
      "\n",
      "Accuracy rate for 90.110000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.93      0.87      0.90      1032\n",
      "           3       0.90      0.88      0.89      1010\n",
      "           4       0.85      0.94      0.89       982\n",
      "           5       0.84      0.88      0.86       892\n",
      "           6       0.93      0.91      0.92       958\n",
      "           7       0.93      0.87      0.90      1028\n",
      "           8       0.89      0.88      0.89       974\n",
      "           9       0.85      0.84      0.84      1009\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 928    0    3    1    0   28   12    2    3    3]\n",
      " [   0 1116    2    7    1    2    4    0    3    0]\n",
      " [  15    5  894   18   19    4   15   26   33    3]\n",
      " [   7    0   18  888    1   41    2   18   24   11]\n",
      " [   1    2    3    1  919    2    6    0    3   45]\n",
      " [  11   12    2   37    9  785   13    5    8   10]\n",
      " [  12    3    6    2   16   35  876    1    7    0]\n",
      " [   1   27   21    4   13    0    0  893    5   64]\n",
      " [   6    6    7   23    9   29    8    5  861   20]\n",
      " [   4   10    6    8   94    4    2   10   20  851]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59625, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [39 22 50 57 54 66 43 45 70 54] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.166 s \n",
      "\n",
      "Accuracy rate for 91.310000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.94      0.87      0.90      1032\n",
      "           3       0.93      0.88      0.91      1010\n",
      "           4       0.84      0.96      0.90       982\n",
      "           5       0.86      0.90      0.88       892\n",
      "           6       0.95      0.90      0.92       958\n",
      "           7       0.95      0.90      0.92      1028\n",
      "           8       0.87      0.91      0.89       974\n",
      "           9       0.90      0.85      0.87      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 958    0    1    0    0   11    4    1    4    1]\n",
      " [   0 1114    3    3    2    1    5    0    7    0]\n",
      " [  12    5  899   11   15   13   16   17   42    2]\n",
      " [   7    0    9  886    1   46    3   13   36    9]\n",
      " [   2    1    2    0  939    0    5    0    5   28]\n",
      " [   6   11    0   27    6  805   10    6   15    6]\n",
      " [  26    4    4    1   31   23  861    0    8    0]\n",
      " [   1   16   30    0   17    3    0  925    5   31]\n",
      " [   5    4    4   13    7   20    7    6  891   17]\n",
      " [   8    9    5    7   94    9    0    9   15  853]]\n",
      "--------------------------------\n",
      "final active learning accuracies [73.39, 86.38, 90.11, 91.31]\n",
      "saved Active-learning-experiment-22.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 23, using model = RfModel, selection_function = MarginSamplingSelection, k = 50, iteration = 0.\n",
      "\n",
      "initial random chosen samples (50,)\n",
      "initial train set: (50, 784) (50,) unique(labels): [11  7  4  4  4  1  7  3  6  3] [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59950, 784) (59950,) (50,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.938 s \n",
      "\n",
      "Accuracy rate for 57.740000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.95      0.65       980\n",
      "           1       0.57      0.99      0.72      1135\n",
      "           2       0.90      0.42      0.57      1032\n",
      "           3       0.59      0.27      0.37      1010\n",
      "           4       0.61      0.66      0.63       982\n",
      "           5       0.68      0.05      0.09       892\n",
      "           6       0.59      0.83      0.69       958\n",
      "           7       0.77      0.60      0.67      1028\n",
      "           8       0.46      0.64      0.53       974\n",
      "           9       0.53      0.28      0.36      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.62      0.57      0.53     10000\n",
      "weighted avg       0.62      0.58      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 933    1    2    4    0    1   37    0    2    0]\n",
      " [   0 1123    1    0    0    0    4    0    7    0]\n",
      " [  78  224  435   71   23    0  106    9   84    2]\n",
      " [ 105  105   10  273   10    0   56   10  409   32]\n",
      " [  58   60    0    4  650    4  125    9   27   45]\n",
      " [ 358  119    3    9   19   45  137    4  147   51]\n",
      " [ 108   33    1    1   15    0  798    0    2    0]\n",
      " [  83  170   23   32   12    0   11  615   21   61]\n",
      " [  80   78    4   55   15   16   31   15  621   59]\n",
      " [  91   65    6   17  327    0   53  140   29  281]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['6' '0' '6' ... '8' '6' '6']\n",
      "probabilities: (59950, 10) \n",
      " [6 0 6 ... 8 6 6]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [11  7 15 11  7  5 10  8 13 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.541 s \n",
      "\n",
      "Accuracy rate for 75.920000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       980\n",
      "           1       0.88      0.95      0.92      1135\n",
      "           2       0.71      0.83      0.77      1032\n",
      "           3       0.75      0.81      0.78      1010\n",
      "           4       0.88      0.51      0.65       982\n",
      "           5       0.87      0.24      0.38       892\n",
      "           6       0.83      0.78      0.80       958\n",
      "           7       0.84      0.80      0.82      1028\n",
      "           8       0.73      0.82      0.77       974\n",
      "           9       0.54      0.85      0.66      1009\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.78      0.75      0.74     10000\n",
      "weighted avg       0.78      0.76      0.75     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 891    1    7    3    0   13   51    2   12    0]\n",
      " [   0 1082   13    2    0    0    4    0   30    4]\n",
      " [  12   39  854   71    2    0   11    6   28    9]\n",
      " [  19    5   31  821    0    3    7   11   63   50]\n",
      " [   7   10   62    1  500    0   31   67   31  273]\n",
      " [  85   23   20  140   15  217   40   26  101  225]\n",
      " [  42   15   97    3    9   13  749    0   13   17]\n",
      " [  11   32   74    0    2    1    0  820    3   85]\n",
      " [   5   13   16   52    4    1   11    9  800   63]\n",
      " [  18    4   23    8   36    1    3   39   19  858]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [15 10 17 14 12 16 15 11 19 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.759 s \n",
      "\n",
      "Accuracy rate for 80.570000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91       980\n",
      "           1       0.90      0.92      0.91      1135\n",
      "           2       0.89      0.81      0.84      1032\n",
      "           3       0.85      0.77      0.81      1010\n",
      "           4       0.91      0.53      0.67       982\n",
      "           5       0.84      0.72      0.78       892\n",
      "           6       0.91      0.89      0.90       958\n",
      "           7       0.96      0.71      0.82      1028\n",
      "           8       0.77      0.80      0.79       974\n",
      "           9       0.51      0.93      0.66      1009\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.84      0.80      0.81     10000\n",
      "weighted avg       0.84      0.81      0.81     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 947    0    0    1    0    3   17    1    9    2]\n",
      " [   0 1047    9    1    0    1    2    3   70    2]\n",
      " [  40   23  834   37    2    7   11    8   43   27]\n",
      " [  15   14   25  774    1   78    5    4   35   59]\n",
      " [   5    5    5    0  518    0   21    2   27  399]\n",
      " [  38   11    5   40   10  642   16    3   28   99]\n",
      " [  30    7   12    0    5   20  850    1    9   24]\n",
      " [  14   30   42   12    3    0    0  729    4  194]\n",
      " [   7   16    9   36    2    9   12    3  782   98]\n",
      " [  12    6    1    9   29    4    1    3   10  934]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59850, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [19 11 24 17 20 24 16 18 26 25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.112 s \n",
      "\n",
      "Accuracy rate for 86.130000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93       980\n",
      "           1       0.94      0.95      0.94      1135\n",
      "           2       0.83      0.86      0.84      1032\n",
      "           3       0.93      0.74      0.83      1010\n",
      "           4       0.88      0.80      0.84       982\n",
      "           5       0.78      0.87      0.82       892\n",
      "           6       0.96      0.83      0.89       958\n",
      "           7       0.87      0.87      0.87      1028\n",
      "           8       0.81      0.84      0.82       974\n",
      "           9       0.77      0.88      0.82      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 954    1    5    0    0    4    6    2    8    0]\n",
      " [   0 1080   10    2    0    2    1    5   35    0]\n",
      " [  27   17  883   13   11   11    7   17   36   10]\n",
      " [  23    5   45  747    1  120    2   14   43   10]\n",
      " [   6    2    7    0  782    3    6   24   19  133]\n",
      " [  28    6    9   10   11  778    7   12   22    9]\n",
      " [  22    7   35    0   36   34  793    9   20    2]\n",
      " [   7   15   47    5    6    1    0  895    5   47]\n",
      " [   4   11   15   18    9   32    2    8  817   58]\n",
      " [  10    7    7    5   31   12    1   45    7  884]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59800,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59800, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [20 12 30 26 29 28 20 20 33 32] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.246 s \n",
      "\n",
      "Accuracy rate for 88.260000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       980\n",
      "           1       0.94      0.95      0.94      1135\n",
      "           2       0.85      0.91      0.88      1032\n",
      "           3       0.90      0.83      0.86      1010\n",
      "           4       0.87      0.88      0.88       982\n",
      "           5       0.83      0.80      0.82       892\n",
      "           6       0.96      0.88      0.92       958\n",
      "           7       0.94      0.82      0.88      1028\n",
      "           8       0.84      0.89      0.86       974\n",
      "           9       0.79      0.88      0.84      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 947    0    8    0    0    7    7    1    9    1]\n",
      " [   0 1076   16    1    0    2    2    5   32    1]\n",
      " [  15   13  937   12   12    3   10   11   14    5]\n",
      " [   8    5   38  841    1   72    1   10   21   13]\n",
      " [   1    1    7    0  867    0    8    4   20   74]\n",
      " [  17   13    6   52   16  716    7   10   33   22]\n",
      " [  22    8   15    1   23   27  842    2   18    0]\n",
      " [   7   12   58    8    9    0    0  846    5   83]\n",
      " [   3   10   12   16    6   27    1    1  862   36]\n",
      " [   9    6    3    8   59    6    1   13   12  892]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [23 13 34 35 32 35 24 23 41 40] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.559 s \n",
      "\n",
      "Accuracy rate for 88.620000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       980\n",
      "           1       0.95      0.94      0.94      1135\n",
      "           2       0.87      0.89      0.88      1032\n",
      "           3       0.88      0.84      0.86      1010\n",
      "           4       0.90      0.87      0.88       982\n",
      "           5       0.84      0.89      0.86       892\n",
      "           6       0.95      0.90      0.93       958\n",
      "           7       0.95      0.78      0.86      1028\n",
      "           8       0.88      0.86      0.87       974\n",
      "           9       0.75      0.92      0.83      1009\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 959    1    4    0    0    5    5    1    4    1]\n",
      " [   0 1066   25    4    0    2    3    5   29    1]\n",
      " [  18   12  916   19   13    3    6   10   22   13]\n",
      " [   7    6   20  848    1   88    2   11   17   10]\n",
      " [   2    0    4    0  852    0    9    1   16   98]\n",
      " [  11    6    5   41    7  795    6    1    9   11]\n",
      " [  15    6   23    1   23   20  861    2    7    0]\n",
      " [   7   15   47    9   10    1    0  802    5  132]\n",
      " [   2    8   12   35    6   23    9    3  839   37]\n",
      " [   4    7    2    8   36   10    2    9    7  924]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59700, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [28 14 41 44 38 38 25 31 47 44] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.652 s \n",
      "\n",
      "Accuracy rate for 89.880000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       980\n",
      "           1       0.97      0.95      0.96      1135\n",
      "           2       0.90      0.88      0.89      1032\n",
      "           3       0.89      0.89      0.89      1010\n",
      "           4       0.87      0.91      0.89       982\n",
      "           5       0.90      0.86      0.88       892\n",
      "           6       0.95      0.92      0.93       958\n",
      "           7       0.94      0.84      0.89      1028\n",
      "           8       0.85      0.89      0.87       974\n",
      "           9       0.80      0.87      0.83      1009\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 954    0    7    0    0    5    7    1    6    0]\n",
      " [   0 1073    2    4    0    2    2    0   51    1]\n",
      " [  15   12  913   17   12    1    5    9   39    9]\n",
      " [   4    0   20  903    1   43    5   10   14   10]\n",
      " [   2    0    7    0  889    0    8    2   15   59]\n",
      " [  10    5    5   52   12  768   10    1   12   17]\n",
      " [  16    5   11    0   23   17  877    0    9    0]\n",
      " [   1    8   41    4    8    0    0  866    7   93]\n",
      " [   9    2    3   28    8   12    6    5  868   33]\n",
      " [   8    4    2   12   69    6    1   24    6  877]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59650, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [28 17 47 49 41 45 31 39 54 49] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.961 s \n",
      "\n",
      "Accuracy rate for 90.930000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       980\n",
      "           1       0.97      0.94      0.96      1135\n",
      "           2       0.89      0.87      0.88      1032\n",
      "           3       0.91      0.90      0.91      1010\n",
      "           4       0.90      0.91      0.90       982\n",
      "           5       0.90      0.89      0.90       892\n",
      "           6       0.95      0.93      0.94       958\n",
      "           7       0.93      0.90      0.92      1028\n",
      "           8       0.83      0.90      0.87       974\n",
      "           9       0.84      0.89      0.87      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 935    0   13    1    0   15   11    1    4    0]\n",
      " [   0 1071   10    4    0    2    3    2   41    2]\n",
      " [  11    7  896   12   13    4    6   16   64    3]\n",
      " [   1    1   18  909    1   30    1   16   21   12]\n",
      " [   1    0    7    0  889    0    6    5    8   66]\n",
      " [   4    1    5   35    7  798   11    3   14   14]\n",
      " [   7    3    9    1   23   15  891    0    9    0]\n",
      " [   1    8   28    3    6    1    0  928    6   47]\n",
      " [   8    2   14   18    5   13    5    7  875   27]\n",
      " [   5    8    3   11   45   10    1   19    6  901]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59600, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [33 19 52 53 47 56 35 41 59 55] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.995 s \n",
      "\n",
      "Accuracy rate for 91.020000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       980\n",
      "           1       0.98      0.95      0.96      1135\n",
      "           2       0.91      0.88      0.89      1032\n",
      "           3       0.94      0.86      0.90      1010\n",
      "           4       0.90      0.91      0.90       982\n",
      "           5       0.82      0.92      0.87       892\n",
      "           6       0.97      0.93      0.95       958\n",
      "           7       0.94      0.91      0.92      1028\n",
      "           8       0.85      0.88      0.87       974\n",
      "           9       0.83      0.91      0.87      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 950    0    7    1    0   13    6    1    2    0]\n",
      " [   0 1073   13    5    0    2    2    3   31    6]\n",
      " [  10    9  905   12   12    3    3   16   58    4]\n",
      " [   0    0   15  868    1   89    1   11   19    6]\n",
      " [   1    0    8    0  889    0    6    2   11   65]\n",
      " [   5    2    5    7    9  821    9    3    8   23]\n",
      " [  10    3    5    1   20   22  891    0    6    0]\n",
      " [   2    5   23    2    5    1    0  932    5   53]\n",
      " [   5    3    9   18   10   31    4    6  858   30]\n",
      " [   4    3    3   10   37   15    1   14    7  915]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59550, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [34 24 53 59 49 65 38 47 68 63] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.259 s \n",
      "\n",
      "Accuracy rate for 92.170000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.93      0.87      0.90      1032\n",
      "           3       0.93      0.90      0.92      1010\n",
      "           4       0.92      0.88      0.90       982\n",
      "           5       0.87      0.93      0.90       892\n",
      "           6       0.97      0.93      0.95       958\n",
      "           7       0.95      0.92      0.93      1028\n",
      "           8       0.87      0.90      0.89       974\n",
      "           9       0.85      0.93      0.89      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 951    1    5    0    0   14    7    1    1    0]\n",
      " [   0 1108    2    3    0   10    2    1    6    3]\n",
      " [  10    5  893   16   13    4    5   16   64    6]\n",
      " [   6    0   11  910    1   50    1   11   15    5]\n",
      " [   1    1    7    0  869    0    6    4   13   81]\n",
      " [   7    2    5   20    7  829    5    1   11    5]\n",
      " [  15    3    8    0   16   15  894    0    7    0]\n",
      " [   2    7   17    0    6    1    0  947    7   41]\n",
      " [   4    4    6   18    8   22    5    7  880   20]\n",
      " [   6    3    3   10   23   11    1   12    4  936]]\n",
      "--------------------------------\n",
      "final active learning accuracies [57.74, 75.92, 80.57, 86.13, 88.26, 88.62, 89.88000000000001, 90.93, 91.02, 92.17]\n",
      "saved Active-learning-experiment-23.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 24, using model = RfModel, selection_function = MarginSamplingSelection, k = 25, iteration = 0.\n",
      "\n",
      "initial random chosen samples (25,)\n",
      "initial train set: (25, 784) (25,) unique(labels): [3 2 1 4 4 0 4 3 3 1] [0 1 2 3 4 6 7 8 9]\n",
      "val set: (59975, 784) (59975,) (25,)\n",
      "\n",
      "Train set: (25, 784) y: (25,)\n",
      "Val   set: (59975, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.485 s \n",
      "\n",
      "Accuracy rate for 53.340000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72       980\n",
      "           1       0.80      0.66      0.72      1135\n",
      "           2       0.69      0.02      0.03      1032\n",
      "           3       0.47      0.82      0.60      1010\n",
      "           4       0.41      0.83      0.55       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.58      0.88      0.70       958\n",
      "           7       0.46      0.76      0.57      1028\n",
      "           8       0.51      0.57      0.54       974\n",
      "           9       0.24      0.01      0.02      1009\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.49      0.53      0.45     10000\n",
      "weighted avg       0.50      0.53      0.45     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[739   0   2 106  31   0  50  14  37   1]\n",
      " [  0 747   0  20  19   0   2 299  48   0]\n",
      " [ 52  72  18 244 141   0 307  60 136   2]\n",
      " [  6   7   2 824  17   0   7  83  61   3]\n",
      " [  2  12   0   1 816   0  73  31  41   6]\n",
      " [206  18   2 295 191   0  35  91  52   2]\n",
      " [ 25  11   0   8  49   0 844   7  14   0]\n",
      " [  3  29   1   8 120   0   3 784  77   3]\n",
      " [ 18  29   1 224  33   0  51  54 553  11]\n",
      " [ 10   5   0  19 554   0  72 284  56   9]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59975,) ['0' '0' '4' ... '7' '6' '8']\n",
      "probabilities: (59975, 9) \n",
      " [0 0 4 ... 6 5 7]\n",
      "trainset before (25, 784) (25,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [3 5 6 5 5 7 5 7 4 3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.160 s \n",
      "\n",
      "Accuracy rate for 63.860000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.62      0.74       980\n",
      "           1       0.66      0.97      0.79      1135\n",
      "           2       0.74      0.54      0.62      1032\n",
      "           3       0.73      0.65      0.69      1010\n",
      "           4       0.66      0.62      0.63       982\n",
      "           5       0.39      0.65      0.49       892\n",
      "           6       0.70      0.87      0.77       958\n",
      "           7       0.55      0.92      0.69      1028\n",
      "           8       0.77      0.36      0.49       974\n",
      "           9       0.57      0.16      0.25      1009\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.67      0.63      0.62     10000\n",
      "weighted avg       0.67      0.64      0.62     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 607   17   42   12    1  215   50   27    9    0]\n",
      " [   0 1099    0    7    8    8    6    2    5    0]\n",
      " [   3  216  557   64   18   19   43   71   41    0]\n",
      " [   1   67   20  654    3  207    4   38   12    4]\n",
      " [   1   27   16    0  604    6  136  107    5   80]\n",
      " [  15   76    8   67   32  576   28   62   21    7]\n",
      " [  16   34   36    0   18   16  830    7    1    0]\n",
      " [   0   48   13    2   13    4    0  942    1    5]\n",
      " [  15   58   36   84   12  316   48   22  353   30]\n",
      " [   1   16   25    7  213  110   41  421   11  164]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['0' '4' '1' ... '5' '6' '2']\n",
      "probabilities: (59950, 10) \n",
      " [0 4 1 ... 5 6 2]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (75, 784) (75,)\n",
      "updated train set: (75, 784) (75,) unique(labels): [ 5  5  9  8 10  9  5  9  6  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59925, 784) (59925,)\n",
      "\n",
      "Train set: (75, 784) y: (75,)\n",
      "Val   set: (59925, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.287 s \n",
      "\n",
      "Accuracy rate for 70.770000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81       980\n",
      "           1       0.81      0.94      0.87      1135\n",
      "           2       0.67      0.54      0.60      1032\n",
      "           3       0.67      0.72      0.69      1010\n",
      "           4       0.56      0.88      0.68       982\n",
      "           5       0.60      0.69      0.64       892\n",
      "           6       0.93      0.74      0.82       958\n",
      "           7       0.74      0.89      0.81      1028\n",
      "           8       0.82      0.45      0.58       974\n",
      "           9       0.56      0.41      0.47      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.70      0.70     10000\n",
      "weighted avg       0.72      0.71      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 773    1   70    7   11   78   17    3   18    2]\n",
      " [   0 1069    3   18   12   16    2    1   13    1]\n",
      " [  13  119  560  143   59    8   13   60   38   19]\n",
      " [   2   29   27  726   19  139    0   32    9   27]\n",
      " [   8    5   12    0  863    1    9   22    0   62]\n",
      " [  13   27   61   58   52  615    3   27   13   23]\n",
      " [  93   19   36    0   59   28  705    3    6    9]\n",
      " [   2   20   11   10   30    7    0  912    0   36]\n",
      " [  25   26   44  114   39  109    7   27  441  142]\n",
      " [   6    4    9    8  395   21    1  149    3  413]]\n",
      "--------------------------------\n",
      "val predicted: (59925,) ['0' '4' '1' ... '5' '2' '9']\n",
      "probabilities: (59925, 10) \n",
      " [0 4 1 ... 5 2 9]\n",
      "trainset before (75, 784) (75,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 8  5 14  9 11 12  5 11 12 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.619 s \n",
      "\n",
      "Accuracy rate for 75.540000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       980\n",
      "           1       0.91      0.87      0.89      1135\n",
      "           2       0.63      0.77      0.69      1032\n",
      "           3       0.81      0.69      0.75      1010\n",
      "           4       0.65      0.74      0.69       982\n",
      "           5       0.64      0.76      0.70       892\n",
      "           6       0.97      0.60      0.75       958\n",
      "           7       0.79      0.86      0.82      1028\n",
      "           8       0.78      0.75      0.77       974\n",
      "           9       0.60      0.58      0.59      1009\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.77      0.75      0.75     10000\n",
      "weighted avg       0.77      0.76      0.76     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[888   0  22   1   5  22   6   4  11  21]\n",
      " [  0 993  91  18  14   6   2   0  11   0]\n",
      " [  8  47 792  32  12  11   1  26  78  25]\n",
      " [  6  11  23 701   3 165   0  21  52  28]\n",
      " [  0   1  29   2 730   4   3  31   3 179]\n",
      " [ 11   8  67  43  45 675   2  16  15  10]\n",
      " [ 49  10 172   0  41  76 579   2  18  11]\n",
      " [  2  16  29   9  17   8   0 882  13  52]\n",
      " [  7   6  33  49  13  53   2  16 732  63]\n",
      " [  5   3   5  12 242  30   0 125   5 582]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['0' '9' '1' ... '5' '2' '8']\n",
      "probabilities: (59900, 10) \n",
      " [0 9 1 ... 5 2 8]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (125, 784) (125,)\n",
      "updated train set: (125, 784) (125,) unique(labels): [12  5 18 14 14 12  9 12 14 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.658 s \n",
      "\n",
      "Accuracy rate for 79.220000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90       980\n",
      "           1       0.96      0.79      0.87      1135\n",
      "           2       0.67      0.83      0.74      1032\n",
      "           3       0.69      0.82      0.75      1010\n",
      "           4       0.75      0.81      0.78       982\n",
      "           5       0.84      0.63      0.72       892\n",
      "           6       0.93      0.78      0.85       958\n",
      "           7       0.88      0.84      0.86      1028\n",
      "           8       0.84      0.70      0.76       974\n",
      "           9       0.66      0.74      0.70      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.81      0.79      0.79     10000\n",
      "weighted avg       0.81      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[934   0  12   0   1   6   9   1   7  10]\n",
      " [  0 894 134  89   3   1   5   0   9   0]\n",
      " [ 22   8 860  56  18   3   5  13  41   6]\n",
      " [  6   1  26 833   1  34   5  15  49  40]\n",
      " [  6   1  22   0 800   1   9  10   4 129]\n",
      " [ 28   7  57  97  48 562  13  20  13  47]\n",
      " [ 65   6  89   0  14  28 750   0   5   1]\n",
      " [  6   9  50  20  20   2   0 859   2  60]\n",
      " [ 11   2  26  91  13  29  14   8 682  98]\n",
      " [ 19   2   7  15 155   7   0  53   3 748]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59875,) ['0' '4' '1' ... '5' '0' '8']\n",
      "probabilities: (59875, 10) \n",
      " [0 4 1 ... 5 0 8]\n",
      "trainset before (125, 784) (125,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [12  7 21 15 17 19 14 12 16 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.914 s \n",
      "\n",
      "Accuracy rate for 83.190000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       980\n",
      "           1       0.95      0.88      0.92      1135\n",
      "           2       0.73      0.88      0.80      1032\n",
      "           3       0.79      0.77      0.78      1010\n",
      "           4       0.76      0.89      0.82       982\n",
      "           5       0.75      0.83      0.79       892\n",
      "           6       0.90      0.86      0.88       958\n",
      "           7       0.92      0.82      0.86      1028\n",
      "           8       0.87      0.75      0.81       974\n",
      "           9       0.77      0.72      0.74      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 899    0    7    0    0   40   19    2    8    5]\n",
      " [   0 1003   93   17    2    5   10    0    5    0]\n",
      " [  13   13  908   16   21    9   12    7   28    5]\n",
      " [   0    1   44  778    3   89    5   13   45   32]\n",
      " [   2    0   16    0  878    2    9    2    5   68]\n",
      " [  10    1   21   84   10  736   12    2   11    5]\n",
      " [  45    1   50    1    7   30  823    0    1    0]\n",
      " [   1   27   55   17   27    6    1  838    2   54]\n",
      " [   7    2   47   60   11   38   23    7  734   45]\n",
      " [   8    3    7   11  191   20    1   41    5  722]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59850, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (175, 784) (175,)\n",
      "updated train set: (175, 784) (175,) unique(labels): [13  8 21 18 21 20 15 14 18 27] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59825, 784) (59825,)\n",
      "\n",
      "Train set: (175, 784) y: (175,)\n",
      "Val   set: (59825, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.949 s \n",
      "\n",
      "Accuracy rate for 83.180000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       980\n",
      "           1       0.94      0.92      0.93      1135\n",
      "           2       0.84      0.84      0.84      1032\n",
      "           3       0.72      0.81      0.77      1010\n",
      "           4       0.85      0.84      0.85       982\n",
      "           5       0.79      0.76      0.78       892\n",
      "           6       0.91      0.88      0.89       958\n",
      "           7       0.97      0.75      0.84      1028\n",
      "           8       0.89      0.64      0.74       974\n",
      "           9       0.64      0.91      0.75      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.85      0.83      0.83     10000\n",
      "weighted avg       0.85      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 932    0    2    1    1   17   10    1   10    6]\n",
      " [   0 1044   29   31    1    9    9    0    9    3]\n",
      " [  16   25  865   41   24    6   11    8   26   10]\n",
      " [   2    2   28  822    2   72    5    5   16   56]\n",
      " [   2    1    5    0  829    1    6    0    3  135]\n",
      " [  16    3   18  104    9  679   22    2    8   31]\n",
      " [  49    3   26    1   13   22  842    0    1    1]\n",
      " [   1   24   30   17   24    3    0  768    3  158]\n",
      " [  14    1   26  113   15   37   22    0  621  125]\n",
      " [   8    4    2    8   55    9    1    6    0  916]]\n",
      "--------------------------------\n",
      "val predicted: (59825,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59825, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (175, 784) (175,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [15 10 24 23 26 20 17 15 23 27] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.204 s \n",
      "\n",
      "Accuracy rate for 84.820000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       980\n",
      "           1       0.94      0.95      0.95      1135\n",
      "           2       0.85      0.83      0.84      1032\n",
      "           3       0.74      0.85      0.79      1010\n",
      "           4       0.80      0.93      0.86       982\n",
      "           5       0.88      0.69      0.77       892\n",
      "           6       0.90      0.88      0.89       958\n",
      "           7       0.97      0.76      0.85      1028\n",
      "           8       0.81      0.76      0.79       974\n",
      "           9       0.73      0.88      0.80      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 922    0    6    4    2   10    8    0   21    7]\n",
      " [   0 1078    4   29    3    1    8    0   11    1]\n",
      " [  16   19  857   32   31    3   11    3   53    7]\n",
      " [   6    1   25  855    4   38    8    7   33   33]\n",
      " [   1    1    5    0  911    0    9    0    4   51]\n",
      " [  19    7   13  118   24  613   30    3   39   26]\n",
      " [  22    3   40    1   38    8  842    0    4    0]\n",
      " [   3   29   39   33   27    0    1  779    2  115]\n",
      " [  12    3   15   67   22   15   17    1  741   81]\n",
      " [   9    3    2   15   80    5    1    7    3  884]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59800, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (225, 784) (225,)\n",
      "updated train set: (225, 784) (225,) unique(labels): [15 12 25 23 28 26 21 20 26 29] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59775, 784) (59775,)\n",
      "\n",
      "Train set: (225, 784) y: (225,)\n",
      "Val   set: (59775, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.183 s \n",
      "\n",
      "Accuracy rate for 86.210000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       980\n",
      "           1       0.93      0.99      0.96      1135\n",
      "           2       0.88      0.80      0.83      1032\n",
      "           3       0.82      0.80      0.81      1010\n",
      "           4       0.81      0.93      0.86       982\n",
      "           5       0.81      0.79      0.80       892\n",
      "           6       0.91      0.90      0.91       958\n",
      "           7       0.94      0.84      0.89      1028\n",
      "           8       0.82      0.78      0.80       974\n",
      "           9       0.78      0.86      0.82      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 914    0    2    1    3   21   12    2   20    5]\n",
      " [   0 1118    4    1    1    1    5    0    5    0]\n",
      " [  12   38  821   25   31    5   16   10   65    9]\n",
      " [   5    3   24  803    7   80    6   14   41   27]\n",
      " [   1    2    5    0  913    0    9    2    3   47]\n",
      " [  11    9    8   81   19  702   21    8   22   11]\n",
      " [  19    4   18    0   30   21  863    0    3    0]\n",
      " [   1   17   39   21   23    2    1  861    2   61]\n",
      " [   7    8   14   41   20   24   10    3  761   86]\n",
      " [   8    7    2   10   84   10    1   16    6  865]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59775,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59775, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (225, 784) (225,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [17 12 27 28 33 31 23 20 28 31] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.426 s \n",
      "\n",
      "Accuracy rate for 86.730000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.88      0.82      0.85      1032\n",
      "           3       0.80      0.77      0.78      1010\n",
      "           4       0.79      0.95      0.86       982\n",
      "           5       0.75      0.86      0.80       892\n",
      "           6       0.93      0.91      0.92       958\n",
      "           7       0.95      0.84      0.89      1028\n",
      "           8       0.86      0.77      0.81       974\n",
      "           9       0.83      0.84      0.83      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 911    0    5    1    5   26   14    2   13    3]\n",
      " [   0 1108    8   13    0    3    2    1    0    0]\n",
      " [  15   12  845   45   32    5   16    7   50    5]\n",
      " [   5    1   24  773    6  147    3   11   28   12]\n",
      " [   1    1    5    0  936    0    5    1    4   29]\n",
      " [   5    3    3   40   22  769   17    4   16   13]\n",
      " [  13    3   13    0   31   24  872    0    2    0]\n",
      " [   1   16   39   23   29    0    0  862    1   57]\n",
      " [   6    8   14   64   25   37   10    3  749   58]\n",
      " [   3    5    2   13  106   12    2   13    5  848]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (275, 784) (275,)\n",
      "updated train set: (275, 784) (275,) unique(labels): [17 13 27 31 35 35 26 21 34 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59725, 784) (59725,)\n",
      "\n",
      "Train set: (275, 784) y: (275,)\n",
      "Val   set: (59725, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.414 s \n",
      "\n",
      "Accuracy rate for 88.180000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       980\n",
      "           1       0.96      0.99      0.97      1135\n",
      "           2       0.92      0.78      0.85      1032\n",
      "           3       0.81      0.83      0.82      1010\n",
      "           4       0.84      0.94      0.89       982\n",
      "           5       0.83      0.84      0.83       892\n",
      "           6       0.92      0.93      0.93       958\n",
      "           7       0.95      0.84      0.89      1028\n",
      "           8       0.83      0.84      0.84       974\n",
      "           9       0.82      0.87      0.85      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 919    0    1    3    3   16   13    1   12   12]\n",
      " [   0 1119    6    1    1    2    3    0    3    0]\n",
      " [  15   10  810   52   25    4   17   15   76    8]\n",
      " [   6    0   15  841    2   75    9    8   40   14]\n",
      " [   1    3    3    1  925    1    7    1    3   37]\n",
      " [   7    2    4   51   17  748   19    3   21   20]\n",
      " [  12    3    4    0   20   21  895    0    3    0]\n",
      " [   1   13   32   28   24    3    1  863    0   63]\n",
      " [   4    3    6   51   14   31    8    2  820   35]\n",
      " [   2    8    1   15   76    5    1   12   11  878]]\n",
      "--------------------------------\n",
      "val predicted: (59725,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59725, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (275, 784) (275,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [17 14 33 35 36 39 28 24 36 38] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.644 s \n",
      "\n",
      "Accuracy rate for 89.200000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.90      0.88      0.89      1032\n",
      "           3       0.84      0.84      0.84      1010\n",
      "           4       0.84      0.94      0.89       982\n",
      "           5       0.83      0.85      0.84       892\n",
      "           6       0.94      0.93      0.93       958\n",
      "           7       0.95      0.85      0.90      1028\n",
      "           8       0.88      0.83      0.86       974\n",
      "           9       0.83      0.87      0.85      1009\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 916    0    3    2    1   21   12    1   14   10]\n",
      " [   0 1111   10    1    1    2    3    0    7    0]\n",
      " [  14    7  904   22   24    4   12   10   27    8]\n",
      " [   3    1   27  851    3   72    5   10   24   14]\n",
      " [   1    2    4    0  925    1    5    2    3   39]\n",
      " [   7    3    5   48   15  759   13    7   19   16]\n",
      " [   8    4    9    0   19   26  889    0    3    0]\n",
      " [   1   16   35   19   17    1    0  877    1   61]\n",
      " [   2    2   10   57   14   28    9    3  813   36]\n",
      " [   3    8    2   12   82    5    2   10   10  875]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59700, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (325, 784) (325,)\n",
      "updated train set: (325, 784) (325,) unique(labels): [19 15 36 37 36 43 31 25 39 44] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59675, 784) (59675,)\n",
      "\n",
      "Train set: (325, 784) y: (325,)\n",
      "Val   set: (59675, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.651 s \n",
      "\n",
      "Accuracy rate for 88.470000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.93      0.86      0.89      1032\n",
      "           3       0.81      0.85      0.83      1010\n",
      "           4       0.91      0.87      0.89       982\n",
      "           5       0.82      0.87      0.84       892\n",
      "           6       0.93      0.94      0.93       958\n",
      "           7       0.96      0.79      0.86      1028\n",
      "           8       0.90      0.82      0.86       974\n",
      "           9       0.73      0.91      0.81      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.89      0.88      0.88     10000\n",
      "weighted avg       0.89      0.88      0.89     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 925    0    4    3    0   17   16    1    7    7]\n",
      " [   0 1114    5    9    0    3    3    0    1    0]\n",
      " [   9   10  887   29   14    9   15   14   31   14]\n",
      " [   3    0   18  859    2   70    3    6   31   18]\n",
      " [   1    3    4    3  857    1    9    1    0  103]\n",
      " [   6    3    5   61    5  778   13    3   10    8]\n",
      " [  10    5    3    0    8   27  903    0    0    2]\n",
      " [   1   14   21   32    7    1    0  807    2  143]\n",
      " [   3    3    8   53    9   38   12    3  801   44]\n",
      " [   4    5    2   16   44    7    0    5   10  916]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59675,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59675, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (325, 784) (325,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [20 15 37 41 38 51 31 28 44 45] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.001 s \n",
      "\n",
      "Accuracy rate for 89.650000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.92      0.88      0.90      1032\n",
      "           3       0.89      0.82      0.85      1010\n",
      "           4       0.88      0.89      0.89       982\n",
      "           5       0.77      0.93      0.84       892\n",
      "           6       0.95      0.92      0.93       958\n",
      "           7       0.95      0.85      0.90      1028\n",
      "           8       0.91      0.83      0.87       974\n",
      "           9       0.79      0.89      0.84      1009\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 935    0    5    0    0   18   11    1    5    5]\n",
      " [   0 1115    8    4    0    3    2    0    3    0]\n",
      " [   8    8  908   21   17   11   10   17   24    8]\n",
      " [   3    0   17  833    2  104    0   13   27   11]\n",
      " [   1    2    3    1  875    4    8    3    1   84]\n",
      " [   5    3    7   26    1  828    6    3    8    5]\n",
      " [  11    4    5    0   17   37  881    0    2    1]\n",
      " [   2   12   18   16   14    5    0  875    1   85]\n",
      " [   3    2    9   32   10   54   10    2  813   39]\n",
      " [   4    5    2    6   54   17    1   10    8  902]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['0' '4' '1' ... '3' '5' '6']\n",
      "probabilities: (59650, 10) \n",
      " [0 4 1 ... 3 5 6]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [20 15 40 47 38 51 34 30 51 49] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.766 s \n",
      "\n",
      "Accuracy rate for 90.200000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.94      0.86      0.90      1032\n",
      "           3       0.83      0.90      0.87      1010\n",
      "           4       0.91      0.88      0.89       982\n",
      "           5       0.87      0.89      0.88       892\n",
      "           6       0.94      0.95      0.94       958\n",
      "           7       0.95      0.84      0.89      1028\n",
      "           8       0.90      0.86      0.88       974\n",
      "           9       0.77      0.92      0.84      1009\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.91      0.90      0.90     10000\n",
      "weighted avg       0.91      0.90      0.90     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 933    0    2    1    1   15   13    1    8    6]\n",
      " [   0 1109    6    9    1    1    3    0    6    0]\n",
      " [   7    8  883   38   17    9   13   17   27   13]\n",
      " [   3    0   15  913    1   33    2    8   23   12]\n",
      " [   1    0    4    1  860    0    9    3    7   97]\n",
      " [   6    1    3   55    3  791    8    3    7   15]\n",
      " [   8    5    2    1   11   20  907    0    2    2]\n",
      " [   1    8   17   30   10    1    0  860    3   98]\n",
      " [   2    2    6   41    8   32    8    4  836   35]\n",
      " [   4    5    1   11   36   11    1    5    7  928]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['0' '4' '1' ... '3' '5' '6']\n",
      "probabilities: (59625, 10) \n",
      " [0 4 1 ... 3 5 6]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [21 16 41 50 42 53 34 35 54 54] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.956 s \n",
      "\n",
      "Accuracy rate for 90.680000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       980\n",
      "           1       0.98      0.97      0.97      1135\n",
      "           2       0.95      0.87      0.91      1032\n",
      "           3       0.86      0.89      0.88      1010\n",
      "           4       0.91      0.89      0.90       982\n",
      "           5       0.85      0.88      0.86       892\n",
      "           6       0.94      0.95      0.94       958\n",
      "           7       0.95      0.87      0.91      1028\n",
      "           8       0.90      0.88      0.89       974\n",
      "           9       0.80      0.91      0.85      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 929    0    3    1    2   15   17    2    5    6]\n",
      " [   0 1104    3    9    0    2    4    0   13    0]\n",
      " [   7    9  896   24   16    9   13   19   29   10]\n",
      " [   5    0   16  901    1   40    2   12   25    8]\n",
      " [   1    1    2    1  870    0    7    1    8   91]\n",
      " [  12    2    2   63    2  784    7    4    5   11]\n",
      " [   7    3    2    1    8   25  909    0    2    1]\n",
      " [   1    8   15   12    8    0    0  897    4   83]\n",
      " [   4    1    6   25    8   38    6    3  855   28]\n",
      " [   2    3    0    9   41   11    1   11    8  923]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['0' '4' '1' ... '3' '5' '6']\n",
      "probabilities: (59600, 10) \n",
      " [0 4 1 ... 3 5 6]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (425, 784) (425,)\n",
      "updated train set: (425, 784) (425,) unique(labels): [23 17 45 53 45 57 37 36 58 54] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59575, 784) (59575,)\n",
      "\n",
      "Train set: (425, 784) y: (425,)\n",
      "Val   set: (59575, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.945 s \n",
      "\n",
      "Accuracy rate for 91.560000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.95      0.88      0.92      1032\n",
      "           3       0.87      0.92      0.89      1010\n",
      "           4       0.92      0.90      0.91       982\n",
      "           5       0.88      0.87      0.88       892\n",
      "           6       0.95      0.95      0.95       958\n",
      "           7       0.95      0.87      0.91      1028\n",
      "           8       0.88      0.90      0.89       974\n",
      "           9       0.82      0.92      0.87      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.91      0.91     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 933    0    1    1    1   12   14    1   11    6]\n",
      " [   0 1111    4    4    0    3    2    0   11    0]\n",
      " [  13    8  913   19    8   10    6   16   30    9]\n",
      " [   1    0   11  925    1   26    1   13   21   11]\n",
      " [   0    2    6    0  888    2    6    2    7   69]\n",
      " [  11    3    2   63    3  777   13    4   10    6]\n",
      " [   8    3    1    1   12   24  906    0    3    0]\n",
      " [   2   10   15   11    7    0    0  897    9   77]\n",
      " [   2    1    6   25    8   19    4    4  880   25]\n",
      " [   2    5    2    9   36    6    1    9   13  926]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59575,) ['0' '4' '1' ... '3' '5' '6']\n",
      "probabilities: (59575, 10) \n",
      " [0 4 1 ... 3 5 6]\n",
      "trainset before (425, 784) (425,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [24 20 48 57 48 60 37 41 58 57] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.159 s \n",
      "\n",
      "Accuracy rate for 91.640000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       980\n",
      "           1       0.97      0.98      0.97      1135\n",
      "           2       0.95      0.89      0.92      1032\n",
      "           3       0.85      0.92      0.88      1010\n",
      "           4       0.91      0.93      0.92       982\n",
      "           5       0.85      0.89      0.87       892\n",
      "           6       0.96      0.94      0.95       958\n",
      "           7       0.96      0.87      0.91      1028\n",
      "           8       0.92      0.87      0.89       974\n",
      "           9       0.84      0.92      0.88      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 938    0    3    1    2   14   10    2    4    6]\n",
      " [   0 1113    2    4    0    3    3    0   10    0]\n",
      " [   8    9  917   28   12    9    6   15   17   11]\n",
      " [   1    0   11  928    1   31    1    8   19   10]\n",
      " [   1    0    4    0  913    2    5    1    5   51]\n",
      " [   8    2    5   65    2  792    7    4    3    4]\n",
      " [   5    3    2    2   15   35  896    0    0    0]\n",
      " [   2   10   17   13   10    3    0  896    6   71]\n",
      " [   2    4    5   38   11   36    6    1  846   25]\n",
      " [   2    8    0   12   36    6    1    7   12  925]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['0' '4' '1' ... '3' '5' '6']\n",
      "probabilities: (59550, 10) \n",
      " [0 4 1 ... 3 5 6]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (475, 784) (475,)\n",
      "updated train set: (475, 784) (475,) unique(labels): [24 21 52 58 50 63 39 45 64 59] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59525, 784) (59525,)\n",
      "\n",
      "Train set: (475, 784) y: (475,)\n",
      "Val   set: (59525, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.084 s \n",
      "\n",
      "Accuracy rate for 92.100000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.88      0.91      1032\n",
      "           3       0.86      0.91      0.89      1010\n",
      "           4       0.91      0.93      0.92       982\n",
      "           5       0.86      0.90      0.88       892\n",
      "           6       0.96      0.94      0.95       958\n",
      "           7       0.96      0.89      0.92      1028\n",
      "           8       0.90      0.90      0.90       974\n",
      "           9       0.86      0.91      0.89      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 939    0    2    0    0   12   15    1    6    5]\n",
      " [   0 1115    2    3    0    3    2    0   10    0]\n",
      " [   7   10  905   29   10    9    1   13   37   11]\n",
      " [   2    0   13  921    1   38    0    9   17    9]\n",
      " [   1    0    4    0  916    2    6    3    8   42]\n",
      " [   8    1    3   59    2  799    8    6    3    3]\n",
      " [   6    3    0    0   15   29  902    0    3    0]\n",
      " [   2    9   16   16    7    3    0  920    4   51]\n",
      " [   2    0    3   27   10   31    3    3  872   23]\n",
      " [   2    5    0   12   42    6    2    8   11  921]]\n",
      "--------------------------------\n",
      "val predicted: (59525,) ['0' '4' '1' ... '3' '5' '6']\n",
      "probabilities: (59525, 10) \n",
      " [0 4 1 ... 3 5 6]\n",
      "trainset before (475, 784) (475,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [28 22 56 60 53 64 40 48 67 62] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.303 s \n",
      "\n",
      "Accuracy rate for 92.300000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.88      0.91      1032\n",
      "           3       0.87      0.91      0.89      1010\n",
      "           4       0.91      0.93      0.92       982\n",
      "           5       0.87      0.88      0.88       892\n",
      "           6       0.96      0.93      0.95       958\n",
      "           7       0.95      0.91      0.93      1028\n",
      "           8       0.90      0.90      0.90       974\n",
      "           9       0.88      0.92      0.90      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 947    0    4    2    1   10    8    1    4    3]\n",
      " [   0 1116    3    3    1    3    2    0    7    0]\n",
      " [  15    6  910   24   11    5    5   17   34    5]\n",
      " [   2    1   10  922    1   35    1   12   21    5]\n",
      " [   1    0    4    1  917    1    5    2    5   46]\n",
      " [   5    2    4   67    2  789    8    6    7    2]\n",
      " [   6    3    3    1   23   27  891    0    4    0]\n",
      " [   3    8   16    9    6    3    0  939    5   39]\n",
      " [   4    0    5   23    7   26    4    5  874   26]\n",
      " [   4    6    1   11   37    6    1   10    8  925]]\n",
      "--------------------------------\n",
      "final active learning accuracies [53.339999999999996, 63.85999999999999, 70.77, 75.53999999999999, 79.22, 83.19, 83.17999999999999, 84.82, 86.21, 86.72999999999999, 88.18, 89.2, 88.47, 89.64999999999999, 90.2, 90.68, 91.56, 91.64, 92.10000000000001, 92.30000000000001]\n",
      "saved Active-learning-experiment-24.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 25, using model = RfModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
      "\n",
      "initial random chosen samples (10,)\n",
      "initial train set: (10, 784) (10,) unique(labels): [3 2 1 1 1 1 0 0 0 1] [0 1 2 3 4 5 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59990, 784) (59990,) (10,)\n",
      "\n",
      "Train set: (10, 784) y: (10,)\n",
      "Val   set: (59990, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.747 s \n",
      "\n",
      "Accuracy rate for 26.560000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.98      0.34       980\n",
      "           1       0.27      1.00      0.43      1135\n",
      "           2       0.67      0.11      0.19      1032\n",
      "           3       0.26      0.04      0.08      1010\n",
      "           4       0.46      0.09      0.15       982\n",
      "           5       0.30      0.02      0.04       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.00      0.00      0.00      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.54      0.29      0.38      1009\n",
      "\n",
      "    accuracy                           0.27     10000\n",
      "   macro avg       0.27      0.25      0.16     10000\n",
      "weighted avg       0.27      0.27      0.17     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 961    3    0    6    0    9    0    0    0    1]\n",
      " [   0 1134    1    0    0    0    0    0    0    0]\n",
      " [ 588  321  111    5    6    0    0    0    0    1]\n",
      " [ 434  444   28   45   25   27    0    0    0    7]\n",
      " [ 375  407    0    2   91    0    0    0    0  107]\n",
      " [ 612  203    5   25   11   21    0    0    0   15]\n",
      " [ 543  383    7    1    9    7    0    0    0    8]\n",
      " [ 663  262    0    9    3    0    0    0    0   91]\n",
      " [ 187  656   13   73   19    2    0    0    0   24]\n",
      " [ 313  362    0    5   32    4    0    0    0  293]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59990,) ['0' '0' '0' ... '1' '0' '0']\n",
      "probabilities: (59990, 7) \n",
      " [0 0 0 ... 1 0 0]\n",
      "trainset before (10, 784) (10,)\n",
      "trainset after (20, 784) (20,)\n",
      "updated train set: (20, 784) (20,) unique(labels): [4 2 1 2 2 2 2 1 2 2] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59980, 784) (59980,)\n",
      "\n",
      "Train set: (20, 784) y: (20,)\n",
      "Val   set: (59980, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.659 s \n",
      "\n",
      "Accuracy rate for 45.550000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.94      0.48       980\n",
      "           1       0.43      1.00      0.60      1135\n",
      "           2       0.86      0.14      0.25      1032\n",
      "           3       0.52      0.14      0.22      1010\n",
      "           4       0.65      0.53      0.59       982\n",
      "           5       0.44      0.18      0.26       892\n",
      "           6       0.57      0.72      0.64       958\n",
      "           7       0.91      0.13      0.22      1028\n",
      "           8       0.51      0.10      0.17       974\n",
      "           9       0.45      0.60      0.51      1009\n",
      "\n",
      "    accuracy                           0.46     10000\n",
      "   macro avg       0.57      0.45      0.39     10000\n",
      "weighted avg       0.57      0.46      0.40     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 918    3    0    0    0   29   25    0    5    0]\n",
      " [   1 1132    0    0    0    0    1    0    1    0]\n",
      " [ 445  253  149    1   20   28  127    1    7    1]\n",
      " [ 353  266   15  145    5  116   32    2   44   32]\n",
      " [ 129   90    0   24  524    0   60    3    2  150]\n",
      " [ 366  140    3   62   15  160   39    2   32   73]\n",
      " [ 195   52    6    0   12    0  693    0    0    0]\n",
      " [ 186  221    0    7   68    1    6  130    1  408]\n",
      " [ 168  355    1   31   18   18  205    4  100   74]\n",
      " [  92  114    0   11  141    8   34    1    4  604]]\n",
      "--------------------------------\n",
      "val predicted: (59980,) ['5' '0' '4' ... '5' '0' '0']\n",
      "probabilities: (59980, 10) \n",
      " [5 0 4 ... 5 0 0]\n",
      "trainset before (20, 784) (20,)\n",
      "trainset after (30, 784) (30,)\n",
      "updated train set: (30, 784) (30,) unique(labels): [4 2 5 4 2 2 2 2 4 3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59970, 784) (59970,)\n",
      "\n",
      "Train set: (30, 784) y: (30,)\n",
      "Val   set: (59970, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.754 s \n",
      "\n",
      "Accuracy rate for 56.820000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.96      0.66       980\n",
      "           1       0.77      0.94      0.85      1135\n",
      "           2       0.44      0.79      0.57      1032\n",
      "           3       0.54      0.58      0.56      1010\n",
      "           4       0.84      0.25      0.38       982\n",
      "           5       0.70      0.15      0.25       892\n",
      "           6       0.92      0.47      0.62       958\n",
      "           7       0.68      0.18      0.29      1028\n",
      "           8       0.61      0.55      0.58       974\n",
      "           9       0.43      0.71      0.54      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.64      0.56      0.53     10000\n",
      "weighted avg       0.64      0.57      0.53     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 943    1   11    2    0   16    4    1    1    1]\n",
      " [   0 1070   56    4    0    0    1    0    3    1]\n",
      " [ 141   25  818   11    2    6    1    3   23    2]\n",
      " [ 121   25  105  588    2   14    1    1  137   16]\n",
      " [  77   27  194   85  245    0   21   51   31  251]\n",
      " [ 258   82   27  197    7  133    5   14  101   68]\n",
      " [ 133   22  319   24    3    5  448    1    3    0]\n",
      " [ 102   45  143   29    3    0    0  190   17  499]\n",
      " [  62   74   80  113    3    9    7    3  534   89]\n",
      " [  61   17   98   43   27    8    1   17   24  713]]\n",
      "--------------------------------\n",
      "val predicted: (59970,) ['3' '0' '7' ... '5' '0' '2']\n",
      "probabilities: (59970, 10) \n",
      " [3 0 7 ... 5 0 2]\n",
      "trainset before (30, 784) (30,)\n",
      "trainset after (40, 784) (40,)\n",
      "updated train set: (40, 784) (40,) unique(labels): [4 2 6 5 3 4 4 4 4 4] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59960, 784) (59960,)\n",
      "\n",
      "Train set: (40, 784) y: (40,)\n",
      "Val   set: (59960, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.008 s \n",
      "\n",
      "Accuracy rate for 67.990000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.85      0.75       980\n",
      "           1       0.76      0.98      0.86      1135\n",
      "           2       0.68      0.74      0.71      1032\n",
      "           3       0.60      0.67      0.63      1010\n",
      "           4       0.81      0.48      0.60       982\n",
      "           5       0.55      0.39      0.46       892\n",
      "           6       0.86      0.71      0.78       958\n",
      "           7       0.62      0.74      0.67      1028\n",
      "           8       0.75      0.45      0.57       974\n",
      "           9       0.59      0.71      0.65      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.69      0.67      0.67     10000\n",
      "weighted avg       0.69      0.68      0.67     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 832    3   13    6    0  107    6   12    1    0]\n",
      " [   0 1111   14    3    0    0    4    1    1    1]\n",
      " [  83   53  767   46    3    3   29   22   18    8]\n",
      " [  68   36   87  676    0   45    1   19   61   17]\n",
      " [  38   23   26   21  473    8   19  186   22  166]\n",
      " [ 113   87   26  107   16  351   11   89   23   69]\n",
      " [  67   14  110    8   10   51  676   22    0    0]\n",
      " [   6   35   36   19    1    0    1  757   10  163]\n",
      " [  25   78   34  208    9   59   32   22  443   64]\n",
      " [  21   21   18   26   74   19    5   98   14  713]]\n",
      "--------------------------------\n",
      "val predicted: (59960,) ['3' '0' '7' ... '5' '0' '7']\n",
      "probabilities: (59960, 10) \n",
      " [3 0 7 ... 5 0 7]\n",
      "trainset before (40, 784) (40,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [5 2 6 5 4 5 4 5 6 8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.018 s \n",
      "\n",
      "Accuracy rate for 67.680000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.96      0.77       980\n",
      "           1       0.81      0.93      0.87      1135\n",
      "           2       0.73      0.66      0.69      1032\n",
      "           3       0.76      0.58      0.66      1010\n",
      "           4       0.83      0.30      0.44       982\n",
      "           5       0.66      0.32      0.43       892\n",
      "           6       0.93      0.67      0.78       958\n",
      "           7       0.80      0.73      0.76      1028\n",
      "           8       0.68      0.64      0.66       974\n",
      "           9       0.42      0.89      0.57      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.72      0.67      0.66     10000\n",
      "weighted avg       0.73      0.68      0.67     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 945    2    7    1    0   18    1    4    1    1]\n",
      " [   0 1054   11    1    0    0    3    1   55   10]\n",
      " [ 118   50  685   21    3    2   14   30   61   48]\n",
      " [  73   23   79  583    1   51    1   15  111   73]\n",
      " [  41    6   10    0  294    1    9   49   12  560]\n",
      " [ 159   82   21   70   15  287   12   38   11  197]\n",
      " [  93   13  102    3   13   24  646    7   26   31]\n",
      " [  16   24   11    4    1    0    1  747   10  214]\n",
      " [  15   34   14   80    6   46    8   12  628  131]\n",
      " [  16    8    2    6   21    9    2   32   14  899]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59950,) ['3' '0' '4' ... '9' '0' '9']\n",
      "probabilities: (59950, 10) \n",
      " [3 0 4 ... 9 0 9]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (60, 784) (60,)\n",
      "updated train set: (60, 784) (60,) unique(labels): [5 4 7 5 6 8 5 5 7 8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59940, 784) (59940,)\n",
      "\n",
      "Train set: (60, 784) y: (60,)\n",
      "Val   set: (59940, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.275 s \n",
      "\n",
      "Accuracy rate for 71.170000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80       980\n",
      "           1       0.81      0.97      0.88      1135\n",
      "           2       0.69      0.68      0.68      1032\n",
      "           3       0.88      0.47      0.61      1010\n",
      "           4       0.84      0.36      0.51       982\n",
      "           5       0.56      0.76      0.64       892\n",
      "           6       0.90      0.64      0.75       958\n",
      "           7       0.88      0.76      0.82      1028\n",
      "           8       0.72      0.70      0.71       974\n",
      "           9       0.50      0.85      0.63      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.75      0.71      0.70     10000\n",
      "weighted avg       0.75      0.71      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 875    1    9    1    0   88    4    1    0    1]\n",
      " [   0 1103    1    1    0    9    3    0    8   10]\n",
      " [  70   93  700    8    2   29   11   21   76   22]\n",
      " [  84    5   68  473    1  176    2   14  121   66]\n",
      " [  32   22   22    0  356   16   11   26    7  490]\n",
      " [  80   10   15   26    2  681   20    5   13   40]\n",
      " [  36    4  172    0    5   99  610    2   16   14]\n",
      " [  11   48   11    1    6    7    1  780    9  154]\n",
      " [   4   69    9   26    5   91   12    9  684   65]\n",
      " [  13   11    8    3   45   31    1   27   15  855]]\n",
      "--------------------------------\n",
      "val predicted: (59940,) ['3' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59940, 10) \n",
      " [3 0 4 ... 5 6 5]\n",
      "trainset before (60, 784) (60,)\n",
      "trainset after (70, 784) (70,)\n",
      "updated train set: (70, 784) (70,) unique(labels): [5 4 9 6 8 8 9 5 8 8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59930, 784) (59930,)\n",
      "\n",
      "Train set: (70, 784) y: (70,)\n",
      "Val   set: (59930, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.270 s \n",
      "\n",
      "Accuracy rate for 76.080000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84       980\n",
      "           1       0.86      0.95      0.90      1135\n",
      "           2       0.76      0.77      0.77      1032\n",
      "           3       0.83      0.63      0.72      1010\n",
      "           4       0.79      0.61      0.69       982\n",
      "           5       0.67      0.67      0.67       892\n",
      "           6       0.79      0.85      0.82       958\n",
      "           7       0.90      0.72      0.80      1028\n",
      "           8       0.75      0.68      0.71       974\n",
      "           9       0.56      0.81      0.66      1009\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.77      0.76      0.76     10000\n",
      "weighted avg       0.77      0.76      0.76     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 873    1   25    0    1   70    8    1    1    0]\n",
      " [   0 1075   17    1    0    8    7    0   22    5]\n",
      " [  50   41  796   20    2   13   39   15   46   10]\n",
      " [  43    4   72  639    3   75   20   13   92   49]\n",
      " [  16   12   18    0  596    8   30   13    5  284]\n",
      " [  65   10   14   69   17  600   43    6   17   51]\n",
      " [  27    2   65    1   15   31  814    1    2    0]\n",
      " [   6   49    7    1   11    2    5  738   16  193]\n",
      " [   5   51   22   34   17   77   54    3  658   53]\n",
      " [   9    5    7    3   94   18    8   27   19  819]]\n",
      "--------------------------------\n",
      "val predicted: (59930,) ['5' '0' '4' ... '5' '0' '5']\n",
      "probabilities: (59930, 10) \n",
      " [5 0 4 ... 5 0 5]\n",
      "trainset before (70, 784) (70,)\n",
      "trainset after (80, 784) (80,)\n",
      "updated train set: (80, 784) (80,) unique(labels): [ 6  4 11  8  9  9  9  6  9  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59920, 784) (59920,)\n",
      "\n",
      "Train set: (80, 784) y: (80,)\n",
      "Val   set: (59920, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.489 s \n",
      "\n",
      "Accuracy rate for 78.130000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       980\n",
      "           1       0.89      0.92      0.90      1135\n",
      "           2       0.67      0.87      0.76      1032\n",
      "           3       0.80      0.71      0.75      1010\n",
      "           4       0.82      0.65      0.73       982\n",
      "           5       0.69      0.68      0.69       892\n",
      "           6       0.82      0.81      0.82       958\n",
      "           7       0.91      0.78      0.84      1028\n",
      "           8       0.80      0.65      0.72       974\n",
      "           9       0.65      0.80      0.72      1009\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.79      0.78      0.78     10000\n",
      "weighted avg       0.79      0.78      0.78     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 895    1   11    2    0   61    8    1    1    0]\n",
      " [   0 1039   48    6    0    2    6   11   20    3]\n",
      " [  23   19  895   14    1   10   26   16   24    4]\n",
      " [  39    1   68  717    1   69    9   10   70   26]\n",
      " [   8    9   60    0  640    5   33   13    7  207]\n",
      " [  58    8   28   89   15  611   32    8   15   28]\n",
      " [  45    2   95    1    4   36  773    0    0    2]\n",
      " [   9   29   34    1    9    7    4  802    8  125]\n",
      " [  10   57   61   59   11   57   41    5  629   44]\n",
      " [   9    5   26    6   98   23    5   17    8  812]]\n",
      "--------------------------------\n",
      "val predicted: (59920,) ['3' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59920, 10) \n",
      " [3 0 4 ... 5 6 5]\n",
      "trainset before (80, 784) (80,)\n",
      "trainset after (90, 784) (90,)\n",
      "updated train set: (90, 784) (90,) unique(labels): [ 7  4 11  8 12  9 11  7 11 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59910, 784) (59910,)\n",
      "\n",
      "Train set: (90, 784) y: (90,)\n",
      "Val   set: (59910, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.449 s \n",
      "\n",
      "Accuracy rate for 79.380000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.86       980\n",
      "           1       0.93      0.88      0.90      1135\n",
      "           2       0.75      0.83      0.78      1032\n",
      "           3       0.82      0.69      0.75      1010\n",
      "           4       0.69      0.80      0.74       982\n",
      "           5       0.85      0.58      0.69       892\n",
      "           6       0.78      0.89      0.83       958\n",
      "           7       0.94      0.80      0.86      1028\n",
      "           8       0.75      0.76      0.76       974\n",
      "           9       0.72      0.72      0.72      1009\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[947   0   6   1   1  13   9   1   2   0]\n",
      " [  0 997  39   5  11   0  10   9  24  40]\n",
      " [ 38  17 854  16   7   3  32  14  46   5]\n",
      " [ 53   0  59 699  12  40  19  10  96  22]\n",
      " [ 15   8  41   0 789   0  40   1   5  83]\n",
      " [ 89   3  31  98  33 517  52   5  33  31]\n",
      " [ 54   3  28   1  18   5 849   0   0   0]\n",
      " [  5  27  28   0  41   2   3 818  20  84]\n",
      " [ 15  20  33  31  31  21  62   2 740  19]\n",
      " [  8   1  27   6 197  10   7   9  16 728]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59910,) ['3' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59910, 10) \n",
      " [3 0 4 ... 5 0 8]\n",
      "trainset before (90, 784) (90,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 7  6 12 10 12 10 12  7 13 11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.643 s \n",
      "\n",
      "Accuracy rate for 79.690000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.85       980\n",
      "           1       0.91      0.96      0.94      1135\n",
      "           2       0.78      0.81      0.80      1032\n",
      "           3       0.77      0.71      0.74      1010\n",
      "           4       0.75      0.73      0.74       982\n",
      "           5       0.84      0.51      0.64       892\n",
      "           6       0.80      0.92      0.85       958\n",
      "           7       0.93      0.76      0.84      1028\n",
      "           8       0.78      0.79      0.79       974\n",
      "           9       0.68      0.77      0.72      1009\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.80      0.79     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 944    0    5    3    1    9   16    1    1    0]\n",
      " [   0 1095    4    2    2    0    4    5   10   13]\n",
      " [  48   15  836   18    5    5   30   16   56    3]\n",
      " [  62    2   48  718    5   40   13    7   89   26]\n",
      " [  16    8   58    0  715    2   52    4    4  123]\n",
      " [  97   20   15  149   27  457   49    6   34   38]\n",
      " [  38    3   25    4    6    3  877    0    0    2]\n",
      " [   7   37   26    2   29    3    2  781   13  128]\n",
      " [  13   22   18   35   23   13   48    4  769   29]\n",
      " [   8    4   31    7  139   13    9   13    8  777]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '4' ... '3' '0' '8']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 4 ... 3 0 8]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (110, 784) (110,)\n",
      "updated train set: (110, 784) (110,) unique(labels): [ 7  6 13 13 13 10 12  9 15 12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59890, 784) (59890,)\n",
      "\n",
      "Train set: (110, 784) y: (110,)\n",
      "Val   set: (59890, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.602 s \n",
      "\n",
      "Accuracy rate for 81.760000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       980\n",
      "           1       0.94      0.96      0.95      1135\n",
      "           2       0.78      0.83      0.80      1032\n",
      "           3       0.72      0.82      0.76      1010\n",
      "           4       0.79      0.77      0.78       982\n",
      "           5       0.87      0.48      0.62       892\n",
      "           6       0.86      0.87      0.86       958\n",
      "           7       0.89      0.83      0.86      1028\n",
      "           8       0.77      0.87      0.81       974\n",
      "           9       0.76      0.76      0.76      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.81      0.81     10000\n",
      "weighted avg       0.82      0.82      0.81     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 928    0    8    0    0   13   21    2    7    1]\n",
      " [   0 1092    8   10    0    0    4    8   12    1]\n",
      " [  33    7  857   20    6    4   16   11   75    3]\n",
      " [  32    0   37  826    1   20   12    7   63   12]\n",
      " [   7    5   43    2  758    1   27   23   18   98]\n",
      " [  54   12   14  244   16  425   34    7   57   29]\n",
      " [  34    3   57    4   18    4  831    0    7    0]\n",
      " [   6   30   30    1   28    0    2  849    6   76]\n",
      " [   6    9   20   28   15    9   15    8  843   21]\n",
      " [   5    2   31   15  123   11    6   41    8  767]]\n",
      "--------------------------------\n",
      "val predicted: (59890,) ['3' '0' '4' ... '3' '6' '8']\n",
      "probabilities: (59890, 10) \n",
      " [3 0 4 ... 3 6 8]\n",
      "trainset before (110, 784) (110,)\n",
      "trainset after (120, 784) (120,)\n",
      "updated train set: (120, 784) (120,) unique(labels): [ 8  6 13 15 14 11 12 10 17 14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59880, 784) (59880,)\n",
      "\n",
      "Train set: (120, 784) y: (120,)\n",
      "Val   set: (59880, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.774 s \n",
      "\n",
      "Accuracy rate for 82.430000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89       980\n",
      "           1       0.95      0.95      0.95      1135\n",
      "           2       0.88      0.81      0.85      1032\n",
      "           3       0.74      0.84      0.79      1010\n",
      "           4       0.80      0.78      0.79       982\n",
      "           5       0.88      0.43      0.58       892\n",
      "           6       0.88      0.85      0.87       958\n",
      "           7       0.89      0.85      0.87      1028\n",
      "           8       0.76      0.86      0.81       974\n",
      "           9       0.70      0.84      0.77      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.83      0.82      0.82     10000\n",
      "weighted avg       0.83      0.82      0.82     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 948    0    3    0    1    9   10    1    7    1]\n",
      " [   0 1079    6    9    2    0    4   15   18    2]\n",
      " [  33   11  838   17   14    2   16   26   69    6]\n",
      " [  25    0   13  848    2   12    7   11   68   24]\n",
      " [   8    4    9    0  766    0   23    8   14  150]\n",
      " [  60    9    4  240   30  386   31    6   66   60]\n",
      " [  48    3   41    1   29    5  818    0   12    1]\n",
      " [   4   22   17    0   26    1    0  869    8   81]\n",
      " [   9    7    7   21   13   11   18   10  840   38]\n",
      " [   9    2   13   11   70   12    3   32    6  851]]\n",
      "--------------------------------\n",
      "val predicted: (59880,) ['3' '0' '4' ... '3' '6' '8']\n",
      "probabilities: (59880, 10) \n",
      " [3 0 4 ... 3 6 8]\n",
      "trainset before (120, 784) (120,)\n",
      "trainset after (130, 784) (130,)\n",
      "updated train set: (130, 784) (130,) unique(labels): [10  7 14 15 16 13 12 10 18 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59870, 784) (59870,)\n",
      "\n",
      "Train set: (130, 784) y: (130,)\n",
      "Val   set: (59870, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.723 s \n",
      "\n",
      "Accuracy rate for 83.470000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90       980\n",
      "           1       0.95      0.98      0.96      1135\n",
      "           2       0.86      0.83      0.85      1032\n",
      "           3       0.78      0.80      0.79      1010\n",
      "           4       0.78      0.85      0.82       982\n",
      "           5       0.88      0.54      0.67       892\n",
      "           6       0.92      0.84      0.88       958\n",
      "           7       0.94      0.83      0.88      1028\n",
      "           8       0.75      0.85      0.79       974\n",
      "           9       0.72      0.81      0.76      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 954    0    2    0    0    6    7    1    9    1]\n",
      " [   0 1109    2    4    0    0    3    1   14    2]\n",
      " [  30    5  857   12   17    2   11   19   78    1]\n",
      " [  20    2   28  809    3   32    6   10   77   23]\n",
      " [   9    2    8    2  836    0   17    2   12   94]\n",
      " [  49   15    4  187   16  479   19    2   70   51]\n",
      " [  47    2   50    2   31    3  809    0   14    0]\n",
      " [  11   20   25    1   25    0    0  851    3   92]\n",
      " [  14   12    2   16   25   12    5    6  826   56]\n",
      " [  13    6   16   10  114   12    0   16    5  817]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59870,) ['3' '0' '4' ... '3' '6' '8']\n",
      "probabilities: (59870, 10) \n",
      " [3 0 4 ... 3 6 8]\n",
      "trainset before (130, 784) (130,)\n",
      "trainset after (140, 784) (140,)\n",
      "updated train set: (140, 784) (140,) unique(labels): [10  7 14 17 17 15 13 11 19 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59860, 784) (59860,)\n",
      "\n",
      "Train set: (140, 784) y: (140,)\n",
      "Val   set: (59860, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.889 s \n",
      "\n",
      "Accuracy rate for 84.990000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       980\n",
      "           1       0.95      0.98      0.96      1135\n",
      "           2       0.92      0.79      0.85      1032\n",
      "           3       0.82      0.80      0.81      1010\n",
      "           4       0.84      0.83      0.84       982\n",
      "           5       0.83      0.65      0.73       892\n",
      "           6       0.91      0.86      0.89       958\n",
      "           7       0.91      0.86      0.88      1028\n",
      "           8       0.76      0.85      0.80       974\n",
      "           9       0.73      0.86      0.79      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 957    0    1    1    1    8    3    1    7    1]\n",
      " [   0 1108    3    3    0    0    4    1   13    3]\n",
      " [  34    9  819    8   22    5   20   33   77    5]\n",
      " [  11    2   17  810    1   51    5   14   78   21]\n",
      " [   9    2    3    1  819    0   15    7    8  118]\n",
      " [  25   14    2  146   17  581   21    4   48   34]\n",
      " [  37    4   26    1   22   22  828    0   16    2]\n",
      " [   9   21   16    1   14    2    0  881    8   76]\n",
      " [  11    5    3   12   15   21   11    9  829   58]\n",
      " [  11    6    5    8   66   14    4   21    7  867]]\n",
      "--------------------------------\n",
      "val predicted: (59860,) ['3' '0' '4' ... '3' '6' '8']\n",
      "probabilities: (59860, 10) \n",
      " [3 0 4 ... 3 6 8]\n",
      "trainset before (140, 784) (140,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [10  7 15 18 18 16 13 13 20 20] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.839 s \n",
      "\n",
      "Accuracy rate for 85.180000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.93      0.79      0.85      1032\n",
      "           3       0.81      0.84      0.82      1010\n",
      "           4       0.83      0.82      0.82       982\n",
      "           5       0.85      0.65      0.73       892\n",
      "           6       0.90      0.87      0.88       958\n",
      "           7       0.94      0.85      0.89      1028\n",
      "           8       0.78      0.83      0.81       974\n",
      "           9       0.70      0.89      0.78      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 949    0    0    1    2   14    4    1    8    1]\n",
      " [   0 1114    3    5    0    0    4    0    8    1]\n",
      " [  29   11  816   14   27    7   22   23   77    6]\n",
      " [   5    1   10  844    2   32    4    9   74   29]\n",
      " [   4    3    2    1  804    0   19    1    6  142]\n",
      " [  21   17    1  144   20  578   30    3   36   42]\n",
      " [  31    4   25    2   28   24  830    1    9    4]\n",
      " [   7   21   17    0   11    1    0  871    8   92]\n",
      " [   7    9    3   17   21   18    8    5  813   73]\n",
      " [  12    5    5   12   54    7    1   10    4  899]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59850, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (160, 784) (160,)\n",
      "updated train set: (160, 784) (160,) unique(labels): [11  7 16 20 19 17 14 13 22 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59840, 784) (59840,)\n",
      "\n",
      "Train set: (160, 784) y: (160,)\n",
      "Val   set: (59840, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.017 s \n",
      "\n",
      "Accuracy rate for 86.000000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       980\n",
      "           1       0.94      0.98      0.96      1135\n",
      "           2       0.92      0.82      0.87      1032\n",
      "           3       0.84      0.79      0.81      1010\n",
      "           4       0.84      0.82      0.83       982\n",
      "           5       0.83      0.76      0.79       892\n",
      "           6       0.91      0.86      0.89       958\n",
      "           7       0.94      0.84      0.89      1028\n",
      "           8       0.77      0.85      0.81       974\n",
      "           9       0.72      0.88      0.79      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 947    0    0    6    1   15    4    1    5    1]\n",
      " [   0 1116    4    3    0    0    3    0    8    1]\n",
      " [  28    1  846   17   23    8   19   18   67    5]\n",
      " [   2    3    8  797    0   61    3   12   99   25]\n",
      " [   8    3    4    0  804    2   23    1    8  129]\n",
      " [  12   17    3   96   17  677   18    6   28   18]\n",
      " [  26    4   27    3   27   34  827    1    9    0]\n",
      " [   4   21   21    1   14    2    0  868    9   88]\n",
      " [   7   11    4   13   11   15   10    2  828   73]\n",
      " [  13    7    6   11   56    6    2   10    8  890]]\n",
      "--------------------------------\n",
      "val predicted: (59840,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59840, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (160, 784) (160,)\n",
      "trainset after (170, 784) (170,)\n",
      "updated train set: (170, 784) (170,) unique(labels): [11  7 18 20 21 18 14 15 23 23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59830, 784) (59830,)\n",
      "\n",
      "Train set: (170, 784) y: (170,)\n",
      "Val   set: (59830, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.952 s \n",
      "\n",
      "Accuracy rate for 84.940000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       980\n",
      "           1       0.96      0.97      0.97      1135\n",
      "           2       0.91      0.76      0.83      1032\n",
      "           3       0.83      0.80      0.81      1010\n",
      "           4       0.78      0.85      0.81       982\n",
      "           5       0.84      0.72      0.77       892\n",
      "           6       0.92      0.85      0.88       958\n",
      "           7       0.94      0.87      0.90      1028\n",
      "           8       0.74      0.84      0.79       974\n",
      "           9       0.70      0.86      0.78      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 940    0    3    8    3   11    5    1    8    1]\n",
      " [   0 1106    5    2    0    1    5    2    8    6]\n",
      " [  22    3  785   26   34    5   18   26  102   11]\n",
      " [   4    1    9  803    2   53    2    9   90   37]\n",
      " [   2    2    2    0  832    3   11    0    7  123]\n",
      " [  15   13    1  110   37  638   20    6   32   20]\n",
      " [  23    4   30    2   43   25  815    0   14    2]\n",
      " [   3   11   18    0   17    0    0  891   11   77]\n",
      " [   5    5    5   14   15   16    8    4  814   88]\n",
      " [   8    6    3    5   90    7    0   12    8  870]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59830,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59830, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (170, 784) (170,)\n",
      "trainset after (180, 784) (180,)\n",
      "updated train set: (180, 784) (180,) unique(labels): [12  7 22 20 21 19 14 16 26 23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59820, 784) (59820,)\n",
      "\n",
      "Train set: (180, 784) y: (180,)\n",
      "Val   set: (59820, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.116 s \n",
      "\n",
      "Accuracy rate for 86.070000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       980\n",
      "           1       0.97      0.97      0.97      1135\n",
      "           2       0.88      0.84      0.86      1032\n",
      "           3       0.89      0.75      0.82      1010\n",
      "           4       0.78      0.87      0.82       982\n",
      "           5       0.88      0.75      0.81       892\n",
      "           6       0.94      0.82      0.88       958\n",
      "           7       0.92      0.89      0.90      1028\n",
      "           8       0.72      0.88      0.79       974\n",
      "           9       0.78      0.84      0.81      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 948    0    5    1    3    9    4    2    7    1]\n",
      " [   0 1105    5    1    0    1    3    3   17    0]\n",
      " [  25    0  865    5   25    4    6   24   75    3]\n",
      " [   7    3   21  762    2   36    1   13  138   27]\n",
      " [   2    2    3    1  856    3   11    1   14   89]\n",
      " [  20    6    8   77   31  671   15    9   42   13]\n",
      " [  21    2   48    1   60   22  784    0   20    0]\n",
      " [   4   13   21    0   15    0    0  910   15   50]\n",
      " [   7    4    8    1   21    7    5    4  855   62]\n",
      " [  10    6    1    4   91   12    2   21   11  851]]\n",
      "--------------------------------\n",
      "val predicted: (59820,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59820, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (180, 784) (180,)\n",
      "trainset after (190, 784) (190,)\n",
      "updated train set: (190, 784) (190,) unique(labels): [12  7 22 21 24 21 16 16 26 25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59810, 784) (59810,)\n",
      "\n",
      "Train set: (190, 784) y: (190,)\n",
      "Val   set: (59810, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.060 s \n",
      "\n",
      "Accuracy rate for 86.980000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       980\n",
      "           1       0.98      0.97      0.97      1135\n",
      "           2       0.89      0.85      0.87      1032\n",
      "           3       0.90      0.77      0.83      1010\n",
      "           4       0.81      0.86      0.84       982\n",
      "           5       0.88      0.78      0.83       892\n",
      "           6       0.93      0.86      0.90       958\n",
      "           7       0.93      0.88      0.90      1028\n",
      "           8       0.74      0.88      0.80       974\n",
      "           9       0.76      0.86      0.81      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 946    0    5    1    5    6    4    4    8    1]\n",
      " [   0 1102    6    3    0    3    2    2   15    2]\n",
      " [  19    0  876    4   20    5   10   23   68    7]\n",
      " [   7    0   25  773    1   34    2   10  124   34]\n",
      " [   2    0    2    0  848    2   12    0   12  104]\n",
      " [  17    4    4   71   18  699   19    9   33   18]\n",
      " [  20    2   36    1   41   23  825    0   10    0]\n",
      " [   5   14   16    0   12    0    0  906   13   62]\n",
      " [   5    3    9    4   16   15    9    6  853   54]\n",
      " [  12    5    2    3   81    6    2   15   13  870]]\n",
      "--------------------------------\n",
      "val predicted: (59810,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59810, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (190, 784) (190,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [12  7 23 22 26 22 18 17 28 25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.208 s \n",
      "\n",
      "Accuracy rate for 86.560000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       980\n",
      "           1       0.98      0.96      0.97      1135\n",
      "           2       0.92      0.83      0.87      1032\n",
      "           3       0.88      0.73      0.80      1010\n",
      "           4       0.78      0.90      0.84       982\n",
      "           5       0.82      0.80      0.81       892\n",
      "           6       0.94      0.86      0.89       958\n",
      "           7       0.92      0.89      0.90      1028\n",
      "           8       0.72      0.90      0.80       974\n",
      "           9       0.80      0.83      0.82      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 935    0    3    2    4   16    7    3    9    1]\n",
      " [   0 1084    9    4    0    5    1   17   15    0]\n",
      " [  21    1  859    6   26    7    3   19   86    4]\n",
      " [   2    0   18  736    1   79    0   13  137   24]\n",
      " [   3    0    0    0  885    1    9    1   13   70]\n",
      " [  13    3    0   74   18  715   24    8   25   12]\n",
      " [  15    2   29    2   66   16  821    0    7    0]\n",
      " [   4   12   10    0   13    0    0  914   27   48]\n",
      " [   6    0    3    8   11   16   10    4  872   44]\n",
      " [   9    3    1    2  107   15    3   18   16  835]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (210, 784) (210,)\n",
      "updated train set: (210, 784) (210,) unique(labels): [13  7 26 24 26 23 18 19 29 25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59790, 784) (59790,)\n",
      "\n",
      "Train set: (210, 784) y: (210,)\n",
      "Val   set: (59790, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 21\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.144 s \n",
      "\n",
      "Accuracy rate for 88.030000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       980\n",
      "           1       0.97      0.96      0.97      1135\n",
      "           2       0.87      0.88      0.88      1032\n",
      "           3       0.90      0.82      0.86      1010\n",
      "           4       0.79      0.90      0.84       982\n",
      "           5       0.89      0.81      0.85       892\n",
      "           6       0.92      0.87      0.89       958\n",
      "           7       0.90      0.88      0.89      1028\n",
      "           8       0.83      0.86      0.84       974\n",
      "           9       0.79      0.83      0.81      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 943    0    6    0    2   11    9    2    6    1]\n",
      " [   0 1089    6    4    0    2    3   21    8    2]\n",
      " [   7    0  912    8   27    5    9   22   41    1]\n",
      " [   2    0   23  833    1   39    2   16   71   23]\n",
      " [   2    1    1    1  886    1   14    2    3   71]\n",
      " [  11    5    3   59   22  722   23    8   22   17]\n",
      " [  10    2   43    3   56    8  832    0    4    0]\n",
      " [   3   11   39    0    8    0    0  909   11   47]\n",
      " [   4    7   11   12   10   12   15    6  840   57]\n",
      " [   7    4    4    5  108   10    2   23    9  837]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59790,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59790, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (210, 784) (210,)\n",
      "trainset after (220, 784) (220,)\n",
      "updated train set: (220, 784) (220,) unique(labels): [13  7 27 24 26 24 19 20 34 26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59780, 784) (59780,)\n",
      "\n",
      "Train set: (220, 784) y: (220,)\n",
      "Val   set: (59780, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 22\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.321 s \n",
      "\n",
      "Accuracy rate for 87.930000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       980\n",
      "           1       0.98      0.96      0.97      1135\n",
      "           2       0.89      0.86      0.88      1032\n",
      "           3       0.92      0.77      0.84      1010\n",
      "           4       0.81      0.89      0.85       982\n",
      "           5       0.90      0.80      0.85       892\n",
      "           6       0.93      0.86      0.90       958\n",
      "           7       0.93      0.89      0.91      1028\n",
      "           8       0.73      0.91      0.81       974\n",
      "           9       0.80      0.86      0.83      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 942    0    6    0    6    8    8    1    8    1]\n",
      " [   0 1086    8    3    0    2    4    1   27    4]\n",
      " [  11    0  889    4   24    4    8   20   67    5]\n",
      " [   4    0   21  780    2   37    0   16  130   20]\n",
      " [   2    0    5    0  878    0    7    1   12   77]\n",
      " [  13    2    3   49   19  716   21    9   33   27]\n",
      " [  14    1   38    1   55   11  828    0    9    1]\n",
      " [   4   10   19    0   10    0    0  920   15   50]\n",
      " [   1    2    7    7   11    8   10    6  889   33]\n",
      " [   7    2    1    3   80    8    1   17   25  865]]\n",
      "--------------------------------\n",
      "val predicted: (59780,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59780, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (220, 784) (220,)\n",
      "trainset after (230, 784) (230,)\n",
      "updated train set: (230, 784) (230,) unique(labels): [13  7 29 26 28 26 21 20 34 26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59770, 784) (59770,)\n",
      "\n",
      "Train set: (230, 784) y: (230,)\n",
      "Val   set: (59770, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 23\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.249 s \n",
      "\n",
      "Accuracy rate for 88.530000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       980\n",
      "           1       0.98      0.93      0.95      1135\n",
      "           2       0.90      0.89      0.89      1032\n",
      "           3       0.93      0.78      0.84      1010\n",
      "           4       0.82      0.92      0.87       982\n",
      "           5       0.86      0.84      0.85       892\n",
      "           6       0.93      0.89      0.91       958\n",
      "           7       0.90      0.89      0.90      1028\n",
      "           8       0.76      0.92      0.83       974\n",
      "           9       0.85      0.83      0.84      1009\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.88      0.88     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 949    0    2    0    4    7    6    1   11    0]\n",
      " [   0 1053   20    3    0    2    7   21   28    1]\n",
      " [  14    0  920    7   12    2    5   19   51    2]\n",
      " [   4    0   21  784    1   69    0   17   99   15]\n",
      " [   1    0    2    0  899    0   14    1   15   50]\n",
      " [   6    3    3   41   17  751   21    7   30   13]\n",
      " [  21    1   25    1   34   16  849    0   11    0]\n",
      " [   6   10   23    1   10    0    0  920   13   45]\n",
      " [   1    3    7    6   13    8    8    8  895   25]\n",
      " [   8    5    2    3  100   14    0   23   21  833]]\n",
      "--------------------------------\n",
      "val predicted: (59770,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59770, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (230, 784) (230,)\n",
      "trainset after (240, 784) (240,)\n",
      "updated train set: (240, 784) (240,) unique(labels): [13  7 29 28 29 29 22 20 35 28] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59760, 784) (59760,)\n",
      "\n",
      "Train set: (240, 784) y: (240,)\n",
      "Val   set: (59760, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 24\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.408 s \n",
      "\n",
      "Accuracy rate for 89.200000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       980\n",
      "           1       0.98      0.96      0.97      1135\n",
      "           2       0.92      0.87      0.89      1032\n",
      "           3       0.92      0.81      0.86      1010\n",
      "           4       0.84      0.92      0.88       982\n",
      "           5       0.85      0.84      0.84       892\n",
      "           6       0.91      0.91      0.91       958\n",
      "           7       0.93      0.88      0.91      1028\n",
      "           8       0.80      0.90      0.85       974\n",
      "           9       0.83      0.85      0.84      1009\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 946    0    0    1    2    9   12    1    9    0]\n",
      " [   0 1090    6    2    0    1    7    5   22    2]\n",
      " [  11    0  893   15   18    2    8   19   61    5]\n",
      " [   1    0   18  821    0   85    2    9   53   21]\n",
      " [   2    0    3    0  902    0   15    1   14   45]\n",
      " [   8    3    1   38   16  751   26    8   21   20]\n",
      " [  19    2   17    3   27    9  873    0    6    2]\n",
      " [   5   10   23    1    9    1    0  909   13   57]\n",
      " [   2    0    6   11   14   17   15    5  879   25]\n",
      " [   7    4    2    4   91   12    1   18   14  856]]\n",
      "--------------------------------\n",
      "val predicted: (59760,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59760, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (240, 784) (240,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [13  7 31 31 29 31 23 21 36 28] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 25\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.329 s \n",
      "\n",
      "Accuracy rate for 89.200000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       980\n",
      "           1       0.99      0.93      0.96      1135\n",
      "           2       0.87      0.88      0.88      1032\n",
      "           3       0.92      0.86      0.89      1010\n",
      "           4       0.82      0.93      0.87       982\n",
      "           5       0.86      0.87      0.87       892\n",
      "           6       0.90      0.91      0.90       958\n",
      "           7       0.91      0.89      0.90      1028\n",
      "           8       0.82      0.87      0.84       974\n",
      "           9       0.86      0.84      0.85      1009\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 934    0    4    1    3   21    9    2    6    0]\n",
      " [   0 1057   28    3    0    2   10   20   14    1]\n",
      " [   9    0  905   10   12    3   11   23   56    3]\n",
      " [   1    0   22  868    2   43    1   13   48   12]\n",
      " [   1    0    5    0  911    1   13    2   13   36]\n",
      " [   4    1    3   37   17  774   20    4   17   15]\n",
      " [   8    1   27    0   35   14  868    0    5    0]\n",
      " [   3    9   27    3   12    2    0  915   11   46]\n",
      " [   0    0   11   15   13   25   29    7  844   30]\n",
      " [   3    5    3    7  102   12    4   15   14  844]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (260, 784) (260,)\n",
      "updated train set: (260, 784) (260,) unique(labels): [13  8 31 32 29 33 25 22 38 29] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59740, 784) (59740,)\n",
      "\n",
      "Train set: (260, 784) y: (260,)\n",
      "Val   set: (59740, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 26\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.489 s \n",
      "\n",
      "Accuracy rate for 89.710000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       980\n",
      "           1       0.98      0.97      0.97      1135\n",
      "           2       0.91      0.88      0.89      1032\n",
      "           3       0.92      0.84      0.87      1010\n",
      "           4       0.84      0.93      0.88       982\n",
      "           5       0.83      0.88      0.86       892\n",
      "           6       0.90      0.93      0.91       958\n",
      "           7       0.94      0.88      0.91      1028\n",
      "           8       0.83      0.88      0.86       974\n",
      "           9       0.85      0.84      0.84      1009\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 921    0    7    1    3   20   21    1    5    1]\n",
      " [   0 1098    3    3    0    4    5    0   20    2]\n",
      " [   8    0  910   12    9    3   13   18   55    4]\n",
      " [   2    0   25  844    0   77    4   13   36    9]\n",
      " [   1    1    3    0  915    0   17    4    9   32]\n",
      " [   1    3    4   32   14  785   18    5   16   14]\n",
      " [   4    2   16    1   26   17  888    0    4    0]\n",
      " [   2   11   25    1   12    2    0  903    9   63]\n",
      " [   1    1    5   17   16   28   15    4  856   31]\n",
      " [   2    5    4    9   96    7    5   14   16  851]]\n",
      "--------------------------------\n",
      "val predicted: (59740,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59740, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (260, 784) (260,)\n",
      "trainset after (270, 784) (270,)\n",
      "updated train set: (270, 784) (270,) unique(labels): [13  8 32 35 30 35 25 24 38 30] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59730, 784) (59730,)\n",
      "\n",
      "Train set: (270, 784) y: (270,)\n",
      "Val   set: (59730, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 27\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.390 s \n",
      "\n",
      "Accuracy rate for 90.120000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       980\n",
      "           1       0.98      0.95      0.97      1135\n",
      "           2       0.93      0.88      0.90      1032\n",
      "           3       0.89      0.89      0.89      1010\n",
      "           4       0.86      0.92      0.89       982\n",
      "           5       0.85      0.86      0.86       892\n",
      "           6       0.90      0.93      0.91       958\n",
      "           7       0.92      0.89      0.91      1028\n",
      "           8       0.85      0.87      0.86       974\n",
      "           9       0.85      0.86      0.85      1009\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 920    0    3    1    2   29   19    1    4    1]\n",
      " [   0 1083    2    6    1    3   10    5   25    0]\n",
      " [   8    0  909   13   11    8    9   27   45    2]\n",
      " [   2    0   16  898    1   40    3   13   26   11]\n",
      " [   1    0    3    1  907    0   16    4   12   38]\n",
      " [   2    3    1   54   15  771   16    9    8   13]\n",
      " [   3    2   13    2   17   26  887    0    8    0]\n",
      " [   2   11   24    2    8    0    0  920    7   54]\n",
      " [   2    1    4   21   16   22   17    4  849   38]\n",
      " [   3    5    3    8   73   12    8   17   12  868]]\n",
      "--------------------------------\n",
      "val predicted: (59730,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59730, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (270, 784) (270,)\n",
      "trainset after (280, 784) (280,)\n",
      "updated train set: (280, 784) (280,) unique(labels): [16  8 35 35 30 35 25 25 40 31] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59720, 784) (59720,)\n",
      "\n",
      "Train set: (280, 784) y: (280,)\n",
      "Val   set: (59720, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 28\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.630 s \n",
      "\n",
      "Accuracy rate for 90.570000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       980\n",
      "           1       0.98      0.96      0.97      1135\n",
      "           2       0.93      0.88      0.90      1032\n",
      "           3       0.92      0.87      0.89      1010\n",
      "           4       0.89      0.90      0.89       982\n",
      "           5       0.87      0.86      0.86       892\n",
      "           6       0.92      0.92      0.92       958\n",
      "           7       0.92      0.91      0.91      1028\n",
      "           8       0.82      0.90      0.86       974\n",
      "           9       0.85      0.88      0.87      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.90      0.90     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 941    0    1    0    2   12   10    2   11    1]\n",
      " [   0 1092    2    5    0    2    9    3   21    1]\n",
      " [  11    0  907    9   10    4   12   21   54    4]\n",
      " [   4    0   17  875    2   50    2   13   38    9]\n",
      " [   1    0    4    0  883    0   13    2   20   59]\n",
      " [   6    3    4   41   12  768   16    9   19   14]\n",
      " [   7    2   14    0   20   22  886    0    7    0]\n",
      " [   2   11   20    1    9    1    0  933    9   42]\n",
      " [   0    1    4   19    7   13   17    7  881   25]\n",
      " [   3    4    4    6   51   14    3   24    9  891]]\n",
      "--------------------------------\n",
      "val predicted: (59720,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59720, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (280, 784) (280,)\n",
      "trainset after (290, 784) (290,)\n",
      "updated train set: (290, 784) (290,) unique(labels): [16  9 36 36 32 39 25 25 41 31] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59710, 784) (59710,)\n",
      "\n",
      "Train set: (290, 784) y: (290,)\n",
      "Val   set: (59710, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 29\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.519 s \n",
      "\n",
      "Accuracy rate for 90.240000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.98      0.96      0.97      1135\n",
      "           2       0.91      0.89      0.90      1032\n",
      "           3       0.93      0.84      0.88      1010\n",
      "           4       0.86      0.91      0.89       982\n",
      "           5       0.82      0.89      0.85       892\n",
      "           6       0.92      0.91      0.92       958\n",
      "           7       0.92      0.89      0.91      1028\n",
      "           8       0.85      0.89      0.87       974\n",
      "           9       0.86      0.86      0.86      1009\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 937    0    3    3    2   20    9    1    5    0]\n",
      " [   0 1095    2    6    0    4    8    2   18    0]\n",
      " [   9    0  922    9    7    7   10   23   42    3]\n",
      " [   3    0   24  848    0   70    2   14   40    9]\n",
      " [   1    1    6    0  896    1   18    3    9   47]\n",
      " [   6    3    3   32   13  795   11    7   15    7]\n",
      " [  10    1   17    2   21   32  871    0    4    0]\n",
      " [   3   11   25    0   13    1    0  918    6   51]\n",
      " [   1    4    5    9   13   27   14    4  870   27]\n",
      " [   6    4    4    7   72   11    2   22    9  872]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59710,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59710, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (290, 784) (290,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [17  9 36 39 33 39 26 25 42 34] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 30\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.679 s \n",
      "\n",
      "Accuracy rate for 90.490000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.98      0.96      0.97      1135\n",
      "           2       0.92      0.88      0.90      1032\n",
      "           3       0.89      0.89      0.89      1010\n",
      "           4       0.86      0.93      0.90       982\n",
      "           5       0.87      0.87      0.87       892\n",
      "           6       0.94      0.91      0.93       958\n",
      "           7       0.93      0.89      0.91      1028\n",
      "           8       0.83      0.88      0.86       974\n",
      "           9       0.86      0.86      0.86      1009\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.91      0.90      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 937    0    4    0    2   19   10    1    5    2]\n",
      " [   0 1093    3    7    0    2    5    2   23    0]\n",
      " [  11    1  911   23   10    2    5   18   49    2]\n",
      " [   2    0   18  898    1   38    1   17   26    9]\n",
      " [   1    0    7    0  917    0   13    3   13   28]\n",
      " [   7    3    2   38   17  774    9    5   24   13]\n",
      " [   4    1   15    3   21   30  875    0    9    0]\n",
      " [   4   10   23    3   11    0    0  915   11   51]\n",
      " [   1    3    4   25   18   19    9    3  858   34]\n",
      " [   6    6    4   11   67    8    4   21   11  871]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59700, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (310, 784) (310,)\n",
      "updated train set: (310, 784) (310,) unique(labels): [17 10 40 39 33 40 27 25 44 35] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59690, 784) (59690,)\n",
      "\n",
      "Train set: (310, 784) y: (310,)\n",
      "Val   set: (59690, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 31\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.605 s \n",
      "\n",
      "Accuracy rate for 90.610000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       980\n",
      "           1       0.97      0.97      0.97      1135\n",
      "           2       0.90      0.91      0.91      1032\n",
      "           3       0.93      0.86      0.89      1010\n",
      "           4       0.88      0.90      0.89       982\n",
      "           5       0.85      0.87      0.86       892\n",
      "           6       0.93      0.91      0.92       958\n",
      "           7       0.94      0.89      0.91      1028\n",
      "           8       0.85      0.90      0.88       974\n",
      "           9       0.83      0.89      0.86      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 927    0    4    2    2   20   15    1    8    1]\n",
      " [   0 1102    4    2    0    2    4    1   19    1]\n",
      " [  10    1  944    8    8    4    7   18   30    2]\n",
      " [   1    0   21  870    1   52    1   14   39   11]\n",
      " [   1    1    7    0  886    2   17    3   13   52]\n",
      " [   7    7    4   38   10  780    6    3   20   17]\n",
      " [   8    2   22    0   18   33  868    0    7    0]\n",
      " [   3   11   28    0   10    1    0  913    5   57]\n",
      " [   0    4   10   11   11   10    9    5  876   38]\n",
      " [   5    5    4    4   57   11    3   16    9  895]]\n",
      "--------------------------------\n",
      "val predicted: (59690,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59690, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (310, 784) (310,)\n",
      "trainset after (320, 784) (320,)\n",
      "updated train set: (320, 784) (320,) unique(labels): [18 10 42 41 34 42 27 25 44 37] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59680, 784) (59680,)\n",
      "\n",
      "Train set: (320, 784) y: (320,)\n",
      "Val   set: (59680, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 32\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.689 s \n",
      "\n",
      "Accuracy rate for 91.090000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.87      0.93      0.90      1032\n",
      "           3       0.94      0.87      0.90      1010\n",
      "           4       0.91      0.92      0.91       982\n",
      "           5       0.85      0.90      0.87       892\n",
      "           6       0.94      0.90      0.92       958\n",
      "           7       0.95      0.88      0.91      1028\n",
      "           8       0.89      0.88      0.88       974\n",
      "           9       0.83      0.90      0.86      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 924    0    7    2    1   25   13    1    6    1]\n",
      " [   0 1110    4    1    0    4    5    1    9    1]\n",
      " [   9    0  960    8    9    3    7   10   24    2]\n",
      " [   1    0   34  881    0   42    2   10   28   12]\n",
      " [   1    0    9    0  904    1   11    2    7   47]\n",
      " [   7    3    5   27    7  801    9    8   12   13]\n",
      " [   4    2   25    1   20   33  866    0    7    0]\n",
      " [   6   12   36    1    5    0    0  903    5   60]\n",
      " [   1    5   11   12   11   28    6    2  855   43]\n",
      " [   4    6    7    8   41   10    1   16   11  905]]\n",
      "--------------------------------\n",
      "val predicted: (59680,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59680, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (320, 784) (320,)\n",
      "trainset after (330, 784) (330,)\n",
      "updated train set: (330, 784) (330,) unique(labels): [19 10 42 43 35 43 28 25 46 39] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59670, 784) (59670,)\n",
      "\n",
      "Train set: (330, 784) y: (330,)\n",
      "Val   set: (59670, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 33\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.614 s \n",
      "\n",
      "Accuracy rate for 91.300000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       980\n",
      "           1       0.98      0.97      0.97      1135\n",
      "           2       0.90      0.92      0.91      1032\n",
      "           3       0.93      0.89      0.91      1010\n",
      "           4       0.90      0.91      0.90       982\n",
      "           5       0.88      0.90      0.89       892\n",
      "           6       0.92      0.92      0.92       958\n",
      "           7       0.96      0.86      0.91      1028\n",
      "           8       0.87      0.89      0.88       974\n",
      "           9       0.83      0.90      0.87      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 945    0    3    1    1    8   13    1    8    0]\n",
      " [   0 1100    3    4    0    4    5    1   17    1]\n",
      " [  10    0  945    8   10    4   11   10   28    6]\n",
      " [   1    0   26  901    0   34    2    9   27   10]\n",
      " [   1    0    6    1  893    0   18    1    9   53]\n",
      " [   4    4    3   33    9  805    8    2   13   11]\n",
      " [   7    2   15    1   13   30  881    0    9    0]\n",
      " [   7   13   37    2    8    0    1  881    9   70]\n",
      " [   1    3    9   15   13   15   11    4  868   35]\n",
      " [   3    6    2    8   47   11    5    5   11  911]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59670,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59670, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (330, 784) (330,)\n",
      "trainset after (340, 784) (340,)\n",
      "updated train set: (340, 784) (340,) unique(labels): [19 13 42 44 35 44 29 27 46 41] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59660, 784) (59660,)\n",
      "\n",
      "Train set: (340, 784) y: (340,)\n",
      "Val   set: (59660, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 34\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.739 s \n",
      "\n",
      "Accuracy rate for 91.070000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.89      0.92      0.91      1032\n",
      "           3       0.92      0.88      0.90      1010\n",
      "           4       0.89      0.91      0.90       982\n",
      "           5       0.87      0.89      0.88       892\n",
      "           6       0.92      0.91      0.91       958\n",
      "           7       0.95      0.88      0.91      1028\n",
      "           8       0.90      0.87      0.88       974\n",
      "           9       0.84      0.90      0.87      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 933    0    5    0    2   15   18    1    6    0]\n",
      " [   0 1116    5    2    0    3    2    0    6    1]\n",
      " [  10    4  952    9    9    5    9   11   20    3]\n",
      " [   3    0   34  889    1   41    3   11   19    9]\n",
      " [   1    1    6    0  897    0   17    1    7   52]\n",
      " [   6    5    3   33    9  791   12    3   17   13]\n",
      " [   6    4   19    1   20   32  870    0    6    0]\n",
      " [   5   15   33    2   12    0    0  901    7   53]\n",
      " [   1    6   10   23   14   18    9    4  846   43]\n",
      " [   4    8    4    6   41    9    5   14    6  912]]\n",
      "--------------------------------\n",
      "val predicted: (59660,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59660, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (340, 784) (340,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [19 14 42 45 39 45 29 28 46 43] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 35\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.683 s \n",
      "\n",
      "Accuracy rate for 90.930000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.90      0.91      0.91      1032\n",
      "           3       0.91      0.88      0.90      1010\n",
      "           4       0.89      0.92      0.90       982\n",
      "           5       0.87      0.89      0.88       892\n",
      "           6       0.93      0.91      0.92       958\n",
      "           7       0.94      0.88      0.91      1028\n",
      "           8       0.90      0.85      0.87       974\n",
      "           9       0.83      0.90      0.87      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 941    0    5    1    1   11   13    1    7    0]\n",
      " [   0 1116    3    1    0    4    3    1    7    0]\n",
      " [  10    7  944    9    8    1    8   17   23    5]\n",
      " [   2    4   28  891    0   39    2   15   19   10]\n",
      " [   1    1    6    1  900    1   13    3    6   50]\n",
      " [   7    7    1   40    6  791   11    7   12   10]\n",
      " [   9    5   20    0   18   31  868    1    6    0]\n",
      " [   4   16   33    1    6    0    0  904    8   56]\n",
      " [   1    4    6   24   16   27   13    3  830   50]\n",
      " [   4    7    3    7   54    6    2   11    7  908]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59650, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (360, 784) (360,)\n",
      "updated train set: (360, 784) (360,) unique(labels): [20 15 42 46 39 47 30 29 47 45] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59640, 784) (59640,)\n",
      "\n",
      "Train set: (360, 784) y: (360,)\n",
      "Val   set: (59640, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 36\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.848 s \n",
      "\n",
      "Accuracy rate for 91.170000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       980\n",
      "           1       0.95      0.99      0.97      1135\n",
      "           2       0.90      0.91      0.91      1032\n",
      "           3       0.94      0.88      0.91      1010\n",
      "           4       0.88      0.91      0.89       982\n",
      "           5       0.87      0.91      0.89       892\n",
      "           6       0.93      0.90      0.92       958\n",
      "           7       0.95      0.88      0.91      1028\n",
      "           8       0.91      0.85      0.88       974\n",
      "           9       0.84      0.91      0.87      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 947    0    3    1    2   12    8    1    5    1]\n",
      " [   0 1119    5    1    0    3    3    1    3    0]\n",
      " [  10    7  943    7    7    5    9   16   23    5]\n",
      " [   4    5   32  885    3   39    1   13   21    7]\n",
      " [   1    3    4    0  893    1   15    2    7   56]\n",
      " [   7    5    3   22    9  813   10    4    9   10]\n",
      " [  13    5   18    1   21   31  866    0    3    0]\n",
      " [   3   17   33    2   10    0    0  906    7   50]\n",
      " [   1    9    8   17   20   27   14    4  829   45]\n",
      " [   4    8    2    6   52    5    2    9    5  916]]\n",
      "--------------------------------\n",
      "val predicted: (59640,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59640, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (360, 784) (360,)\n",
      "trainset after (370, 784) (370,)\n",
      "updated train set: (370, 784) (370,) unique(labels): [20 15 44 46 39 51 31 29 49 46] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59630, 784) (59630,)\n",
      "\n",
      "Train set: (370, 784) y: (370,)\n",
      "Val   set: (59630, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 37\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.759 s \n",
      "\n",
      "Accuracy rate for 90.960000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.91      0.91      0.91      1032\n",
      "           3       0.94      0.89      0.91      1010\n",
      "           4       0.88      0.90      0.89       982\n",
      "           5       0.83      0.93      0.88       892\n",
      "           6       0.94      0.89      0.91       958\n",
      "           7       0.95      0.88      0.91      1028\n",
      "           8       0.92      0.85      0.88       974\n",
      "           9       0.82      0.90      0.86      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 939    0    4    2    2   17   10    1    3    2]\n",
      " [   0 1117    3    1    0    7    2    0    4    1]\n",
      " [  11    7  935    7   11    7    9   18   23    4]\n",
      " [   1    3   23  897    0   44    2   11   20    9]\n",
      " [   2    2    3    0  881    4   17    2    7   64]\n",
      " [   6    3    2   23    2  832    6    2    6   10]\n",
      " [  10    5   14    1   18   52  852    0    4    2]\n",
      " [   4   14   38    2   11    0    0  902    4   53]\n",
      " [   1    8    5   14   17   29    7    3  830   60]\n",
      " [   3    8    1    8   58    8    2    6    4  911]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59630,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59630, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (370, 784) (370,)\n",
      "trainset after (380, 784) (380,)\n",
      "updated train set: (380, 784) (380,) unique(labels): [21 15 45 47 41 52 31 32 50 46] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59620, 784) (59620,)\n",
      "\n",
      "Train set: (380, 784) y: (380,)\n",
      "Val   set: (59620, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 38\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.887 s \n",
      "\n",
      "Accuracy rate for 91.380000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.96      0.99      0.97      1135\n",
      "           2       0.90      0.92      0.91      1032\n",
      "           3       0.95      0.88      0.92      1010\n",
      "           4       0.90      0.90      0.90       982\n",
      "           5       0.84      0.94      0.89       892\n",
      "           6       0.94      0.89      0.91       958\n",
      "           7       0.95      0.89      0.92      1028\n",
      "           8       0.91      0.87      0.89       974\n",
      "           9       0.83      0.90      0.86      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.92      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 943    0    4    0    1   16    9    1    5    1]\n",
      " [   0 1119    4    1    0    5    3    0    2    1]\n",
      " [  11    8  948    7    3    5    7   17   21    5]\n",
      " [   3    1   32  890    1   47    0    9   17   10]\n",
      " [   1    2    4    0  884    3   16    3    7   62]\n",
      " [   7    2    1   17    2  840    7    2    7    7]\n",
      " [  12    5   19    1   21   42  850    1    7    0]\n",
      " [   3   14   30    2    5    1    0  910    7   56]\n",
      " [   1    8    7    8   13   27   11    5  846   48]\n",
      " [   4    8    2    7   51   12    2    7    8  908]]\n",
      "--------------------------------\n",
      "val predicted: (59620,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59620, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (380, 784) (380,)\n",
      "trainset after (390, 784) (390,)\n",
      "updated train set: (390, 784) (390,) unique(labels): [21 15 46 47 41 54 32 32 53 49] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59610, 784) (59610,)\n",
      "\n",
      "Train set: (390, 784) y: (390,)\n",
      "Val   set: (59610, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 39\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.820 s \n",
      "\n",
      "Accuracy rate for 90.840000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.92      0.91      0.91      1032\n",
      "           3       0.95      0.84      0.89      1010\n",
      "           4       0.91      0.87      0.89       982\n",
      "           5       0.80      0.94      0.86       892\n",
      "           6       0.95      0.90      0.92       958\n",
      "           7       0.95      0.89      0.92      1028\n",
      "           8       0.89      0.90      0.89       974\n",
      "           9       0.81      0.91      0.86      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 934    0    2    0    1   26   11    1    4    1]\n",
      " [   0 1113    3    1    0    4    4    0    8    2]\n",
      " [  10    7  937    7    6   10    6   15   29    5]\n",
      " [   4    0   23  846    0   80    1   14   29   13]\n",
      " [   1    2    5    0  850    4   14    2    6   98]\n",
      " [   6    2    2   20    2  838    3    2   10    7]\n",
      " [  10    5   11    0   13   52  859    1    7    0]\n",
      " [   3   14   32    1    3    1    0  911    8   55]\n",
      " [   0    8    3    8   11   21    3    4  874   42]\n",
      " [   4    6    4    3   43   10    3    6    8  922]]\n",
      "--------------------------------\n",
      "val predicted: (59610,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59610, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (390, 784) (390,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [21 15 46 49 45 54 33 32 54 51] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 40\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.967 s \n",
      "\n",
      "Accuracy rate for 91.720000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       980\n",
      "           1       0.97      0.98      0.97      1135\n",
      "           2       0.92      0.91      0.91      1032\n",
      "           3       0.94      0.88      0.91      1010\n",
      "           4       0.89      0.92      0.91       982\n",
      "           5       0.86      0.92      0.89       892\n",
      "           6       0.95      0.90      0.92       958\n",
      "           7       0.96      0.89      0.92      1028\n",
      "           8       0.90      0.89      0.89       974\n",
      "           9       0.85      0.90      0.87      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 941    0    2    1    1   15   12    1    5    2]\n",
      " [   0 1114    2    1    0    5    4    0    8    1]\n",
      " [  13    4  940    7    6    7    6   17   28    4]\n",
      " [   3    3   25  890    1   45    0   10   22   11]\n",
      " [   1    2    7    0  908    0   12    2    4   46]\n",
      " [   9    4    1   28    4  822    7    3    8    6]\n",
      " [  12    5   17    0   13   39  864    0    8    0]\n",
      " [   4   13   26    1    8    2    0  916   10   48]\n",
      " [   0    4    5   15   15   16    5    3  868   43]\n",
      " [   7    4    2    4   60    9    2    6    6  909]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59600, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (410, 784) (410,)\n",
      "updated train set: (410, 784) (410,) unique(labels): [22 15 47 51 47 54 33 34 54 53] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59590, 784) (59590,)\n",
      "\n",
      "Train set: (410, 784) y: (410,)\n",
      "Val   set: (59590, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 41\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.892 s \n",
      "\n",
      "Accuracy rate for 91.470000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.90      0.91      0.90      1032\n",
      "           3       0.94      0.87      0.90      1010\n",
      "           4       0.88      0.93      0.91       982\n",
      "           5       0.86      0.92      0.88       892\n",
      "           6       0.94      0.90      0.92       958\n",
      "           7       0.94      0.90      0.92      1028\n",
      "           8       0.90      0.89      0.89       974\n",
      "           9       0.85      0.89      0.87      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.92      0.91      0.91     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 933    0    5    0    1   18   15    1    5    2]\n",
      " [   0 1116    3    1    0    4    2    0    7    2]\n",
      " [  11    5  938   11    7    5    7   16   28    4]\n",
      " [   4    2   27  879    2   47    2   16   19   12]\n",
      " [   1    0    5    0  916    0   10    2    6   42]\n",
      " [   7    1    1   28    4  817    7    5    8   14]\n",
      " [   5    4   23    0   16   39  858    2   11    0]\n",
      " [   2   12   26    1    8    0    0  928    6   45]\n",
      " [   1    3    9   12   18   16    6    4  864   41]\n",
      " [   4    5    5    3   68    9    1    9    7  898]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59590,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59590, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (410, 784) (410,)\n",
      "trainset after (420, 784) (420,)\n",
      "updated train set: (420, 784) (420,) unique(labels): [23 15 48 53 47 55 34 35 57 53] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59580, 784) (59580,)\n",
      "\n",
      "Train set: (420, 784) y: (420,)\n",
      "Val   set: (59580, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 42\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.030 s \n",
      "\n",
      "Accuracy rate for 91.560000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.97      0.98      0.97      1135\n",
      "           2       0.91      0.91      0.91      1032\n",
      "           3       0.91      0.89      0.90      1010\n",
      "           4       0.90      0.92      0.91       982\n",
      "           5       0.89      0.87      0.88       892\n",
      "           6       0.95      0.91      0.93       958\n",
      "           7       0.95      0.89      0.92      1028\n",
      "           8       0.88      0.91      0.90       974\n",
      "           9       0.83      0.90      0.87      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.91      0.91     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 940    0    3    3    2   13   13    1    5    0]\n",
      " [   0 1108    4    1    0    3    4    0   13    2]\n",
      " [  13    5  937   11    6    3    7   15   30    5]\n",
      " [   0    2   24  900    1   32    0   11   31    9]\n",
      " [   1    0    5    1  900    0   11    2    8   54]\n",
      " [   6    1    2   58    4  778    4    2   19   18]\n",
      " [  10    6   16    1   12   31  873    3    5    1]\n",
      " [   3   12   30    1    5    0    0  919    5   53]\n",
      " [   0    4    4   10   10   10    6    3  888   39]\n",
      " [   7    6    2    6   55    5    2    7    6  913]]\n",
      "--------------------------------\n",
      "val predicted: (59580,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59580, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (420, 784) (420,)\n",
      "trainset after (430, 784) (430,)\n",
      "updated train set: (430, 784) (430,) unique(labels): [24 15 48 55 47 57 35 37 57 55] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59570, 784) (59570,)\n",
      "\n",
      "Train set: (430, 784) y: (430,)\n",
      "Val   set: (59570, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 43\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.934 s \n",
      "\n",
      "Accuracy rate for 92.010000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.92      0.91      0.91      1032\n",
      "           3       0.93      0.89      0.91      1010\n",
      "           4       0.91      0.92      0.92       982\n",
      "           5       0.87      0.91      0.89       892\n",
      "           6       0.95      0.92      0.94       958\n",
      "           7       0.94      0.90      0.92      1028\n",
      "           8       0.90      0.90      0.90       974\n",
      "           9       0.85      0.90      0.87      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 941    0    2    2    0   19    9    1    6    0]\n",
      " [   0 1113    4    1    0    5    2    0    9    1]\n",
      " [  11    7  935    8    6    4    6   19   32    4]\n",
      " [   2    2   23  899    0   39    1   12   21   11]\n",
      " [   1    1    4    0  903    2   11    3    6   51]\n",
      " [   4    1    2   38    4  816    8    3    8    8]\n",
      " [   5    5   12    0   11   34  884    0    6    1]\n",
      " [   3   13   27    1    5    1    0  923    8   47]\n",
      " [   0    9    4    9   11   14    6    5  874   42]\n",
      " [   4    7    2    7   47    9    3   12    5  913]]\n",
      "--------------------------------\n",
      "val predicted: (59570,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59570, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (430, 784) (430,)\n",
      "trainset after (440, 784) (440,)\n",
      "updated train set: (440, 784) (440,) unique(labels): [26 15 49 56 49 58 36 37 58 56] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59560, 784) (59560,)\n",
      "\n",
      "Train set: (440, 784) y: (440,)\n",
      "Val   set: (59560, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 44\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.095 s \n",
      "\n",
      "Accuracy rate for 91.940000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.97      0.98      0.97      1135\n",
      "           2       0.92      0.91      0.92      1032\n",
      "           3       0.93      0.90      0.92      1010\n",
      "           4       0.88      0.93      0.91       982\n",
      "           5       0.90      0.91      0.90       892\n",
      "           6       0.94      0.93      0.94       958\n",
      "           7       0.94      0.89      0.92      1028\n",
      "           8       0.90      0.89      0.89       974\n",
      "           9       0.84      0.88      0.86      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 940    0    3    2    0   13   13    1    7    1]\n",
      " [   0 1113    4    1    0    4    3    0    9    1]\n",
      " [   9    6  942    6    5    5    5   20   34    0]\n",
      " [   1    3   22  912    3   26    0   12   17   14]\n",
      " [   2    0    4    0  913    0   15    3    5   40]\n",
      " [   6    1    3   37    5  809    7    3    8   13]\n",
      " [  11    4   10    1   15   20  893    0    4    0]\n",
      " [   4   13   28    1    9    3    0  913    5   52]\n",
      " [   2    6    2   14   17   11    7    3  867   45]\n",
      " [   5    6    6    6   67    5    2   12    8  892]]\n",
      "--------------------------------\n",
      "val predicted: (59560,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59560, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (440, 784) (440,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [27 15 51 56 50 58 38 37 60 58] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 45\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.015 s \n",
      "\n",
      "Accuracy rate for 92.430000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.92      0.92      0.92      1032\n",
      "           3       0.94      0.89      0.91      1010\n",
      "           4       0.92      0.92      0.92       982\n",
      "           5       0.89      0.92      0.90       892\n",
      "           6       0.94      0.94      0.94       958\n",
      "           7       0.95      0.90      0.92      1028\n",
      "           8       0.91      0.90      0.91       974\n",
      "           9       0.84      0.92      0.87      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.93      0.92      0.92     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 939    0    3    1    0   17   14    1    4    1]\n",
      " [   0 1111    4    2    0    4    4    0    9    1]\n",
      " [  10    5  949   10    6    2   10   17   20    3]\n",
      " [   1    2   21  901    1   28    1   15   29   11]\n",
      " [   2    1    7    0  899    0   13    4    3   53]\n",
      " [   5    1    1   32    3  819    6    1    8   16]\n",
      " [   9    3   14    0   11   20  898    0    3    0]\n",
      " [   3   12   22    2    6    0    0  921    6   56]\n",
      " [   1    3    5    8   11   18    4    3  881   40]\n",
      " [   2    4    2    7   42   10    4    8    5  925]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59550,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59550, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (460, 784) (460,)\n",
      "updated train set: (460, 784) (460,) unique(labels): [30 15 51 56 53 60 39 37 60 59] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59540, 784) (59540,)\n",
      "\n",
      "Train set: (460, 784) y: (460,)\n",
      "Val   set: (59540, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 46\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.136 s \n",
      "\n",
      "Accuracy rate for 92.430000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.93      0.91      0.92      1032\n",
      "           3       0.92      0.91      0.92      1010\n",
      "           4       0.90      0.92      0.91       982\n",
      "           5       0.92      0.89      0.91       892\n",
      "           6       0.95      0.94      0.94       958\n",
      "           7       0.96      0.89      0.92      1028\n",
      "           8       0.92      0.90      0.91       974\n",
      "           9       0.84      0.90      0.87      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.93      0.92      0.92     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 961    0    1    0    0    6    5    0    6    1]\n",
      " [   0 1114    3    3    0    2    5    0    7    1]\n",
      " [  13    6  943    8    5    3    9   17   22    6]\n",
      " [   1    2   20  923    1   22    0   10   20   11]\n",
      " [   3    0    4    0  904    0    9    3    5   54]\n",
      " [  10    1    1   45    6  797   10    1    9   12]\n",
      " [  14    5    5    1   16   15  900    1    0    1]\n",
      " [   3   10   28    3    7    0    1  916    5   55]\n",
      " [   1    5    6   14   16   12    8    5  872   35]\n",
      " [   6    6    5    6   53    9    2    5    4  913]]\n",
      "--------------------------------\n",
      "val predicted: (59540,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59540, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (460, 784) (460,)\n",
      "trainset after (470, 784) (470,)\n",
      "updated train set: (470, 784) (470,) unique(labels): [30 15 52 58 53 62 39 39 62 60] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59530, 784) (59530,)\n",
      "\n",
      "Train set: (470, 784) y: (470,)\n",
      "Val   set: (59530, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 47\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.066 s \n",
      "\n",
      "Accuracy rate for 92.590000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.92      0.91      0.92      1032\n",
      "           3       0.93      0.91      0.92      1010\n",
      "           4       0.89      0.93      0.91       982\n",
      "           5       0.92      0.91      0.92       892\n",
      "           6       0.96      0.93      0.94       958\n",
      "           7       0.94      0.91      0.93      1028\n",
      "           8       0.90      0.90      0.90       974\n",
      "           9       0.87      0.88      0.87      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 960    0    2    1    0    6    5    1    5    0]\n",
      " [   0 1110    4    1    0    3    4    0   11    2]\n",
      " [  12    5  939    9    5    2    7   21   28    4]\n",
      " [   0    0   22  922    0   26    1   13   18    8]\n",
      " [   2    0    7    1  918    0    9    3    4   38]\n",
      " [   6    1    0   30    6  813   11    2   12   11]\n",
      " [  15    3    9    0   17   17  894    0    3    0]\n",
      " [   3   10   25    3    8    1    0  939    5   34]\n",
      " [   3    5    5   15   10   12    4    5  874   41]\n",
      " [   7    5    7    6   71    3    1   13    6  890]]\n",
      "--------------------------------\n",
      "val predicted: (59530,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59530, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (470, 784) (470,)\n",
      "trainset after (480, 784) (480,)\n",
      "updated train set: (480, 784) (480,) unique(labels): [30 15 53 60 53 65 40 40 62 62] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59520, 784) (59520,)\n",
      "\n",
      "Train set: (480, 784) y: (480,)\n",
      "Val   set: (59520, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 48\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.215 s \n",
      "\n",
      "Accuracy rate for 92.560000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.93      0.91      0.92      1032\n",
      "           3       0.93      0.91      0.92      1010\n",
      "           4       0.90      0.92      0.91       982\n",
      "           5       0.90      0.92      0.91       892\n",
      "           6       0.94      0.94      0.94       958\n",
      "           7       0.95      0.90      0.93      1028\n",
      "           8       0.91      0.88      0.90       974\n",
      "           9       0.84      0.92      0.88      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 957    0    1    1    0    7    8    1    5    0]\n",
      " [   0 1110    3    1    0    3    5    0   11    2]\n",
      " [   9    4  935    8    7    5    9   21   28    6]\n",
      " [   0    0   17  916    1   37    0   11   21    7]\n",
      " [   2    0    3    0  904    1   12    3    4   53]\n",
      " [   6    3    1   25    6  823    9    3    6   10]\n",
      " [   8    3    5    2   15   20  902    0    3    0]\n",
      " [   2    9   25    4    6    2    0  925    5   50]\n",
      " [   2    4   10   23   10   11    8    3  860   43]\n",
      " [   5    5    2    7   50    7    2    3    4  924]]\n",
      "--------------------------------\n",
      "val predicted: (59520,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59520, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (480, 784) (480,)\n",
      "trainset after (490, 784) (490,)\n",
      "updated train set: (490, 784) (490,) unique(labels): [30 16 56 61 53 65 40 42 64 63] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59510, 784) (59510,)\n",
      "\n",
      "Train set: (490, 784) y: (490,)\n",
      "Val   set: (59510, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 49\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.182 s \n",
      "\n",
      "Accuracy rate for 92.980000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.93      0.92      0.92      1032\n",
      "           3       0.93      0.91      0.92      1010\n",
      "           4       0.91      0.93      0.92       982\n",
      "           5       0.91      0.93      0.92       892\n",
      "           6       0.96      0.93      0.94       958\n",
      "           7       0.95      0.92      0.93      1028\n",
      "           8       0.91      0.90      0.91       974\n",
      "           9       0.87      0.90      0.89      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 956    0    4    2    0   10    3    1    4    0]\n",
      " [   0 1113    4    3    0    3    4    0    7    1]\n",
      " [  13    7  947   10    3    1    5   18   26    2]\n",
      " [   0    0   16  923    1   28    0   12   21    9]\n",
      " [   2    1    7    0  909    0   10    2    3   48]\n",
      " [   7    1    0   26    5  828    7    1   10    7]\n",
      " [   8    3   11    2   16   23  890    0    5    0]\n",
      " [   5   13   22    2    6    1    0  945    3   31]\n",
      " [   2    5    5   18   10   12    6    6  877   33]\n",
      " [   7    5    2    9   50    6    2   13    5  910]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59510,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59510, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (490, 784) (490,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [30 16 57 62 53 67 41 42 69 63] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 50\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 6.263 s \n",
      "\n",
      "Accuracy rate for 92.800000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       980\n",
      "           1       0.97      0.98      0.97      1135\n",
      "           2       0.93      0.92      0.92      1032\n",
      "           3       0.93      0.92      0.92      1010\n",
      "           4       0.90      0.92      0.91       982\n",
      "           5       0.91      0.92      0.92       892\n",
      "           6       0.95      0.94      0.94       958\n",
      "           7       0.94      0.91      0.93      1028\n",
      "           8       0.90      0.91      0.91       974\n",
      "           9       0.88      0.90      0.89      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 950    0    4    2    0   10    8    1    5    0]\n",
      " [   0 1108    6    1    0    4    3    0   12    1]\n",
      " [   9    9  947   13    4    2    5   19   19    5]\n",
      " [   0    0   18  926    1   25    2   12   20    6]\n",
      " [   2    0   11    0  902    0   10    4    8   45]\n",
      " [   8    3    3   27    6  817   10    2   11    5]\n",
      " [  10    3    9    0   16   17  897    0    6    0]\n",
      " [   6   13   20    3    7    1    0  938    5   35]\n",
      " [   2    4    2   21   11   11    5    5  885   28]\n",
      " [   6    4    3    6   50    6    1   14    9  910]]\n",
      "--------------------------------\n",
      "final active learning accuracies [26.56, 45.550000000000004, 56.82000000000001, 67.99, 67.67999999999999, 71.17, 76.08, 78.13, 79.38, 79.69000000000001, 81.76, 82.43, 83.47, 84.99, 85.18, 86.0, 84.94, 86.07000000000001, 86.98, 86.56, 88.03, 87.92999999999999, 88.53, 89.2, 89.2, 89.71000000000001, 90.12, 90.57, 90.24, 90.49000000000001, 90.61, 91.09, 91.3, 91.07, 90.93, 91.17, 90.96, 91.38, 90.84, 91.72, 91.47, 91.56, 92.01, 91.94, 92.43, 92.43, 92.58999999999999, 92.56, 92.97999999999999, 92.80000000000001]\n",
      "saved Active-learning-experiment-25.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "{\n",
      "  \"RfModel\": {\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          26.56,\n",
      "          45.550000000000004,\n",
      "          56.82000000000001,\n",
      "          67.99,\n",
      "          67.67999999999999,\n",
      "          71.17,\n",
      "          76.08,\n",
      "          78.13,\n",
      "          79.38,\n",
      "          79.69000000000001,\n",
      "          81.76,\n",
      "          82.43,\n",
      "          83.47,\n",
      "          84.99,\n",
      "          85.18,\n",
      "          86.0,\n",
      "          84.94,\n",
      "          86.07000000000001,\n",
      "          86.98,\n",
      "          86.56,\n",
      "          88.03,\n",
      "          87.92999999999999,\n",
      "          88.53,\n",
      "          89.2,\n",
      "          89.2,\n",
      "          89.71000000000001,\n",
      "          90.12,\n",
      "          90.57,\n",
      "          90.24,\n",
      "          90.49000000000001,\n",
      "          90.61,\n",
      "          91.09,\n",
      "          91.3,\n",
      "          91.07,\n",
      "          90.93,\n",
      "          91.17,\n",
      "          90.96,\n",
      "          91.38,\n",
      "          90.84,\n",
      "          91.72,\n",
      "          91.47,\n",
      "          91.56,\n",
      "          92.01,\n",
      "          91.94,\n",
      "          92.43,\n",
      "          92.43,\n",
      "          92.58999999999999,\n",
      "          92.56,\n",
      "          92.97999999999999,\n",
      "          92.80000000000001\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          73.39,\n",
      "          86.38,\n",
      "          90.11,\n",
      "          91.31\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          53.339999999999996,\n",
      "          63.85999999999999,\n",
      "          70.77,\n",
      "          75.53999999999999,\n",
      "          79.22,\n",
      "          83.19,\n",
      "          83.17999999999999,\n",
      "          84.82,\n",
      "          86.21,\n",
      "          86.72999999999999,\n",
      "          88.18,\n",
      "          89.2,\n",
      "          88.47,\n",
      "          89.64999999999999,\n",
      "          90.2,\n",
      "          90.68,\n",
      "          91.56,\n",
      "          91.64,\n",
      "          92.10000000000001,\n",
      "          92.30000000000001\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          80.64,\n",
      "          89.2\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          57.74,\n",
      "          75.92,\n",
      "          80.57,\n",
      "          86.13,\n",
      "          88.26,\n",
      "          88.62,\n",
      "          89.88000000000001,\n",
      "          90.93,\n",
      "          91.02,\n",
      "          92.17\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          28.470000000000002,\n",
      "          35.38,\n",
      "          44.85,\n",
      "          50.71,\n",
      "          58.48,\n",
      "          61.3,\n",
      "          63.739999999999995,\n",
      "          65.48,\n",
      "          70.15,\n",
      "          71.58,\n",
      "          74.52,\n",
      "          75.67,\n",
      "          77.11,\n",
      "          77.31,\n",
      "          77.44,\n",
      "          77.61,\n",
      "          78.07,\n",
      "          78.64,\n",
      "          78.99000000000001,\n",
      "          79.33,\n",
      "          79.99000000000001,\n",
      "          80.12,\n",
      "          82.24000000000001,\n",
      "          81.91000000000001,\n",
      "          82.74000000000001,\n",
      "          82.82000000000001,\n",
      "          83.21,\n",
      "          83.71,\n",
      "          83.38,\n",
      "          84.19,\n",
      "          84.61,\n",
      "          84.65,\n",
      "          84.7,\n",
      "          84.99,\n",
      "          85.13,\n",
      "          85.2,\n",
      "          85.72999999999999,\n",
      "          86.18,\n",
      "          86.25,\n",
      "          86.08,\n",
      "          85.76,\n",
      "          85.92999999999999,\n",
      "          86.33,\n",
      "          86.52,\n",
      "          86.94,\n",
      "          87.24,\n",
      "          87.26,\n",
      "          87.85,\n",
      "          87.91,\n",
      "          87.52\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          75.48,\n",
      "          83.13000000000001,\n",
      "          85.79,\n",
      "          87.78\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          35.36,\n",
      "          60.41,\n",
      "          67.99,\n",
      "          74.92,\n",
      "          78.18,\n",
      "          80.60000000000001,\n",
      "          81.69999999999999,\n",
      "          81.97,\n",
      "          82.43,\n",
      "          83.53,\n",
      "          84.89999999999999,\n",
      "          84.94,\n",
      "          85.24000000000001,\n",
      "          85.81,\n",
      "          85.96000000000001,\n",
      "          86.8,\n",
      "          87.25,\n",
      "          87.81,\n",
      "          87.9,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          79.44,\n",
      "          87.52\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          58.269999999999996,\n",
      "          71.76,\n",
      "          79.64,\n",
      "          82.54,\n",
      "          83.82,\n",
      "          83.98,\n",
      "          84.63000000000001,\n",
      "          84.89,\n",
      "          85.77,\n",
      "          86.59\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"SvmModel\": {\n",
      "    \"EntropySelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          34.22,\n",
      "          36.5,\n",
      "          41.5,\n",
      "          41.699999999999996,\n",
      "          43.05,\n",
      "          46.93,\n",
      "          50.62,\n",
      "          51.129999999999995,\n",
      "          55.74,\n",
      "          57.089999999999996,\n",
      "          56.84,\n",
      "          61.22,\n",
      "          62.029999999999994,\n",
      "          62.83,\n",
      "          62.029999999999994,\n",
      "          62.21,\n",
      "          63.28,\n",
      "          63.54,\n",
      "          65.23,\n",
      "          66.36999999999999,\n",
      "          68.42,\n",
      "          69.95,\n",
      "          69.55,\n",
      "          69.82000000000001,\n",
      "          74.8,\n",
      "          75.44,\n",
      "          74.92999999999999,\n",
      "          76.36,\n",
      "          77.23,\n",
      "          76.91,\n",
      "          75.79,\n",
      "          77.34,\n",
      "          77.81,\n",
      "          78.97,\n",
      "          80.16,\n",
      "          79.45,\n",
      "          79.65,\n",
      "          79.33,\n",
      "          79.41,\n",
      "          79.31,\n",
      "          78.95,\n",
      "          79.33,\n",
      "          78.78,\n",
      "          79.05,\n",
      "          79.11,\n",
      "          79.63,\n",
      "          79.60000000000001,\n",
      "          79.73,\n",
      "          80.13,\n",
      "          80.13\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.17,\n",
      "          79.14999999999999,\n",
      "          79.42,\n",
      "          80.08\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          52.65,\n",
      "          55.769999999999996,\n",
      "          58.5,\n",
      "          67.9,\n",
      "          68.63,\n",
      "          72.32,\n",
      "          72.37,\n",
      "          72.08,\n",
      "          72.49,\n",
      "          71.94,\n",
      "          73.11,\n",
      "          75.18,\n",
      "          76.25,\n",
      "          75.6,\n",
      "          76.79,\n",
      "          77.42999999999999,\n",
      "          77.56,\n",
      "          77.45,\n",
      "          78.3,\n",
      "          78.86\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.73,\n",
      "          84.64\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          68.25,\n",
      "          69.56,\n",
      "          71.76,\n",
      "          70.64,\n",
      "          70.59,\n",
      "          74.49,\n",
      "          76.31,\n",
      "          78.17,\n",
      "          77.95,\n",
      "          78.78\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          24.41,\n",
      "          39.12,\n",
      "          51.55,\n",
      "          58.15,\n",
      "          64.19,\n",
      "          67.33,\n",
      "          72.46000000000001,\n",
      "          73.94,\n",
      "          78.06,\n",
      "          78.57,\n",
      "          79.01,\n",
      "          78.68,\n",
      "          79.80000000000001,\n",
      "          80.78999999999999,\n",
      "          81.54,\n",
      "          82.21000000000001,\n",
      "          82.08,\n",
      "          83.17999999999999,\n",
      "          83.36,\n",
      "          83.13000000000001,\n",
      "          82.5,\n",
      "          83.24000000000001,\n",
      "          84.03,\n",
      "          84.84,\n",
      "          85.2,\n",
      "          85.17,\n",
      "          85.24000000000001,\n",
      "          85.1,\n",
      "          85.33,\n",
      "          85.00999999999999,\n",
      "          85.57000000000001,\n",
      "          85.91,\n",
      "          85.91,\n",
      "          86.4,\n",
      "          86.53999999999999,\n",
      "          86.78,\n",
      "          87.02,\n",
      "          87.18,\n",
      "          87.41,\n",
      "          87.33,\n",
      "          87.72,\n",
      "          87.8,\n",
      "          87.9,\n",
      "          88.1,\n",
      "          88.41,\n",
      "          88.22,\n",
      "          88.42999999999999,\n",
      "          88.38000000000001,\n",
      "          88.31,\n",
      "          88.6\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          76.8,\n",
      "          83.96000000000001,\n",
      "          87.08,\n",
      "          88.94\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          48.209999999999994,\n",
      "          59.870000000000005,\n",
      "          70.07,\n",
      "          73.88,\n",
      "          79.62,\n",
      "          80.99,\n",
      "          82.69999999999999,\n",
      "          83.2,\n",
      "          84.13000000000001,\n",
      "          84.61999999999999,\n",
      "          85.53,\n",
      "          86.32,\n",
      "          86.46000000000001,\n",
      "          87.16000000000001,\n",
      "          87.74,\n",
      "          87.87,\n",
      "          88.16000000000001,\n",
      "          88.24,\n",
      "          88.42,\n",
      "          88.13\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          82.87,\n",
      "          87.59\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          59.74,\n",
      "          70.57,\n",
      "          79.12,\n",
      "          83.25,\n",
      "          84.19,\n",
      "          86.44,\n",
      "          87.3,\n",
      "          87.81,\n",
      "          87.58,\n",
      "          88.63\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          30.12,\n",
      "          41.54,\n",
      "          51.15,\n",
      "          59.5,\n",
      "          64.64999999999999,\n",
      "          65.02,\n",
      "          66.7,\n",
      "          68.81,\n",
      "          70.28,\n",
      "          73.48,\n",
      "          73.83,\n",
      "          76.64,\n",
      "          76.83,\n",
      "          77.68,\n",
      "          77.38000000000001,\n",
      "          77.77,\n",
      "          79.17,\n",
      "          79.59,\n",
      "          80.86,\n",
      "          80.89,\n",
      "          81.24,\n",
      "          81.47999999999999,\n",
      "          82.23,\n",
      "          82.8,\n",
      "          82.96,\n",
      "          83.00999999999999,\n",
      "          83.64,\n",
      "          83.72,\n",
      "          83.35000000000001,\n",
      "          83.41,\n",
      "          83.69,\n",
      "          83.67999999999999,\n",
      "          84.23,\n",
      "          84.26,\n",
      "          84.48,\n",
      "          84.98,\n",
      "          85.38,\n",
      "          85.39,\n",
      "          85.63,\n",
      "          85.74000000000001,\n",
      "          86.17,\n",
      "          86.28,\n",
      "          86.38,\n",
      "          86.57000000000001,\n",
      "          86.42,\n",
      "          86.56,\n",
      "          86.38,\n",
      "          86.37,\n",
      "          86.44,\n",
      "          86.53999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.53999999999999,\n",
      "          80.67,\n",
      "          84.16,\n",
      "          86.61999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          55.489999999999995,\n",
      "          64.21,\n",
      "          71.63000000000001,\n",
      "          74.95,\n",
      "          76.49000000000001,\n",
      "          80.08999999999999,\n",
      "          82.11,\n",
      "          82.25,\n",
      "          82.65,\n",
      "          83.3,\n",
      "          84.02,\n",
      "          85.05,\n",
      "          85.15,\n",
      "          85.67,\n",
      "          86.18,\n",
      "          86.83999999999999,\n",
      "          87.41,\n",
      "          87.63,\n",
      "          87.82,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.15,\n",
      "          86.91\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          67.52,\n",
      "          75.52,\n",
      "          80.19,\n",
      "          84.26,\n",
      "          85.77,\n",
      "          86.16,\n",
      "          86.58,\n",
      "          86.65,\n",
      "          87.18,\n",
      "          87.09\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 26, using model = RfModel, selection_function = EntropySelection, k = 250, iteration = 0.\n",
      "\n",
      "initial random chosen samples (250,)\n",
      "initial train set: (250, 784) (250,) unique(labels): [25 27 25 35 20 22 23 32 19 22] [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59750, 784) (59750,) (250,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.993 s \n",
      "\n",
      "Accuracy rate for 82.870000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       980\n",
      "           1       0.85      0.98      0.91      1135\n",
      "           2       0.89      0.79      0.84      1032\n",
      "           3       0.67      0.92      0.78      1010\n",
      "           4       0.85      0.79      0.82       982\n",
      "           5       0.90      0.67      0.77       892\n",
      "           6       0.84      0.87      0.85       958\n",
      "           7       0.86      0.86      0.86      1028\n",
      "           8       0.88      0.59      0.71       974\n",
      "           9       0.78      0.80      0.79      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.82      0.82     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 941    0    1    6    0    6   20    3    2    1]\n",
      " [   0 1116    3    9    0    0    3    1    3    0]\n",
      " [  35   45  815   43    8    7   34   26    5   14]\n",
      " [   8    7   13  929    1   10    4   21    5   12]\n",
      " [   4   13   10    1  780    3   30    8   16  117]\n",
      " [  19   23    1  170   16  598   32   17    5   11]\n",
      " [  50    9   14    9   19   17  835    4    1    0]\n",
      " [   2   51   26    3    5    1    0  889   21   30]\n",
      " [   6   42   32  193   18   16   36   18  575   38]\n",
      " [  15   11    4   21   75    7    2   46   19  809]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 0 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (250, 784) (250,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [ 70 154  26  42  27  25  24  78  21  33] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.469 s \n",
      "\n",
      "Accuracy rate for 81.830000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88       980\n",
      "           1       0.72      0.99      0.83      1135\n",
      "           2       0.91      0.74      0.81      1032\n",
      "           3       0.75      0.89      0.82      1010\n",
      "           4       0.86      0.80      0.83       982\n",
      "           5       0.92      0.67      0.78       892\n",
      "           6       0.86      0.84      0.85       958\n",
      "           7       0.80      0.88      0.84      1028\n",
      "           8       0.93      0.58      0.71       974\n",
      "           9       0.81      0.78      0.79      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.84      0.81      0.81     10000\n",
      "weighted avg       0.83      0.82      0.81     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 952    2    1    0    0    6   14    4    1    0]\n",
      " [   0 1127    1    3    0    0    3    1    0    0]\n",
      " [  49  108  762   34    8    2   26   29    7    7]\n",
      " [  13   31   14  896    1    9    4   24    1   17]\n",
      " [   8   26    7    1  789    2   33   15   11   90]\n",
      " [  42   49    3  103   20  602   18   32    4   19]\n",
      " [  76   21    9    5   22   17  801    7    0    0]\n",
      " [   1   69   23    0    1    0    1  909    9   15]\n",
      " [  25  117   13  133   24   10   32   19  563   38]\n",
      " [  22   25    7   13   48    7    1   94   10  782]]\n",
      "--------------------------------\n",
      "final active learning accuracies [82.87, 81.83]\n",
      "saved Active-learning-experiment-26.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 27, using model = RfModel, selection_function = EntropySelection, k = 125, iteration = 0.\n",
      "\n",
      "initial random chosen samples (125,)\n",
      "initial train set: (125, 784) (125,) unique(labels): [12 11 10 15 12  5 14 17 11 18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,) (125,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.580 s \n",
      "\n",
      "Accuracy rate for 73.800000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       980\n",
      "           1       0.84      0.98      0.91      1135\n",
      "           2       0.89      0.63      0.73      1032\n",
      "           3       0.60      0.87      0.71      1010\n",
      "           4       0.77      0.72      0.74       982\n",
      "           5       0.89      0.29      0.44       892\n",
      "           6       0.74      0.78      0.76       958\n",
      "           7       0.68      0.72      0.70      1028\n",
      "           8       0.84      0.62      0.71       974\n",
      "           9       0.56      0.78      0.65      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.77      0.73      0.72     10000\n",
      "weighted avg       0.77      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 894    1    2    5    0   10   29   36    1    2]\n",
      " [   0 1115    4    3    0    0    6    0    5    2]\n",
      " [  68   32  648  123   28    3   29   17   60   24]\n",
      " [   1   12    0  877    1    0   13   19   23   64]\n",
      " [   3   15    0    0  707    0   30   19   11  197]\n",
      " [  13   49    3  270   23  261  110   91    4   68]\n",
      " [  17    6   61    6  110    6  749    2    0    1]\n",
      " [   1   45    8    2    7    0    1  736    2  226]\n",
      " [  23   37    4  163   11   12   50   30  601   43]\n",
      " [  12   13    2   17   31    0    1  134    7  792]]\n",
      "--------------------------------\n",
      "val predicted: (59875,) ['5' '0' '4' ... '5' '6' '6']\n",
      "probabilities: (59875, 10) \n",
      " [5 0 4 ... 5 6 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (125, 784) (125,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [33 30 14 16 14  5 38 53 13 34] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.029 s \n",
      "\n",
      "Accuracy rate for 73.650000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.95      0.83       980\n",
      "           1       0.86      0.99      0.92      1135\n",
      "           2       0.98      0.52      0.68      1032\n",
      "           3       0.71      0.80      0.75      1010\n",
      "           4       0.92      0.61      0.73       982\n",
      "           5       0.90      0.30      0.45       892\n",
      "           6       0.66      0.95      0.78       958\n",
      "           7       0.56      0.92      0.70      1028\n",
      "           8       0.83      0.55      0.66       974\n",
      "           9       0.65      0.71      0.68      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.78      0.73      0.72     10000\n",
      "weighted avg       0.78      0.74      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 931    0    0    2    0    0   38    8    1    0]\n",
      " [   0 1120    2    2    0    0    6    4    1    0]\n",
      " [ 109   30  532   63   18    2  120   68   72   18]\n",
      " [  17   32    2  807    1    0   25   72   26   28]\n",
      " [   3   17    0    0  596    0   71   71    3  221]\n",
      " [  52   28    0  178   11  267  108  191    5   52]\n",
      " [  22    6    0    0    7    7  912    4    0    0]\n",
      " [   1   25    4    1    2    0    5  944    1   45]\n",
      " [  95   32    3   74    4   20   89  100  535   22]\n",
      " [  23   11    0    9   10    0   10  225    0  721]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '7']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 6 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (250, 784) (250,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [41 68 17 17 17  6 49 93 14 53] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.124 s \n",
      "\n",
      "Accuracy rate for 74.140000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85       980\n",
      "           1       0.82      0.99      0.90      1135\n",
      "           2       0.98      0.55      0.70      1032\n",
      "           3       0.71      0.76      0.73      1010\n",
      "           4       0.95      0.62      0.75       982\n",
      "           5       0.92      0.26      0.40       892\n",
      "           6       0.65      0.95      0.77       958\n",
      "           7       0.59      0.93      0.72      1028\n",
      "           8       0.85      0.56      0.67       974\n",
      "           9       0.65      0.78      0.71      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.79      0.73      0.72     10000\n",
      "weighted avg       0.79      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 918    0    0    2    0    1   41   17    1    0]\n",
      " [   0 1121    2    2    0    0    7    2    1    0]\n",
      " [  89   33  565   63    7    1  102   78   73   21]\n",
      " [  13   54    3  766    1    0   24   83   19   47]\n",
      " [   1   18    1    0  611    0   77   60    1  213]\n",
      " [  40   34    0  179    9  230  139  181    3   77]\n",
      " [  18    7    0    1    8    8  912    3    0    1]\n",
      " [   1   29    4    0    1    0    3  961    0   29]\n",
      " [  83   51    4   59    3   10   88   90  542   44]\n",
      " [  19   15    0   10    6    0   10  161    0  788]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['5' '0' '4' ... '5' '6' '7']\n",
      "probabilities: (59625, 10) \n",
      " [5 0 4 ... 5 6 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (375, 784) (375,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [ 53 123  25  17  17   6  53 131  14  61] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.383 s \n",
      "\n",
      "Accuracy rate for 74.590000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83       980\n",
      "           1       0.78      0.99      0.87      1135\n",
      "           2       0.96      0.64      0.77      1032\n",
      "           3       0.76      0.73      0.75      1010\n",
      "           4       0.94      0.60      0.73       982\n",
      "           5       0.91      0.24      0.39       892\n",
      "           6       0.71      0.94      0.81       958\n",
      "           7       0.61      0.93      0.74      1028\n",
      "           8       0.90      0.51      0.65       974\n",
      "           9       0.61      0.82      0.70      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.79      0.74      0.72     10000\n",
      "weighted avg       0.79      0.75      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 942    1    1    1    0    0   24    9    1    1]\n",
      " [   0 1121    7    1    0    0    4    2    0    0]\n",
      " [ 110   36  664   28    8    1   72   57   30   26]\n",
      " [  20   67    4  741    1    1   26   71   14   65]\n",
      " [   3   18    1    0  585    0   61   64    1  249]\n",
      " [  80   55    1  140    9  218   98  177    5  109]\n",
      " [  33    7    0    0    9    5  898    5    0    1]\n",
      " [   1   35    4    1    1    0    2  959    0   25]\n",
      " [  87   72    7   58    1   15   78  102  499   55]\n",
      " [  21   20    0    7    6    0    5  116    2  832]]\n",
      "--------------------------------\n",
      "final active learning accuracies [73.8, 73.65, 74.14, 74.59]\n",
      "saved Active-learning-experiment-27.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 28, using model = RfModel, selection_function = EntropySelection, k = 50, iteration = 0.\n",
      "\n",
      "initial random chosen samples (50,)\n",
      "initial train set: (50, 784) (50,) unique(labels): [7 5 1 7 3 3 8 6 6 4] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,) (50,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.970 s \n",
      "\n",
      "Accuracy rate for 58.250000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80       980\n",
      "           1       0.73      0.94      0.82      1135\n",
      "           2       0.87      0.08      0.14      1032\n",
      "           3       0.44      0.77      0.56      1010\n",
      "           4       0.83      0.35      0.49       982\n",
      "           5       0.72      0.28      0.40       892\n",
      "           6       0.45      0.84      0.59       958\n",
      "           7       0.59      0.91      0.71      1028\n",
      "           8       0.54      0.31      0.39       974\n",
      "           9       0.48      0.47      0.48      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.64      0.58      0.54     10000\n",
      "weighted avg       0.64      0.58      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 809    0    1   28    0   45   82   13    1    1]\n",
      " [   0 1066    1   32    0    0    8    1   27    0]\n",
      " [  38  140   79  383   11    0  219  133   10   19]\n",
      " [  11   40    1  776    0    1   41   41   95    4]\n",
      " [   4   22    1    4  339    5  213   60    8  326]\n",
      " [  72   52    1  233    1  247  141   36   78   31]\n",
      " [  39   22    3   11    2    3  803   10    0   65]\n",
      " [   4   51    0    9    3    2    4  931    7   17]\n",
      " [  36   49    3  258    4   37  181   57  300   49]\n",
      " [  20   16    1   23   50    4   95  298   27  475]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['8' '0' '4' ... '5' '6' '6']\n",
      "probabilities: (59950, 10) \n",
      " [8 0 4 ... 5 6 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (50, 784) (50,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [10 24  2 12  6  9 10  7  8 12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.442 s \n",
      "\n",
      "Accuracy rate for 65.070000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       980\n",
      "           1       0.60      0.97      0.74      1135\n",
      "           2       0.92      0.14      0.24      1032\n",
      "           3       0.54      0.90      0.68      1010\n",
      "           4       0.84      0.56      0.67       982\n",
      "           5       0.75      0.44      0.56       892\n",
      "           6       0.61      0.84      0.71       958\n",
      "           7       0.68      0.71      0.69      1028\n",
      "           8       0.91      0.26      0.41       974\n",
      "           9       0.54      0.72      0.62      1009\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.72      0.65      0.62     10000\n",
      "weighted avg       0.72      0.65      0.62     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 881    2    1   18    0   26   43    6    1    2]\n",
      " [   0 1102    0   20    0    0    4    0    8    1]\n",
      " [  62  273  140  177   31    1  248   61    9   30]\n",
      " [   5   30    0  913    2    8    8   12    1   31]\n",
      " [   4   56    1    0  550    2   62   69    3  235]\n",
      " [  44   87    0  247    8  395   58    7    2   44]\n",
      " [  44   44    4   15   25    2  805    4    0   15]\n",
      " [   2  101    0    6    4    0    0  733    0  182]\n",
      " [  63  105    6  272    9   77   86   19  257   80]\n",
      " [  13   35    1   12   23   15    5  174    0  731]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '4' ... '5' '6' '6']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 4 ... 5 6 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (100, 784) (100,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [10 54  3 18  7 14 10  9  8 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.480 s \n",
      "\n",
      "Accuracy rate for 65.140000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.85       980\n",
      "           1       0.55      0.97      0.70      1135\n",
      "           2       0.81      0.20      0.32      1032\n",
      "           3       0.51      0.91      0.66      1010\n",
      "           4       0.88      0.57      0.69       982\n",
      "           5       0.65      0.49      0.56       892\n",
      "           6       0.63      0.82      0.71       958\n",
      "           7       0.77      0.76      0.77      1028\n",
      "           8       0.97      0.13      0.23       974\n",
      "           9       0.61      0.73      0.67      1009\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.72      0.65      0.62     10000\n",
      "weighted avg       0.72      0.65      0.62     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 868    3    1   30    0   25   45    3    1    4]\n",
      " [   0 1103    2   26    0    0    3    0    1    0]\n",
      " [  50  257  207  204   18    0  214   56    2   24]\n",
      " [   1   30    4  919    0   15    8   11    0   22]\n",
      " [   7  104    3    2  558    8   58   39    0  203]\n",
      " [  25  127    0  215    9  435   48    4    0   29]\n",
      " [  45   58   31   14   20    0  782    1    0    7]\n",
      " [   1  117    0    5    5    1    0  777    0  122]\n",
      " [  42  152    6  359   12  135   75    8  129   56]\n",
      " [  13   68    1   15   12   51    9  104    0  736]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['3' '0' '4' ... '5' '6' '6']\n",
      "probabilities: (59850, 10) \n",
      " [3 0 4 ... 5 6 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (150, 784) (150,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [13 77  3 27  9 16 10 14  9 22] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.745 s \n",
      "\n",
      "Accuracy rate for 65.880000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       980\n",
      "           1       0.55      0.98      0.71      1135\n",
      "           2       0.88      0.18      0.30      1032\n",
      "           3       0.52      0.92      0.66      1010\n",
      "           4       0.89      0.51      0.65       982\n",
      "           5       0.72      0.46      0.56       892\n",
      "           6       0.67      0.82      0.74       958\n",
      "           7       0.74      0.80      0.77      1028\n",
      "           8       0.95      0.19      0.31       974\n",
      "           9       0.61      0.75      0.67      1009\n",
      "\n",
      "    accuracy                           0.66     10000\n",
      "   macro avg       0.73      0.65      0.62     10000\n",
      "weighted avg       0.73      0.66      0.62     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 892    3    1   29    0   11   38    3    1    2]\n",
      " [   0 1115    2   14    0    0    3    0    1    0]\n",
      " [  57  324  190  194    6    4  180   51    5   21]\n",
      " [   6   30    1  934    0    5    5   13    0   16]\n",
      " [   5   84    0    3  499   22   58   63    1  247]\n",
      " [  45  118    0  230    8  407   37    8    2   37]\n",
      " [  45   57   16   13   22    1  788    6    0   10]\n",
      " [   1   94    0    6    5    1    1  824    0   96]\n",
      " [  41  138    4  365   10   89   65   21  182   59]\n",
      " [  10   49    1   22    8   29    6  127    0  757]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['0' '4' '1' ... '5' '6' '1']\n",
      "probabilities: (59800, 10) \n",
      " [0 4 1 ... 5 6 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (200, 784) (200,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [ 15 104   3  29  11  21  10  18   9  30] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.767 s \n",
      "\n",
      "Accuracy rate for 64.940000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       980\n",
      "           1       0.53      0.99      0.69      1135\n",
      "           2       0.89      0.15      0.25      1032\n",
      "           3       0.51      0.90      0.65      1010\n",
      "           4       0.84      0.53      0.65       982\n",
      "           5       0.66      0.47      0.55       892\n",
      "           6       0.69      0.77      0.73       958\n",
      "           7       0.83      0.82      0.82      1028\n",
      "           8       0.95      0.11      0.20       974\n",
      "           9       0.58      0.78      0.66      1009\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.73      0.64      0.61     10000\n",
      "weighted avg       0.73      0.65      0.61     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 900    3    1   28    0    3   37    3    1    4]\n",
      " [   0 1129    0    4    0    0    1    0    0    1]\n",
      " [  88  355  152  174   19    2  162   40    4   36]\n",
      " [   5   44    0  906    0   11    2   10    0   32]\n",
      " [   6   79    0    2  525   30   42   25    1  272]\n",
      " [  37  121    0  225   12  416   32    2    0   47]\n",
      " [  45   83   13   17   47    2  733    3    0   15]\n",
      " [   1  101    0    4    5    2    0  839    0   76]\n",
      " [  42  175    4  392   10   97   42   16  110   86]\n",
      " [  10   52    0   18    6   67    4   68    0  784]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['0' '4' '1' ... '5' '6' '0']\n",
      "probabilities: (59750, 10) \n",
      " [0 4 1 ... 5 6 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (250, 784) (250,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [ 18 132   3  31  13  23  10  22   9  39] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.981 s \n",
      "\n",
      "Accuracy rate for 65.430000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.84       980\n",
      "           1       0.54      0.99      0.70      1135\n",
      "           2       0.93      0.12      0.22      1032\n",
      "           3       0.55      0.88      0.68      1010\n",
      "           4       0.82      0.53      0.64       982\n",
      "           5       0.71      0.51      0.59       892\n",
      "           6       0.66      0.77      0.71       958\n",
      "           7       0.85      0.83      0.84      1028\n",
      "           8       0.96      0.11      0.20       974\n",
      "           9       0.56      0.82      0.66      1009\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.73      0.65      0.61     10000\n",
      "weighted avg       0.73      0.65      0.61     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 906    3    1   18    1    5   34    3    1    8]\n",
      " [   0 1129    1    3    0    0    1    0    0    1]\n",
      " [ 103  326  127  172   23    4  219   26    1   31]\n",
      " [  12   45    1  884    0   13    6    8    0   41]\n",
      " [   6   66    0    0  516   12   40   26    3  313]\n",
      " [  34  113    0  183   10  456   32    6    0   58]\n",
      " [  50   66    5    6   67    7  739    2    0   16]\n",
      " [   2   95    0    1    3    0    0  851    0   76]\n",
      " [  61  196    2  324    3  110   43   10  109  116]\n",
      " [  12   48    0   13    6   37    3   64    0  826]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['4' '1' '9' ... '5' '6' '1']\n",
      "probabilities: (59700, 10) \n",
      " [4 1 9 ... 5 6 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (300, 784) (300,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [ 20 157   3  32  16  26  11  27  10  48] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.991 s \n",
      "\n",
      "Accuracy rate for 66.640000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85       980\n",
      "           1       0.57      0.99      0.72      1135\n",
      "           2       0.90      0.13      0.22      1032\n",
      "           3       0.58      0.87      0.70      1010\n",
      "           4       0.83      0.52      0.64       982\n",
      "           5       0.72      0.57      0.63       892\n",
      "           6       0.64      0.78      0.70       958\n",
      "           7       0.82      0.84      0.83      1028\n",
      "           8       0.97      0.16      0.28       974\n",
      "           9       0.56      0.85      0.67      1009\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.74      0.66      0.62     10000\n",
      "weighted avg       0.74      0.67      0.63     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 878    3    1   20    1   17   49    7    1    3]\n",
      " [   0 1127    0    4    0    0    3    0    0    1]\n",
      " [  86  331  131  166   21    2  214   47    2   32]\n",
      " [   7   39    1  882    0   16    3   16    0   46]\n",
      " [   4   64    1    1  515    7   48   29    0  313]\n",
      " [  23   97    0  151    6  504   39   10    1   61]\n",
      " [  38   53    8   11   66   12  749    5    0   16]\n",
      " [   1   81    0    0    3    0    0  860    1   82]\n",
      " [  44  161    3  279    5  116   69   14  160  123]\n",
      " [  11   31    0   11    5   22    4   67    0  858]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['4' '1' '9' ... '5' '0' '5']\n",
      "probabilities: (59650, 10) \n",
      " [4 1 9 ... 5 0 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (350, 784) (350,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [ 21 171   3  36  23  30  11  37  12  56] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.283 s \n",
      "\n",
      "Accuracy rate for 69.800000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       980\n",
      "           1       0.61      0.99      0.75      1135\n",
      "           2       0.91      0.16      0.27      1032\n",
      "           3       0.62      0.86      0.72      1010\n",
      "           4       0.81      0.69      0.74       982\n",
      "           5       0.79      0.61      0.69       892\n",
      "           6       0.64      0.79      0.71       958\n",
      "           7       0.83      0.87      0.85      1028\n",
      "           8       0.98      0.20      0.34       974\n",
      "           9       0.60      0.86      0.70      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.76      0.69      0.66     10000\n",
      "weighted avg       0.75      0.70      0.66     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 890    3    2    8    0   11   56    4    0    6]\n",
      " [   0 1127    0    4    0    0    2    0    1    1]\n",
      " [  84  297  167  158   36    3  185   53    2   47]\n",
      " [   9   38    4  864    0   15    8   20    0   52]\n",
      " [   2   35    0    0  675    1   47   13    1  208]\n",
      " [  25   90    0   90   12  541   42    7    0   85]\n",
      " [  37   50    8    5   83   11  757    2    0    5]\n",
      " [   1   62    0    5    3    0    0  895    1   61]\n",
      " [  59  135    3  251   17   91   84   16  199  119]\n",
      " [  10   23    0   12   11   11    6   71    0  865]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['4' '1' '9' ... '5' '0' '0']\n",
      "probabilities: (59600, 10) \n",
      " [4 1 9 ... 5 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (400, 784) (400,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [ 23 187   3  40  28  34  12  47  12  64] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.257 s \n",
      "\n",
      "Accuracy rate for 69.130000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.84       980\n",
      "           1       0.62      0.99      0.76      1135\n",
      "           2       0.87      0.11      0.19      1032\n",
      "           3       0.63      0.85      0.73      1010\n",
      "           4       0.75      0.74      0.75       982\n",
      "           5       0.75      0.59      0.66       892\n",
      "           6       0.65      0.76      0.70       958\n",
      "           7       0.78      0.88      0.83      1028\n",
      "           8       0.98      0.19      0.32       974\n",
      "           9       0.61      0.84      0.71      1009\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.74      0.69      0.65     10000\n",
      "weighted avg       0.74      0.69      0.65     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 887    3    1    9    1   14   46   13    0    6]\n",
      " [   0 1128    1    3    0    0    2    0    0    1]\n",
      " [  89  322  112  150   63    1  188   74    1   32]\n",
      " [  11   36    0  862    1   13    5   25    0   57]\n",
      " [   2   17    0    0  728    2   42   22    1  168]\n",
      " [  21   77    0  104   22  527   40   15    1   85]\n",
      " [  46   39   10    4  111    9  725   13    0    1]\n",
      " [   0   61    0    5    5    0    0  908    0   49]\n",
      " [  63  132    5  223   23  119   68   16  184  141]\n",
      " [  10   18    0    7   18   17    4   83    0  852]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['4' '1' '9' ... '5' '0' '5']\n",
      "probabilities: (59550, 10) \n",
      " [4 1 9 ... 5 0 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (450, 784) (450,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [ 24 201   3  45  30  36  12  65  12  72] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.479 s \n",
      "\n",
      "Accuracy rate for 69.860000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83       980\n",
      "           1       0.64      0.99      0.78      1135\n",
      "           2       0.90      0.15      0.25      1032\n",
      "           3       0.62      0.86      0.72      1010\n",
      "           4       0.76      0.73      0.75       982\n",
      "           5       0.75      0.60      0.66       892\n",
      "           6       0.67      0.78      0.72       958\n",
      "           7       0.76      0.91      0.83      1028\n",
      "           8       0.99      0.19      0.32       974\n",
      "           9       0.62      0.85      0.72      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.75      0.69      0.66     10000\n",
      "weighted avg       0.75      0.70      0.66     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 863    2    1    8    1   16   65   16    0    8]\n",
      " [   0 1129    1    3    0    0    1    0    0    1]\n",
      " [  92  288  152  163   59    3  149   92    1   33]\n",
      " [  10   39    2  866    1   15    3   30    0   44]\n",
      " [   2   19    0    1  720    0   37   25    1  177]\n",
      " [  23   55    0   95   33  531   41   21    0   93]\n",
      " [  43   44   10    4   88    8  745   15    0    1]\n",
      " [   0   49    0    8    1    0    0  931    0   39]\n",
      " [  59  121    3  239   30  121   71   18  187  125]\n",
      " [  12   14    0    9   14   18    2   78    0  862]]\n",
      "--------------------------------\n",
      "final active learning accuracies [58.25, 65.07, 65.14, 65.88000000000001, 64.94, 65.42999999999999, 66.64, 69.8, 69.13, 69.86]\n",
      "saved Active-learning-experiment-28.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 29, using model = RfModel, selection_function = EntropySelection, k = 25, iteration = 0.\n",
      "\n",
      "initial random chosen samples (25,)\n",
      "initial train set: (25, 784) (25,) unique(labels): [5 2 2 2 2 2 5 1 0 4] [0 1 2 3 4 5 6 7 9]\n",
      "val set: (59975, 784) (59975,) (25,)\n",
      "\n",
      "Train set: (25, 784) y: (25,)\n",
      "Val   set: (59975, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.481 s \n",
      "\n",
      "Accuracy rate for 49.920000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.87      0.63       980\n",
      "           1       0.59      0.98      0.74      1135\n",
      "           2       0.70      0.39      0.50      1032\n",
      "           3       0.73      0.54      0.62      1010\n",
      "           4       0.40      0.11      0.17       982\n",
      "           5       0.84      0.30      0.45       892\n",
      "           6       0.46      0.87      0.60       958\n",
      "           7       0.95      0.02      0.03      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.32      0.84      0.46      1009\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.55      0.49      0.42     10000\n",
      "weighted avg       0.55      0.50      0.42     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 853   10    0    6    0    2  102    0    0    7]\n",
      " [   3 1116    4    0    2    0    3    0    0    7]\n",
      " [  99  160  406  112    2    0  230    0    0   23]\n",
      " [ 169   70   17  543   13    5   20    0    0  173]\n",
      " [   8   28    1    0  107    0  273    0    0  565]\n",
      " [ 205   98    5   39    0  270  106    0    0  169]\n",
      " [  29   75    2    1    2    5  835    0    0    9]\n",
      " [  51  122   88    2   28    5    6   18    0  708]\n",
      " [ 238  179   56   36   86   33  195    0    0  151]\n",
      " [  52   37    4    1   29    1   40    1    0  844]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59975,) ['0' '0' '9' ... '5' '6' '1']\n",
      "probabilities: (59975, 9) \n",
      " [0 0 8 ... 5 6 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (25, 784) (25,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [ 5  2  5  2  3  5 11  5  8  4] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.039 s \n",
      "\n",
      "Accuracy rate for 57.490000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80       980\n",
      "           1       0.88      0.84      0.86      1135\n",
      "           2       0.66      0.64      0.65      1032\n",
      "           3       0.93      0.18      0.30      1010\n",
      "           4       0.78      0.09      0.16       982\n",
      "           5       0.82      0.41      0.55       892\n",
      "           6       0.39      0.95      0.55       958\n",
      "           7       0.57      0.54      0.55      1028\n",
      "           8       0.42      0.74      0.54       974\n",
      "           9       0.45      0.59      0.51      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.68      0.57      0.55     10000\n",
      "weighted avg       0.68      0.57      0.55     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[722   0  21   0   0   4 224   3   6   0]\n",
      " [  0 948   4   0   0   0   6  79  90   8]\n",
      " [ 12  26 658  10   0   0 250  11  61   4]\n",
      " [ 20  13 247 178   0  41  45  18 377  71]\n",
      " [  2  10   1   0  88   1 480 129  24 247]\n",
      " [ 30  11  15   3   0 369 154  50 210  50]\n",
      " [  6  19   1   0   0  10 910   1  10   1]\n",
      " [ 13  32  23   0   6   2  19 557  57 319]\n",
      " [ 16  12  31   1   7  24 113  16 721  33]\n",
      " [ 10   6   2   0  12   0 123 116 142 598]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['8' '0' '6' ... '8' '6' '7']\n",
      "probabilities: (59950, 10) \n",
      " [8 0 6 ... 8 6 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (50, 784) (50,)\n",
      "trainset after (75, 784) (75,)\n",
      "updated train set: (75, 784) (75,) unique(labels): [ 5  2  6  2 11  5 13 13  8 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59925, 784) (59925,)\n",
      "\n",
      "Train set: (75, 784) y: (75,)\n",
      "Val   set: (59925, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.203 s \n",
      "\n",
      "Accuracy rate for 63.130000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79       980\n",
      "           1       0.90      0.82      0.86      1135\n",
      "           2       0.58      0.64      0.61      1032\n",
      "           3       0.87      0.13      0.22      1010\n",
      "           4       0.74      0.58      0.65       982\n",
      "           5       0.76      0.42      0.54       892\n",
      "           6       0.54      0.96      0.69       958\n",
      "           7       0.61      0.61      0.61      1028\n",
      "           8       0.53      0.68      0.60       974\n",
      "           9       0.45      0.73      0.56      1009\n",
      "\n",
      "    accuracy                           0.63     10000\n",
      "   macro avg       0.68      0.63      0.61     10000\n",
      "weighted avg       0.69      0.63      0.62     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[717   0  38   1   1  15 198   7   2   1]\n",
      " [  0 928   7   0   0   1   9  19 142  29]\n",
      " [ 10  21 660   9  66   0 198  13  45  10]\n",
      " [ 34  13 363 129   7  56  49  23 242  94]\n",
      " [  0   4   0   0 568   0  56  59  10 285]\n",
      " [ 44  17  32   7  20 376 142  85  96  73]\n",
      " [  6  10   1   0   4  13 917   1   4   2]\n",
      " [  0  18   5   0  15   1  16 623  16 334]\n",
      " [ 18  14  35   3  19  29  96  38 662  60]\n",
      " [  5   2   2   0  66   2  22 157  20 733]]\n",
      "--------------------------------\n",
      "val predicted: (59925,) ['5' '0' '4' ... '5' '6' '7']\n",
      "probabilities: (59925, 10) \n",
      " [5 0 4 ... 5 6 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (75, 784) (75,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 6  2  7  2 19  5 15 15 10 19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.485 s \n",
      "\n",
      "Accuracy rate for 65.530000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.79      0.84       980\n",
      "           1       0.90      0.79      0.84      1135\n",
      "           2       0.59      0.71      0.64      1032\n",
      "           3       0.87      0.13      0.23      1010\n",
      "           4       0.74      0.75      0.74       982\n",
      "           5       0.80      0.41      0.54       892\n",
      "           6       0.64      0.93      0.75       958\n",
      "           7       0.76      0.55      0.64      1028\n",
      "           8       0.49      0.68      0.57       974\n",
      "           9       0.45      0.80      0.58      1009\n",
      "\n",
      "    accuracy                           0.66     10000\n",
      "   macro avg       0.71      0.65      0.64     10000\n",
      "weighted avg       0.71      0.66      0.64     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[773   2  46   1   3  12 129   3   6   5]\n",
      " [  0 892  46   0   3   0   3   2 150  39]\n",
      " [  7  30 729  10  53   0 117  12  59  15]\n",
      " [ 22   9 318 131  17  47  25  26 247 168]\n",
      " [  0   3   1   0 732   0  27  15  16 188]\n",
      " [ 28  11  36   8  39 364 132  50 124 100]\n",
      " [  7  15   4   0  15  14 890   0   4   9]\n",
      " [  8  18  15   0  22   0   9 570  40 346]\n",
      " [ 14  12  49   0  41  19  55   7 660 117]\n",
      " [  3   1   2   1  70   0  14  63  43 812]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['8' '0' '4' ... '5' '6' '7']\n",
      "probabilities: (59900, 10) \n",
      " [8 0 4 ... 5 6 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (100, 784) (100,)\n",
      "trainset after (125, 784) (125,)\n",
      "updated train set: (125, 784) (125,) unique(labels): [ 6  2  7  2 29  7 16 20 11 25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.491 s \n",
      "\n",
      "Accuracy rate for 69.400000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.81      0.85       980\n",
      "           1       0.92      0.81      0.86      1135\n",
      "           2       0.62      0.70      0.66      1032\n",
      "           3       0.85      0.10      0.18      1010\n",
      "           4       0.66      0.88      0.75       982\n",
      "           5       0.77      0.41      0.53       892\n",
      "           6       0.70      0.92      0.79       958\n",
      "           7       0.78      0.81      0.79      1028\n",
      "           8       0.49      0.69      0.57       974\n",
      "           9       0.59      0.79      0.67      1009\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.73      0.69      0.67     10000\n",
      "weighted avg       0.73      0.69      0.67     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[791   0  36   0  11  30  87   7   7  11]\n",
      " [  0 921  28   0  18   0   3  17 138  10]\n",
      " [  7  25 720  10  89   0  91  21  51  18]\n",
      " [ 28   7 297 104  45  42  23  44 279 141]\n",
      " [  0   3   0   0 868   0  15   9   3  84]\n",
      " [ 33   8  24   7  69 364  99  43 175  70]\n",
      " [  5  18   3   0  29  16 877   1   5   4]\n",
      " [  4  13   9   0  30   1   2 828  24 117]\n",
      " [  6  10  36   1  76  16  48  13 673  95]\n",
      " [  7   1   2   0  85   1  10  78  31 794]]\n",
      "--------------------------------\n",
      "val predicted: (59875,) ['8' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59875, 10) \n",
      " [8 0 4 ... 5 6 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (125, 784) (125,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [ 6  2  8  2 40  9 16 23 12 32] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.698 s \n",
      "\n",
      "Accuracy rate for 69.730000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82       980\n",
      "           1       0.93      0.77      0.84      1135\n",
      "           2       0.65      0.72      0.69      1032\n",
      "           3       0.85      0.15      0.25      1010\n",
      "           4       0.64      0.91      0.75       982\n",
      "           5       0.59      0.53      0.56       892\n",
      "           6       0.73      0.87      0.79       958\n",
      "           7       0.81      0.79      0.80      1028\n",
      "           8       0.50      0.67      0.57       974\n",
      "           9       0.63      0.79      0.70      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.72      0.70      0.68     10000\n",
      "weighted avg       0.73      0.70      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[739   0  33   1  10  84  85   5  15   8]\n",
      " [  0 872  44   0  24  12   3  20 136  24]\n",
      " [  8  21 746  13  82   9  61  20  54  18]\n",
      " [ 25   5 256 149  48 135  13  49 204 126]\n",
      " [  0   3   0   0 893   3  10   5   2  66]\n",
      " [ 28   6  12  10  56 474  90  17 167  32]\n",
      " [  6   9   8   0  46  39 831   2  15   2]\n",
      " [  1  11   5   0  40  10   3 814  32 112]\n",
      " [ 10   7  36   3 109  32  37   9 654  77]\n",
      " [  3   1   0   0  83  10   9  67  35 801]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['8' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59850, 10) \n",
      " [8 0 4 ... 5 6 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (150, 784) (150,)\n",
      "trainset after (175, 784) (175,)\n",
      "updated train set: (175, 784) (175,) unique(labels): [ 6  2  8  2 45 11 18 28 12 43] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59825, 784) (59825,)\n",
      "\n",
      "Train set: (175, 784) y: (175,)\n",
      "Val   set: (59825, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.638 s \n",
      "\n",
      "Accuracy rate for 69.320000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.74      0.82       980\n",
      "           1       0.95      0.78      0.86      1135\n",
      "           2       0.65      0.72      0.68      1032\n",
      "           3       0.85      0.13      0.22      1010\n",
      "           4       0.67      0.86      0.75       982\n",
      "           5       0.60      0.55      0.57       892\n",
      "           6       0.70      0.85      0.77       958\n",
      "           7       0.79      0.81      0.80      1028\n",
      "           8       0.56      0.63      0.59       974\n",
      "           9       0.54      0.85      0.66      1009\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.72      0.69      0.67     10000\n",
      "weighted avg       0.73      0.69      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[728   0  37   0   4  60 103   3  13  32]\n",
      " [  0 886  20   0  68  15   6  56  64  20]\n",
      " [  4  16 745  11  56   9  77  26  42  46]\n",
      " [ 25   3 269 130  30 127  22  38 168 198]\n",
      " [  0   1   0   0 843   4  16   7   1 110]\n",
      " [ 21   7  25   7  46 488  74  20 143  61]\n",
      " [  8   8   1   0  44  62 819   2   6   8]\n",
      " [  1   8   7   0  24   6   1 829  26 126]\n",
      " [  9   6  39   5  86  31  42  13 611 132]\n",
      " [  2   1   1   0  54   9   7  59  23 853]]\n",
      "--------------------------------\n",
      "val predicted: (59825,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59825, 10) \n",
      " [5 0 4 ... 5 6 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (175, 784) (175,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [ 6  2  8  2 56 12 19 31 12 52] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.863 s \n",
      "\n",
      "Accuracy rate for 66.680000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82       980\n",
      "           1       0.96      0.64      0.77      1135\n",
      "           2       0.63      0.73      0.68      1032\n",
      "           3       0.85      0.09      0.17      1010\n",
      "           4       0.44      0.92      0.59       982\n",
      "           5       0.58      0.57      0.57       892\n",
      "           6       0.78      0.78      0.78       958\n",
      "           7       0.85      0.80      0.83      1028\n",
      "           8       0.62      0.56      0.59       974\n",
      "           9       0.61      0.82      0.70      1009\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.72      0.67      0.65     10000\n",
      "weighted avg       0.73      0.67      0.65     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[741   0  42   1  30  81  56   5   7  17]\n",
      " [  0 725  45   0 285  22   3   8  31  16]\n",
      " [  5  14 755   8  98  10  47  25  41  29]\n",
      " [ 26   0 274  93 129 163  16  37 128 144]\n",
      " [  0   2   0   0 907   5   6   2   2  58]\n",
      " [ 24   5  20   7 144 504  45  16  88  39]\n",
      " [ 10   4   2   0 143  47 745   0   6   1]\n",
      " [  2   4  11   0  71   7   1 825  16  91]\n",
      " [  9   3  45   0 179  27  32   5 550 124]\n",
      " [  4   1   1   0  97   9   3  48  23 823]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59800, 10) \n",
      " [5 0 4 ... 5 6 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (200, 784) (200,)\n",
      "trainset after (225, 784) (225,)\n",
      "updated train set: (225, 784) (225,) unique(labels): [ 6  2  9  2 62 13 19 37 14 61] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59775, 784) (59775,)\n",
      "\n",
      "Train set: (225, 784) y: (225,)\n",
      "Val   set: (59775, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.865 s \n",
      "\n",
      "Accuracy rate for 67.250000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.83       980\n",
      "           1       0.95      0.60      0.74      1135\n",
      "           2       0.67      0.70      0.69      1032\n",
      "           3       0.85      0.10      0.17      1010\n",
      "           4       0.53      0.86      0.66       982\n",
      "           5       0.58      0.60      0.59       892\n",
      "           6       0.75      0.82      0.78       958\n",
      "           7       0.76      0.84      0.80      1028\n",
      "           8       0.69      0.58      0.63       974\n",
      "           9       0.50      0.89      0.64      1009\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.72      0.67      0.65     10000\n",
      "weighted avg       0.73      0.67      0.65     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[744   0  31   1  13  72  72   7   6  34]\n",
      " [  0 681  15   0 206  25   5  67  18 118]\n",
      " [  5  17 723   8  76   5  63  32  44  59]\n",
      " [ 24   0 250  98  64 177  16  77  99 205]\n",
      " [  0   1   0   0 844   2   6   6   1 122]\n",
      " [ 18   4  19   7 103 532  62  24  43  80]\n",
      " [  5   3   1   0  86  56 783   1   1  22]\n",
      " [  2   2   4   0  38   1   0 862  20  99]\n",
      " [  7   6  31   1 128  35  28   9 564 165]\n",
      " [  2   1   1   0  34   6   5  46  20 894]]\n",
      "--------------------------------\n",
      "val predicted: (59775,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59775, 10) \n",
      " [5 0 4 ... 5 6 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (225, 784) (225,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [ 6  2  9  2 73 13 20 40 16 69] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.085 s \n",
      "\n",
      "Accuracy rate for 66.980000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83       980\n",
      "           1       0.96      0.65      0.77      1135\n",
      "           2       0.65      0.71      0.68      1032\n",
      "           3       0.82      0.09      0.15      1010\n",
      "           4       0.47      0.89      0.61       982\n",
      "           5       0.61      0.53      0.57       892\n",
      "           6       0.79      0.77      0.78       958\n",
      "           7       0.79      0.84      0.81      1028\n",
      "           8       0.67      0.58      0.62       974\n",
      "           9       0.53      0.89      0.66      1009\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.72      0.67      0.65     10000\n",
      "weighted avg       0.73      0.67      0.65     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[733   0  49   1  35  56  64   6  10  26]\n",
      " [  0 735   8   0 260  23   2  37  19  51]\n",
      " [  5  17 733   9 105   3  34  37  41  48]\n",
      " [ 18   0 270  86  95 137  14  64 106 220]\n",
      " [  0   1   0   0 872   1   4   7   1  96]\n",
      " [ 19   4  25   9 135 469  50  33  63  85]\n",
      " [  5   5   3   0 140  42 740   1   3  19]\n",
      " [  1   2   3   0  41   3   1 866  15  96]\n",
      " [  6   4  33   0 143  29  25   8 569 157]\n",
      " [  3   1   0   0  42   5   3  40  20 895]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '4' '9']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 4 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (250, 784) (250,)\n",
      "trainset after (275, 784) (275,)\n",
      "updated train set: (275, 784) (275,) unique(labels): [ 6  2  9  2 77 13 21 52 17 76] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59725, 784) (59725,)\n",
      "\n",
      "Train set: (275, 784) y: (275,)\n",
      "Val   set: (59725, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.004 s \n",
      "\n",
      "Accuracy rate for 66.370000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.73      0.82       980\n",
      "           1       0.97      0.56      0.71      1135\n",
      "           2       0.72      0.69      0.70      1032\n",
      "           3       0.88      0.12      0.21      1010\n",
      "           4       0.49      0.87      0.62       982\n",
      "           5       0.64      0.53      0.58       892\n",
      "           6       0.74      0.78      0.76       958\n",
      "           7       0.74      0.86      0.80      1028\n",
      "           8       0.64      0.59      0.62       974\n",
      "           9       0.50      0.91      0.64      1009\n",
      "\n",
      "    accuracy                           0.66     10000\n",
      "   macro avg       0.72      0.66      0.65     10000\n",
      "weighted avg       0.73      0.66      0.65     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[713   0  32   0  26  63  91  11   9  35]\n",
      " [  0 632  10   0 269   7   4  81  27 105]\n",
      " [  4  12 714   9  98   4  44  42  45  60]\n",
      " [ 21   1 199 120  77 133  17  80 136 226]\n",
      " [  0   0   0   0 854   1   4   5   1 117]\n",
      " [ 18   5  14   6 120 473  67  37  68  84]\n",
      " [  4   1   1   0 120  33 752   1   3  43]\n",
      " [  1   1   4   0  32   1   1 884  16  88]\n",
      " [  5   2  22   1 134  22  32   8 576 172]\n",
      " [  3   0   0   0  24   6   2  40  15 919]]\n",
      "--------------------------------\n",
      "val predicted: (59725,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59725, 10) \n",
      " [5 0 4 ... 5 6 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (275, 784) (275,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [ 8  2  9  2 82 15 22 60 18 82] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.184 s \n",
      "\n",
      "Accuracy rate for 68.220000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       980\n",
      "           1       0.97      0.61      0.75      1135\n",
      "           2       0.69      0.70      0.69      1032\n",
      "           3       0.83      0.10      0.18      1010\n",
      "           4       0.55      0.87      0.67       982\n",
      "           5       0.60      0.56      0.58       892\n",
      "           6       0.79      0.79      0.79       958\n",
      "           7       0.77      0.86      0.81      1028\n",
      "           8       0.64      0.61      0.63       974\n",
      "           9       0.51      0.91      0.65      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.72      0.68      0.66     10000\n",
      "weighted avg       0.73      0.68      0.66     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[800   0  21   0  23  42  47  10   9  28]\n",
      " [  0 696   1   1 193  39   3  72  43  87]\n",
      " [  9  11 718  12  88  11  41  42  45  55]\n",
      " [ 36   0 233 104  53 135  14  59 128 248]\n",
      " [  0   1   0   0 857   3   3   4   1 113]\n",
      " [ 37   4  23   6  73 498  57  37  63  94]\n",
      " [  8   1   2   0  93  61 756   3  11  23]\n",
      " [  1   1   3   0  30   2   1 882  17  91]\n",
      " [ 10   5  33   3 117  34  27   5 594 146]\n",
      " [  8   1   1   0  31   4   3  31  13 917]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['5' '0' '4' ... '5' '4' '9']\n",
      "probabilities: (59700, 10) \n",
      " [5 0 4 ... 5 4 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (300, 784) (300,)\n",
      "trainset after (325, 784) (325,)\n",
      "updated train set: (325, 784) (325,) unique(labels): [10  2  9  2 90 16 23 66 19 88] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59675, 784) (59675,)\n",
      "\n",
      "Train set: (325, 784) y: (325,)\n",
      "Val   set: (59675, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.183 s \n",
      "\n",
      "Accuracy rate for 66.180000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       980\n",
      "           1       0.98      0.46      0.63      1135\n",
      "           2       0.72      0.63      0.67      1032\n",
      "           3       0.82      0.10      0.18      1010\n",
      "           4       0.49      0.89      0.64       982\n",
      "           5       0.66      0.56      0.60       892\n",
      "           6       0.81      0.77      0.79       958\n",
      "           7       0.84      0.85      0.84      1028\n",
      "           8       0.69      0.58      0.63       974\n",
      "           9       0.44      0.92      0.60      1009\n",
      "\n",
      "    accuracy                           0.66     10000\n",
      "   macro avg       0.73      0.66      0.64     10000\n",
      "weighted avg       0.73      0.66      0.64     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[861   0   5   0  22  28  30   5   5  24]\n",
      " [  0 524   3   0 248  15   3  16  75 251]\n",
      " [ 15   9 654  14 133  12  38  45  46  66]\n",
      " [ 46   0 206  99  92 115  12  56  83 301]\n",
      " [  1   0   0   0 875   2   4   2   1  97]\n",
      " [ 45   1  18   7  76 500  62  19  18 146]\n",
      " [  8   0   0   0 101  59 739   0   3  48]\n",
      " [ 10   1   2   0  39   1   1 869  17  88]\n",
      " [ 10   2  21   1 151  28  25   4 566 166]\n",
      " [  8   0   1   0  34   3   3  17  12 931]]\n",
      "--------------------------------\n",
      "val predicted: (59675,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59675, 10) \n",
      " [5 0 4 ... 5 6 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (325, 784) (325,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [13  2  9  2 94 16 24 72 23 95] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.370 s \n",
      "\n",
      "Accuracy rate for 67.420000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88       980\n",
      "           1       0.97      0.50      0.66      1135\n",
      "           2       0.74      0.63      0.68      1032\n",
      "           3       0.87      0.09      0.16      1010\n",
      "           4       0.50      0.89      0.64       982\n",
      "           5       0.65      0.52      0.58       892\n",
      "           6       0.85      0.76      0.80       958\n",
      "           7       0.84      0.85      0.84      1028\n",
      "           8       0.65      0.65      0.65       974\n",
      "           9       0.48      0.92      0.63      1009\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.74      0.68      0.65     10000\n",
      "weighted avg       0.74      0.67      0.65     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[930   0   3   0  13   9   7   3   9   6]\n",
      " [  0 569   4   0 277  21   2  20  44 198]\n",
      " [ 23  12 650   9 122  10  38  39  63  66]\n",
      " [ 62   0 188  87  87 115  13  57 123 278]\n",
      " [  1   0   0   0 873   2   4   3   1  98]\n",
      " [ 75   1  14   4  88 463  37  25  57 128]\n",
      " [ 19   1   0   0 117  56 726   0  11  28]\n",
      " [  4   1   1   0  37   2   0 875  23  85]\n",
      " [ 17   0  20   0 122  30  23   4 636 122]\n",
      " [ 13   0   0   0  23   3   2  20  15 933]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['7' '0' '4' ... '9' '6' '9']\n",
      "probabilities: (59650, 10) \n",
      " [7 0 4 ... 9 6 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (350, 784) (350,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [ 15   2   9   2 101  17  24  80  26  99] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.304 s \n",
      "\n",
      "Accuracy rate for 67.680000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       980\n",
      "           1       0.97      0.49      0.65      1135\n",
      "           2       0.77      0.61      0.68      1032\n",
      "           3       0.86      0.09      0.16      1010\n",
      "           4       0.62      0.88      0.73       982\n",
      "           5       0.69      0.52      0.59       892\n",
      "           6       0.86      0.77      0.81       958\n",
      "           7       0.80      0.85      0.82      1028\n",
      "           8       0.55      0.69      0.61       974\n",
      "           9       0.45      0.93      0.61      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.74      0.68      0.65     10000\n",
      "weighted avg       0.74      0.68      0.65     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[943   0   0   0   9   5   5   2  10   6]\n",
      " [  0 553   2   0  67   9   3  55 217 229]\n",
      " [ 22  15 631   7  99  11  40  46  91  70]\n",
      " [ 82   0 157  89  76  89   5  68 110 334]\n",
      " [  2   0   0   0 867   2   3   2   1 105]\n",
      " [ 68   2   5   7  61 460  46  23  53 167]\n",
      " [ 24   1   1   0  87  56 735   1  20  33]\n",
      " [ 10   1   2   0  23   1   0 877  30  84]\n",
      " [ 21   0  17   0  94  27  18   8 673 116]\n",
      " [  7   0   0   0  24   4   1  19  14 940]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['9' '0' '4' ... '9' '6' '9']\n",
      "probabilities: (59625, 10) \n",
      " [9 0 4 ... 9 6 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (375, 784) (375,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [ 15   2  10   2 107  20  27  86  26 105] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.506 s \n",
      "\n",
      "Accuracy rate for 67.640000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86       980\n",
      "           1       0.98      0.46      0.63      1135\n",
      "           2       0.77      0.55      0.64      1032\n",
      "           3       0.78      0.08      0.14      1010\n",
      "           4       0.49      0.92      0.64       982\n",
      "           5       0.69      0.55      0.61       892\n",
      "           6       0.81      0.82      0.81       958\n",
      "           7       0.83      0.86      0.84      1028\n",
      "           8       0.62      0.69      0.66       974\n",
      "           9       0.52      0.92      0.67      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.73      0.68      0.65     10000\n",
      "weighted avg       0.73      0.68      0.65     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[935   0   0   0   8   9   7   5   9   7]\n",
      " [  0 521   0   0 269  35   7  26 115 162]\n",
      " [ 21   8 571  11 150  12  85  45  87  42]\n",
      " [ 86   0 154  77  95 104  12  59 114 309]\n",
      " [  2   0   0   0 907   0   6   2   1  64]\n",
      " [ 89   0   8  10  90 490  40  23  37 105]\n",
      " [ 16   0   0   0 111  38 782   1   5   5]\n",
      " [  7   1   3   0  45   1   1 879  20  71]\n",
      " [ 18   0  10   1 135  22  22   4 671  91]\n",
      " [  9   0   0   0  30   4   1  19  15 931]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59600, 10) \n",
      " [5 0 4 ... 5 6 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (400, 784) (400,)\n",
      "trainset after (425, 784) (425,)\n",
      "updated train set: (425, 784) (425,) unique(labels): [ 15   3  10   2 113  20  31  90  28 113] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59575, 784) (59575,)\n",
      "\n",
      "Train set: (425, 784) y: (425,)\n",
      "Val   set: (59575, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.420 s \n",
      "\n",
      "Accuracy rate for 70.990000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       980\n",
      "           1       0.94      0.70      0.81      1135\n",
      "           2       0.80      0.57      0.67      1032\n",
      "           3       0.85      0.09      0.16      1010\n",
      "           4       0.56      0.89      0.69       982\n",
      "           5       0.75      0.58      0.65       892\n",
      "           6       0.79      0.86      0.82       958\n",
      "           7       0.82      0.87      0.84      1028\n",
      "           8       0.71      0.65      0.68       974\n",
      "           9       0.50      0.93      0.65      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.75      0.71      0.69     10000\n",
      "weighted avg       0.76      0.71      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[935   0   5   0  10   8   8   4   5   5]\n",
      " [  0 800   1   0 134  19   5  24  37 115]\n",
      " [ 17  27 588  11 107   6  96  53  67  60]\n",
      " [ 71   0 126  92  94  86  24  65  79 373]\n",
      " [  2   1   0   0 878   1   7   2   1  90]\n",
      " [ 74   3   2   5  68 516  57  24  28 115]\n",
      " [ 10   1   0   0  88  28 827   0   1   3]\n",
      " [  1   6   2   0  24   1   1 895  24  74]\n",
      " [ 17   9  10   0 133  20  27   7 630 121]\n",
      " [  7   0   1   0  25   3   1  18  16 938]]\n",
      "--------------------------------\n",
      "val predicted: (59575,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59575, 10) \n",
      " [5 0 4 ... 5 6 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (425, 784) (425,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [ 15   3  10   2 119  21  34  95  31 120] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.616 s \n",
      "\n",
      "Accuracy rate for 70.590000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       980\n",
      "           1       0.96      0.72      0.82      1135\n",
      "           2       0.81      0.51      0.62      1032\n",
      "           3       0.86      0.08      0.15      1010\n",
      "           4       0.56      0.90      0.69       982\n",
      "           5       0.76      0.54      0.63       892\n",
      "           6       0.75      0.86      0.80       958\n",
      "           7       0.81      0.87      0.84      1028\n",
      "           8       0.66      0.70      0.68       974\n",
      "           9       0.51      0.93      0.66      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.75      0.71      0.68     10000\n",
      "weighted avg       0.75      0.71      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[938   0   1   0   8   7   9   3   6   8]\n",
      " [  0 819   0   0 164  15   5  21  55  56]\n",
      " [ 19  19 522  10 104   8 127  60  96  67]\n",
      " [ 66   0 116  84  88  86  27  77 103 363]\n",
      " [  2   0   0   0 879   1   8   1   2  89]\n",
      " [ 65   1   3   3  81 485  64  26  38 126]\n",
      " [ 14   1   1   0  96  20 821   1   1   3]\n",
      " [  1   4   0   0  23   1   1 895  26  77]\n",
      " [ 16   6   2   1 107  14  38   8 679 103]\n",
      " [  6   1   0   0  23   3   1  17  21 937]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59550, 10) \n",
      " [5 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (450, 784) (450,)\n",
      "trainset after (475, 784) (475,)\n",
      "updated train set: (475, 784) (475,) unique(labels): [ 15   3  10   2 125  24  36 101  32 127] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59525, 784) (59525,)\n",
      "\n",
      "Train set: (475, 784) y: (475,)\n",
      "Val   set: (59525, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.561 s \n",
      "\n",
      "Accuracy rate for 70.810000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.89       980\n",
      "           1       0.95      0.69      0.80      1135\n",
      "           2       0.79      0.57      0.67      1032\n",
      "           3       0.84      0.08      0.15      1010\n",
      "           4       0.62      0.88      0.73       982\n",
      "           5       0.74      0.55      0.63       892\n",
      "           6       0.73      0.88      0.80       958\n",
      "           7       0.81      0.87      0.84      1028\n",
      "           8       0.68      0.69      0.69       974\n",
      "           9       0.49      0.94      0.64      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.75      0.71      0.68     10000\n",
      "weighted avg       0.75      0.71      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[912   0   3   0  10   9  21   7  10   8]\n",
      " [  0 781   1   0 142   8   6  18  59 120]\n",
      " [ 13  21 591  10  79   8 112  59  81  58]\n",
      " [ 60   0 142  81  61 102  31  74  83 376]\n",
      " [  2   2   0   0 865   1   8   2   1 101]\n",
      " [ 61   2   2   5  42 495  79  24  32 150]\n",
      " [ 11   1   1   0  77  22 844   1   0   1]\n",
      " [  3   7   0   0  15   1   1 892  28  81]\n",
      " [ 13  12   4   1  92  20  52   6 674 100]\n",
      " [  6   0   0   0  18   3   1  18  17 946]]\n",
      "--------------------------------\n",
      "val predicted: (59525,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59525, 10) \n",
      " [5 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (475, 784) (475,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [ 17   5  12   2 126  27  37 109  34 131] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.721 s \n",
      "\n",
      "Accuracy rate for 72.480000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       980\n",
      "           1       0.89      0.86      0.87      1135\n",
      "           2       0.83      0.50      0.62      1032\n",
      "           3       0.84      0.09      0.16      1010\n",
      "           4       0.64      0.88      0.74       982\n",
      "           5       0.77      0.56      0.65       892\n",
      "           6       0.76      0.84      0.80       958\n",
      "           7       0.76      0.88      0.82      1028\n",
      "           8       0.66      0.73      0.69       974\n",
      "           9       0.55      0.94      0.69      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.75      0.72      0.69     10000\n",
      "weighted avg       0.76      0.72      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[929   1   0   0   6   9  12  10   6   7]\n",
      " [  0 974   1   0  60   1   5  19   6  69]\n",
      " [ 18  88 519  13  90   6  95  59  83  61]\n",
      " [ 50   4  97  92  57  98  25 116 185 286]\n",
      " [  1   2   0   0 863   4  10   3   2  97]\n",
      " [ 56   2   3   4  48 500  71  48  55 105]\n",
      " [ 14   4   0   0 115  15 804   3   0   3]\n",
      " [  1   7   4   0  17   0   0 908  20  71]\n",
      " [ 12  17   4   0  83  17  30   9 715  87]\n",
      " [  5   1   1   0  19   3   1  18  17 944]]\n",
      "--------------------------------\n",
      "final active learning accuracies [49.919999999999995, 57.489999999999995, 63.129999999999995, 65.53, 69.39999999999999, 69.73, 69.32000000000001, 66.67999999999999, 67.25, 66.97999999999999, 66.36999999999999, 68.22, 66.18, 67.42, 67.67999999999999, 67.64, 70.99, 70.59, 70.81, 72.48]\n",
      "saved Active-learning-experiment-29.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', '.git']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 30, using model = RfModel, selection_function = EntropySelection, k = 10, iteration = 0.\n",
      "\n",
      "initial random chosen samples (10,)\n",
      "initial train set: (10, 784) (10,) unique(labels): [0 0 0 2 0 1 0 3 3 1] [3 5 7 8 9]\n",
      "val set: (59990, 784) (59990,) (10,)\n",
      "\n",
      "Train set: (10, 784) y: (10,)\n",
      "Val   set: (59990, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 2.374 s \n",
      "\n",
      "Accuracy rate for 22.340000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       980\n",
      "           1       0.00      0.00      0.00      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.52      0.40      0.45      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.10      0.02      0.03       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.20      0.97      0.33      1028\n",
      "           8       0.20      0.81      0.32       974\n",
      "           9       0.47      0.04      0.07      1009\n",
      "\n",
      "    accuracy                           0.22     10000\n",
      "   macro avg       0.15      0.22      0.12     10000\n",
      "weighted avg       0.15      0.22      0.12     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  0   0   0  50   0 111   0 358 461   0]\n",
      " [  0   0   0   1   0   0   0 776 358   0]\n",
      " [  0   0   0  32   0   1   0 411 588   0]\n",
      " [  0   0   0 401   0  26   0 143 440   0]\n",
      " [  0   0   0  48   0   1   0 730 166  37]\n",
      " [  0   0   0 153   0  17   0 244 478   0]\n",
      " [  0   0   0   7   0   2   0 383 564   2]\n",
      " [  0   0   0  15   0   1   0 993  15   4]\n",
      " [  0   0   0  39   0   4   0 146 785   0]\n",
      " [  0   0   0  19   0   2   0 810 140  38]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59990,) ['7' '8' '3' ... '8' '7' '8']\n",
      "probabilities: (59990, 5) \n",
      " [2 3 0 ... 3 2 3]\n",
      "trainset before (10, 784) (10,)\n",
      "trainset after (20, 784) (20,)\n",
      "updated train set: (20, 784) (20,) unique(labels): [1 0 0 2 4 1 2 4 4 2] [0 3 4 5 6 7 8 9]\n",
      "val set: (59980, 784) (59980,)\n",
      "\n",
      "Train set: (20, 784) y: (20,)\n",
      "Val   set: (59980, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.209 s \n",
      "\n",
      "Accuracy rate for 27.010000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.11      0.20       980\n",
      "           1       0.00      0.00      0.00      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.80      0.18      0.30      1010\n",
      "           4       0.56      0.42      0.48       982\n",
      "           5       0.30      0.02      0.03       892\n",
      "           6       0.57      0.08      0.14       958\n",
      "           7       0.24      0.95      0.38      1028\n",
      "           8       0.19      0.85      0.31       974\n",
      "           9       0.75      0.10      0.17      1009\n",
      "\n",
      "    accuracy                           0.27     10000\n",
      "   macro avg       0.43      0.27      0.20     10000\n",
      "weighted avg       0.43      0.27      0.20     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[107   0   0   5  54   7  44 362 399   2]\n",
      " [  0   0   0   0   0   0   0 423 712   0]\n",
      " [  1   0   0  10  43   0   5 472 501   0]\n",
      " [  1   0   0 185   1  22   3 153 641   4]\n",
      " [  0   0   0   1 412   0   1 375 190   3]\n",
      " [  3   0   0  22  24  14   3 289 533   4]\n",
      " [  2   0   0   0 105   0  79 324 448   0]\n",
      " [  0   0   0   1  13   0   0 981  20  13]\n",
      " [  0   0   0   7  24   1   1 108 827   6]\n",
      " [  1   0   0   1  54   2   2 679 174  96]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59980,) ['7' '8' '4' ... '8' '7' '8']\n",
      "probabilities: (59980, 8) \n",
      " [5 6 2 ... 6 5 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (20, 784) (20,)\n",
      "trainset after (30, 784) (30,)\n",
      "updated train set: (30, 784) (30,) unique(labels): [1 0 1 2 6 1 4 7 6 2] [0 2 3 4 5 6 7 8 9]\n",
      "val set: (59970, 784) (59970,)\n",
      "\n",
      "Train set: (30, 784) y: (30,)\n",
      "Val   set: (59970, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.515 s \n",
      "\n",
      "Accuracy rate for 32.070000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.06      0.12       980\n",
      "           1       0.00      0.00      0.00      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.86      0.10      0.18      1010\n",
      "           4       0.61      0.70      0.65       982\n",
      "           5       0.19      0.02      0.03       892\n",
      "           6       0.54      0.47      0.51       958\n",
      "           7       0.28      0.94      0.43      1028\n",
      "           8       0.20      0.86      0.32       974\n",
      "           9       0.80      0.08      0.15      1009\n",
      "\n",
      "    accuracy                           0.32     10000\n",
      "   macro avg       0.43      0.32      0.24     10000\n",
      "weighted avg       0.43      0.32      0.24     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 62   0   0   0  12  39  26 370 469   2]\n",
      " [  0   0   0   0   0   0  21 348 766   0]\n",
      " [  1   0   0   5  38   0 192 292 504   0]\n",
      " [  2   0   0 101   3  29   9 168 696   2]\n",
      " [  0   0   0   0 688   0  23 196  74   1]\n",
      " [  3   0   0   9  63  17  91 259 446   4]\n",
      " [  3   0   0   0  95   0 454 120 286   0]\n",
      " [  0   0   0   0  17   0   6 968  29   8]\n",
      " [  1   0   1   2  27   1  15  89 834   4]\n",
      " [  2   0   1   0 176   3   1 676  67  83]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59970,) ['7' '7' '4' ... '7' '7' '8']\n",
      "probabilities: (59970, 9) \n",
      " [6 6 3 ... 6 6 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (30, 784) (30,)\n",
      "trainset after (40, 784) (40,)\n",
      "updated train set: (40, 784) (40,) unique(labels): [ 1  0  3  3  7  1  6 10  7  2] [0 2 3 4 5 6 7 8 9]\n",
      "val set: (59960, 784) (59960,)\n",
      "\n",
      "Train set: (40, 784) y: (40,)\n",
      "Val   set: (59960, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.829 s \n",
      "\n",
      "Accuracy rate for 35.160000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.07      0.12       980\n",
      "           1       0.00      0.00      0.00      1135\n",
      "           2       0.97      0.09      0.16      1032\n",
      "           3       0.66      0.15      0.25      1010\n",
      "           4       0.45      0.83      0.58       982\n",
      "           5       0.06      0.01      0.01       892\n",
      "           6       0.44      0.55      0.49       958\n",
      "           7       0.35      0.93      0.51      1028\n",
      "           8       0.23      0.86      0.37       974\n",
      "           9       0.68      0.07      0.13      1009\n",
      "\n",
      "    accuracy                           0.35     10000\n",
      "   macro avg       0.46      0.35      0.26     10000\n",
      "weighted avg       0.46      0.35      0.26     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 65   0   0  31  70  63  55 316 377   3]\n",
      " [  0   0   0   0   0   0 179 218 738   0]\n",
      " [  6   0  88  10  91   0 230 252 355   0]\n",
      " [  1   0   1 152  18  25  26 143 639   5]\n",
      " [  1   0   0   0 815   0  46  77  41   2]\n",
      " [  3   0   0  31 133   6 111 206 394   8]\n",
      " [  3   0   0   0 244   0 525  34 152   0]\n",
      " [  0   0   2   1  28   0   6 960  24   7]\n",
      " [  2   0   0   3  33   0  21  72 835   8]\n",
      " [  0   0   0   1 390   7   4 493  44  70]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (59960,) ['7' '7' '4' ... '7' '7' '8']\n",
      "probabilities: (59960, 9) \n",
      " [6 6 3 ... 6 6 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (40, 784) (40,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [ 1  3  3  4  7  2  8 12  7  3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 3.963 s \n",
      "\n",
      "Accuracy rate for 47.720000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.18       980\n",
      "           1       0.84      0.56      0.67      1135\n",
      "           2       0.99      0.10      0.17      1032\n",
      "           3       0.66      0.40      0.50      1010\n",
      "           4       0.57      0.80      0.67       982\n",
      "           5       0.25      0.19      0.21       892\n",
      "           6       0.48      0.69      0.57       958\n",
      "           7       0.32      0.94      0.48      1028\n",
      "           8       0.43      0.76      0.55       974\n",
      "           9       0.80      0.21      0.33      1009\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.60      0.47      0.43     10000\n",
      "weighted avg       0.61      0.48      0.44     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[105   0   0  61  20 330  93 231 131   9]\n",
      " [  0 635   0   0   0   0  94 343  63   0]\n",
      " [  8  82  99  61  72   4 217 280 209   0]\n",
      " [  6   8   0 406   6 147  42 163 231   1]\n",
      " [  5   2   0   0 783   0  63 105  17   7]\n",
      " [ 13   2   0  72  67 166 164 212 181  15]\n",
      " [ 19   1   0   0 134   2 665  49  87   1]\n",
      " [  0  15   1   1  18   0   5 964  13  11]\n",
      " [  3  13   0   7  26   2  40 136 738   9]\n",
      " [  3   2   0   6 242   2   7 504  32 211]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['7' '7' '4' ... '7' '6' '6']\n",
      "probabilities: (59950, 10) \n",
      " [7 7 4 ... 7 6 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (50, 784) (50,)\n",
      "trainset after (60, 784) (60,)\n",
      "updated train set: (60, 784) (60,) unique(labels): [ 1  7  4  4  8  2  9 14  8  3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59940, 784) (59940,)\n",
      "\n",
      "Train set: (60, 784) y: (60,)\n",
      "Val   set: (59940, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.203 s \n",
      "\n",
      "Accuracy rate for 47.970000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.09      0.16       980\n",
      "           1       0.77      0.91      0.83      1135\n",
      "           2       0.81      0.11      0.20      1032\n",
      "           3       0.55      0.32      0.40      1010\n",
      "           4       0.43      0.81      0.56       982\n",
      "           5       0.33      0.14      0.19       892\n",
      "           6       0.46      0.58      0.51       958\n",
      "           7       0.37      0.94      0.53      1028\n",
      "           8       0.45      0.71      0.55       974\n",
      "           9       0.74      0.10      0.18      1009\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.56      0.47      0.41     10000\n",
      "weighted avg       0.56      0.48      0.42     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  89    2    2   88   64  122  110  302  189   12]\n",
      " [   0 1031    0    4    0    0   25    7   68    0]\n",
      " [   9   75  116   83   71    1  225  249  203    0]\n",
      " [   5  100   15  320   21  127   32  195  192    3]\n",
      " [   2   13    0    0  798    0   71   91    5    2]\n",
      " [   9   42    5   68  148  122  146  210  134    8]\n",
      " [  10    4    2    1  286    0  556   55   44    0]\n",
      " [   0   21    0    1   16    0    2  970   15    3]\n",
      " [   5   43    2   10   59    0   41  114  692    8]\n",
      " [   2   15    1    4  407    1   13  453   10  103]]\n",
      "--------------------------------\n",
      "val predicted: (59940,) ['7' '7' '4' ... '7' '4' '6']\n",
      "probabilities: (59940, 10) \n",
      " [7 7 4 ... 7 4 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (60, 784) (60,)\n",
      "trainset after (70, 784) (70,)\n",
      "updated train set: (70, 784) (70,) unique(labels): [ 1 10  5  7  8  2 10 15  9  3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59930, 784) (59930,)\n",
      "\n",
      "Train set: (70, 784) y: (70,)\n",
      "Val   set: (59930, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.142 s \n",
      "\n",
      "Accuracy rate for 52.400000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.13      0.22       980\n",
      "           1       0.77      0.97      0.86      1135\n",
      "           2       0.86      0.23      0.36      1032\n",
      "           3       0.73      0.65      0.69      1010\n",
      "           4       0.41      0.79      0.54       982\n",
      "           5       0.28      0.11      0.16       892\n",
      "           6       0.42      0.58      0.49       958\n",
      "           7       0.40      0.92      0.56      1028\n",
      "           8       0.57      0.70      0.63       974\n",
      "           9       0.75      0.06      0.12      1009\n",
      "\n",
      "    accuracy                           0.52     10000\n",
      "   macro avg       0.59      0.51      0.46     10000\n",
      "weighted avg       0.60      0.52      0.47     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 125    3   12   21   84  197  152  299   82    5]\n",
      " [   0 1100    0    0    0    0   20    5   10    0]\n",
      " [  14  126  236   51   68    2  210  193  132    0]\n",
      " [   7   33    8  660    9   58   37   93  104    1]\n",
      " [   3   18    1    2  772    0   85   98    3    0]\n",
      " [  12   28    1  115  120  101  199  172  140    4]\n",
      " [  10    9    8    0  304    0  557   40   30    0]\n",
      " [   2   42    4    4   19    0    3  944    4    6]\n",
      " [   3   46    2   43   58    1   52   83  680    6]\n",
      " [   4   21    2    8  434    2   19  437   17   65]]\n",
      "--------------------------------\n",
      "val predicted: (59930,) ['7' '7' '4' ... '7' '6' '6']\n",
      "probabilities: (59930, 10) \n",
      " [7 7 4 ... 7 6 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (70, 784) (70,)\n",
      "trainset after (80, 784) (80,)\n",
      "updated train set: (80, 784) (80,) unique(labels): [ 1 16  5  8  8  2 10 17 10  3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59920, 784) (59920,)\n",
      "\n",
      "Train set: (80, 784) y: (80,)\n",
      "Val   set: (59920, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.316 s \n",
      "\n",
      "Accuracy rate for 51.090000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.08      0.14       980\n",
      "           1       0.72      0.97      0.82      1135\n",
      "           2       0.85      0.17      0.29      1032\n",
      "           3       0.72      0.65      0.69      1010\n",
      "           4       0.38      0.79      0.51       982\n",
      "           5       0.30      0.12      0.17       892\n",
      "           6       0.43      0.54      0.48       958\n",
      "           7       0.39      0.93      0.55      1028\n",
      "           8       0.61      0.68      0.64       974\n",
      "           9       0.71      0.08      0.14      1009\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.58      0.50      0.44     10000\n",
      "weighted avg       0.58      0.51      0.45     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  77    5   11   11  169  186  126  312   70   13]\n",
      " [   0 1101    0    1    0    0   18    4   11    0]\n",
      " [  10  133  180   40   87    1  167  278  136    0]\n",
      " [   5   57    4  659   13   53   36   93   89    1]\n",
      " [   2   21    0    7  779    0   76   95    1    1]\n",
      " [  10   72    1  118  140  105  179  169   91    7]\n",
      " [   9   14   10    0  336    0  514   57   18    0]\n",
      " [   0   48    2    6   14    0    2  952    1    3]\n",
      " [   2   61    2   47   58    0   47   86  665    6]\n",
      " [   2   23    2   21  458    1   17  398   10   77]]\n",
      "--------------------------------\n",
      "val predicted: (59920,) ['7' '7' '4' ... '7' '4' '6']\n",
      "probabilities: (59920, 10) \n",
      " [7 7 4 ... 7 4 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (80, 784) (80,)\n",
      "trainset after (90, 784) (90,)\n",
      "updated train set: (90, 784) (90,) unique(labels): [ 2 21  5  8  8  3 10 18 11  4] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59910, 784) (59910,)\n",
      "\n",
      "Train set: (90, 784) y: (90,)\n",
      "Val   set: (59910, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.269 s \n",
      "\n",
      "Accuracy rate for 54.460000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.23      0.36       980\n",
      "           1       0.64      0.99      0.78      1135\n",
      "           2       0.79      0.18      0.29      1032\n",
      "           3       0.73      0.57      0.64      1010\n",
      "           4       0.44      0.80      0.57       982\n",
      "           5       0.32      0.19      0.24       892\n",
      "           6       0.48      0.51      0.49       958\n",
      "           7       0.45      0.92      0.60      1028\n",
      "           8       0.58      0.70      0.64       974\n",
      "           9       0.79      0.26      0.39      1009\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.60      0.54      0.50     10000\n",
      "weighted avg       0.61      0.54      0.51     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 222   15   25   30   87  213  117  157  111    3]\n",
      " [   0 1121    1    1    0    0    5    3    4    0]\n",
      " [   4  215  187   58   83    6  142  217  120    0]\n",
      " [   8   85    5  580    7  139   35   59   91    1]\n",
      " [   3   33    0    3  789    0   69   81    3    1]\n",
      " [  14   96    2   83  110  171  120  127  122   47]\n",
      " [   9   19   13    0  370    1  486   34   26    0]\n",
      " [   2   56    2    6   13    0    2  942    1    4]\n",
      " [   5   74    1   21   45    3   32   96  685   12]\n",
      " [   2   24    1   13  298    6    9  381   12  263]]\n",
      "--------------------------------\n",
      "val predicted: (59910,) ['5' '4' '1' ... '7' '6' '6']\n",
      "probabilities: (59910, 10) \n",
      " [5 4 1 ... 7 6 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (90, 784) (90,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 2 29  6  8  8  3 10 18 11  5] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.392 s \n",
      "\n",
      "Accuracy rate for 57.920000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.24      0.38       980\n",
      "           1       0.66      0.99      0.79      1135\n",
      "           2       0.81      0.32      0.46      1032\n",
      "           3       0.73      0.62      0.67      1010\n",
      "           4       0.50      0.79      0.61       982\n",
      "           5       0.35      0.20      0.26       892\n",
      "           6       0.48      0.56      0.52       958\n",
      "           7       0.47      0.91      0.62      1028\n",
      "           8       0.60      0.72      0.65       974\n",
      "           9       0.79      0.34      0.48      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.63      0.57      0.54     10000\n",
      "weighted avg       0.63      0.58      0.55     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 232   20   32   32   77  209  116  170   87    5]\n",
      " [   0 1123    1    1    0    0    5    2    3    0]\n",
      " [   3  140  332   44   79    7  151  176   98    2]\n",
      " [   3   86    9  624    3  110   31   50   90    4]\n",
      " [   2   33    0    2  778    0   85   67    4   11]\n",
      " [   6  111    2  100   70  181  138  100  137   47]\n",
      " [   8   23   24    0  290    4  537   31   41    0]\n",
      " [   0   65    3    7   12    0    1  934    0    6]\n",
      " [   0   75    4   32   35    2   32   73  705   16]\n",
      " [   1   29    1   11  221    6   15  365   14  346]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['5' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59900, 10) \n",
      " [5 4 1 ... 5 6 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (100, 784) (100,)\n",
      "trainset after (110, 784) (110,)\n",
      "updated train set: (110, 784) (110,) unique(labels): [ 2 38  6  8  8  3 10 18 11  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59890, 784) (59890,)\n",
      "\n",
      "Train set: (110, 784) y: (110,)\n",
      "Val   set: (59890, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.296 s \n",
      "\n",
      "Accuracy rate for 57.490000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.17      0.28       980\n",
      "           1       0.61      0.99      0.75      1135\n",
      "           2       0.84      0.28      0.42      1032\n",
      "           3       0.74      0.55      0.63      1010\n",
      "           4       0.56      0.76      0.64       982\n",
      "           5       0.31      0.21      0.25       892\n",
      "           6       0.53      0.59      0.56       958\n",
      "           7       0.49      0.90      0.63      1028\n",
      "           8       0.60      0.68      0.64       974\n",
      "           9       0.62      0.51      0.56      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.61      0.57      0.54     10000\n",
      "weighted avg       0.61      0.57      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 165   22   22   16   40  255  121  159  112   68]\n",
      " [   0 1127    1    1    0    0    3    2    1    0]\n",
      " [   3  197  291   45   78    8  127  189   84   10]\n",
      " [   8  105   11  560    3  132   25   53  103   10]\n",
      " [   2   42    0    2  746    0   64   78    4   44]\n",
      " [  10  128    1  104   56  185  117   70  100  121]\n",
      " [  11   25   14    0  262    1  569   40   27    9]\n",
      " [   3   74    1    2   14    1    1  925    0    7]\n",
      " [   3  105    2   14   29    1   30   72  667   51]\n",
      " [   0   31    2   17  112    7   13  304    9  514]]\n",
      "--------------------------------\n",
      "val predicted: (59890,) ['5' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59890, 10) \n",
      " [5 4 1 ... 5 6 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (110, 784) (110,)\n",
      "trainset after (120, 784) (120,)\n",
      "updated train set: (120, 784) (120,) unique(labels): [ 2 46  7  8  8  3 10 19 11  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59880, 784) (59880,)\n",
      "\n",
      "Train set: (120, 784) y: (120,)\n",
      "Val   set: (59880, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.453 s \n",
      "\n",
      "Accuracy rate for 57.270000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.21      0.33       980\n",
      "           1       0.63      0.99      0.77      1135\n",
      "           2       0.84      0.38      0.53      1032\n",
      "           3       0.75      0.58      0.65      1010\n",
      "           4       0.51      0.75      0.61       982\n",
      "           5       0.33      0.20      0.25       892\n",
      "           6       0.53      0.52      0.52       958\n",
      "           7       0.43      0.91      0.58      1028\n",
      "           8       0.65      0.66      0.66       974\n",
      "           9       0.69      0.42      0.52      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.62      0.56      0.54     10000\n",
      "weighted avg       0.62      0.57      0.55     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 204   11   25   13   61  209  116  258   69   14]\n",
      " [   0 1127    1    0    0    0    2    4    1    0]\n",
      " [   3  127  396   35   84    6  107  197   68    9]\n",
      " [   6   98   14  581    5  132   21   72   74    7]\n",
      " [   0   45    0    1  741    0   64   97    1   33]\n",
      " [  12  135    1  108   54  176  105  117   92   92]\n",
      " [  11   21   26    0  327    2  498   41   31    1]\n",
      " [   0   72    2    2   12    0    1  936    1    2]\n",
      " [   1  115    4   19   35    3   27   93  643   34]\n",
      " [   2   36    1   13  146    7    7  365    7  425]]\n",
      "--------------------------------\n",
      "val predicted: (59880,) ['7' '4' '1' ... '5' '6' '6']\n",
      "probabilities: (59880, 10) \n",
      " [7 4 1 ... 5 6 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (120, 784) (120,)\n",
      "trainset after (130, 784) (130,)\n",
      "updated train set: (130, 784) (130,) unique(labels): [ 2 55  7  8  8  3 10 20 11  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59870, 784) (59870,)\n",
      "\n",
      "Train set: (130, 784) y: (130,)\n",
      "Val   set: (59870, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.327 s \n",
      "\n",
      "Accuracy rate for 56.650000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.20      0.32       980\n",
      "           1       0.63      0.99      0.77      1135\n",
      "           2       0.84      0.34      0.48      1032\n",
      "           3       0.77      0.55      0.64      1010\n",
      "           4       0.52      0.73      0.61       982\n",
      "           5       0.28      0.15      0.20       892\n",
      "           6       0.49      0.52      0.51       958\n",
      "           7       0.44      0.91      0.60      1028\n",
      "           8       0.59      0.67      0.63       974\n",
      "           9       0.67      0.49      0.57      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.61      0.56      0.53     10000\n",
      "weighted avg       0.61      0.57      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 194   12   26    8   60  229  121  209   99   22]\n",
      " [   0 1128    1    0    0    0    3    3    0    0]\n",
      " [   3  146  348   19   85    6  109  221   89    6]\n",
      " [   6  108   15  559    6   97   40   70  101    8]\n",
      " [   0   41    0    1  719    0   73  101    1   46]\n",
      " [  11  117    1  112   51  136  128  106  122  108]\n",
      " [   8   20   17    0  340    1  502   37   30    3]\n",
      " [   3   65    2    3   14    1    1  935    0    4]\n",
      " [   1  114    4   11   33    0   34   86  650   41]\n",
      " [   1   39    1   13   86    8   13  345    9  494]]\n",
      "--------------------------------\n",
      "val predicted: (59870,) ['5' '4' '1' ... '5' '7' '8']\n",
      "probabilities: (59870, 10) \n",
      " [5 4 1 ... 5 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (130, 784) (130,)\n",
      "trainset after (140, 784) (140,)\n",
      "updated train set: (140, 784) (140,) unique(labels): [ 2 64  7  8  8  3 10 21 11  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59860, 784) (59860,)\n",
      "\n",
      "Train set: (140, 784) y: (140,)\n",
      "Val   set: (59860, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.465 s \n",
      "\n",
      "Accuracy rate for 56.420000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.17      0.29       980\n",
      "           1       0.56      0.99      0.71      1135\n",
      "           2       0.88      0.32      0.47      1032\n",
      "           3       0.76      0.52      0.62      1010\n",
      "           4       0.51      0.76      0.61       982\n",
      "           5       0.30      0.20      0.24       892\n",
      "           6       0.56      0.55      0.56       958\n",
      "           7       0.48      0.90      0.62      1028\n",
      "           8       0.61      0.67      0.64       974\n",
      "           9       0.64      0.45      0.53      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.62      0.55      0.53     10000\n",
      "weighted avg       0.62      0.56      0.53     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 169   47   13    3   60  268   95  190   89   46]\n",
      " [   0 1127    0    0    0    0    3    4    1    0]\n",
      " [   2  190  332   18   86    4  115  198   81    6]\n",
      " [   4  146    8  530    3  128   23   64   94   10]\n",
      " [   1   51    0    3  750    0   62   77    2   36]\n",
      " [   6  184    1  110   55  175   83   62  107  109]\n",
      " [   8   31   16    0  297    2  529   39   31    5]\n",
      " [   4   81    2    1   13    1    0  924    0    2]\n",
      " [   1  115    4   17   37    2   27   83  649   39]\n",
      " [   1   47    1   14  161    6   11  299   12  457]]\n",
      "--------------------------------\n",
      "val predicted: (59860,) ['5' '4' '1' ... '5' '6' '6']\n",
      "probabilities: (59860, 10) \n",
      " [5 4 1 ... 5 6 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (140, 784) (140,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [ 2 74  7  8  8  3 10 21 11  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.355 s \n",
      "\n",
      "Accuracy rate for 56.470000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.23      0.36       980\n",
      "           1       0.55      0.99      0.71      1135\n",
      "           2       0.86      0.34      0.49      1032\n",
      "           3       0.73      0.54      0.62      1010\n",
      "           4       0.48      0.74      0.58       982\n",
      "           5       0.30      0.16      0.21       892\n",
      "           6       0.55      0.56      0.56       958\n",
      "           7       0.46      0.89      0.61      1028\n",
      "           8       0.71      0.61      0.66       974\n",
      "           9       0.62      0.49      0.54      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.61      0.55      0.53     10000\n",
      "weighted avg       0.62      0.56      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 225   17   18   14  118  195  114  206   41   32]\n",
      " [   0 1129    1    0    0    0    1    4    0    0]\n",
      " [   2  204  350   24   87    8   90  219   38   10]\n",
      " [   7  152   13  543    6  112   26   67   66   18]\n",
      " [   0   49    0    4  723    0   68   84    1   53]\n",
      " [  13  180    4  120   58  140   93   84   72  128]\n",
      " [  10   30   11    0  319    1  536   29   17    5]\n",
      " [   3   77    1    2   19    0    1  918    0    7]\n",
      " [   1  160    6   20   44    2   27   71  592   51]\n",
      " [   2   43    1   15  118    3   13  317    6  491]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['5' '4' '1' ... '5' '1' '6']\n",
      "probabilities: (59850, 10) \n",
      " [5 4 1 ... 5 1 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (150, 784) (150,)\n",
      "trainset after (160, 784) (160,)\n",
      "updated train set: (160, 784) (160,) unique(labels): [ 2 82  7  8  9  4 10 21 11  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59840, 784) (59840,)\n",
      "\n",
      "Train set: (160, 784) y: (160,)\n",
      "Val   set: (59840, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.495 s \n",
      "\n",
      "Accuracy rate for 54.620000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.22      0.35       980\n",
      "           1       0.49      1.00      0.66      1135\n",
      "           2       0.85      0.28      0.42      1032\n",
      "           3       0.75      0.54      0.62      1010\n",
      "           4       0.46      0.81      0.59       982\n",
      "           5       0.35      0.13      0.19       892\n",
      "           6       0.60      0.42      0.50       958\n",
      "           7       0.46      0.90      0.61      1028\n",
      "           8       0.65      0.59      0.62       974\n",
      "           9       0.60      0.46      0.52      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.60      0.54      0.51     10000\n",
      "weighted avg       0.61      0.55      0.51     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 220   86   14    1   82  162   93  196   66   60]\n",
      " [   0 1130    1    0    0    0    1    3    0    0]\n",
      " [   2  247  292   14  122    4   63  237   43    8]\n",
      " [   8  221   14  542   14   47    7   60   82   15]\n",
      " [   2   43    0    1  798    0   32   69    3   34]\n",
      " [   8  232    4  133   88  118   49   62   76  122]\n",
      " [  20   35   15    0  394    3  405   49   28    9]\n",
      " [   1   81    1    1   14    4    0  921    0    5]\n",
      " [   1  172    3   16   57    0   21   76  573   55]\n",
      " [   2   43    1   18  158    2    4  312    6  463]]\n",
      "--------------------------------\n",
      "val predicted: (59840,) ['5' '4' '1' ... '5' '1' '6']\n",
      "probabilities: (59840, 10) \n",
      " [5 4 1 ... 5 1 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (160, 784) (160,)\n",
      "trainset after (170, 784) (170,)\n",
      "updated train set: (170, 784) (170,) unique(labels): [ 2 90  7  8 10  4 10 22 11  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59830, 784) (59830,)\n",
      "\n",
      "Train set: (170, 784) y: (170,)\n",
      "Val   set: (59830, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.376 s \n",
      "\n",
      "Accuracy rate for 55.110000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.23      0.36       980\n",
      "           1       0.49      1.00      0.66      1135\n",
      "           2       0.79      0.30      0.43      1032\n",
      "           3       0.77      0.51      0.61      1010\n",
      "           4       0.46      0.86      0.60       982\n",
      "           5       0.42      0.15      0.22       892\n",
      "           6       0.59      0.44      0.50       958\n",
      "           7       0.46      0.89      0.61      1028\n",
      "           8       0.66      0.58      0.62       974\n",
      "           9       0.69      0.44      0.54      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.61      0.54      0.52     10000\n",
      "weighted avg       0.62      0.55      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 228   48   31    0  112  131   83  255   72   20]\n",
      " [   0 1130    1    0    0    0    1    3    0    0]\n",
      " [   3  205  309   28  142    2   85  197   55    6]\n",
      " [   8  246   12  517   16   49   17   67   66   12]\n",
      " [   1   47    0    0  844    0   24   46    1   19]\n",
      " [  18  228    4  109  100  137   52   75   70   99]\n",
      " [  15   43   24    0  374    3  420   52   21    6]\n",
      " [   3   83    2    1   17    2    1  916    0    3]\n",
      " [   4  210    5    9   53    0   22   71  569   31]\n",
      " [   3   52    1    8  191    3    5  301    4  441]]\n",
      "--------------------------------\n",
      "val predicted: (59830,) ['5' '4' '1' ... '5' '4' '8']\n",
      "probabilities: (59830, 10) \n",
      " [5 4 1 ... 5 4 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (170, 784) (170,)\n",
      "trainset after (180, 784) (180,)\n",
      "updated train set: (180, 784) (180,) unique(labels): [ 2 98  7  8 11  4 10 22 11  7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59820, 784) (59820,)\n",
      "\n",
      "Train set: (180, 784) y: (180,)\n",
      "Val   set: (59820, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.572 s \n",
      "\n",
      "Accuracy rate for 55.050000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.23      0.36       980\n",
      "           1       0.48      1.00      0.64      1135\n",
      "           2       0.80      0.29      0.42      1032\n",
      "           3       0.80      0.50      0.62      1010\n",
      "           4       0.43      0.86      0.57       982\n",
      "           5       0.37      0.18      0.24       892\n",
      "           6       0.63      0.44      0.52       958\n",
      "           7       0.51      0.90      0.65      1028\n",
      "           8       0.68      0.59      0.64       974\n",
      "           9       0.67      0.41      0.51      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.62      0.54      0.52     10000\n",
      "weighted avg       0.62      0.55      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 228   79   35    3  117  212   82  133   68   23]\n",
      " [   0 1130    1    0    0    0    1    3    0    0]\n",
      " [   3  240  296    9  166    5   60  195   52    6]\n",
      " [  13  259   12  510   26   51   13   52   58   16]\n",
      " [   1   43    0    0  841    0   22   53    2   20]\n",
      " [  19  240    2  102  114  160   45   51   59  100]\n",
      " [  11   45   18    0  377    2  424   55   25    1]\n",
      " [   2   86    0    0   13    2    0  922    0    3]\n",
      " [   4  194    5    7   51    1   25   76  578   33]\n",
      " [   4   53    2    9  240    4    1  277    3  416]]\n",
      "--------------------------------\n",
      "val predicted: (59820,) ['5' '4' '1' ... '5' '4' '1']\n",
      "probabilities: (59820, 10) \n",
      " [5 4 1 ... 5 4 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (180, 784) (180,)\n",
      "trainset after (190, 784) (190,)\n",
      "updated train set: (190, 784) (190,) unique(labels): [  2 106   7   8  11   4  10  24  11   7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59810, 784) (59810,)\n",
      "\n",
      "Train set: (190, 784) y: (190,)\n",
      "Val   set: (59810, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.403 s \n",
      "\n",
      "Accuracy rate for 55.130000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.23      0.36       980\n",
      "           1       0.49      1.00      0.65      1135\n",
      "           2       0.81      0.33      0.47      1032\n",
      "           3       0.78      0.45      0.57      1010\n",
      "           4       0.45      0.85      0.59       982\n",
      "           5       0.33      0.18      0.24       892\n",
      "           6       0.66      0.43      0.52       958\n",
      "           7       0.49      0.89      0.63      1028\n",
      "           8       0.68      0.58      0.62       974\n",
      "           9       0.65      0.47      0.54      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.62      0.54      0.52     10000\n",
      "weighted avg       0.62      0.55      0.53     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 224   45   26    3   98  208   62  221   69   24]\n",
      " [   0 1130    1    0    0    0    1    3    0    0]\n",
      " [   1  211  344   12  161    7   58  184   49    5]\n",
      " [   9  251   18  452   23  114    8   61   57   17]\n",
      " [   2   48    0    0  835    0   24   54    0   19]\n",
      " [  12  258    4   87   96  164   36   44   61  130]\n",
      " [  11   42   26    0  379    3  414   52   29    2]\n",
      " [   3   89    1    1   15    2    0  914    0    3]\n",
      " [   2  202    4   13   49    1   18   64  563   58]\n",
      " [   3   48    1    8  214    2    2  255    3  473]]\n",
      "--------------------------------\n",
      "val predicted: (59810,) ['5' '4' '1' ... '5' '4' '6']\n",
      "probabilities: (59810, 10) \n",
      " [5 4 1 ... 5 4 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (190, 784) (190,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [  2 113   7   8  11   4  10  25  11   9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.564 s \n",
      "\n",
      "Accuracy rate for 55.450000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.22      0.35       980\n",
      "           1       0.47      1.00      0.64      1135\n",
      "           2       0.78      0.30      0.43      1032\n",
      "           3       0.77      0.42      0.55      1010\n",
      "           4       0.48      0.82      0.61       982\n",
      "           5       0.33      0.15      0.21       892\n",
      "           6       0.65      0.50      0.57       958\n",
      "           7       0.55      0.87      0.68      1028\n",
      "           8       0.62      0.57      0.59       974\n",
      "           9       0.55      0.58      0.57      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.61      0.54      0.52     10000\n",
      "weighted avg       0.61      0.55      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 216  106   30    6   86  180   73  145   88   50]\n",
      " [   0 1131    0    0    0    0    0    4    0    0]\n",
      " [   1  249  311    8  129    7   67  184   69    7]\n",
      " [   5  279   17  427   18   71   21   50   88   34]\n",
      " [   0   37    0    0  808    0   20   39    0   78]\n",
      " [   9  195    3   94  103  133   48   33   69  205]\n",
      " [   7   50   37    0  306    3  478   43   25    9]\n",
      " [   3   99    0    0   14    1    1  898    0   12]\n",
      " [   1  207    1   12   37    1   20   53  556   86]\n",
      " [   2   42    2    6  182    3    3  177    5  587]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['5' '4' '1' ... '5' '4' '6']\n",
      "probabilities: (59800, 10) \n",
      " [5 4 1 ... 5 4 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (200, 784) (200,)\n",
      "trainset after (210, 784) (210,)\n",
      "updated train set: (210, 784) (210,) unique(labels): [  2 119   7   8  11   4  10  28  11  10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59790, 784) (59790,)\n",
      "\n",
      "Train set: (210, 784) y: (210,)\n",
      "Val   set: (59790, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 21\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.479 s \n",
      "\n",
      "Accuracy rate for 53.770000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.17      0.28       980\n",
      "           1       0.46      1.00      0.63      1135\n",
      "           2       0.81      0.25      0.38      1032\n",
      "           3       0.77      0.44      0.56      1010\n",
      "           4       0.49      0.79      0.60       982\n",
      "           5       0.33      0.14      0.20       892\n",
      "           6       0.65      0.42      0.51       958\n",
      "           7       0.49      0.88      0.63      1028\n",
      "           8       0.60      0.57      0.58       974\n",
      "           9       0.55      0.61      0.58      1009\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.60      0.53      0.50     10000\n",
      "weighted avg       0.60      0.54      0.50     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 163   80   24   14   73  201   76  196   89   64]\n",
      " [   0 1131    1    0    0    0    0    3    0    0]\n",
      " [   1  274  258   16  130    3   67  214   59   10]\n",
      " [   9  304    9  440   13   44    8   66   76   41]\n",
      " [   0   51    0    0  775    0   21   55    1   79]\n",
      " [  11  227    2   89   81  125   31   64   75  187]\n",
      " [   5   45   22    0  338    2  402   65   66   13]\n",
      " [   4   90    0    0   11    1    0  909    0   13]\n",
      " [   1  203    1    7   31    0   14   68  555   94]\n",
      " [   3   42    2    4  128    1    2  203    5  619]]\n",
      "--------------------------------\n",
      "val predicted: (59790,) ['5' '4' '1' ... '7' '4' '6']\n",
      "probabilities: (59790, 10) \n",
      " [5 4 1 ... 7 4 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (210, 784) (210,)\n",
      "trainset after (220, 784) (220,)\n",
      "updated train set: (220, 784) (220,) unique(labels): [  2 128   7   8  11   4  10  29  11  10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59780, 784) (59780,)\n",
      "\n",
      "Train set: (220, 784) y: (220,)\n",
      "Val   set: (59780, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 22\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.611 s \n",
      "\n",
      "Accuracy rate for 53.330000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.19      0.31       980\n",
      "           1       0.45      1.00      0.62      1135\n",
      "           2       0.83      0.26      0.40      1032\n",
      "           3       0.79      0.44      0.57      1010\n",
      "           4       0.56      0.75      0.64       982\n",
      "           5       0.35      0.13      0.19       892\n",
      "           6       0.68      0.47      0.55       958\n",
      "           7       0.41      0.90      0.57      1028\n",
      "           8       0.60      0.55      0.57       974\n",
      "           9       0.59      0.53      0.56      1009\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.61      0.52      0.50     10000\n",
      "weighted avg       0.61      0.53      0.50     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 186   83   21    3   23  130   82  341  106    5]\n",
      " [   0 1130    0    0    0    0    1    4    0    0]\n",
      " [   2  273  273    8  134    7   52  206   66   11]\n",
      " [   8  277    9  448   11   67    7   87   60   36]\n",
      " [   2   56    0    0  737    0   18   97    0   72]\n",
      " [  11  269    2   90   53  115   29   86   64  173]\n",
      " [  10   73   20    0  225    3  447  120   56    4]\n",
      " [   3   85    0    0    9    3    0  925    0    3]\n",
      " [   3  232    1   11   24    1   21   74  535   72]\n",
      " [   2   45    1    7  111    1    2  301    2  537]]\n",
      "--------------------------------\n",
      "val predicted: (59780,) ['5' '4' '1' ... '9' '1' '8']\n",
      "probabilities: (59780, 10) \n",
      " [5 4 1 ... 9 1 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (220, 784) (220,)\n",
      "trainset after (230, 784) (230,)\n",
      "updated train set: (230, 784) (230,) unique(labels): [  2 137   7   8  11   4  10  30  11  10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59770, 784) (59770,)\n",
      "\n",
      "Train set: (230, 784) y: (230,)\n",
      "Val   set: (59770, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 23\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.500 s \n",
      "\n",
      "Accuracy rate for 53.690000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.22      0.34       980\n",
      "           1       0.43      1.00      0.60      1135\n",
      "           2       0.83      0.27      0.40      1032\n",
      "           3       0.81      0.40      0.53      1010\n",
      "           4       0.52      0.76      0.62       982\n",
      "           5       0.33      0.17      0.22       892\n",
      "           6       0.67      0.45      0.54       958\n",
      "           7       0.49      0.89      0.63      1028\n",
      "           8       0.68      0.52      0.59       974\n",
      "           9       0.52      0.60      0.56      1009\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.61      0.53      0.50     10000\n",
      "weighted avg       0.61      0.54      0.51     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 211  107   20    4   42  186   67  233   63   47]\n",
      " [   0 1131    1    0    0    0    0    3    0    0]\n",
      " [   3  304  275   10  121    7   72  187   37   16]\n",
      " [   8  324   10  401   17  100    5   49   56   40]\n",
      " [   2   50    0    0  742    0   20   77    1   90]\n",
      " [  11  254    2   68   69  148   30   45   47  218]\n",
      " [  11   65   19    0  285    4  434   90   33   17]\n",
      " [   4   92    1    0    7    2    0  913    0    9]\n",
      " [   1  244    2    8   29    0   18   50  504  118]\n",
      " [   4   43    1    6  111    3    1  229    1  610]]\n",
      "--------------------------------\n",
      "val predicted: (59770,) ['5' '4' '1' ... '9' '1' '1']\n",
      "probabilities: (59770, 10) \n",
      " [5 4 1 ... 9 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (230, 784) (230,)\n",
      "trainset after (240, 784) (240,)\n",
      "updated train set: (240, 784) (240,) unique(labels): [  2 146   7   8  11   4  10  31  11  10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59760, 784) (59760,)\n",
      "\n",
      "Train set: (240, 784) y: (240,)\n",
      "Val   set: (59760, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 24\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.637 s \n",
      "\n",
      "Accuracy rate for 53.760000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.21      0.33       980\n",
      "           1       0.47      1.00      0.64      1135\n",
      "           2       0.80      0.27      0.40      1032\n",
      "           3       0.74      0.44      0.55      1010\n",
      "           4       0.52      0.75      0.61       982\n",
      "           5       0.33      0.13      0.19       892\n",
      "           6       0.64      0.50      0.56       958\n",
      "           7       0.43      0.90      0.59      1028\n",
      "           8       0.66      0.52      0.58       974\n",
      "           9       0.57      0.56      0.56      1009\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.60      0.53      0.50     10000\n",
      "weighted avg       0.60      0.54      0.51     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 201   54   32   10   51  140   89  324   59   20]\n",
      " [   0 1130    1    0    0    0    1    3    0    0]\n",
      " [   5  274  279   14  127    9   61  211   42   10]\n",
      " [   8  260   10  446   14   81   12   72   69   38]\n",
      " [   1   50    0    0  735    1   27   93    1   74]\n",
      " [  10  222    4  111   68  116   53   70   58  180]\n",
      " [   9   52   19    0  273    3  476   89   26   11]\n",
      " [   3   89    1    0    6    2    0  926    0    1]\n",
      " [   1  241    1   15   31    1   19   72  507   86]\n",
      " [   2   48    1    6  113    3    2  272    2  560]]\n",
      "--------------------------------\n",
      "val predicted: (59760,) ['5' '4' '1' ... '5' '4' '6']\n",
      "probabilities: (59760, 10) \n",
      " [5 4 1 ... 5 4 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (240, 784) (240,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [  2 151   7   8  13   5  10  31  11  12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 25\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.547 s \n",
      "\n",
      "Accuracy rate for 54.550000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.12      0.21       980\n",
      "           1       0.46      1.00      0.63      1135\n",
      "           2       0.79      0.28      0.42      1032\n",
      "           3       0.83      0.44      0.58      1010\n",
      "           4       0.51      0.81      0.62       982\n",
      "           5       0.34      0.17      0.23       892\n",
      "           6       0.68      0.46      0.55       958\n",
      "           7       0.46      0.90      0.61      1028\n",
      "           8       0.63      0.54      0.58       974\n",
      "           9       0.65      0.62      0.63      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.61      0.53      0.51     10000\n",
      "weighted avg       0.61      0.55      0.51     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 118   50   18    1   53  222   69  348   95    6]\n",
      " [   0 1132    1    0    0    0    0    2    0    0]\n",
      " [   2  282  294   14  126    4   58  191   51   10]\n",
      " [   8  322   14  444   18   53    5   57   58   31]\n",
      " [   1   47    0    0  796    0   24   64    0   50]\n",
      " [  12  222    3   60   96  150   26   74   74  175]\n",
      " [   5   51   32    0  312    4  445   73   34    2]\n",
      " [   1   87    0    0   11    1    0  926    0    2]\n",
      " [   2  231   10    6   35    2   22   72  529   65]\n",
      " [   2   43    1    7  128    3    1  201    2  621]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '4' '1' ... '9' '4' '6']\n",
      "probabilities: (59750, 10) \n",
      " [5 4 1 ... 9 4 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (250, 784) (250,)\n",
      "trainset after (260, 784) (260,)\n",
      "updated train set: (260, 784) (260,) unique(labels): [  2 157   8   8  13   5  10  34  11  12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59740, 784) (59740,)\n",
      "\n",
      "Train set: (260, 784) y: (260,)\n",
      "Val   set: (59740, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 26\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.718 s \n",
      "\n",
      "Accuracy rate for 54.960000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.15      0.25       980\n",
      "           1       0.46      1.00      0.63      1135\n",
      "           2       0.77      0.31      0.45      1032\n",
      "           3       0.79      0.42      0.55      1010\n",
      "           4       0.53      0.81      0.64       982\n",
      "           5       0.29      0.17      0.22       892\n",
      "           6       0.68      0.46      0.55       958\n",
      "           7       0.48      0.90      0.63      1028\n",
      "           8       0.66      0.55      0.60       974\n",
      "           9       0.62      0.62      0.62      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.61      0.54      0.51     10000\n",
      "weighted avg       0.61      0.55      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 148   64   41    1   41  253   56  300   72    4]\n",
      " [   0 1132    1    0    0    0    0    2    0    0]\n",
      " [   4  310  325   11  111    7   69  155   30   10]\n",
      " [   7  282   12  423   17   98   12   68   67   24]\n",
      " [   2   48    0    0  791    1   15   64    1   60]\n",
      " [   9  210    2   81   76  153   38   67   74  182]\n",
      " [   9   55   33    0  296    4  440   83   32    6]\n",
      " [   2   84    0    0   11    0    0  926    0    5]\n",
      " [   4  214    7   13   31    6   19   59  533   88]\n",
      " [   1   40    1    5  121    3    1  211    1  625]]\n",
      "--------------------------------\n",
      "val predicted: (59740,) ['5' '4' '1' ... '9' '7' '8']\n",
      "probabilities: (59740, 10) \n",
      " [5 4 1 ... 9 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (260, 784) (260,)\n",
      "trainset after (270, 784) (270,)\n",
      "updated train set: (270, 784) (270,) unique(labels): [  2 161   8   8  14   5  10  37  11  14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59730, 784) (59730,)\n",
      "\n",
      "Train set: (270, 784) y: (270,)\n",
      "Val   set: (59730, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 27\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.638 s \n",
      "\n",
      "Accuracy rate for 55.120000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.13      0.23       980\n",
      "           1       0.48      1.00      0.65      1135\n",
      "           2       0.80      0.37      0.50      1032\n",
      "           3       0.80      0.41      0.55      1010\n",
      "           4       0.53      0.79      0.63       982\n",
      "           5       0.27      0.17      0.21       892\n",
      "           6       0.71      0.43      0.54       958\n",
      "           7       0.48      0.91      0.62      1028\n",
      "           8       0.65      0.54      0.59       974\n",
      "           9       0.58      0.65      0.61      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.62      0.54      0.51     10000\n",
      "weighted avg       0.62      0.55      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 132   27   34    0   42  300   51  271   93   30]\n",
      " [   0 1131    1    0    0    0    1    2    0    0]\n",
      " [   3  254  379   19  102    7   55  165   34   14]\n",
      " [   3  293   11  419   18   88    6   65   65   42]\n",
      " [   1   43    0    0  776    0   17   84    0   61]\n",
      " [   6  207    3   72   76  155   22   83   58  210]\n",
      " [   5   40   36    0  323    4  413   89   31   17]\n",
      " [   1   74    0    0   11    2    0  931    0    9]\n",
      " [   2  236    7    9   33   10   12   59  522   84]\n",
      " [   2   46    1    2   89    4    1  207    3  654]]\n",
      "--------------------------------\n",
      "val predicted: (59730,) ['5' '4' '1' ... '5' '7' '8']\n",
      "probabilities: (59730, 10) \n",
      " [5 4 1 ... 5 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (270, 784) (270,)\n",
      "trainset after (280, 784) (280,)\n",
      "updated train set: (280, 784) (280,) unique(labels): [  2 170   8   8  14   5  10  38  11  14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59720, 784) (59720,)\n",
      "\n",
      "Train set: (280, 784) y: (280,)\n",
      "Val   set: (59720, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 28\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.750 s \n",
      "\n",
      "Accuracy rate for 53.830000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.16      0.27       980\n",
      "           1       0.44      1.00      0.61      1135\n",
      "           2       0.79      0.30      0.44      1032\n",
      "           3       0.79      0.41      0.54      1010\n",
      "           4       0.54      0.77      0.64       982\n",
      "           5       0.32      0.16      0.21       892\n",
      "           6       0.73      0.43      0.54       958\n",
      "           7       0.45      0.91      0.60      1028\n",
      "           8       0.67      0.49      0.56       974\n",
      "           9       0.58      0.64      0.61      1009\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.61      0.53      0.50     10000\n",
      "weighted avg       0.61      0.54      0.51     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 161   53   28    2   36  210   41  363   79    7]\n",
      " [   0 1131    1    0    0    0    0    3    0    0]\n",
      " [   4  318  312   15  103    2   45  193   29   11]\n",
      " [   6  345    6  416   15   72    4   72   41   33]\n",
      " [   1   58    0    0  757    0   15   89    1   61]\n",
      " [   8  234    3   82   64  141   29   64   47  220]\n",
      " [  12   64   38    0  283    4  413   98   29   17]\n",
      " [   1   77    1    0   11    1    0  932    0    5]\n",
      " [   4  267    5    8   36    9   17   50  473  105]\n",
      " [   1   45    1    5   88    3    1  216    2  647]]\n",
      "--------------------------------\n",
      "val predicted: (59720,) ['7' '4' '1' ... '7' '7' '8']\n",
      "probabilities: (59720, 10) \n",
      " [7 4 1 ... 7 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (280, 784) (280,)\n",
      "trainset after (290, 784) (290,)\n",
      "updated train set: (290, 784) (290,) unique(labels): [  2 174   9   8  14   5  10  41  11  16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59710, 784) (59710,)\n",
      "\n",
      "Train set: (290, 784) y: (290,)\n",
      "Val   set: (59710, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 29\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.662 s \n",
      "\n",
      "Accuracy rate for 55.100000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.14      0.24       980\n",
      "           1       0.43      1.00      0.60      1135\n",
      "           2       0.76      0.39      0.52      1032\n",
      "           3       0.79      0.39      0.52      1010\n",
      "           4       0.54      0.79      0.64       982\n",
      "           5       0.27      0.13      0.17       892\n",
      "           6       0.75      0.42      0.54       958\n",
      "           7       0.57      0.89      0.69      1028\n",
      "           8       0.63      0.51      0.57       974\n",
      "           9       0.55      0.73      0.62      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.61      0.54      0.51     10000\n",
      "weighted avg       0.61      0.55      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 141   97   68    5   41  248   39  189  105   47]\n",
      " [   0 1132    1    0    0    0    0    2    0    0]\n",
      " [   3  284  403   13  121    7   43  108   32   18]\n",
      " [   9  375    9  391   17   51    1   54   54   49]\n",
      " [   1   51    0    0  773    0   16   56    0   85]\n",
      " [  14  247    1   76   67  115   19   46   61  246]\n",
      " [  10   69   42    0  299    3  402   57   38   38]\n",
      " [   0   75    1    0   11    1    1  920    0   19]\n",
      " [   1  262    3    5   34    4   13   46  501  105]\n",
      " [   0   42    2    6   69    2    1  150    5  732]]\n",
      "--------------------------------\n",
      "val predicted: (59710,) ['5' '4' '1' ... '9' '4' '1']\n",
      "probabilities: (59710, 10) \n",
      " [5 4 1 ... 9 4 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (290, 784) (290,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [  2 181   9   8  14   5  11  42  11  17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 30\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.816 s \n",
      "\n",
      "Accuracy rate for 54.710000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.18      0.30       980\n",
      "           1       0.44      1.00      0.61      1135\n",
      "           2       0.75      0.38      0.50      1032\n",
      "           3       0.80      0.36      0.50      1010\n",
      "           4       0.53      0.74      0.62       982\n",
      "           5       0.29      0.13      0.18       892\n",
      "           6       0.69      0.45      0.54       958\n",
      "           7       0.53      0.90      0.66      1028\n",
      "           8       0.68      0.50      0.57       974\n",
      "           9       0.52      0.72      0.61      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.61      0.54      0.51     10000\n",
      "weighted avg       0.61      0.55      0.51     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 177   71   64    0   59  200   55  257   53   44]\n",
      " [   0 1132    1    0    0    0    0    2    0    0]\n",
      " [   6  303  390   15   83    5   65  124   27   14]\n",
      " [   5  389    6  362   11   68    4   54   56   55]\n",
      " [   0   46    0    0  722    0   28   75    0  111]\n",
      " [   7  226    3   65   78  118   24   57   54  260]\n",
      " [   6   53   50    0  283    4  429   61   31   41]\n",
      " [   1   70    1    0   11    2    0  928    0   15]\n",
      " [   0  250    1    5   38    4   18   41  483  134]\n",
      " [   1   35    4    4   65    2    1  165    2  730]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['5' '4' '1' ... '9' '7' '6']\n",
      "probabilities: (59700, 10) \n",
      " [5 4 1 ... 9 7 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (300, 784) (300,)\n",
      "trainset after (310, 784) (310,)\n",
      "updated train set: (310, 784) (310,) unique(labels): [  2 188  10   8  14   5  11  43  11  18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59690, 784) (59690,)\n",
      "\n",
      "Train set: (310, 784) y: (310,)\n",
      "Val   set: (59690, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 31\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.706 s \n",
      "\n",
      "Accuracy rate for 55.510000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.16      0.27       980\n",
      "           1       0.46      1.00      0.63      1135\n",
      "           2       0.74      0.42      0.53      1032\n",
      "           3       0.79      0.39      0.52      1010\n",
      "           4       0.54      0.75      0.63       982\n",
      "           5       0.26      0.15      0.19       892\n",
      "           6       0.70      0.44      0.54       958\n",
      "           7       0.56      0.89      0.68      1028\n",
      "           8       0.69      0.50      0.58       974\n",
      "           9       0.51      0.75      0.61      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.61      0.54      0.52     10000\n",
      "weighted avg       0.61      0.56      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 158   56   64    2   40  283   50  237   63   27]\n",
      " [   0 1131    1    0    0    0    0    3    0    0]\n",
      " [   2  257  432   10  112    8   60  107   31   13]\n",
      " [   7  341   20  389    9   73    3   53   49   66]\n",
      " [   0   38    0    0  733    0   20   52    0  139]\n",
      " [  12  201    4   78   61  132   30   36   50  288]\n",
      " [   7   52   56    0  288    4  421   64   28   38]\n",
      " [   1   83    2    0    9    1    1  910    0   21]\n",
      " [   1  250    3    8   40    1   19   30  487  135]\n",
      " [   1   36    5    3   62    2    1  140    1  758]]\n",
      "--------------------------------\n",
      "val predicted: (59690,) ['5' '4' '1' ... '9' '7' '1']\n",
      "probabilities: (59690, 10) \n",
      " [5 4 1 ... 9 7 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (310, 784) (310,)\n",
      "trainset after (320, 784) (320,)\n",
      "updated train set: (320, 784) (320,) unique(labels): [  2 195  11   9  14   5  11  44  11  18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59680, 784) (59680,)\n",
      "\n",
      "Train set: (320, 784) y: (320,)\n",
      "Val   set: (59680, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 32\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.828 s \n",
      "\n",
      "Accuracy rate for 56.400000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.15      0.26       980\n",
      "           1       0.47      1.00      0.64      1135\n",
      "           2       0.69      0.51      0.59      1032\n",
      "           3       0.79      0.46      0.58      1010\n",
      "           4       0.57      0.71      0.63       982\n",
      "           5       0.26      0.10      0.15       892\n",
      "           6       0.70      0.47      0.56       958\n",
      "           7       0.53      0.89      0.66      1028\n",
      "           8       0.69      0.51      0.58       974\n",
      "           9       0.53      0.70      0.61      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.60      0.55      0.53     10000\n",
      "weighted avg       0.60      0.56      0.53     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 150   61  106    6   27  228   55  250   81   16]\n",
      " [   0 1132    1    0    0    0    0    2    0    0]\n",
      " [   4  204  526   12   89    2   55  109   17   14]\n",
      " [   9  328   36  469   10   22    4   35   48   49]\n",
      " [   0   46    0    0  697    0   34   86    0  119]\n",
      " [  11  231    6   99   54   92   30   50   50  269]\n",
      " [   9   43   70    0  253    4  455   63   27   34]\n",
      " [   2   91    1    0    9    1    1  916    0    7]\n",
      " [   2  239   14    6   36    4   18   45  493  117]\n",
      " [   1   43    3    5   57    1    1  185    3  710]]\n",
      "--------------------------------\n",
      "val predicted: (59680,) ['5' '4' '1' ... '9' '7' '6']\n",
      "probabilities: (59680, 10) \n",
      " [5 4 1 ... 9 7 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (320, 784) (320,)\n",
      "trainset after (330, 784) (330,)\n",
      "updated train set: (330, 784) (330,) unique(labels): [  2 201  11   9  14   5  12  47  11  18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59670, 784) (59670,)\n",
      "\n",
      "Train set: (330, 784) y: (330,)\n",
      "Val   set: (59670, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 33\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.757 s \n",
      "\n",
      "Accuracy rate for 55.380000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.16      0.26       980\n",
      "           1       0.45      1.00      0.62      1135\n",
      "           2       0.72      0.47      0.57      1032\n",
      "           3       0.80      0.40      0.53      1010\n",
      "           4       0.54      0.76      0.63       982\n",
      "           5       0.29      0.12      0.17       892\n",
      "           6       0.69      0.41      0.52       958\n",
      "           7       0.53      0.90      0.67      1028\n",
      "           8       0.62      0.50      0.56       974\n",
      "           9       0.54      0.70      0.61      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.60      0.54      0.51     10000\n",
      "weighted avg       0.60      0.55      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 154   48  101    4   36  187   47  281  113    9]\n",
      " [   0 1131    1    0    0    0    1    2    0    0]\n",
      " [   3  248  483   15   87    5   53  106   17   15]\n",
      " [   7  368   21  402    7   56    4   38   56   51]\n",
      " [   1   54    0    0  746    0   22   68    1   90]\n",
      " [  13  222    6   71   67  105   27   56   65  260]\n",
      " [   7   50   51    0  315    3  393   65   39   35]\n",
      " [   0   77    1    0    9    1    0  929    0   11]\n",
      " [   0  257    6    8   34    4   18   39  488  120]\n",
      " [   0   38    2    5   76    1    1  176    3  707]]\n",
      "--------------------------------\n",
      "val predicted: (59670,) ['5' '4' '1' ... '9' '7' '1']\n",
      "probabilities: (59670, 10) \n",
      " [5 4 1 ... 9 7 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (330, 784) (330,)\n",
      "trainset after (340, 784) (340,)\n",
      "updated train set: (340, 784) (340,) unique(labels): [  2 207  12   9  14   5  12  49  12  18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59660, 784) (59660,)\n",
      "\n",
      "Train set: (340, 784) y: (340,)\n",
      "Val   set: (59660, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 34\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.847 s \n",
      "\n",
      "Accuracy rate for 56.920000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.18      0.29       980\n",
      "           1       0.50      1.00      0.66      1135\n",
      "           2       0.68      0.49      0.57      1032\n",
      "           3       0.77      0.45      0.57      1010\n",
      "           4       0.56      0.70      0.62       982\n",
      "           5       0.26      0.13      0.17       892\n",
      "           6       0.72      0.43      0.54       958\n",
      "           7       0.55      0.90      0.69      1028\n",
      "           8       0.67      0.57      0.61       974\n",
      "           9       0.52      0.72      0.60      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.60      0.56      0.53     10000\n",
      "weighted avg       0.60      0.57      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 175   41  112    9   36  249   46  222   79   11]\n",
      " [   0 1131    1    0    0    0    0    3    0    0]\n",
      " [   5  217  507   16   96    5   45   96   31   14]\n",
      " [   8  310   34  455   10   58    1   37   50   47]\n",
      " [   2   49    0    0  690    0   20   71    0  150]\n",
      " [  14  176    8   99   43  113   32   51   67  289]\n",
      " [   8   38   60    0  279    4  408   65   47   49]\n",
      " [   2   73    1    0   10    1    0  930    0   11]\n",
      " [   1  209   20    4   24    4   13   37  553  109]\n",
      " [   1   35    4    6   53    3    1  174    2  730]]\n",
      "--------------------------------\n",
      "val predicted: (59660,) ['5' '4' '1' ... '9' '7' '8']\n",
      "probabilities: (59660, 10) \n",
      " [5 4 1 ... 9 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (340, 784) (340,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [  2 215  12   9  14   5  12  51  12  18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 35\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.728 s \n",
      "\n",
      "Accuracy rate for 55.850000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.19      0.31       980\n",
      "           1       0.48      1.00      0.64      1135\n",
      "           2       0.74      0.44      0.55      1032\n",
      "           3       0.79      0.46      0.58      1010\n",
      "           4       0.54      0.68      0.60       982\n",
      "           5       0.30      0.11      0.16       892\n",
      "           6       0.72      0.42      0.53       958\n",
      "           7       0.50      0.91      0.64      1028\n",
      "           8       0.73      0.53      0.61       974\n",
      "           9       0.49      0.72      0.59      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.61      0.55      0.52     10000\n",
      "weighted avg       0.61      0.56      0.53     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 187   64   69    5   54  179   42  285   61   34]\n",
      " [   0 1131    1    0    0    0    0    3    0    0]\n",
      " [   5  241  454   18   88    2   47  138   16   23]\n",
      " [   6  324   28  462    9   39    4   40   44   54]\n",
      " [   2   46    0    0  667    0   22   88    0  157]\n",
      " [  12  203    4   93   50  100   25   68   47  290]\n",
      " [  11   43   32    0  276    4  404   87   25   76]\n",
      " [   0   75    0    0   10    1    0  935    0    7]\n",
      " [   1  220   24    4   35    4   13   43  514  116]\n",
      " [   1   33    3    2   47    2    1  188    1  731]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['5' '4' '1' ... '9' '7' '1']\n",
      "probabilities: (59650, 10) \n",
      " [5 4 1 ... 9 7 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (350, 784) (350,)\n",
      "trainset after (360, 784) (360,)\n",
      "updated train set: (360, 784) (360,) unique(labels): [  2 220  12   9  14   5  12  53  13  20] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59640, 784) (59640,)\n",
      "\n",
      "Train set: (360, 784) y: (360,)\n",
      "Val   set: (59640, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 36\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.876 s \n",
      "\n",
      "Accuracy rate for 56.700000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.22      0.34       980\n",
      "           1       0.47      0.99      0.64      1135\n",
      "           2       0.72      0.43      0.54      1032\n",
      "           3       0.82      0.42      0.56      1010\n",
      "           4       0.59      0.68      0.63       982\n",
      "           5       0.30      0.10      0.15       892\n",
      "           6       0.73      0.44      0.55       958\n",
      "           7       0.52      0.89      0.66      1028\n",
      "           8       0.64      0.62      0.63       974\n",
      "           9       0.51      0.75      0.60      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.61      0.55      0.53     10000\n",
      "weighted avg       0.61      0.57      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 213   73   79    2   17  160   38  240  134   24]\n",
      " [   0 1129    1    0    0    0    1    3    0    1]\n",
      " [   5  245  441   28   87    3   61  121   32    9]\n",
      " [  10  340   20  424   10   42    2   44   52   66]\n",
      " [   0   45    0    0  672    0   20   79    1  165]\n",
      " [  13  206    6   57   44   91   24   50   73  328]\n",
      " [  10   46   50    0  234    2  423   96   48   49]\n",
      " [   3   81    1    0    9    0    1  920    0   13]\n",
      " [   1  202   14    4   26    3   11   31  601   81]\n",
      " [   1   23    4    2   42    2    0  175    4  756]]\n",
      "--------------------------------\n",
      "val predicted: (59640,) ['7' '4' '1' ... '9' '7' '8']\n",
      "probabilities: (59640, 10) \n",
      " [7 4 1 ... 9 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (360, 784) (360,)\n",
      "trainset after (370, 784) (370,)\n",
      "updated train set: (370, 784) (370,) unique(labels): [  2 227  12   9  14   5  12  56  13  20] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59630, 784) (59630,)\n",
      "\n",
      "Train set: (370, 784) y: (370,)\n",
      "Val   set: (59630, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 37\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.779 s \n",
      "\n",
      "Accuracy rate for 56.210000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.16      0.27       980\n",
      "           1       0.47      1.00      0.64      1135\n",
      "           2       0.75      0.45      0.56      1032\n",
      "           3       0.80      0.44      0.57      1010\n",
      "           4       0.58      0.69      0.63       982\n",
      "           5       0.24      0.11      0.15       892\n",
      "           6       0.75      0.44      0.56       958\n",
      "           7       0.52      0.89      0.66      1028\n",
      "           8       0.64      0.59      0.62       974\n",
      "           9       0.51      0.72      0.60      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.61      0.55      0.52     10000\n",
      "weighted avg       0.61      0.56      0.53     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 161   64   56    5   30  248   31  266  103   16]\n",
      " [   0 1130    1    0    0    0    0    3    0    1]\n",
      " [   4  252  465   19   96    4   46  107   24   15]\n",
      " [   6  334   22  442    5   36    5   45   58   57]\n",
      " [   1   53    0    0  679    0   23   71    2  153]\n",
      " [  13  204    5   77   36   95   21   58   70  313]\n",
      " [  10   52   44    0  247    4  426   78   54   43]\n",
      " [   2   79    1    0    8    1    1  919    0   17]\n",
      " [   2  208   27    6   19    3   11   45  574   79]\n",
      " [   3   25    3    4   60    1    1  177    5  730]]\n",
      "--------------------------------\n",
      "val predicted: (59630,) ['5' '4' '1' ... '9' '7' '8']\n",
      "probabilities: (59630, 10) \n",
      " [5 4 1 ... 9 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (370, 784) (370,)\n",
      "trainset after (380, 784) (380,)\n",
      "updated train set: (380, 784) (380,) unique(labels): [  2 232  12   9  14   5  12  59  14  21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59620, 784) (59620,)\n",
      "\n",
      "Train set: (380, 784) y: (380,)\n",
      "Val   set: (59620, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 38\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.923 s \n",
      "\n",
      "Accuracy rate for 56.380000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.15      0.25       980\n",
      "           1       0.52      0.99      0.68      1135\n",
      "           2       0.71      0.45      0.55      1032\n",
      "           3       0.82      0.40      0.54      1010\n",
      "           4       0.56      0.69      0.62       982\n",
      "           5       0.24      0.12      0.16       892\n",
      "           6       0.73      0.44      0.55       958\n",
      "           7       0.51      0.92      0.65      1028\n",
      "           8       0.66      0.61      0.64       974\n",
      "           9       0.50      0.72      0.59      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.60      0.55      0.52     10000\n",
      "weighted avg       0.60      0.56      0.53     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 148   28   90    4   24  285   39  249  100   13]\n",
      " [   0 1129    2    0    0    0    1    3    0    0]\n",
      " [   4  226  469   22   98    4   46  120   28   15]\n",
      " [  11  282   33  409    4   62    2   68   64   75]\n",
      " [   1   39    0    0  680    0   18   88    1  155]\n",
      " [  11  164    8   60   42  111   35   72   69  320]\n",
      " [  11   45   38    0  269    4  420   85   42   44]\n",
      " [   1   58    2    0    8    0    0  945    0   14]\n",
      " [   1  183   17    3   23    4   12   43  597   91]\n",
      " [   1   20    3    2   57    1    1  192    2  730]]\n",
      "--------------------------------\n",
      "val predicted: (59620,) ['5' '4' '1' ... '9' '7' '8']\n",
      "probabilities: (59620, 10) \n",
      " [5 4 1 ... 9 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (380, 784) (380,)\n",
      "trainset after (390, 784) (390,)\n",
      "updated train set: (390, 784) (390,) unique(labels): [  2 237  12   9  14   5  12  64  14  21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59610, 784) (59610,)\n",
      "\n",
      "Train set: (390, 784) y: (390,)\n",
      "Val   set: (59610, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 39\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.859 s \n",
      "\n",
      "Accuracy rate for 57.310000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.17      0.28       980\n",
      "           1       0.52      0.99      0.68      1135\n",
      "           2       0.71      0.44      0.54      1032\n",
      "           3       0.82      0.47      0.59      1010\n",
      "           4       0.59      0.70      0.64       982\n",
      "           5       0.26      0.11      0.15       892\n",
      "           6       0.72      0.44      0.55       958\n",
      "           7       0.52      0.91      0.67      1028\n",
      "           8       0.62      0.64      0.63       974\n",
      "           9       0.49      0.74      0.59      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.61      0.56      0.53     10000\n",
      "weighted avg       0.61      0.57      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 165   42   83    5   24  218   49  227  143   24]\n",
      " [   0 1129    1    0    0    0    1    3    0    1]\n",
      " [   3  231  454   25   86    4   51  121   37   20]\n",
      " [  10  270   25  472    2   40    2   70   45   74]\n",
      " [   1   38    0    0  687    0   21   70    2  163]\n",
      " [  11  175    1   69   37   96   25   66   79  333]\n",
      " [   9   49   49    0  244    4  420   68   66   49]\n",
      " [   1   62    1    0    8    2    1  939    0   14]\n",
      " [   1  156   19    5   18    3   12   46  620   94]\n",
      " [   2   18    4    2   52    0    1  179    2  749]]\n",
      "--------------------------------\n",
      "val predicted: (59610,) ['5' '4' '1' ... '9' '1' '8']\n",
      "probabilities: (59610, 10) \n",
      " [5 4 1 ... 9 1 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (390, 784) (390,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [  2 243  12   9  14   5  13  67  14  21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 40\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.925 s \n",
      "\n",
      "Accuracy rate for 56.120000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.17      0.29       980\n",
      "           1       0.48      0.99      0.65      1135\n",
      "           2       0.72      0.44      0.54      1032\n",
      "           3       0.82      0.39      0.52      1010\n",
      "           4       0.59      0.68      0.63       982\n",
      "           5       0.22      0.11      0.15       892\n",
      "           6       0.76      0.44      0.56       958\n",
      "           7       0.50      0.91      0.65      1028\n",
      "           8       0.65      0.63      0.64       974\n",
      "           9       0.52      0.74      0.61      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.61      0.55      0.52     10000\n",
      "weighted avg       0.61      0.56      0.53     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 171   67   76    3   14  271   31  249   89    9]\n",
      " [   0 1129    1    0    0    0    1    3    0    1]\n",
      " [   4  230  449   11   99    3   48  140   31   17]\n",
      " [   6  342   24  389    7   58    1   56   59   68]\n",
      " [   2   40    0    0  663    0   22   86    1  168]\n",
      " [  14  209    3   64   39   98   20   66   75  304]\n",
      " [   9   48   51    0  225    4  423   91   72   35]\n",
      " [   1   65    1    0    6    0    1  937    0   17]\n",
      " [   0  185   17    2   19    3   10   55  611   72]\n",
      " [   1   17    4    4   50    2    1  186    2  742]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['5' '4' '1' ... '9' '7' '8']\n",
      "probabilities: (59600, 10) \n",
      " [5 4 1 ... 9 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (400, 784) (400,)\n",
      "trainset after (410, 784) (410,)\n",
      "updated train set: (410, 784) (410,) unique(labels): [  2 246  13   9  15   5  13  71  14  22] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59590, 784) (59590,)\n",
      "\n",
      "Train set: (410, 784) y: (410,)\n",
      "Val   set: (59590, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 41\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.853 s \n",
      "\n",
      "Accuracy rate for 56.440000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.12      0.21       980\n",
      "           1       0.52      0.99      0.68      1135\n",
      "           2       0.72      0.45      0.55      1032\n",
      "           3       0.80      0.44      0.56      1010\n",
      "           4       0.60      0.71      0.65       982\n",
      "           5       0.23      0.10      0.14       892\n",
      "           6       0.76      0.44      0.56       958\n",
      "           7       0.47      0.92      0.62      1028\n",
      "           8       0.62      0.64      0.63       974\n",
      "           9       0.53      0.71      0.61      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.61      0.55      0.52     10000\n",
      "weighted avg       0.61      0.56      0.53     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 116   50   76    3   16  251   35  293  128   12]\n",
      " [   0 1129    1    0    0    0    1    3    0    1]\n",
      " [   3  226  461   16   77    3   45  148   35   18]\n",
      " [   6  270   30  440    5   45    1   84   57   72]\n",
      " [   0   40    0    0  698    0   25  101    2  116]\n",
      " [   9  184    3   81   49   90   22   81   77  296]\n",
      " [   6   47   46    0  233    3  425   99   78   21]\n",
      " [   0   60    1    0    7    1    1  946    0   12]\n",
      " [   1  162   15    6   25    2    6   58  624   75]\n",
      " [   0   16    3    5   46    0    1  220    3  715]]\n",
      "--------------------------------\n",
      "val predicted: (59590,) ['5' '4' '1' ... '9' '7' '8']\n",
      "probabilities: (59590, 10) \n",
      " [5 4 1 ... 9 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (410, 784) (410,)\n",
      "trainset after (420, 784) (420,)\n",
      "updated train set: (420, 784) (420,) unique(labels): [  2 251  13   9  16   5  13  74  14  23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59580, 784) (59580,)\n",
      "\n",
      "Train set: (420, 784) y: (420,)\n",
      "Val   set: (59580, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 42\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.988 s \n",
      "\n",
      "Accuracy rate for 57.310000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.18      0.30       980\n",
      "           1       0.52      0.99      0.68      1135\n",
      "           2       0.72      0.46      0.56      1032\n",
      "           3       0.81      0.43      0.56      1010\n",
      "           4       0.57      0.75      0.65       982\n",
      "           5       0.23      0.10      0.14       892\n",
      "           6       0.72      0.43      0.54       958\n",
      "           7       0.51      0.92      0.66      1028\n",
      "           8       0.69      0.61      0.65       974\n",
      "           9       0.51      0.73      0.60      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.61      0.56      0.53     10000\n",
      "weighted avg       0.61      0.57      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 180   29   84    7   23  234   39  249   98   37]\n",
      " [   0 1129    1    0    0    0    1    4    0    0]\n",
      " [   4  213  474   24   92    5   48  132   24   16]\n",
      " [   9  302   27  432    8   54    3   57   37   81]\n",
      " [   1   35    0    0  736    0   22   84    0  104]\n",
      " [  12  173    8   63   54   90   30   73   63  326]\n",
      " [  10   41   40    0  293    3  408   78   48   37]\n",
      " [   1   61    1    0    8    0    0  949    0    8]\n",
      " [   1  178   17    4   33    1   12   46  599   83]\n",
      " [   1   18    5    3   48    1    1  197    1  734]]\n",
      "--------------------------------\n",
      "val predicted: (59580,) ['5' '4' '1' ... '9' '7' '8']\n",
      "probabilities: (59580, 10) \n",
      " [5 4 1 ... 9 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (420, 784) (420,)\n",
      "trainset after (430, 784) (430,)\n",
      "updated train set: (430, 784) (430,) unique(labels): [  2 258  13   9  17   5  13  75  15  23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59570, 784) (59570,)\n",
      "\n",
      "Train set: (430, 784) y: (430,)\n",
      "Val   set: (59570, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 43\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.912 s \n",
      "\n",
      "Accuracy rate for 58.470000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.22      0.35       980\n",
      "           1       0.54      0.99      0.70      1135\n",
      "           2       0.72      0.46      0.56      1032\n",
      "           3       0.79      0.48      0.60      1010\n",
      "           4       0.61      0.75      0.67       982\n",
      "           5       0.27      0.10      0.14       892\n",
      "           6       0.75      0.46      0.57       958\n",
      "           7       0.48      0.92      0.63      1028\n",
      "           8       0.63      0.62      0.63       974\n",
      "           9       0.55      0.72      0.62      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.62      0.57      0.55     10000\n",
      "weighted avg       0.62      0.58      0.55     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 217   20   71    5   14  181   32  319  110   11]\n",
      " [   0 1128    1    0    0    0    1    5    0    0]\n",
      " [   6  214  474   29   71    5   56  125   38   14]\n",
      " [   7  245   38  486    6   43    2   71   46   66]\n",
      " [   1   38    0    0  736    1   22   88    1   95]\n",
      " [  13  156   10   88   52   88   22   88   76  299]\n",
      " [   6   35   35    0  256    4  439   81   77   25]\n",
      " [   2   59    1    0    8    2    0  948    0    8]\n",
      " [   1  171   20    7   24    5   11   52  608   75]\n",
      " [   1   15    4    4   47    1    1  210    3  723]]\n",
      "--------------------------------\n",
      "val predicted: (59570,) ['7' '4' '1' ... '9' '7' '8']\n",
      "probabilities: (59570, 10) \n",
      " [7 4 1 ... 9 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (430, 784) (430,)\n",
      "trainset after (440, 784) (440,)\n",
      "updated train set: (440, 784) (440,) unique(labels): [  2 264  13   9  20   5  13  76  15  23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59560, 784) (59560,)\n",
      "\n",
      "Train set: (440, 784) y: (440,)\n",
      "Val   set: (59560, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 44\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.002 s \n",
      "\n",
      "Accuracy rate for 55.820000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.14      0.24       980\n",
      "           1       0.52      1.00      0.68      1135\n",
      "           2       0.71      0.44      0.54      1032\n",
      "           3       0.86      0.37      0.52      1010\n",
      "           4       0.57      0.76      0.66       982\n",
      "           5       0.24      0.12      0.16       892\n",
      "           6       0.73      0.39      0.51       958\n",
      "           7       0.49      0.92      0.64      1028\n",
      "           8       0.60      0.61      0.61       974\n",
      "           9       0.53      0.70      0.60      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.60      0.55      0.52     10000\n",
      "weighted avg       0.60      0.56      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 139   28   84    0   14  266   35  273  127   14]\n",
      " [   0 1130    1    0    0    0    0    4    0    0]\n",
      " [   1  199  450    8  107    6   53  142   34   32]\n",
      " [  17  305   37  378   11   55    2   71   52   82]\n",
      " [   3   36    0    0  751    0   18   77    2   95]\n",
      " [  15  182    7   50   54  108   21   83   80  292]\n",
      " [  12   45   33    0  272    3  374  100   91   28]\n",
      " [   1   61    0    0    6    0    0  947    0   13]\n",
      " [   1  180   22    2   30    3   11   47  594   84]\n",
      " [   0   19    3    3   66    2    1  202    2  711]]\n",
      "--------------------------------\n",
      "val predicted: (59560,) ['5' '4' '1' ... '9' '7' '8']\n",
      "probabilities: (59560, 10) \n",
      " [5 4 1 ... 9 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (440, 784) (440,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [  2 269  14   9  21   5  13  77  15  25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 45\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.936 s \n",
      "\n",
      "Accuracy rate for 57.370000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.18      0.30       980\n",
      "           1       0.52      1.00      0.68      1135\n",
      "           2       0.68      0.47      0.55      1032\n",
      "           3       0.80      0.41      0.54      1010\n",
      "           4       0.57      0.79      0.66       982\n",
      "           5       0.28      0.11      0.16       892\n",
      "           6       0.74      0.40      0.52       958\n",
      "           7       0.52      0.92      0.67      1028\n",
      "           8       0.58      0.62      0.60       974\n",
      "           9       0.56      0.71      0.63      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.61      0.56      0.53     10000\n",
      "weighted avg       0.61      0.57      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 180   45   99    5   11  186   30  259  154   11]\n",
      " [   0 1130    2    0    0    0    0    2    0    1]\n",
      " [   2  211  482   20  114    2   37  113   33   18]\n",
      " [   9  298   43  414    9   60    2   64   53   58]\n",
      " [   1   37    0    0  780    0   22   51    0   91]\n",
      " [  15  171    5   72   64  100   26   75   94  270]\n",
      " [   8   55   40    0  277    4  384   66  102   22]\n",
      " [   2   59    2    0    8    1    1  946    0    9]\n",
      " [   1  167   27    6   33    1   14   46  606   73]\n",
      " [   0   21    5    3   70    1    1  191    2  715]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['5' '4' '1' ... '9' '4' '8']\n",
      "probabilities: (59550, 10) \n",
      " [5 4 1 ... 9 4 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (450, 784) (450,)\n",
      "trainset after (460, 784) (460,)\n",
      "updated train set: (460, 784) (460,) unique(labels): [  2 274  14  10  21   5  13  81  15  25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59540, 784) (59540,)\n",
      "\n",
      "Train set: (460, 784) y: (460,)\n",
      "Val   set: (59540, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 46\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.077 s \n",
      "\n",
      "Accuracy rate for 58.610000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.17      0.29       980\n",
      "           1       0.54      0.99      0.70      1135\n",
      "           2       0.71      0.48      0.57      1032\n",
      "           3       0.81      0.54      0.65      1010\n",
      "           4       0.56      0.81      0.66       982\n",
      "           5       0.27      0.11      0.15       892\n",
      "           6       0.78      0.38      0.51       958\n",
      "           7       0.50      0.92      0.65      1028\n",
      "           8       0.60      0.63      0.62       974\n",
      "           9       0.59      0.71      0.64      1009\n",
      "\n",
      "    accuracy                           0.59     10000\n",
      "   macro avg       0.62      0.57      0.54     10000\n",
      "weighted avg       0.62      0.59      0.55     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 170   26   84    3   23  192   25  309  138   10]\n",
      " [   0 1129    1    0    0    0    1    4    0    0]\n",
      " [   7  223  491   10  107    5   38  101   37   13]\n",
      " [   6  199   37  543   10   47    1   63   46   58]\n",
      " [   1   36    0    0  793    0   15   56    1   80]\n",
      " [  11  174    6  101   66   96   12   94   74  258]\n",
      " [  10   43   43    0  298    4  361   78  112    9]\n",
      " [   0   65    2    0    8    0    0  949    0    4]\n",
      " [   1  166   27    9   28    6    8   49  617   63]\n",
      " [   1   22    4    5   75    0    1  188    1  712]]\n",
      "--------------------------------\n",
      "val predicted: (59540,) ['5' '4' '1' ... '9' '7' '8']\n",
      "probabilities: (59540, 10) \n",
      " [5 4 1 ... 9 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (460, 784) (460,)\n",
      "trainset after (470, 784) (470,)\n",
      "updated train set: (470, 784) (470,) unique(labels): [  2 282  14  10  21   6  13  82  15  25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59530, 784) (59530,)\n",
      "\n",
      "Train set: (470, 784) y: (470,)\n",
      "Val   set: (59530, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 47\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.012 s \n",
      "\n",
      "Accuracy rate for 58.850000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.19      0.31       980\n",
      "           1       0.57      1.00      0.72      1135\n",
      "           2       0.70      0.46      0.56      1032\n",
      "           3       0.82      0.52      0.63      1010\n",
      "           4       0.58      0.78      0.67       982\n",
      "           5       0.28      0.13      0.18       892\n",
      "           6       0.77      0.43      0.55       958\n",
      "           7       0.47      0.93      0.63      1028\n",
      "           8       0.67      0.63      0.65       974\n",
      "           9       0.56      0.69      0.62      1009\n",
      "\n",
      "    accuracy                           0.59     10000\n",
      "   macro avg       0.62      0.58      0.55     10000\n",
      "weighted avg       0.63      0.59      0.56     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 187   19   77   16   10  219   33  315   98    6]\n",
      " [   0 1130    1    0    0    0    1    3    0    0]\n",
      " [   6  200  476   17   99   10   45  133   32   14]\n",
      " [   9  189   39  522    7   69    1   70   38   66]\n",
      " [   2   31    0    0  765    0   19   74    1   90]\n",
      " [  11  148    7   78   66  119   16  113   63  271]\n",
      " [  12   37   46    0  263    5  411   88   74   22]\n",
      " [   0   56    1    0    7    0    0  960    0    4]\n",
      " [   1  161   27    4   33    1    9   56  616   66]\n",
      " [   0   20    4    3   66    0    1  213    3  699]]\n",
      "--------------------------------\n",
      "val predicted: (59530,) ['5' '4' '1' ... '9' '7' '8']\n",
      "probabilities: (59530, 10) \n",
      " [5 4 1 ... 9 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (470, 784) (470,)\n",
      "trainset after (480, 784) (480,)\n",
      "updated train set: (480, 784) (480,) unique(labels): [  2 289  14  10  21   6  13  84  15  26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59520, 784) (59520,)\n",
      "\n",
      "Train set: (480, 784) y: (480,)\n",
      "Val   set: (59520, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 48\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.087 s \n",
      "\n",
      "Accuracy rate for 57.860000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.14      0.23       980\n",
      "           1       0.54      0.99      0.70      1135\n",
      "           2       0.72      0.48      0.57      1032\n",
      "           3       0.82      0.44      0.57      1010\n",
      "           4       0.60      0.78      0.68       982\n",
      "           5       0.26      0.15      0.19       892\n",
      "           6       0.74      0.43      0.55       958\n",
      "           7       0.50      0.92      0.65      1028\n",
      "           8       0.69      0.61      0.65       974\n",
      "           9       0.52      0.72      0.60      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.61      0.57      0.54     10000\n",
      "weighted avg       0.62      0.58      0.55     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 135   30   80    0   10  247   42  316  102   18]\n",
      " [   0 1129    1    0    0    0    1    3    0    1]\n",
      " [   5  208  493    9  104    7   49  115   20   22]\n",
      " [  11  223   33  444    5  120    1   52   39   82]\n",
      " [   3   33    0    0  769    0   18   61    0   98]\n",
      " [  12  164    8   75   43  135   22   75   40  318]\n",
      " [  11   46   50    0  255    6  414   75   60   41]\n",
      " [   0   58    1    0    6    1    1  948    0   13]\n",
      " [   2  183   17    7   32    5   11   48  591   78]\n",
      " [   0   17    3    4   60    2    0  194    1  728]]\n",
      "--------------------------------\n",
      "val predicted: (59520,) ['5' '4' '1' ... '9' '7' '8']\n",
      "probabilities: (59520, 10) \n",
      " [5 4 1 ... 9 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (480, 784) (480,)\n",
      "trainset after (490, 784) (490,)\n",
      "updated train set: (490, 784) (490,) unique(labels): [  2 295  14  10  21   6  13  87  15  27] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59510, 784) (59510,)\n",
      "\n",
      "Train set: (490, 784) y: (490,)\n",
      "Val   set: (59510, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 49\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 4.980 s \n",
      "\n",
      "Accuracy rate for 57.360000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.13      0.22       980\n",
      "           1       0.53      1.00      0.69      1135\n",
      "           2       0.72      0.48      0.58      1032\n",
      "           3       0.81      0.45      0.58      1010\n",
      "           4       0.57      0.80      0.67       982\n",
      "           5       0.22      0.12      0.16       892\n",
      "           6       0.77      0.39      0.52       958\n",
      "           7       0.50      0.92      0.65      1028\n",
      "           8       0.62      0.62      0.62       974\n",
      "           9       0.56      0.69      0.62      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.61      0.56      0.53     10000\n",
      "weighted avg       0.62      0.57      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 127   61   62    5    9  273   31  274  134    4]\n",
      " [   0 1130    1    0    0    0    1    2    0    1]\n",
      " [   2  199  493   14  107    7   37  126   26   21]\n",
      " [   8  232   43  457    7   85    1   50   54   73]\n",
      " [   2   36    0    0  790    0   14   61    1   78]\n",
      " [   8  183    5   77   67  110   17   78   79  268]\n",
      " [   7   48   47    0  274    5  378   94   81   24]\n",
      " [   0   61    2    0    8    0    0  948    0    9]\n",
      " [   1  180   24    8   31    6    8   47  608   61]\n",
      " [   1   19    5    2   82    3    1  198    3  695]]\n",
      "--------------------------------\n",
      "val predicted: (59510,) ['5' '4' '1' ... '9' '7' '8']\n",
      "probabilities: (59510, 10) \n",
      " [5 4 1 ... 9 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/ruslan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (490, 784) (490,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [  2 299  14  10  21   6  13  91  15  29] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 50\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 5.091 s \n",
      "\n",
      "Accuracy rate for 58.180000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.12      0.21       980\n",
      "           1       0.54      1.00      0.70      1135\n",
      "           2       0.74      0.48      0.58      1032\n",
      "           3       0.82      0.46      0.58      1010\n",
      "           4       0.61      0.77      0.68       982\n",
      "           5       0.24      0.14      0.18       892\n",
      "           6       0.77      0.49      0.60       958\n",
      "           7       0.51      0.93      0.66      1028\n",
      "           8       0.66      0.61      0.63       974\n",
      "           9       0.52      0.71      0.60      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.62      0.57      0.54     10000\n",
      "weighted avg       0.63      0.58      0.55     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 115   48   60    9    8  314   40  271  106    9]\n",
      " [   0 1130    1    1    0    0    1    1    0    1]\n",
      " [   2  189  493   12   96   11   51  126   24   28]\n",
      " [   5  247   37  460    8   65    1   58   50   79]\n",
      " [   1   34    0    0  760    0   18   61    2  106]\n",
      " [   7  157    6   73   64  126   22   81   66  290]\n",
      " [   6   43   47    0  209    6  469   74   63   41]\n",
      " [   0   59    0    0    7    0    1  952    0    9]\n",
      " [   0  177   16    5   34    4    8   42  595   93]\n",
      " [   1   19    3    4   58    1    0  204    1  718]]\n",
      "--------------------------------\n",
      "final active learning accuracies [22.34, 27.01, 32.07, 35.160000000000004, 47.72, 47.97, 52.400000000000006, 51.09, 54.459999999999994, 57.92, 57.489999999999995, 57.269999999999996, 56.65, 56.42, 56.47, 54.620000000000005, 55.11000000000001, 55.05, 55.13, 55.45, 53.769999999999996, 53.33, 53.690000000000005, 53.76, 54.55, 54.96, 55.120000000000005, 53.83, 55.1, 54.71, 55.510000000000005, 56.39999999999999, 55.379999999999995, 56.92, 55.85, 56.699999999999996, 56.21000000000001, 56.379999999999995, 57.31, 56.120000000000005, 56.44, 57.31, 58.47, 55.82, 57.37, 58.60999999999999, 58.85, 57.86, 57.36, 58.18]\n",
      "saved Active-learning-experiment-30.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "{\n",
      "  \"RfModel\": {\n",
      "    \"EntropySelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          22.34,\n",
      "          27.01,\n",
      "          32.07,\n",
      "          35.160000000000004,\n",
      "          47.72,\n",
      "          47.97,\n",
      "          52.400000000000006,\n",
      "          51.09,\n",
      "          54.459999999999994,\n",
      "          57.92,\n",
      "          57.489999999999995,\n",
      "          57.269999999999996,\n",
      "          56.65,\n",
      "          56.42,\n",
      "          56.47,\n",
      "          54.620000000000005,\n",
      "          55.11000000000001,\n",
      "          55.05,\n",
      "          55.13,\n",
      "          55.45,\n",
      "          53.769999999999996,\n",
      "          53.33,\n",
      "          53.690000000000005,\n",
      "          53.76,\n",
      "          54.55,\n",
      "          54.96,\n",
      "          55.120000000000005,\n",
      "          53.83,\n",
      "          55.1,\n",
      "          54.71,\n",
      "          55.510000000000005,\n",
      "          56.39999999999999,\n",
      "          55.379999999999995,\n",
      "          56.92,\n",
      "          55.85,\n",
      "          56.699999999999996,\n",
      "          56.21000000000001,\n",
      "          56.379999999999995,\n",
      "          57.31,\n",
      "          56.120000000000005,\n",
      "          56.44,\n",
      "          57.31,\n",
      "          58.47,\n",
      "          55.82,\n",
      "          57.37,\n",
      "          58.60999999999999,\n",
      "          58.85,\n",
      "          57.86,\n",
      "          57.36,\n",
      "          58.18\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          73.8,\n",
      "          73.65,\n",
      "          74.14,\n",
      "          74.59\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          49.919999999999995,\n",
      "          57.489999999999995,\n",
      "          63.129999999999995,\n",
      "          65.53,\n",
      "          69.39999999999999,\n",
      "          69.73,\n",
      "          69.32000000000001,\n",
      "          66.67999999999999,\n",
      "          67.25,\n",
      "          66.97999999999999,\n",
      "          66.36999999999999,\n",
      "          68.22,\n",
      "          66.18,\n",
      "          67.42,\n",
      "          67.67999999999999,\n",
      "          67.64,\n",
      "          70.99,\n",
      "          70.59,\n",
      "          70.81,\n",
      "          72.48\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          82.87,\n",
      "          81.83\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          58.25,\n",
      "          65.07,\n",
      "          65.14,\n",
      "          65.88000000000001,\n",
      "          64.94,\n",
      "          65.42999999999999,\n",
      "          66.64,\n",
      "          69.8,\n",
      "          69.13,\n",
      "          69.86\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          26.56,\n",
      "          45.550000000000004,\n",
      "          56.82000000000001,\n",
      "          67.99,\n",
      "          67.67999999999999,\n",
      "          71.17,\n",
      "          76.08,\n",
      "          78.13,\n",
      "          79.38,\n",
      "          79.69000000000001,\n",
      "          81.76,\n",
      "          82.43,\n",
      "          83.47,\n",
      "          84.99,\n",
      "          85.18,\n",
      "          86.0,\n",
      "          84.94,\n",
      "          86.07000000000001,\n",
      "          86.98,\n",
      "          86.56,\n",
      "          88.03,\n",
      "          87.92999999999999,\n",
      "          88.53,\n",
      "          89.2,\n",
      "          89.2,\n",
      "          89.71000000000001,\n",
      "          90.12,\n",
      "          90.57,\n",
      "          90.24,\n",
      "          90.49000000000001,\n",
      "          90.61,\n",
      "          91.09,\n",
      "          91.3,\n",
      "          91.07,\n",
      "          90.93,\n",
      "          91.17,\n",
      "          90.96,\n",
      "          91.38,\n",
      "          90.84,\n",
      "          91.72,\n",
      "          91.47,\n",
      "          91.56,\n",
      "          92.01,\n",
      "          91.94,\n",
      "          92.43,\n",
      "          92.43,\n",
      "          92.58999999999999,\n",
      "          92.56,\n",
      "          92.97999999999999,\n",
      "          92.80000000000001\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          73.39,\n",
      "          86.38,\n",
      "          90.11,\n",
      "          91.31\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          53.339999999999996,\n",
      "          63.85999999999999,\n",
      "          70.77,\n",
      "          75.53999999999999,\n",
      "          79.22,\n",
      "          83.19,\n",
      "          83.17999999999999,\n",
      "          84.82,\n",
      "          86.21,\n",
      "          86.72999999999999,\n",
      "          88.18,\n",
      "          89.2,\n",
      "          88.47,\n",
      "          89.64999999999999,\n",
      "          90.2,\n",
      "          90.68,\n",
      "          91.56,\n",
      "          91.64,\n",
      "          92.10000000000001,\n",
      "          92.30000000000001\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          80.64,\n",
      "          89.2\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          57.74,\n",
      "          75.92,\n",
      "          80.57,\n",
      "          86.13,\n",
      "          88.26,\n",
      "          88.62,\n",
      "          89.88000000000001,\n",
      "          90.93,\n",
      "          91.02,\n",
      "          92.17\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          28.470000000000002,\n",
      "          35.38,\n",
      "          44.85,\n",
      "          50.71,\n",
      "          58.48,\n",
      "          61.3,\n",
      "          63.739999999999995,\n",
      "          65.48,\n",
      "          70.15,\n",
      "          71.58,\n",
      "          74.52,\n",
      "          75.67,\n",
      "          77.11,\n",
      "          77.31,\n",
      "          77.44,\n",
      "          77.61,\n",
      "          78.07,\n",
      "          78.64,\n",
      "          78.99000000000001,\n",
      "          79.33,\n",
      "          79.99000000000001,\n",
      "          80.12,\n",
      "          82.24000000000001,\n",
      "          81.91000000000001,\n",
      "          82.74000000000001,\n",
      "          82.82000000000001,\n",
      "          83.21,\n",
      "          83.71,\n",
      "          83.38,\n",
      "          84.19,\n",
      "          84.61,\n",
      "          84.65,\n",
      "          84.7,\n",
      "          84.99,\n",
      "          85.13,\n",
      "          85.2,\n",
      "          85.72999999999999,\n",
      "          86.18,\n",
      "          86.25,\n",
      "          86.08,\n",
      "          85.76,\n",
      "          85.92999999999999,\n",
      "          86.33,\n",
      "          86.52,\n",
      "          86.94,\n",
      "          87.24,\n",
      "          87.26,\n",
      "          87.85,\n",
      "          87.91,\n",
      "          87.52\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          75.48,\n",
      "          83.13000000000001,\n",
      "          85.79,\n",
      "          87.78\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          35.36,\n",
      "          60.41,\n",
      "          67.99,\n",
      "          74.92,\n",
      "          78.18,\n",
      "          80.60000000000001,\n",
      "          81.69999999999999,\n",
      "          81.97,\n",
      "          82.43,\n",
      "          83.53,\n",
      "          84.89999999999999,\n",
      "          84.94,\n",
      "          85.24000000000001,\n",
      "          85.81,\n",
      "          85.96000000000001,\n",
      "          86.8,\n",
      "          87.25,\n",
      "          87.81,\n",
      "          87.9,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          79.44,\n",
      "          87.52\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          58.269999999999996,\n",
      "          71.76,\n",
      "          79.64,\n",
      "          82.54,\n",
      "          83.82,\n",
      "          83.98,\n",
      "          84.63000000000001,\n",
      "          84.89,\n",
      "          85.77,\n",
      "          86.59\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"SvmModel\": {\n",
      "    \"EntropySelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          34.22,\n",
      "          36.5,\n",
      "          41.5,\n",
      "          41.699999999999996,\n",
      "          43.05,\n",
      "          46.93,\n",
      "          50.62,\n",
      "          51.129999999999995,\n",
      "          55.74,\n",
      "          57.089999999999996,\n",
      "          56.84,\n",
      "          61.22,\n",
      "          62.029999999999994,\n",
      "          62.83,\n",
      "          62.029999999999994,\n",
      "          62.21,\n",
      "          63.28,\n",
      "          63.54,\n",
      "          65.23,\n",
      "          66.36999999999999,\n",
      "          68.42,\n",
      "          69.95,\n",
      "          69.55,\n",
      "          69.82000000000001,\n",
      "          74.8,\n",
      "          75.44,\n",
      "          74.92999999999999,\n",
      "          76.36,\n",
      "          77.23,\n",
      "          76.91,\n",
      "          75.79,\n",
      "          77.34,\n",
      "          77.81,\n",
      "          78.97,\n",
      "          80.16,\n",
      "          79.45,\n",
      "          79.65,\n",
      "          79.33,\n",
      "          79.41,\n",
      "          79.31,\n",
      "          78.95,\n",
      "          79.33,\n",
      "          78.78,\n",
      "          79.05,\n",
      "          79.11,\n",
      "          79.63,\n",
      "          79.60000000000001,\n",
      "          79.73,\n",
      "          80.13,\n",
      "          80.13\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.17,\n",
      "          79.14999999999999,\n",
      "          79.42,\n",
      "          80.08\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          52.65,\n",
      "          55.769999999999996,\n",
      "          58.5,\n",
      "          67.9,\n",
      "          68.63,\n",
      "          72.32,\n",
      "          72.37,\n",
      "          72.08,\n",
      "          72.49,\n",
      "          71.94,\n",
      "          73.11,\n",
      "          75.18,\n",
      "          76.25,\n",
      "          75.6,\n",
      "          76.79,\n",
      "          77.42999999999999,\n",
      "          77.56,\n",
      "          77.45,\n",
      "          78.3,\n",
      "          78.86\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.73,\n",
      "          84.64\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          68.25,\n",
      "          69.56,\n",
      "          71.76,\n",
      "          70.64,\n",
      "          70.59,\n",
      "          74.49,\n",
      "          76.31,\n",
      "          78.17,\n",
      "          77.95,\n",
      "          78.78\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          24.41,\n",
      "          39.12,\n",
      "          51.55,\n",
      "          58.15,\n",
      "          64.19,\n",
      "          67.33,\n",
      "          72.46000000000001,\n",
      "          73.94,\n",
      "          78.06,\n",
      "          78.57,\n",
      "          79.01,\n",
      "          78.68,\n",
      "          79.80000000000001,\n",
      "          80.78999999999999,\n",
      "          81.54,\n",
      "          82.21000000000001,\n",
      "          82.08,\n",
      "          83.17999999999999,\n",
      "          83.36,\n",
      "          83.13000000000001,\n",
      "          82.5,\n",
      "          83.24000000000001,\n",
      "          84.03,\n",
      "          84.84,\n",
      "          85.2,\n",
      "          85.17,\n",
      "          85.24000000000001,\n",
      "          85.1,\n",
      "          85.33,\n",
      "          85.00999999999999,\n",
      "          85.57000000000001,\n",
      "          85.91,\n",
      "          85.91,\n",
      "          86.4,\n",
      "          86.53999999999999,\n",
      "          86.78,\n",
      "          87.02,\n",
      "          87.18,\n",
      "          87.41,\n",
      "          87.33,\n",
      "          87.72,\n",
      "          87.8,\n",
      "          87.9,\n",
      "          88.1,\n",
      "          88.41,\n",
      "          88.22,\n",
      "          88.42999999999999,\n",
      "          88.38000000000001,\n",
      "          88.31,\n",
      "          88.6\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          76.8,\n",
      "          83.96000000000001,\n",
      "          87.08,\n",
      "          88.94\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          48.209999999999994,\n",
      "          59.870000000000005,\n",
      "          70.07,\n",
      "          73.88,\n",
      "          79.62,\n",
      "          80.99,\n",
      "          82.69999999999999,\n",
      "          83.2,\n",
      "          84.13000000000001,\n",
      "          84.61999999999999,\n",
      "          85.53,\n",
      "          86.32,\n",
      "          86.46000000000001,\n",
      "          87.16000000000001,\n",
      "          87.74,\n",
      "          87.87,\n",
      "          88.16000000000001,\n",
      "          88.24,\n",
      "          88.42,\n",
      "          88.13\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          82.87,\n",
      "          87.59\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          59.74,\n",
      "          70.57,\n",
      "          79.12,\n",
      "          83.25,\n",
      "          84.19,\n",
      "          86.44,\n",
      "          87.3,\n",
      "          87.81,\n",
      "          87.58,\n",
      "          88.63\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          30.12,\n",
      "          41.54,\n",
      "          51.15,\n",
      "          59.5,\n",
      "          64.64999999999999,\n",
      "          65.02,\n",
      "          66.7,\n",
      "          68.81,\n",
      "          70.28,\n",
      "          73.48,\n",
      "          73.83,\n",
      "          76.64,\n",
      "          76.83,\n",
      "          77.68,\n",
      "          77.38000000000001,\n",
      "          77.77,\n",
      "          79.17,\n",
      "          79.59,\n",
      "          80.86,\n",
      "          80.89,\n",
      "          81.24,\n",
      "          81.47999999999999,\n",
      "          82.23,\n",
      "          82.8,\n",
      "          82.96,\n",
      "          83.00999999999999,\n",
      "          83.64,\n",
      "          83.72,\n",
      "          83.35000000000001,\n",
      "          83.41,\n",
      "          83.69,\n",
      "          83.67999999999999,\n",
      "          84.23,\n",
      "          84.26,\n",
      "          84.48,\n",
      "          84.98,\n",
      "          85.38,\n",
      "          85.39,\n",
      "          85.63,\n",
      "          85.74000000000001,\n",
      "          86.17,\n",
      "          86.28,\n",
      "          86.38,\n",
      "          86.57000000000001,\n",
      "          86.42,\n",
      "          86.56,\n",
      "          86.38,\n",
      "          86.37,\n",
      "          86.44,\n",
      "          86.53999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.53999999999999,\n",
      "          80.67,\n",
      "          84.16,\n",
      "          86.61999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          55.489999999999995,\n",
      "          64.21,\n",
      "          71.63000000000001,\n",
      "          74.95,\n",
      "          76.49000000000001,\n",
      "          80.08999999999999,\n",
      "          82.11,\n",
      "          82.25,\n",
      "          82.65,\n",
      "          83.3,\n",
      "          84.02,\n",
      "          85.05,\n",
      "          85.15,\n",
      "          85.67,\n",
      "          86.18,\n",
      "          86.83999999999999,\n",
      "          87.41,\n",
      "          87.63,\n",
      "          87.82,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.15,\n",
      "          86.91\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          67.52,\n",
      "          75.52,\n",
      "          80.19,\n",
      "          84.26,\n",
      "          85.77,\n",
      "          86.16,\n",
      "          86.58,\n",
      "          86.65,\n",
      "          87.18,\n",
      "          87.09\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 31, using model = LogModel, selection_function = RandomSelection, k = 250, iteration = 0.\n",
      "\n",
      "initial random chosen samples (250,)\n",
      "initial train set: (250, 784) (250,) unique(labels): [31 23 25 19 28 27 21 26 23 27] [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59750, 784) (59750,) (250,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.158 s \n",
      "\n",
      "Accuracy rate for 74.590000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       980\n",
      "           1       0.66      0.98      0.79      1135\n",
      "           2       0.75      0.62      0.68      1032\n",
      "           3       0.70      0.78      0.74      1010\n",
      "           4       0.76      0.82      0.79       982\n",
      "           5       0.74      0.46      0.56       892\n",
      "           6       0.76      0.85      0.80       958\n",
      "           7       0.83      0.78      0.80      1028\n",
      "           8       0.79      0.46      0.58       974\n",
      "           9       0.76      0.74      0.75      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.74      0.73     10000\n",
      "weighted avg       0.75      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 903    1    2    5    0   20   30    3   14    2]\n",
      " [   0 1112   10    1    0    0    5    3    4    0]\n",
      " [  64  144  639   17   39    0   72   29   22    6]\n",
      " [  17   51   67  787    2   31   11   20   14   10]\n",
      " [  13   29    1    6  804   14   43    5   10   57]\n",
      " [  40   37   37  157   62  408   46   32   25   48]\n",
      " [  47   11   13    4   19   31  818    1   14    0]\n",
      " [   5   76   49    2   31    3    3  799    5   55]\n",
      " [  19  200   33  123   15   30   38   11  444   61]\n",
      " [  11   36    3   22   90   18   13   60   11  745]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 0 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [61 56 49 38 48 54 48 48 50 48] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.181 s \n",
      "\n",
      "Accuracy rate for 75.290000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       980\n",
      "           1       0.71      0.96      0.82      1135\n",
      "           2       0.78      0.65      0.71      1032\n",
      "           3       0.68      0.77      0.72      1010\n",
      "           4       0.77      0.80      0.79       982\n",
      "           5       0.73      0.48      0.58       892\n",
      "           6       0.66      0.92      0.77       958\n",
      "           7       0.83      0.79      0.81      1028\n",
      "           8       0.75      0.54      0.63       974\n",
      "           9       0.84      0.66      0.74      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.76      0.75      0.74     10000\n",
      "weighted avg       0.76      0.75      0.75     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 885    2    3   10    1   10   57    3    9    0]\n",
      " [   0 1091   26    1    0    1    6    1    9    0]\n",
      " [  41   94  670   18   27    1  114   21   44    2]\n",
      " [  10   56   42  780    1   20   32   33   32    4]\n",
      " [  11   31    2    2  788   42   49    4   17   36]\n",
      " [  26   38   19  178   43  430   86   29   17   26]\n",
      " [  22    7   10    1   10   18  879    1   10    0]\n",
      " [  10   61   63    2   25    8    9  808   13   29]\n",
      " [  16  120   15  139   15   20   77    8  530   34]\n",
      " [  13   36    5   21  113   36   22   70   25  668]]\n",
      "--------------------------------\n",
      "final active learning accuracies [74.59, 75.29]\n",
      "saved Active-learning-experiment-31.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 32, using model = LogModel, selection_function = RandomSelection, k = 125, iteration = 0.\n",
      "\n",
      "initial random chosen samples (125,)\n",
      "initial train set: (125, 784) (125,) unique(labels): [16 15  7 14 12  7 21 12  9 12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,) (125,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.136 s \n",
      "\n",
      "Accuracy rate for 72.860000 \n",
      "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.86       980\n",
      "           1       0.69      0.98      0.81      1135\n",
      "           2       0.80      0.60      0.69      1032\n",
      "           3       0.62      0.82      0.70      1010\n",
      "           4       0.74      0.74      0.74       982\n",
      "           5       0.83      0.39      0.53       892\n",
      "           6       0.73      0.87      0.79       958\n",
      "           7       0.72      0.73      0.73      1028\n",
      "           8       0.80      0.51      0.62       974\n",
      "           9       0.71      0.67      0.69      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.72      0.72     10000\n",
      "weighted avg       0.74      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 916    2    1    3    2   12   36    6    1    1]\n",
      " [   0 1111    1    3    0    1    4    1   14    0]\n",
      " [  52  108  622   86   52    1   56   25   24    6]\n",
      " [   8   83   15  825    8   13    2   25   15   16]\n",
      " [  12   27   15    7  723    0   74    6   11  107]\n",
      " [  46   70    4  233   53  344   44   71   20    7]\n",
      " [  47   21   27   10   20    2  829    0    2    0]\n",
      " [  29   41   36    5   38    0    1  753   15  110]\n",
      " [   9  133   12  148   29   29   69   26  492   27]\n",
      " [  34   22   42   16   46   12   15  132   19  671]]\n",
      "--------------------------------\n",
      "val predicted: (59875,) ['5' '0' '4' ... '5' '0' '6']\n",
      "probabilities: (59875, 10) \n",
      " [5 0 4 ... 5 0 6]\n",
      "trainset before (125, 784) (125,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [26 26 18 29 27 14 37 25 25 23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.152 s \n",
      "\n",
      "Accuracy rate for 72.120000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87       980\n",
      "           1       0.69      0.97      0.81      1135\n",
      "           2       0.69      0.52      0.59      1032\n",
      "           3       0.70      0.74      0.72      1010\n",
      "           4       0.75      0.76      0.76       982\n",
      "           5       0.69      0.58      0.63       892\n",
      "           6       0.72      0.87      0.78       958\n",
      "           7       0.76      0.77      0.77      1028\n",
      "           8       0.59      0.42      0.49       974\n",
      "           9       0.79      0.60      0.68      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.72      0.72      0.71     10000\n",
      "weighted avg       0.72      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 921    2   15    1    1   12   23    0    5    0]\n",
      " [   0 1105   17    2    0    0    5    2    4    0]\n",
      " [  38  140  533  102   25    3  115   18   54    4]\n",
      " [   9   45   15  749    3   93    8   32   49    7]\n",
      " [  11   26   29    2  749   11   49    9   41   55]\n",
      " [  44   67    7   70   35  516   33   59   53    8]\n",
      " [  40   17   26    1   17   21  831    0    5    0]\n",
      " [  37   49   22    4   18    2    5  796   39   56]\n",
      " [   4  131   84  131   19   77   76   19  405   28]\n",
      " [  22   22   29   15  133   14   16  118   33  607]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '2']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 6 2]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [37 41 25 48 37 24 52 40 35 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.210 s \n",
      "\n",
      "Accuracy rate for 70.680000 \n",
      "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86       980\n",
      "           1       0.69      0.98      0.81      1135\n",
      "           2       0.71      0.49      0.58      1032\n",
      "           3       0.71      0.74      0.73      1010\n",
      "           4       0.68      0.77      0.72       982\n",
      "           5       0.60      0.49      0.54       892\n",
      "           6       0.70      0.87      0.77       958\n",
      "           7       0.82      0.81      0.81      1028\n",
      "           8       0.54      0.39      0.46       974\n",
      "           9       0.78      0.54      0.64      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.70      0.70      0.69     10000\n",
      "weighted avg       0.70      0.71      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 929    2    7    2    0   12   24    1    3    0]\n",
      " [   0 1107   15    4    0    0    5    2    2    0]\n",
      " [  67  156  502   41   33    4  122   36   70    1]\n",
      " [  21   52   13  748    6   76    8   19   51   16]\n",
      " [  10   25   25    3  759   29   59   10   34   28]\n",
      " [  55   51   25   77   55  439   33   36   87   34]\n",
      " [  44   18   21    2   23   18  829    1    2    0]\n",
      " [  33   49   19    4   10    7    6  831   32   37]\n",
      " [   9  125   67  143   25   89   92    4  382   38]\n",
      " [  24   26   13   25  203   52   13   73   38  542]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['8' '0' '4' ... '5' '5' '2']\n",
      "probabilities: (59625, 10) \n",
      " [8 0 4 ... 5 5 2]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [46 55 35 58 52 33 65 52 46 58] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.221 s \n",
      "\n",
      "Accuracy rate for 71.370000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       980\n",
      "           1       0.67      0.97      0.79      1135\n",
      "           2       0.77      0.57      0.65      1032\n",
      "           3       0.68      0.76      0.72      1010\n",
      "           4       0.73      0.78      0.76       982\n",
      "           5       0.59      0.41      0.49       892\n",
      "           6       0.72      0.88      0.79       958\n",
      "           7       0.79      0.79      0.79      1028\n",
      "           8       0.56      0.40      0.47       974\n",
      "           9       0.74      0.61      0.67      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 895    2    4    3    0   45   24    2    4    1]\n",
      " [   0 1098   25    1    0    0    5    2    4    0]\n",
      " [  67  145  584   28   43    5   93   32   30    5]\n",
      " [  16   59   11  766    4   63    7   21   47   16]\n",
      " [   9   25    8    3  766   25   67    8   30   41]\n",
      " [  35   53    7  117   61  366   34   56  119   44]\n",
      " [  32   18   21    9   22   14  839    1    2    0]\n",
      " [  20   50   23    3   14   12    3  814   28   61]\n",
      " [   8  154   71  153   12   48   82    7  394   45]\n",
      " [  16   25    8   36  121   39   19   83   47  615]]\n",
      "--------------------------------\n",
      "final active learning accuracies [72.86, 72.11999999999999, 70.67999999999999, 71.37]\n",
      "saved Active-learning-experiment-32.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 33, using model = LogModel, selection_function = RandomSelection, k = 50, iteration = 0.\n",
      "\n",
      "initial random chosen samples (50,)\n",
      "initial train set: (50, 784) (50,) unique(labels): [6 8 4 4 1 5 5 8 4 5] [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59950, 784) (59950,) (50,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.124 s \n",
      "\n",
      "Accuracy rate for 61.740000 \n",
      "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.77      0.84       980\n",
      "           1       0.69      0.88      0.77      1135\n",
      "           2       0.53      0.47      0.50      1032\n",
      "           3       0.59      0.81      0.68      1010\n",
      "           4       0.83      0.10      0.17       982\n",
      "           5       0.65      0.30      0.41       892\n",
      "           6       0.73      0.81      0.76       958\n",
      "           7       0.57      0.63      0.60      1028\n",
      "           8       0.49      0.66      0.56       974\n",
      "           9       0.50      0.69      0.58      1009\n",
      "\n",
      "    accuracy                           0.62     10000\n",
      "   macro avg       0.65      0.61      0.59     10000\n",
      "weighted avg       0.65      0.62      0.59     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[759   1  99  14   0   5  68  21  12   1]\n",
      " [  0 994   0   5   0  27   2   0 107   0]\n",
      " [ 15 128 481  87   1   1  27  38 233  21]\n",
      " [  5  26  50 818   0  16  11   6  24  54]\n",
      " [  1  70  69   7  95   4  91 252 110 283]\n",
      " [ 30  36 104 305   2 267  54  28  23  43]\n",
      " [  6  23  51   3   0  19 772   2  67  15]\n",
      " [  5  73   4   3   4  48   4 650  27 210]\n",
      " [  7  76  27 112   1   7  10  18 644  72]\n",
      " [  5  14  20  32  12  17  25 116  74 694]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['3' '0' '2' ... '5' '6' '8']\n",
      "probabilities: (59950, 10) \n",
      " [3 0 2 ... 5 6 8]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 9 13  7 12  6  9 14 12  9  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.128 s \n",
      "\n",
      "Accuracy rate for 69.950000 \n",
      "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       980\n",
      "           1       0.75      0.91      0.82      1135\n",
      "           2       0.81      0.55      0.65      1032\n",
      "           3       0.60      0.83      0.70      1010\n",
      "           4       0.64      0.73      0.68       982\n",
      "           5       0.72      0.23      0.35       892\n",
      "           6       0.76      0.84      0.80       958\n",
      "           7       0.77      0.69      0.73      1028\n",
      "           8       0.61      0.65      0.63       974\n",
      "           9       0.59      0.65      0.62      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.69      0.68     10000\n",
      "weighted avg       0.71      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 837    1   22    7    1    2   63   20   27    0]\n",
      " [   0 1031    0    2    1    6    3    0   91    1]\n",
      " [  64   75  565   16   28    0   57   34  166   27]\n",
      " [   7   26   26  836    9   24    7    8   26   41]\n",
      " [   3   17    4   10  714    1   50   28   11  144]\n",
      " [  51   45   17  359   83  206   53   21   27   30]\n",
      " [  15   20   18   14   24   26  807    2   30    2]\n",
      " [   7   67    2    8   43    3    1  708   26  163]\n",
      " [  13   70   34  105   36   15   11   10  634   46]\n",
      " [  21   17   11   25  169    2   12   89    6  657]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '3' ... '5' '6' '8']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 3 ... 5 6 8]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [16 15 13 18 14 15 18 16 11 14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.142 s \n",
      "\n",
      "Accuracy rate for 75.090000 \n",
      "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.88       980\n",
      "           1       0.70      0.96      0.81      1135\n",
      "           2       0.81      0.62      0.70      1032\n",
      "           3       0.60      0.82      0.70      1010\n",
      "           4       0.80      0.77      0.79       982\n",
      "           5       0.83      0.38      0.53       892\n",
      "           6       0.77      0.85      0.81       958\n",
      "           7       0.88      0.74      0.80      1028\n",
      "           8       0.69      0.69      0.69       974\n",
      "           9       0.76      0.69      0.72      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.77      0.75      0.74     10000\n",
      "weighted avg       0.76      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 904    1    2    6    1    2   23    3   38    0]\n",
      " [   0 1093    7    2    0    2    3    0   27    1]\n",
      " [  54  109  641   27   16    2   60   23   99    1]\n",
      " [  13   55   17  832    5   11   10    6   39   22]\n",
      " [   6   38   17   14  759    9   59    8   13   59]\n",
      " [  28   32   25  340   17  343   50    8   27   22]\n",
      " [  33   15   26   12    4   26  811    1   30    0]\n",
      " [  16   90   23    9   17    5    9  763   22   74]\n",
      " [  18  103   22   93    8    5   13    3  670   39]\n",
      " [  14   32   16   41  124    9   16   53   11  693]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59850, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [21 23 18 20 21 19 19 19 19 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.147 s \n",
      "\n",
      "Accuracy rate for 73.910000 \n",
      "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       980\n",
      "           1       0.67      0.99      0.80      1135\n",
      "           2       0.83      0.57      0.68      1032\n",
      "           3       0.62      0.82      0.70      1010\n",
      "           4       0.80      0.77      0.79       982\n",
      "           5       0.80      0.34      0.47       892\n",
      "           6       0.71      0.88      0.79       958\n",
      "           7       0.81      0.80      0.81      1028\n",
      "           8       0.69      0.66      0.67       974\n",
      "           9       0.80      0.59      0.68      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.76      0.73      0.73     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 884    2    0    8    1    2   38    6   39    0]\n",
      " [   0 1123    0    1    0    3    4    0    4    0]\n",
      " [  61  155  589   17   16    2   92   23   74    3]\n",
      " [  12   69   29  826    4    9    7   11   26   17]\n",
      " [   1   31    6   12  761   14   92   15   18   32]\n",
      " [  51   36   11  332   17  299   55   17   41   33]\n",
      " [  28   15    7    6    3   17  843    3   36    0]\n",
      " [   8   86   22    9   10    5   12  823   24   29]\n",
      " [  13  123   33   91    7    5   17    5  646   34]\n",
      " [  12   34    9   40  134   19   22  108   34  597]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (200, 784) (200,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [26 30 22 25 28 25 27 21 21 25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.174 s \n",
      "\n",
      "Accuracy rate for 74.170000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       980\n",
      "           1       0.68      0.99      0.81      1135\n",
      "           2       0.81      0.59      0.69      1032\n",
      "           3       0.66      0.82      0.73      1010\n",
      "           4       0.77      0.80      0.78       982\n",
      "           5       0.76      0.44      0.55       892\n",
      "           6       0.71      0.87      0.78       958\n",
      "           7       0.80      0.78      0.79      1028\n",
      "           8       0.77      0.57      0.65       974\n",
      "           9       0.75      0.61      0.67      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.74      0.73     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 896    2    3    1    1    8   40    2   27    0]\n",
      " [   0 1120    0    2    0    6    5    0    2    0]\n",
      " [  68  134  612   21   29    2   98   12   49    7]\n",
      " [  22   56   26  824    7   14   16   13    9   23]\n",
      " [   5   30    8    6  786   18   56   19    9   45]\n",
      " [  58   35   16  245   31  389   59   20   17   22]\n",
      " [  37   12   15    2   19   22  829    3   19    0]\n",
      " [  11   83   32    7   12    7    7  798   11   60]\n",
      " [  24  140   32  104   14   26   37    3  551   43]\n",
      " [  10   34    9   34  124   23   18  128   17  612]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [29 36 31 30 34 29 31 25 26 29] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.186 s \n",
      "\n",
      "Accuracy rate for 74.210000 \n",
      "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       980\n",
      "           1       0.69      0.98      0.81      1135\n",
      "           2       0.79      0.62      0.69      1032\n",
      "           3       0.64      0.82      0.72      1010\n",
      "           4       0.78      0.80      0.79       982\n",
      "           5       0.71      0.42      0.53       892\n",
      "           6       0.72      0.86      0.78       958\n",
      "           7       0.81      0.77      0.79      1028\n",
      "           8       0.79      0.52      0.63       974\n",
      "           9       0.74      0.64      0.69      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.74      0.73     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 908    2    3    2    0   11   34    5   15    0]\n",
      " [   0 1110    5    4    0    2    7    0    6    1]\n",
      " [  58  123  643   29   26    1   93   12   40    7]\n",
      " [  20   47   26  826    4   26   16   14   12   19]\n",
      " [   6   29   20    4  789   22   41   14   11   46]\n",
      " [  46   40   23  248   33  374   61   27    7   33]\n",
      " [  35    9   23    4   13   26  822    1   25    0]\n",
      " [  13   83   37    3   11    6    9  795    8   63]\n",
      " [  18  138   30  134   11   33   43    3  510   54]\n",
      " [  14   35    9   27  122   27   12  108   11  644]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59700, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [36 42 33 37 42 34 35 30 30 31] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.202 s \n",
      "\n",
      "Accuracy rate for 74.190000 \n",
      "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       980\n",
      "           1       0.68      0.98      0.81      1135\n",
      "           2       0.80      0.63      0.71      1032\n",
      "           3       0.66      0.81      0.73      1010\n",
      "           4       0.76      0.79      0.78       982\n",
      "           5       0.73      0.39      0.51       892\n",
      "           6       0.74      0.87      0.80       958\n",
      "           7       0.80      0.76      0.78      1028\n",
      "           8       0.73      0.57      0.64       974\n",
      "           9       0.74      0.64      0.69      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.74      0.73     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 880    2    3    2    2    5   37   13   36    0]\n",
      " [   0 1115    2    2    0    1    4    0   11    0]\n",
      " [  57  109  653   26   33    1   85   11   52    5]\n",
      " [  12   52   28  817    4   33   18   14   15   17]\n",
      " [  11   33   11    1  780   17   41   25   12   51]\n",
      " [  42   42   17  241   48  352   60   21   22   47]\n",
      " [  27    9   19    0   19   24  837    0   23    0]\n",
      " [  16   86   42    5   14    6    4  778   12   65]\n",
      " [  12  144   27  115   11   26   30    2  560   47]\n",
      " [  16   42   10   24  111   20   13  105   21  647]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59650, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [44 48 36 40 55 37 40 33 31 36] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.197 s \n",
      "\n",
      "Accuracy rate for 73.740000 \n",
      "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86       980\n",
      "           1       0.67      0.98      0.80      1135\n",
      "           2       0.81      0.61      0.70      1032\n",
      "           3       0.64      0.84      0.73      1010\n",
      "           4       0.77      0.78      0.78       982\n",
      "           5       0.74      0.36      0.48       892\n",
      "           6       0.73      0.88      0.80       958\n",
      "           7       0.78      0.75      0.76      1028\n",
      "           8       0.75      0.58      0.65       974\n",
      "           9       0.74      0.64      0.69      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.73      0.72     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 867    2    3    2    2    7   42   25   30    0]\n",
      " [   0 1116    1    5    0    4    4    0    5    0]\n",
      " [  52  137  630   29   25    2   84   16   53    4]\n",
      " [  13   42   26  846    3   20   20   16   15    9]\n",
      " [   9   39   12    2  769   18   46   22   11   54]\n",
      " [  37   38   14  271   49  321   58   25   28   51]\n",
      " [  27   11   19    0   17   22  843    0   19    0]\n",
      " [  14   88   44    7   13    6    4  769   13   70]\n",
      " [  12  145   20  127   12   17   36    3  565   37]\n",
      " [  17   43    8   29  104   15   15  113   17  648]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59600, 10) \n",
      " [3 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (400, 784) (400,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [50 56 40 48 62 39 47 36 32 40] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.195 s \n",
      "\n",
      "Accuracy rate for 73.920000 \n",
      "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       980\n",
      "           1       0.68      0.99      0.81      1135\n",
      "           2       0.81      0.61      0.69      1032\n",
      "           3       0.64      0.82      0.72      1010\n",
      "           4       0.77      0.81      0.79       982\n",
      "           5       0.74      0.32      0.45       892\n",
      "           6       0.73      0.89      0.80       958\n",
      "           7       0.76      0.78      0.77      1028\n",
      "           8       0.74      0.57      0.64       974\n",
      "           9       0.76      0.65      0.70      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.73      0.72     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 886    2    3    2    2    2   35   13   33    2]\n",
      " [   0 1119    0    4    0    2    6    0    4    0]\n",
      " [  50  134  627   36   22    2   85   12   58    6]\n",
      " [  17   43   24  828    1   35   20   19   14    9]\n",
      " [   6   33    6    2  793   14   48   13   12   55]\n",
      " [  42   36   13  269   56  287   63   60   25   41]\n",
      " [  26    8   14    0   21   16  849    1   23    0]\n",
      " [  11   80   56    5   15    1    4  798    9   49]\n",
      " [  10  143   22  116   15   20   43    3  554   48]\n",
      " [  13   43    8   28  100   11   11  127   17  651]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59550, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [55 62 40 50 64 48 50 45 38 48] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.201 s \n",
      "\n",
      "Accuracy rate for 74.620000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87       980\n",
      "           1       0.69      0.98      0.81      1135\n",
      "           2       0.82      0.63      0.71      1032\n",
      "           3       0.64      0.81      0.72      1010\n",
      "           4       0.77      0.80      0.79       982\n",
      "           5       0.73      0.37      0.49       892\n",
      "           6       0.75      0.87      0.81       958\n",
      "           7       0.78      0.76      0.77      1028\n",
      "           8       0.75      0.60      0.67       974\n",
      "           9       0.73      0.69      0.71      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.74      0.73     10000\n",
      "weighted avg       0.75      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 863    2    3    1    2    4   46   15   43    1]\n",
      " [   0 1117    3    3    0    2    4    0    6    0]\n",
      " [  46  123  646   39   24    2   73   14   54   11]\n",
      " [  11   53   24  821    0   24   18   26   17   16]\n",
      " [   7   25    3    5  790   24   43   10    9   66]\n",
      " [  35   32   15  256   51  330   56   49   24   44]\n",
      " [  21   11   18    1   25   28  835    1   18    0]\n",
      " [   8   75   44    1   18    3    4  786   10   79]\n",
      " [   8  133   22  125   14   18   26    3  580   45]\n",
      " [  13   39    7   26   98   15   10   98    9  694]]\n",
      "--------------------------------\n",
      "final active learning accuracies [61.739999999999995, 69.95, 75.09, 73.91, 74.17, 74.21, 74.19, 73.74000000000001, 73.92, 74.62]\n",
      "saved Active-learning-experiment-33.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 34, using model = LogModel, selection_function = RandomSelection, k = 25, iteration = 0.\n",
      "\n",
      "initial random chosen samples (25,)\n",
      "initial train set: (25, 784) (25,) unique(labels): [6 4 2 3 3 1 2 2 2] [0 1 2 3 4 5 6 7 8]\n",
      "val set: (59975, 784) (59975,) (25,)\n",
      "\n",
      "Train set: (25, 784) y: (25,)\n",
      "Val   set: (59975, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.114 s \n",
      "\n",
      "Accuracy rate for 54.280000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=2.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78       980\n",
      "           1       0.87      0.71      0.78      1135\n",
      "           2       0.51      0.53      0.52      1032\n",
      "           3       0.51      0.74      0.60      1010\n",
      "           4       0.30      0.82      0.44       982\n",
      "           5       0.60      0.21      0.31       892\n",
      "           6       0.78      0.75      0.76       958\n",
      "           7       0.81      0.43      0.57      1028\n",
      "           8       0.36      0.34      0.35       974\n",
      "           9       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.55      0.54      0.51     10000\n",
      "weighted avg       0.55      0.54      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[833   0   0  24   7  15  82   5  14   0]\n",
      " [  0 810 254  14  21   0   2   0  34   0]\n",
      " [ 42  18 543 106  51   0  28   5 239   0]\n",
      " [  8  14  11 749  53  75   9  16  75   0]\n",
      " [ 40   3  23   7 804   1  18  12  74   0]\n",
      " [ 59  26  55 261 211 190  38  33  19   0]\n",
      " [105  14  56  29  31   1 716   0   6   0]\n",
      " [ 13  14  38  14 411   0   2 447  89   0]\n",
      " [ 15  32  72 237 221  33  20   8 336   0]\n",
      " [ 38   2  16  41 835   3   7  26  41   0]]\n",
      "--------------------------------\n",
      "val predicted: (59975,) ['3' '0' '7' ... '4' '6' '8']\n",
      "probabilities: (59975, 9) \n",
      " [3 0 7 ... 4 6 8]\n",
      "trainset before (25, 784) (25,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [ 7 11  5  5  6  1  2  6  2  5] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.126 s \n",
      "\n",
      "Accuracy rate for 58.240000 \n",
      "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.75       980\n",
      "           1       0.74      0.93      0.82      1135\n",
      "           2       0.67      0.59      0.63      1032\n",
      "           3       0.47      0.84      0.60      1010\n",
      "           4       0.44      0.83      0.57       982\n",
      "           5       1.00      0.00      0.00       892\n",
      "           6       0.90      0.61      0.73       958\n",
      "           7       0.69      0.55      0.61      1028\n",
      "           8       0.29      0.07      0.12       974\n",
      "           9       0.44      0.38      0.41      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.63      0.57      0.52     10000\n",
      "weighted avg       0.62      0.58      0.53     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 886    1    8   34    5    0   29    1    2   14]\n",
      " [   0 1060   46   10    2    0    2    0   15    0]\n",
      " [  26   51  614  170   34    0    6   18   94   19]\n",
      " [   9   36   19  851   13    0    1   38   24   19]\n",
      " [  47   16   19    5  811    0    4   28   17   35]\n",
      " [ 129   77   49  348  166    1   16   34    5   67]\n",
      " [ 177   34   66   43   48    0  585    1    3    1]\n",
      " [  24   38   34    1   92    0    1  563    7  268]\n",
      " [  34  114   50  336  252    0    4   41   70   73]\n",
      " [  49   15   16   24  422    0    0   97    3  383]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['3' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59950, 10) \n",
      " [3 0 4 ... 9 6 8]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (75, 784) (75,)\n",
      "updated train set: (75, 784) (75,) unique(labels): [ 9 14  8  6  8  6  6  7  3  8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59925, 784) (59925,)\n",
      "\n",
      "Train set: (75, 784) y: (75,)\n",
      "Val   set: (59925, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.125 s \n",
      "\n",
      "Accuracy rate for 61.840000 \n",
      "Classification report for classifier LogisticRegression(C=0.6666666666666666, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81       980\n",
      "           1       0.73      0.91      0.81      1135\n",
      "           2       0.62      0.66      0.64      1032\n",
      "           3       0.56      0.72      0.63      1010\n",
      "           4       0.53      0.81      0.64       982\n",
      "           5       0.52      0.28      0.36       892\n",
      "           6       0.65      0.64      0.64       958\n",
      "           7       0.79      0.59      0.67      1028\n",
      "           8       0.39      0.21      0.27       974\n",
      "           9       0.50      0.41      0.45      1009\n",
      "\n",
      "    accuracy                           0.62     10000\n",
      "   macro avg       0.60      0.61      0.59     10000\n",
      "weighted avg       0.61      0.62      0.60     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 856    0    4    8    1    7  100    1    0    3]\n",
      " [   0 1031   58    7    1    0    3    0   35    0]\n",
      " [  24   77  686  103   31    0    9   19   75    8]\n",
      " [  10   12   19  731    5   72    3   21  119   18]\n",
      " [  13   12   21    0  793   11   67   13   18   34]\n",
      " [  40   81   25  250   97  251   45   19   30   54]\n",
      " [ 141   27   94    6   56   11  610    2   11    0]\n",
      " [  12   46   79    0   58    1    2  603   14  213]\n",
      " [  17  110   96  185   81  102   76   17  205   85]\n",
      " [  20    9   28   14  368   30   27   73   22  418]]\n",
      "--------------------------------\n",
      "val predicted: (59925,) ['3' '0' '4' ... '9' '6' '6']\n",
      "probabilities: (59925, 10) \n",
      " [3 0 4 ... 9 6 6]\n",
      "trainset before (75, 784) (75,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [11 21 10  7 10  9  7  9  6 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.127 s \n",
      "\n",
      "Accuracy rate for 68.430000 \n",
      "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       980\n",
      "           1       0.69      0.96      0.81      1135\n",
      "           2       0.68      0.70      0.69      1032\n",
      "           3       0.65      0.78      0.71      1010\n",
      "           4       0.77      0.62      0.69       982\n",
      "           5       0.69      0.40      0.50       892\n",
      "           6       0.64      0.71      0.67       958\n",
      "           7       0.70      0.66      0.68      1028\n",
      "           8       0.75      0.37      0.49       974\n",
      "           9       0.56      0.63      0.59      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.69      0.68      0.67     10000\n",
      "weighted avg       0.69      0.68      0.67     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 932    2    2    1    0    1   36    3    0    3]\n",
      " [   0 1094   28    8    1    0    3    0    1    0]\n",
      " [  23  124  723   54   18    2   22   17   43    6]\n",
      " [  40   31   14  790    1   31    7   41   29   26]\n",
      " [   5   27   18    2  608   12  141   13    5  151]\n",
      " [  86   45   10  233    6  353   73   41   18   27]\n",
      " [  84   23  110    5   27   18  681    1    8    1]\n",
      " [  14   52   66    0    6    1    6  675    4  204]\n",
      " [  19  163   56  110   18   68   44   58  356   82]\n",
      " [  15   15   35   12  100   23   48  120   10  631]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 4 ... 9 6 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (100, 784) (100,)\n",
      "trainset after (125, 784) (125,)\n",
      "updated train set: (125, 784) (125,) unique(labels): [13 23 10 12 13 13  9 12  7 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.132 s \n",
      "\n",
      "Accuracy rate for 68.440000 \n",
      "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       980\n",
      "           1       0.74      0.93      0.82      1135\n",
      "           2       0.67      0.73      0.70      1032\n",
      "           3       0.64      0.86      0.74      1010\n",
      "           4       0.70      0.49      0.58       982\n",
      "           5       0.86      0.42      0.57       892\n",
      "           6       0.66      0.78      0.71       958\n",
      "           7       0.77      0.57      0.65      1028\n",
      "           8       0.85      0.40      0.54       974\n",
      "           9       0.45      0.68      0.54      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.72      0.68      0.67     10000\n",
      "weighted avg       0.71      0.68      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 913    2    2    7    0    2   45    5    0    4]\n",
      " [   0 1055   55   17    0    0    2    1    5    0]\n",
      " [  20   75  750   43   13    0   69   10   30   22]\n",
      " [  20   15   17  868    2   10    5   14   14   45]\n",
      " [   1   22   22    6  484    6  101   14    2  324]\n",
      " [  48   75   11  235   34  378   61   26   10   14]\n",
      " [  58   19   99    2   24    5  743    0    5    3]\n",
      " [  18   50   62    3    5    0    2  581    1  306]\n",
      " [  10  107   60  140   22   29   82   22  390  112]\n",
      " [  14   15   37   27  111   12   23   85    3  682]]\n",
      "--------------------------------\n",
      "val predicted: (59875,) ['3' '0' '4' ... '5' '6' '6']\n",
      "probabilities: (59875, 10) \n",
      " [3 0 4 ... 5 6 6]\n",
      "trainset before (125, 784) (125,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [15 27 12 14 18 15 10 13 11 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.139 s \n",
      "\n",
      "Accuracy rate for 71.430000 \n",
      "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       980\n",
      "           1       0.74      0.96      0.84      1135\n",
      "           2       0.77      0.68      0.72      1032\n",
      "           3       0.61      0.84      0.70      1010\n",
      "           4       0.65      0.83      0.73       982\n",
      "           5       0.78      0.35      0.48       892\n",
      "           6       0.78      0.73      0.75       958\n",
      "           7       0.74      0.68      0.71      1028\n",
      "           8       0.75      0.46      0.57       974\n",
      "           9       0.62      0.59      0.61      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.70     10000\n",
      "weighted avg       0.72      0.71      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 942    1    2    9    2    1   15    3    4    1]\n",
      " [   0 1084   27   11    1    1    2    0    9    0]\n",
      " [  26   77  702   55   31    0   68   22   44    7]\n",
      " [  33   18   36  844    3   12    6   16   24   18]\n",
      " [   1   21    4    6  818    2   27   15    8   80]\n",
      " [  71   62   10  261   80  314   29   25   26   14]\n",
      " [  61   26   44    2  105   12  699    3    6    0]\n",
      " [  18   49   46    2   39    0    0  697   13  164]\n",
      " [  11   99   19  170   26   50   50   23  444   82]\n",
      " [  16   22   16   31  163   11    3  136   12  599]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59850, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (175, 784) (175,)\n",
      "updated train set: (175, 784) (175,) unique(labels): [19 28 15 18 19 18 11 18 13 16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59825, 784) (59825,)\n",
      "\n",
      "Train set: (175, 784) y: (175,)\n",
      "Val   set: (59825, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.143 s \n",
      "\n",
      "Accuracy rate for 74.020000 \n",
      "Classification report for classifier LogisticRegression(C=0.2857142857142857, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       980\n",
      "           1       0.74      0.96      0.84      1135\n",
      "           2       0.75      0.70      0.72      1032\n",
      "           3       0.67      0.86      0.75      1010\n",
      "           4       0.71      0.83      0.77       982\n",
      "           5       0.86      0.48      0.62       892\n",
      "           6       0.74      0.77      0.75       958\n",
      "           7       0.74      0.72      0.73      1028\n",
      "           8       0.76      0.54      0.63       974\n",
      "           9       0.66      0.57      0.61      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.73      0.73     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 901    1    3    4    2    0   61    5    0    3]\n",
      " [   0 1094   13   10    2    0    2    0   14    0]\n",
      " [  33   77  721   41   36    1   40   19   61    3]\n",
      " [  16   16   21  870    0   19    8   17   16   27]\n",
      " [   1   27    9   17  811    4   34   11   10   58]\n",
      " [  47   82    7  168   46  430   59   27   13   13]\n",
      " [  32   16   73    3   65   10  735    0   24    0]\n",
      " [  11   51   63    1   35    0    0  737   15  115]\n",
      " [  12   84   21  144   20   17   52   21  527   76]\n",
      " [  14   25   34   44  118   19    3  158   18  576]]\n",
      "--------------------------------\n",
      "val predicted: (59825,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59825, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (175, 784) (175,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [19 32 16 19 20 21 15 21 15 22] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.157 s \n",
      "\n",
      "Accuracy rate for 73.870000 \n",
      "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       980\n",
      "           1       0.73      0.96      0.83      1135\n",
      "           2       0.76      0.67      0.71      1032\n",
      "           3       0.71      0.82      0.76      1010\n",
      "           4       0.67      0.84      0.74       982\n",
      "           5       0.79      0.48      0.60       892\n",
      "           6       0.72      0.79      0.75       958\n",
      "           7       0.78      0.72      0.75      1028\n",
      "           8       0.77      0.51      0.61       974\n",
      "           9       0.69      0.62      0.65      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.73      0.73     10000\n",
      "weighted avg       0.74      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 911    2    2    3    4    1   48    4    0    5]\n",
      " [   0 1093   21    8    1    1    3    1    7    0]\n",
      " [  26   88  687   16   42    2   79   27   61    4]\n",
      " [  26   28   38  824    4   13   13   22   14   28]\n",
      " [   0   31    4    9  824    6   30    7   10   61]\n",
      " [  60   58    8  175   49  429   65   17   10   21]\n",
      " [  36   12   34    2   98    6  755    4    9    2]\n",
      " [  15   58   47    1   42    1    0  740   17  107]\n",
      " [  14   95   45  102   25   64   56   19  495   59]\n",
      " [  14   32   18   17  147   22    5  106   19  629]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (200, 784) (200,)\n",
      "trainset after (225, 784) (225,)\n",
      "updated train set: (225, 784) (225,) unique(labels): [23 38 17 20 20 25 17 23 17 25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59775, 784) (59775,)\n",
      "\n",
      "Train set: (225, 784) y: (225,)\n",
      "Val   set: (59775, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.159 s \n",
      "\n",
      "Accuracy rate for 73.400000 \n",
      "Classification report for classifier LogisticRegression(C=0.2222222222222222, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       980\n",
      "           1       0.73      0.97      0.83      1135\n",
      "           2       0.79      0.60      0.69      1032\n",
      "           3       0.74      0.83      0.78      1010\n",
      "           4       0.65      0.86      0.74       982\n",
      "           5       0.78      0.51      0.62       892\n",
      "           6       0.70      0.75      0.72       958\n",
      "           7       0.72      0.70      0.71      1028\n",
      "           8       0.78      0.48      0.60       974\n",
      "           9       0.68      0.64      0.66      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.73      0.72     10000\n",
      "weighted avg       0.74      0.73      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 936    2    2    0    4    1   30    3    0    2]\n",
      " [   0 1096   17    4    3    0    4    2    9    0]\n",
      " [  24  110  624   31   53    2   90   42   53    3]\n",
      " [  20   31   25  836    3   14   21   26   12   22]\n",
      " [   1   29    8   11  843    6   14   12    8   50]\n",
      " [  50   51   10  135   66  455   75   21    9   20]\n",
      " [  36   12   23    4  144    9  717    1    8    4]\n",
      " [  18   54   33    0   45    0    1  721   22  134]\n",
      " [  15   92   37   98   23   82   67   25  471   64]\n",
      " [  17   31    9   17  122   18    1  142   11  641]]\n",
      "--------------------------------\n",
      "val predicted: (59775,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59775, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (225, 784) (225,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [25 43 20 24 21 26 18 24 21 28] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.153 s \n",
      "\n",
      "Accuracy rate for 74.360000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       980\n",
      "           1       0.69      0.96      0.81      1135\n",
      "           2       0.73      0.66      0.69      1032\n",
      "           3       0.75      0.76      0.76      1010\n",
      "           4       0.66      0.84      0.74       982\n",
      "           5       0.78      0.55      0.64       892\n",
      "           6       0.78      0.71      0.75       958\n",
      "           7       0.77      0.73      0.75      1028\n",
      "           8       0.77      0.55      0.64       974\n",
      "           9       0.72      0.69      0.71      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.74      0.74     10000\n",
      "weighted avg       0.75      0.74      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 912    2    6    4    5    2   44    1    1    3]\n",
      " [   0 1094   21    2    1    0    3    2   11    1]\n",
      " [  22  113  683   16   46    2   44   40   59    7]\n",
      " [  13   62   59  768    5   17    6   24   23   33]\n",
      " [   3   37   11    7  824   11   10   11   11   57]\n",
      " [  55   64   13  111   64  492   40   19   13   21]\n",
      " [  38   12   55    7  140    9  681    5    9    2]\n",
      " [  13   69   38    2   45    1    0  747   14   99]\n",
      " [  10   92   44   92   21   76   41   16  534   48]\n",
      " [  18   31   12   10   95   24    1  102   15  701]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '2' '8']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 2 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (275, 784) (275,)\n",
      "updated train set: (275, 784) (275,) unique(labels): [28 45 25 26 22 29 21 26 22 31] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59725, 784) (59725,)\n",
      "\n",
      "Train set: (275, 784) y: (275,)\n",
      "Val   set: (59725, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.160 s \n",
      "\n",
      "Accuracy rate for 75.390000 \n",
      "Classification report for classifier LogisticRegression(C=0.18181818181818182, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       980\n",
      "           1       0.73      0.97      0.83      1135\n",
      "           2       0.80      0.66      0.72      1032\n",
      "           3       0.71      0.78      0.74      1010\n",
      "           4       0.69      0.84      0.76       982\n",
      "           5       0.75      0.54      0.63       892\n",
      "           6       0.73      0.83      0.78       958\n",
      "           7       0.80      0.78      0.79      1028\n",
      "           8       0.85      0.51      0.64       974\n",
      "           9       0.73      0.64      0.69      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.76      0.75      0.74     10000\n",
      "weighted avg       0.76      0.75      0.75     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 936    2    1    0    1    2   32    1    2    3]\n",
      " [   0 1099   13    6    3    0    4    4    6    0]\n",
      " [  35  109  676    8   46    2   88   37   26    5]\n",
      " [  31   37   46  784    5   21   22   18   22   24]\n",
      " [   5   24    8    9  820   10   22   10    4   70]\n",
      " [  69   50    5  138   47  484   70   15    6    8]\n",
      " [  31   11   19    4   78   11  797    5    1    1]\n",
      " [  16   69   29    2   32    0    0  797   13   70]\n",
      " [  15   81   34  122   26   83   49   14  497   53]\n",
      " [  21   29    9   29  132   30    3   96   11  649]]\n",
      "--------------------------------\n",
      "val predicted: (59725,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59725, 10) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (275, 784) (275,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [34 48 28 33 25 29 23 26 22 32] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.162 s \n",
      "\n",
      "Accuracy rate for 74.620000 \n",
      "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       980\n",
      "           1       0.73      0.97      0.84      1135\n",
      "           2       0.79      0.67      0.73      1032\n",
      "           3       0.73      0.79      0.76      1010\n",
      "           4       0.64      0.84      0.73       982\n",
      "           5       0.68      0.55      0.61       892\n",
      "           6       0.75      0.76      0.75       958\n",
      "           7       0.78      0.76      0.77      1028\n",
      "           8       0.84      0.49      0.62       974\n",
      "           9       0.75      0.63      0.68      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.74      0.74     10000\n",
      "weighted avg       0.75      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 925    2    4    2    1    6   30    3    3    4]\n",
      " [   0 1101   17    5    2    0    5    3    2    0]\n",
      " [  39  101  694   19   44    1   70   37   20    7]\n",
      " [  26   34   41  797    3   25   19   19   23   23]\n",
      " [   2   26    6   11  822   22    7   15    8   63]\n",
      " [  52   43    6  139   61  493   67   14    7   10]\n",
      " [  39   10   23    4  136   11  729    3    3    0]\n",
      " [  10   71   34    5   41    0    1  784   14   68]\n",
      " [  14   82   44   98   30  124   45   14  482   41]\n",
      " [  11   29    8   19  138   39    3  115   12  635]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59700, 10) \n",
      " [3 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (300, 784) (300,)\n",
      "trainset after (325, 784) (325,)\n",
      "updated train set: (325, 784) (325,) unique(labels): [35 50 31 38 27 31 25 31 22 35] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59675, 784) (59675,)\n",
      "\n",
      "Train set: (325, 784) y: (325,)\n",
      "Val   set: (59675, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.170 s \n",
      "\n",
      "Accuracy rate for 74.850000 \n",
      "Classification report for classifier LogisticRegression(C=0.15384615384615385, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       980\n",
      "           1       0.73      0.96      0.83      1135\n",
      "           2       0.76      0.71      0.73      1032\n",
      "           3       0.70      0.78      0.74      1010\n",
      "           4       0.64      0.84      0.72       982\n",
      "           5       0.76      0.52      0.62       892\n",
      "           6       0.74      0.79      0.77       958\n",
      "           7       0.84      0.75      0.79      1028\n",
      "           8       0.85      0.47      0.61       974\n",
      "           9       0.75      0.65      0.69      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.76      0.74      0.74     10000\n",
      "weighted avg       0.76      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 931    2    2    3    6    2   29    2    1    2]\n",
      " [   0 1095   24    4    0    0    5    3    4    0]\n",
      " [  33   80  734   13   49    1   71   28   11   12]\n",
      " [  25   42   60  791    2   12   13   18   22   25]\n",
      " [   3   29    2   10  825   12   21    4    8   68]\n",
      " [  58   48   10  143   79  462   64   13    7    8]\n",
      " [  40    7   28    4  108   11  758    1    1    0]\n",
      " [  17   63   44    4   46    2    0  774   13   65]\n",
      " [  13   93   53  132   24   86   59   10  461   43]\n",
      " [  17   33    9   28  157   22    2   73   14  654]]\n",
      "--------------------------------\n",
      "val predicted: (59675,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59675, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (325, 784) (325,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [37 50 33 38 31 33 32 34 25 37] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.158 s \n",
      "\n",
      "Accuracy rate for 75.230000 \n",
      "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88       980\n",
      "           1       0.70      0.95      0.80      1135\n",
      "           2       0.74      0.74      0.74      1032\n",
      "           3       0.74      0.77      0.75      1010\n",
      "           4       0.65      0.85      0.74       982\n",
      "           5       0.74      0.55      0.63       892\n",
      "           6       0.80      0.81      0.80       958\n",
      "           7       0.84      0.75      0.79      1028\n",
      "           8       0.91      0.46      0.61       974\n",
      "           9       0.74      0.63      0.68      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.77      0.75      0.74     10000\n",
      "weighted avg       0.76      0.75      0.75     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 940    2    1    5    2    2   23    1    1    3]\n",
      " [   0 1079   45    4    0    0    4    2    1    0]\n",
      " [  28   82  766   12   54    2   45   28    3   12]\n",
      " [  30   47   69  779    3   11   13   23   11   24]\n",
      " [   2   35    3   11  836   15   17    3    8   52]\n",
      " [  63   67    3  121   70  490   48   16    6    8]\n",
      " [  44   12   17    5   91   10  776    1    1    1]\n",
      " [  13   62   47    4   44    1    0  773    4   80]\n",
      " [  13  123   79   96   20   99   42    7  445   50]\n",
      " [  18   42    7   20  169   31    4   70    9  639]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59650, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [40 53 35 38 33 37 36 37 27 39] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.179 s \n",
      "\n",
      "Accuracy rate for 73.800000 \n",
      "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       980\n",
      "           1       0.70      0.97      0.81      1135\n",
      "           2       0.80      0.62      0.70      1032\n",
      "           3       0.67      0.78      0.72      1010\n",
      "           4       0.65      0.82      0.73       982\n",
      "           5       0.81      0.44      0.57       892\n",
      "           6       0.71      0.87      0.78       958\n",
      "           7       0.81      0.79      0.80      1028\n",
      "           8       0.91      0.48      0.63       974\n",
      "           9       0.68      0.64      0.66      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.76      0.73      0.73     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 913    2    1    5    2    2   41    2    9    3]\n",
      " [   0 1099   23    5    0    0    5    3    0    0]\n",
      " [  55  103  642   16   44    4  105   37   12   14]\n",
      " [  24   53   50  783    2    9   22   25    9   33]\n",
      " [   5   33    1   12  806    6   21    7    2   89]\n",
      " [  55   57    6  188   79  390   70   22    5   20]\n",
      " [  34   10    9    5   58    7  829    1    2    3]\n",
      " [   7   57   33    3   32    0    2  809    4   81]\n",
      " [  13  129   31  130   26   53   60   10  468   54]\n",
      " [  15   33    4   25  185   13    8   79    6  641]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59625, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [41 56 37 40 37 38 39 42 27 43] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.197 s \n",
      "\n",
      "Accuracy rate for 74.850000 \n",
      "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       980\n",
      "           1       0.71      0.96      0.81      1135\n",
      "           2       0.76      0.68      0.72      1032\n",
      "           3       0.73      0.76      0.74      1010\n",
      "           4       0.69      0.81      0.75       982\n",
      "           5       0.73      0.47      0.57       892\n",
      "           6       0.74      0.87      0.80       958\n",
      "           7       0.80      0.79      0.79      1028\n",
      "           8       0.91      0.51      0.66       974\n",
      "           9       0.69      0.66      0.68      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.76      0.74      0.74     10000\n",
      "weighted avg       0.76      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 907    2    4    4    3    3   46    3    5    3]\n",
      " [   0 1085   37    5    0    0    5    3    0    0]\n",
      " [  41  109  699   12   37    0   75   34   13   12]\n",
      " [  32   57   47  769    4   11   21   22   13   34]\n",
      " [   5   28    6    5  796   22   22    9    6   83]\n",
      " [  56   61    9  149   81  415   61   35    5   20]\n",
      " [  31    9   24    4   38   11  835    1    2    3]\n",
      " [   8   53   43    1   25    0    4  811    2   81]\n",
      " [  12  102   41   95   18   76   56   11  500   63]\n",
      " [  11   32    9   14  144   27    9   90    5  668]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59600, 10) \n",
      " [3 0 4 ... 5 6 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (400, 784) (400,)\n",
      "trainset after (425, 784) (425,)\n",
      "updated train set: (425, 784) (425,) unique(labels): [44 61 39 42 39 41 41 46 28 44] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59575, 784) (59575,)\n",
      "\n",
      "Train set: (425, 784) y: (425,)\n",
      "Val   set: (59575, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.188 s \n",
      "\n",
      "Accuracy rate for 75.150000 \n",
      "Classification report for classifier LogisticRegression(C=0.11764705882352941, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85       980\n",
      "           1       0.70      0.95      0.81      1135\n",
      "           2       0.76      0.65      0.70      1032\n",
      "           3       0.76      0.76      0.76      1010\n",
      "           4       0.68      0.83      0.75       982\n",
      "           5       0.77      0.49      0.60       892\n",
      "           6       0.75      0.86      0.80       958\n",
      "           7       0.80      0.78      0.79      1028\n",
      "           8       0.90      0.57      0.70       974\n",
      "           9       0.73      0.63      0.68      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.76      0.75      0.74     10000\n",
      "weighted avg       0.76      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 920    2    2    5    6    0   33    2    7    3]\n",
      " [   0 1081   40    3    0    0    5    4    2    0]\n",
      " [  61  111  670   13   34    0   87   31   13   12]\n",
      " [  34   54   52  771    3   11   22   31   11   21]\n",
      " [   9   30    7    7  812   21   19    7    6   64]\n",
      " [  70   59   21  110   91  440   49   32    7   13]\n",
      " [  36   11   21    4   41   10  827    1    6    1]\n",
      " [  15   58   44    2   29    1    3  798    2   76]\n",
      " [  24  105   23   76   19   59   53    9  557   49]\n",
      " [  22   33    4   19  160   31    7   87    7  639]]\n",
      "--------------------------------\n",
      "val predicted: (59575,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59575, 10) \n",
      " [3 0 4 ... 5 0 9]\n",
      "trainset before (425, 784) (425,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [46 65 40 44 42 46 44 46 29 48] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.192 s \n",
      "\n",
      "Accuracy rate for 74.630000 \n",
      "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85       980\n",
      "           1       0.70      0.96      0.81      1135\n",
      "           2       0.73      0.65      0.69      1032\n",
      "           3       0.74      0.78      0.76      1010\n",
      "           4       0.69      0.84      0.76       982\n",
      "           5       0.71      0.48      0.57       892\n",
      "           6       0.77      0.85      0.81       958\n",
      "           7       0.79      0.79      0.79      1028\n",
      "           8       0.89      0.48      0.62       974\n",
      "           9       0.74      0.65      0.69      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.74      0.73     10000\n",
      "weighted avg       0.75      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 921    2    4    3    4    2   27    3   11    3]\n",
      " [   0 1086   37    5    0    0    5    2    0    0]\n",
      " [  57  113  668   12   40    0   77   33   20   12]\n",
      " [  34   51   44  785    3   13   21   28    6   25]\n",
      " [   5   30    9    8  824   17   17    7   11   54]\n",
      " [  67   62   22  126   90  425   48   36    7    9]\n",
      " [  33   13   30    4   46   11  818    1    2    0]\n",
      " [  16   51   50    2   26    0    2  815    1   65]\n",
      " [  22  106   41  102   23   95   46    8  470   61]\n",
      " [  20   32    8   20  138   37    6   94    3  651]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59550, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (475, 784) (475,)\n",
      "updated train set: (475, 784) (475,) unique(labels): [48 69 45 49 44 47 45 49 30 49] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59525, 784) (59525,)\n",
      "\n",
      "Train set: (475, 784) y: (475,)\n",
      "Val   set: (59525, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.198 s \n",
      "\n",
      "Accuracy rate for 74.160000 \n",
      "Classification report for classifier LogisticRegression(C=0.10526315789473684, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       980\n",
      "           1       0.70      0.96      0.81      1135\n",
      "           2       0.75      0.61      0.67      1032\n",
      "           3       0.72      0.81      0.76      1010\n",
      "           4       0.67      0.83      0.74       982\n",
      "           5       0.73      0.45      0.55       892\n",
      "           6       0.71      0.86      0.78       958\n",
      "           7       0.80      0.80      0.80      1028\n",
      "           8       0.88      0.54      0.67       974\n",
      "           9       0.75      0.59      0.66      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.74      0.73     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 901    2    1    6    6    0   44    5   12    3]\n",
      " [   0 1087   37    4    0    0    5    1    1    0]\n",
      " [  58  112  632   22   39    0  111   33   17    8]\n",
      " [  31   42   26  819    2   14   23   23    7   23]\n",
      " [   4   35   15    8  813   22   23    9    6   47]\n",
      " [  55   68   13  143   99  400   59   27   11   17]\n",
      " [  28   13   34    7   43    7  820    1    5    0]\n",
      " [  12   55   46    2   35    3    4  818    4   49]\n",
      " [  12  111   28   98   20   57   55   10  530   53]\n",
      " [  13   34   15   24  163   47    9  100    8  596]]\n",
      "--------------------------------\n",
      "val predicted: (59525,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59525, 10) \n",
      " [3 0 4 ... 5 0 9]\n",
      "trainset before (475, 784) (475,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [52 73 47 51 46 49 46 52 34 50] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.201 s \n",
      "\n",
      "Accuracy rate for 73.910000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       980\n",
      "           1       0.70      0.95      0.81      1135\n",
      "           2       0.70      0.64      0.67      1032\n",
      "           3       0.76      0.78      0.77      1010\n",
      "           4       0.64      0.84      0.73       982\n",
      "           5       0.72      0.51      0.60       892\n",
      "           6       0.72      0.83      0.77       958\n",
      "           7       0.81      0.80      0.80      1028\n",
      "           8       0.87      0.48      0.62       974\n",
      "           9       0.75      0.60      0.67      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.73      0.73     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 897    2    4    4    9    3   41    3   13    4]\n",
      " [   0 1079   45    3    0    0    6    2    0    0]\n",
      " [  55  114  659   12   42    0   88   32   22    8]\n",
      " [  31   53   37  788    3   24   20   18    5   31]\n",
      " [   4   30   13    8  822   21   23    6    7   48]\n",
      " [  60   62   22   90   98  454   54   27   10   15]\n",
      " [  25    9   39    3   72   12  794    1    3    0]\n",
      " [  11   54   51    2   36    3    2  821    1   47]\n",
      " [  18  102   53  102   25   80   63    9  468   54]\n",
      " [  13   33   19   23  168   33    9   95    7  609]]\n",
      "--------------------------------\n",
      "final active learning accuracies [54.279999999999994, 58.24, 61.839999999999996, 68.43, 68.44, 71.43, 74.02, 73.87, 73.4, 74.36, 75.39, 74.62, 74.85000000000001, 75.22999999999999, 73.8, 74.85000000000001, 75.14999999999999, 74.63, 74.16, 73.91]\n",
      "saved Active-learning-experiment-34.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 35, using model = LogModel, selection_function = RandomSelection, k = 10, iteration = 0.\n",
      "\n",
      "initial random chosen samples (10,)\n",
      "initial train set: (10, 784) (10,) unique(labels): [1 3 0 1 0 1 1 1 1 1] [0 1 3 5 6 7 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59990, 784) (59990,) (10,)\n",
      "\n",
      "Train set: (10, 784) y: (10,)\n",
      "Val   set: (59990, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.107 s \n",
      "\n",
      "Accuracy rate for 37.630000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=5.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.30      0.41       980\n",
      "           1       0.64      0.89      0.75      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.37      0.37      0.37      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.13      0.32      0.19       892\n",
      "           6       0.54      0.45      0.49       958\n",
      "           7       0.34      0.57      0.43      1028\n",
      "           8       0.38      0.54      0.45       974\n",
      "           9       0.27      0.25      0.26      1009\n",
      "\n",
      "    accuracy                           0.38     10000\n",
      "   macro avg       0.33      0.37      0.33     10000\n",
      "weighted avg       0.34      0.38      0.34     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 296    0    0   51    0  571   28    1   20   13]\n",
      " [   0 1009    0    2    0   14    5  101    3    1]\n",
      " [  18  129    0  258    0  334  137   19  107   30]\n",
      " [  23   67    0  374    0  122   21   59  249   95]\n",
      " [   3   60    0   21    0  271   59  285   41  242]\n",
      " [  38   20    0   85    0  284   58   54  292   61]\n",
      " [  50   11    0  158    0  143  430   57   35   74]\n",
      " [   2  125    0   13    0  124    0  589   37  138]\n",
      " [  24   78    0   31    0  157   40   77  527   40]\n",
      " [   6   68    0    9    0  100   18  481   73  254]]\n",
      "--------------------------------\n",
      "val predicted: (59990,) ['9' '0' '9' ... '8' '6' '5']\n",
      "probabilities: (59990, 8) \n",
      " [7 0 7 ... 6 4 3]\n",
      "trainset before (10, 784) (10,)\n",
      "trainset after (20, 784) (20,)\n",
      "updated train set: (20, 784) (20,) unique(labels): [2 3 2 2 0 3 2 3 2 1] [0 1 2 3 5 6 7 8 9]\n",
      "val set: (59980, 784) (59980,)\n",
      "\n",
      "Train set: (20, 784) y: (20,)\n",
      "Val   set: (59980, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.110 s \n",
      "\n",
      "Accuracy rate for 50.610000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=2.5, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76       980\n",
      "           1       0.72      0.94      0.82      1135\n",
      "           2       0.43      0.42      0.42      1032\n",
      "           3       0.53      0.74      0.62      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.35      0.24      0.29       892\n",
      "           6       0.53      0.59      0.56       958\n",
      "           7       0.53      0.53      0.53      1028\n",
      "           8       0.29      0.56      0.38       974\n",
      "           9       0.40      0.16      0.22      1009\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.45      0.50      0.46     10000\n",
      "weighted avg       0.45      0.51      0.47     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 782    0   43   13    0   31   58    4   45    4]\n",
      " [   1 1069   13    1    0   42    7    2    0    0]\n",
      " [  19  137  430  178    0   15  194   18   33    8]\n",
      " [  10   27   24  751    0   54   23   23   85   13]\n",
      " [  18   44   47   47    0  128   38   75  432  153]\n",
      " [ 113   11   14  157    0  218  111   28  219   21]\n",
      " [  58   23  259   13    0    4  563    1   36    1]\n",
      " [  17   65  117  135    0   33    1  548   82   30]\n",
      " [  62   84   41  116    0   29   72   17  543   10]\n",
      " [   8   16   12   10    0   64    1  311  430  157]]\n",
      "--------------------------------\n",
      "val predicted: (59980,) ['2' '0' '3' ... '8' '6' '0']\n",
      "probabilities: (59980, 9) \n",
      " [2 0 3 ... 7 5 0]\n",
      "trainset before (20, 784) (20,)\n",
      "trainset after (30, 784) (30,)\n",
      "updated train set: (30, 784) (30,) unique(labels): [3 4 2 2 0 5 4 3 5 2] [0 1 2 3 5 6 7 8 9]\n",
      "val set: (59970, 784) (59970,)\n",
      "\n",
      "Train set: (30, 784) y: (30,)\n",
      "Val   set: (59970, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.116 s \n",
      "\n",
      "Accuracy rate for 57.880000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=1.6666666666666667, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       980\n",
      "           1       0.72      0.99      0.83      1135\n",
      "           2       0.63      0.34      0.44      1032\n",
      "           3       0.56      0.68      0.61      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.42      0.34      0.37       892\n",
      "           6       0.53      0.85      0.65       958\n",
      "           7       0.69      0.57      0.62      1028\n",
      "           8       0.42      0.64      0.51       974\n",
      "           9       0.47      0.46      0.47      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.52      0.57      0.53     10000\n",
      "weighted avg       0.53      0.58      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 840    0   19   11    0   24   57    1   27    1]\n",
      " [   0 1121    5    1    0    1    2    2    3    0]\n",
      " [  30  154  348  156    0   12  244   26   55    7]\n",
      " [  38   51   16  690    0   62   12   21   75   45]\n",
      " [   3   34   16   41    0  106  273   15  175  319]\n",
      " [  82   12   15  114    0  303   40   29  250   47]\n",
      " [  19   11   25    8    0   35  817    0   43    0]\n",
      " [   9   78   82  141    0   35    6  582   26   69]\n",
      " [  48   71   16   68    0   61   41   11  619   39]\n",
      " [  12   26    7    6    0   90   60  156  184  468]]\n",
      "--------------------------------\n",
      "val predicted: (59970,) ['2' '0' '3' ... '8' '6' '0']\n",
      "probabilities: (59970, 9) \n",
      " [2 0 3 ... 7 5 0]\n",
      "trainset before (30, 784) (30,)\n",
      "trainset after (40, 784) (40,)\n",
      "updated train set: (40, 784) (40,) unique(labels): [3 4 2 3 1 7 6 5 7 2] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59960, 784) (59960,)\n",
      "\n",
      "Train set: (40, 784) y: (40,)\n",
      "Val   set: (59960, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.123 s \n",
      "\n",
      "Accuracy rate for 60.150000 \n",
      "Classification report for classifier LogisticRegression(C=1.25, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.77      0.83       980\n",
      "           1       0.68      0.99      0.81      1135\n",
      "           2       0.61      0.39      0.48      1032\n",
      "           3       0.64      0.68      0.66      1010\n",
      "           4       0.98      0.14      0.24       982\n",
      "           5       0.43      0.35      0.38       892\n",
      "           6       0.60      0.86      0.70       958\n",
      "           7       0.71      0.63      0.67      1028\n",
      "           8       0.42      0.67      0.52       974\n",
      "           9       0.43      0.47      0.45      1009\n",
      "\n",
      "    accuracy                           0.60     10000\n",
      "   macro avg       0.64      0.59      0.57     10000\n",
      "weighted avg       0.64      0.60      0.58     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 756    2   33    8    0   49   73    2   54    3]\n",
      " [   0 1124    5    1    0    0    1    1    3    0]\n",
      " [  19  156  405  143    1   27  150   14  111    6]\n",
      " [  18   48   16  689    0   68   13   18   90   50]\n",
      " [   0   66   20    6  134   63  206   34   86  367]\n",
      " [  16   22   13  148    0  309   41   29  249   65]\n",
      " [   8   14   24    1    0   34  821    0   56    0]\n",
      " [   9   84  109    3    1   54    8  647   25   88]\n",
      " [   5   84   25   75    0   48   25    6  653   53]\n",
      " [   6   42   11    9    1   63   34  156  210  477]]\n",
      "--------------------------------\n",
      "val predicted: (59960,) ['2' '0' '9' ... '3' '8' '0']\n",
      "probabilities: (59960, 10) \n",
      " [2 0 9 ... 3 8 0]\n",
      "trainset before (40, 784) (40,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [6 6 3 3 1 7 7 7 7 3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.122 s \n",
      "\n",
      "Accuracy rate for 67.540000 \n",
      "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       980\n",
      "           1       0.73      0.98      0.83      1135\n",
      "           2       0.76      0.46      0.57      1032\n",
      "           3       0.63      0.78      0.69      1010\n",
      "           4       0.78      0.36      0.49       982\n",
      "           5       0.51      0.35      0.42       892\n",
      "           6       0.73      0.88      0.80       958\n",
      "           7       0.78      0.73      0.76      1028\n",
      "           8       0.56      0.62      0.59       974\n",
      "           9       0.49      0.66      0.56      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.68      0.67      0.66     10000\n",
      "weighted avg       0.69      0.68      0.66     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 858    0    5   13    5   43   33    0   22    1]\n",
      " [   0 1110   12    1    1    4    2    2    3    0]\n",
      " [  38  150  475  151   50   25   79   27   20   17]\n",
      " [   8   21   13  786    0   56   16   26   36   48]\n",
      " [   4   42    5   20  352   31  100    4   20  404]\n",
      " [  15   19    7  165    9  312   42   27  218   78]\n",
      " [  19   13   11    3    4   27  844    0   36    1]\n",
      " [  13   54   63   16   11   18    8  751    2   92]\n",
      " [  15   97   31   91    2   54   22   17  600   45]\n",
      " [  22   22    4   10   17   38   15  105  110  666]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['3' '0' '3' ... '3' '8' '0']\n",
      "probabilities: (59950, 10) \n",
      " [3 0 3 ... 3 8 0]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (60, 784) (60,)\n",
      "updated train set: (60, 784) (60,) unique(labels): [9 8 4 4 1 7 8 9 7 3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59940, 784) (59940,)\n",
      "\n",
      "Train set: (60, 784) y: (60,)\n",
      "Val   set: (59940, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.120 s \n",
      "\n",
      "Accuracy rate for 65.030000 \n",
      "Classification report for classifier LogisticRegression(C=0.8333333333333334, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       980\n",
      "           1       0.74      0.99      0.84      1135\n",
      "           2       0.79      0.62      0.69      1032\n",
      "           3       0.71      0.69      0.70      1010\n",
      "           4       0.97      0.20      0.33       982\n",
      "           5       0.45      0.30      0.36       892\n",
      "           6       0.72      0.85      0.78       958\n",
      "           7       0.64      0.69      0.67      1028\n",
      "           8       0.44      0.70      0.54       974\n",
      "           9       0.48      0.52      0.50      1009\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.68      0.64      0.63     10000\n",
      "weighted avg       0.68      0.65      0.63     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 855    1    2    5    0   22   44    1   46    4]\n",
      " [   0 1118   10    1    0    0    2    2    2    0]\n",
      " [  55  132  638   48    4   27   49   32   43    4]\n",
      " [  12   27   25  696    0   67   23   35   78   47]\n",
      " [   8   46    9   24  197   68  113   50  154  313]\n",
      " [  19   24    6  159    0  267   40   55  267   55]\n",
      " [  22   12   11    2    0   47  811    0   53    0]\n",
      " [  19   50   71   10    2   20    9  713   17  117]\n",
      " [  16   88   28   38    0   37   25   30  680   32]\n",
      " [  18   19    4    4    1   39   16  188  192  528]]\n",
      "--------------------------------\n",
      "val predicted: (59940,) ['3' '0' '9' ... '3' '8' '7']\n",
      "probabilities: (59940, 10) \n",
      " [3 0 9 ... 3 8 7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (60, 784) (60,)\n",
      "trainset after (70, 784) (70,)\n",
      "updated train set: (70, 784) (70,) unique(labels): [ 9  8  4  7  3  7 11 11  7  3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59930, 784) (59930,)\n",
      "\n",
      "Train set: (70, 784) y: (70,)\n",
      "Val   set: (59930, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.126 s \n",
      "\n",
      "Accuracy rate for 65.520000 \n",
      "Classification report for classifier LogisticRegression(C=0.7142857142857143, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       980\n",
      "           1       0.79      0.99      0.87      1135\n",
      "           2       0.79      0.43      0.55      1032\n",
      "           3       0.62      0.80      0.70      1010\n",
      "           4       0.50      0.34      0.40       982\n",
      "           5       0.61      0.31      0.41       892\n",
      "           6       0.68      0.89      0.77       958\n",
      "           7       0.80      0.60      0.69      1028\n",
      "           8       0.54      0.62      0.58       974\n",
      "           9       0.44      0.63      0.51      1009\n",
      "\n",
      "    accuracy                           0.66     10000\n",
      "   macro avg       0.66      0.65      0.64     10000\n",
      "weighted avg       0.67      0.66      0.64     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 865    1    2    5    0   21   53    1   30    2]\n",
      " [   0 1119    5    1    0    1    4    3    2    0]\n",
      " [  44  125  441  106   13   11  174   20   62   36]\n",
      " [  10    9   35  810    1   28   10   21   40   46]\n",
      " [   3   20    4    3  329   21   78    2   43  479]\n",
      " [  19   17    4  215    7  278   40   38  187   87]\n",
      " [  34    8   19    1   10   14  855    0   16    1]\n",
      " [  16   48   43    7  144   24    4  618   14  110]\n",
      " [  10   65    3  139    9   35   32   19  603   59]\n",
      " [   8   13    2   15  143   26   11   46  111  634]]\n",
      "--------------------------------\n",
      "val predicted: (59930,) ['3' '0' '9' ... '3' '8' '5']\n",
      "probabilities: (59930, 10) \n",
      " [3 0 9 ... 3 8 5]\n",
      "trainset before (70, 784) (70,)\n",
      "trainset after (80, 784) (80,)\n",
      "updated train set: (80, 784) (80,) unique(labels): [12  9  5  7  5  7 12 13  7  3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59920, 784) (59920,)\n",
      "\n",
      "Train set: (80, 784) y: (80,)\n",
      "Val   set: (59920, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.124 s \n",
      "\n",
      "Accuracy rate for 69.200000 \n",
      "Classification report for classifier LogisticRegression(C=0.625, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86       980\n",
      "           1       0.77      0.99      0.87      1135\n",
      "           2       0.77      0.67      0.72      1032\n",
      "           3       0.64      0.82      0.72      1010\n",
      "           4       0.62      0.53      0.57       982\n",
      "           5       0.61      0.28      0.38       892\n",
      "           6       0.75      0.86      0.80       958\n",
      "           7       0.70      0.73      0.72      1028\n",
      "           8       0.54      0.62      0.58       974\n",
      "           9       0.58      0.45      0.51      1009\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.68      0.68      0.67     10000\n",
      "weighted avg       0.68      0.69      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 869    0    4    3    2   23   39    2   38    0]\n",
      " [   0 1121    5    1    0    0    4    3    1    0]\n",
      " [  56   93  692   51   39    7   48   20   20    6]\n",
      " [  14   19   24  833    0   30   14   36   26   14]\n",
      " [   0   30    0    8  517   16   98   14   58  241]\n",
      " [  36   21    9  243    8  246   33   66  200   30]\n",
      " [  24    9   23    1   23   27  827    0   24    0]\n",
      " [  14   44   88    6   79    8    6  750    9   24]\n",
      " [  17   85   40  130    5   32   24   24  607   10]\n",
      " [   7   27   13   19  164   17   14  153  137  458]]\n",
      "--------------------------------\n",
      "val predicted: (59920,) ['3' '0' '9' ... '3' '8' '0']\n",
      "probabilities: (59920, 10) \n",
      " [3 0 9 ... 3 8 0]\n",
      "trainset before (80, 784) (80,)\n",
      "trainset after (90, 784) (90,)\n",
      "updated train set: (90, 784) (90,) unique(labels): [13 10  7  7  5  8 14 15  8  3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59910, 784) (59910,)\n",
      "\n",
      "Train set: (90, 784) y: (90,)\n",
      "Val   set: (59910, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.132 s \n",
      "\n",
      "Accuracy rate for 68.750000 \n",
      "Classification report for classifier LogisticRegression(C=0.5555555555555556, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       980\n",
      "           1       0.73      0.99      0.84      1135\n",
      "           2       0.81      0.63      0.71      1032\n",
      "           3       0.67      0.81      0.73      1010\n",
      "           4       0.69      0.39      0.50       982\n",
      "           5       0.57      0.29      0.38       892\n",
      "           6       0.82      0.89      0.85       958\n",
      "           7       0.79      0.70      0.74      1028\n",
      "           8       0.55      0.58      0.57       974\n",
      "           9       0.45      0.65      0.53      1009\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.68      0.67     10000\n",
      "weighted avg       0.70      0.69      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 855    2    4    2    4   32   44    3   31    3]\n",
      " [   0 1125    4    1    0    0    2    3    0    0]\n",
      " [  50  124  646   61   17   18   27   17   41   31]\n",
      " [  13   20   17  816    0   29   15   23   19   58]\n",
      " [   0   37    4    2  385   28   36    6   37  447]\n",
      " [  30   20    9  208    7  256   31   53  190   88]\n",
      " [  21   18   14    1   10   21  849    0   23    1]\n",
      " [  11   53   62    5   43   10    7  719   11  107]\n",
      " [  17  103   29  115    2   38   13   21  569   67]\n",
      " [   7   32   11   11   92   14    9   65  113  655]]\n",
      "--------------------------------\n",
      "val predicted: (59910,) ['3' '0' '9' ... '3' '8' '5']\n",
      "probabilities: (59910, 10) \n",
      " [3 0 9 ... 3 8 5]\n",
      "trainset before (90, 784) (90,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [14 12  8  9  5  8 15 17  9  3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.139 s \n",
      "\n",
      "Accuracy rate for 67.020000 \n",
      "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       980\n",
      "           1       0.68      0.99      0.81      1135\n",
      "           2       0.81      0.50      0.62      1032\n",
      "           3       0.64      0.82      0.72      1010\n",
      "           4       0.72      0.34      0.46       982\n",
      "           5       0.57      0.28      0.37       892\n",
      "           6       0.78      0.89      0.83       958\n",
      "           7       0.78      0.71      0.75      1028\n",
      "           8       0.55      0.54      0.55       974\n",
      "           9       0.46      0.70      0.55      1009\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.68      0.66      0.65     10000\n",
      "weighted avg       0.68      0.67      0.65     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 832    2    1   13    3   25   55    1   45    3]\n",
      " [   0 1123    3    3    0    0    2    4    0    0]\n",
      " [  61  169  518   83   33   17   61   18   46   26]\n",
      " [   8   25    9  827    0   25   13   23   21   59]\n",
      " [   0   51    4    2  334   29   54    2   27  479]\n",
      " [  23   27    3  217    5  248   32   58  187   92]\n",
      " [  22   16    4    0   18   19  851    0   28    0]\n",
      " [  14   62   68    5   11   11    6  734    7  110]\n",
      " [  27  138   23  115    0   45   13   19  530   64]\n",
      " [   9   37    6   18   58   15   11   80   70  705]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '9' ... '3' '8' '0']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 9 ... 3 8 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (100, 784) (100,)\n",
      "trainset after (110, 784) (110,)\n",
      "updated train set: (110, 784) (110,) unique(labels): [17 13  8 12  6  8 16 18  9  3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59890, 784) (59890,)\n",
      "\n",
      "Train set: (110, 784) y: (110,)\n",
      "Val   set: (59890, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.147 s \n",
      "\n",
      "Accuracy rate for 67.790000 \n",
      "Classification report for classifier LogisticRegression(C=0.45454545454545453, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       980\n",
      "           1       0.69      0.99      0.81      1135\n",
      "           2       0.79      0.53      0.64      1032\n",
      "           3       0.64      0.83      0.72      1010\n",
      "           4       0.71      0.44      0.54       982\n",
      "           5       0.62      0.27      0.37       892\n",
      "           6       0.78      0.89      0.83       958\n",
      "           7       0.77      0.72      0.74      1028\n",
      "           8       0.56      0.53      0.55       974\n",
      "           9       0.48      0.66      0.55      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.69      0.67      0.66     10000\n",
      "weighted avg       0.69      0.68      0.66     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 824    1    2   10    1   18   64    2   54    4]\n",
      " [   0 1121    5    3    0    0    2    4    0    0]\n",
      " [  71  171  549   51   35   15   53   24   38   25]\n",
      " [   7   23   20  837    0   18    8   24   23   50]\n",
      " [   2   39    4    1  434   20   42    2   19  419]\n",
      " [  17   23    4  250   10  239   27   67  174   81]\n",
      " [  27   12   15    3   27    6  849    0   19    0]\n",
      " [  14   69   56    5   17   10    6  739    6  106]\n",
      " [  17  137   32  124    2   49   23   18  519   53]\n",
      " [  12   35    7   22   86   10   12   82   75  668]]\n",
      "--------------------------------\n",
      "val predicted: (59890,) ['3' '0' '9' ... '3' '8' '0']\n",
      "probabilities: (59890, 10) \n",
      " [3 0 9 ... 3 8 0]\n",
      "trainset before (110, 784) (110,)\n",
      "trainset after (120, 784) (120,)\n",
      "updated train set: (120, 784) (120,) unique(labels): [20 13  9 13  6  8 17 19 11  4] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59880, 784) (59880,)\n",
      "\n",
      "Train set: (120, 784) y: (120,)\n",
      "Val   set: (59880, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.137 s \n",
      "\n",
      "Accuracy rate for 68.700000 \n",
      "Classification report for classifier LogisticRegression(C=0.4166666666666667, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84       980\n",
      "           1       0.70      0.98      0.82      1135\n",
      "           2       0.78      0.56      0.65      1032\n",
      "           3       0.63      0.83      0.72      1010\n",
      "           4       0.70      0.62      0.66       982\n",
      "           5       0.63      0.25      0.36       892\n",
      "           6       0.73      0.88      0.80       958\n",
      "           7       0.66      0.78      0.71      1028\n",
      "           8       0.57      0.59      0.58       974\n",
      "           9       0.58      0.46      0.52      1009\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.68      0.67     10000\n",
      "weighted avg       0.69      0.69      0.67     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 812    1    2   16    2   13   95    3   35    1]\n",
      " [   0 1117    8    3    0    0    2    4    1    0]\n",
      " [  61  165  580   44   48   17   54   27   34    2]\n",
      " [   6   28   17  841    1   22   11   29   31   24]\n",
      " [   2   42    6   10  606   16   55   20   23  202]\n",
      " [  13   16    3  257    8  225   39   98  201   32]\n",
      " [  20   12   13    3   32   10  847    0   21    0]\n",
      " [  11   66   62    1   17    5    4  799    8   55]\n",
      " [   6  110   41  131    4   42   27   21  578   14]\n",
      " [  15   31   10   20  146    7   21  206   88  465]]\n",
      "--------------------------------\n",
      "val predicted: (59880,) ['3' '0' '4' ... '3' '8' '5']\n",
      "probabilities: (59880, 10) \n",
      " [3 0 4 ... 3 8 5]\n",
      "trainset before (120, 784) (120,)\n",
      "trainset after (130, 784) (130,)\n",
      "updated train set: (130, 784) (130,) unique(labels): [20 16 10 14  6 10 17 20 11  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59870, 784) (59870,)\n",
      "\n",
      "Train set: (130, 784) y: (130,)\n",
      "Val   set: (59870, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.131 s \n",
      "\n",
      "Accuracy rate for 69.160000 \n",
      "Classification report for classifier LogisticRegression(C=0.38461538461538464, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86       980\n",
      "           1       0.70      0.98      0.82      1135\n",
      "           2       0.76      0.58      0.66      1032\n",
      "           3       0.70      0.82      0.75      1010\n",
      "           4       0.72      0.72      0.72       982\n",
      "           5       0.64      0.32      0.43       892\n",
      "           6       0.74      0.90      0.81       958\n",
      "           7       0.62      0.80      0.70      1028\n",
      "           8       0.51      0.65      0.57       974\n",
      "           9       0.75      0.23      0.35      1009\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.70      0.69      0.67     10000\n",
      "weighted avg       0.70      0.69      0.67     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 843    1    2    7    1   22   67    2   35    0]\n",
      " [   0 1107   15    2    0    2    4    3    2    0]\n",
      " [  51  177  599   37   39   10   49   26   43    1]\n",
      " [   6   27   26  825    2   18   19   38   46    3]\n",
      " [   0   36    6   10  708   23   58   42   35   64]\n",
      " [  13   13    5  202   12  285   41   66  252    3]\n",
      " [  22   14   20    2   24    7  859    0   10    0]\n",
      " [  12   68   58    1   22   11    5  826   20    5]\n",
      " [   9   99   33   82    5   60   30   26  630    0]\n",
      " [  14   32   26   16  177    7   32  303  168  234]]\n",
      "--------------------------------\n",
      "val predicted: (59870,) ['3' '0' '9' ... '3' '8' '5']\n",
      "probabilities: (59870, 10) \n",
      " [3 0 9 ... 3 8 5]\n",
      "trainset before (130, 784) (130,)\n",
      "trainset after (140, 784) (140,)\n",
      "updated train set: (140, 784) (140,) unique(labels): [21 16 12 17  7 10 18 21 12  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59860, 784) (59860,)\n",
      "\n",
      "Train set: (140, 784) y: (140,)\n",
      "Val   set: (59860, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.136 s \n",
      "\n",
      "Accuracy rate for 70.200000 \n",
      "Classification report for classifier LogisticRegression(C=0.35714285714285715, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       980\n",
      "           1       0.72      0.98      0.83      1135\n",
      "           2       0.77      0.56      0.65      1032\n",
      "           3       0.64      0.83      0.72      1010\n",
      "           4       0.78      0.49      0.60       982\n",
      "           5       0.63      0.31      0.41       892\n",
      "           6       0.73      0.91      0.81       958\n",
      "           7       0.79      0.77      0.78      1028\n",
      "           8       0.59      0.57      0.58       974\n",
      "           9       0.56      0.70      0.62      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.69      0.68     10000\n",
      "weighted avg       0.71      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 814    1    2   14    0   11   88    1   41    8]\n",
      " [   0 1111   11    3    1    2    3    3    1    0]\n",
      " [  55  152  575   52   24   15   60   25   62   12]\n",
      " [   6   25   15  839    1   21   25   20   16   42]\n",
      " [   2   42    7    7  477   25   46   10   15  351]\n",
      " [  15   10    6  247   10  273   45   47  165   74]\n",
      " [  21   11   18    3   13    6  874    0   12    0]\n",
      " [  10   65   60    1   24   10    4  796   13   45]\n",
      " [   6   98   46  130    6   62   31   18  555   22]\n",
      " [  11   27   10   20   59    8   20   87   61  706]]\n",
      "--------------------------------\n",
      "val predicted: (59860,) ['3' '0' '9' ... '3' '8' '9']\n",
      "probabilities: (59860, 10) \n",
      " [3 0 9 ... 3 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (140, 784) (140,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [24 16 14 18  8 11 19 22 12  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.147 s \n",
      "\n",
      "Accuracy rate for 70.430000 \n",
      "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       980\n",
      "           1       0.71      0.98      0.82      1135\n",
      "           2       0.82      0.53      0.64      1032\n",
      "           3       0.63      0.84      0.72      1010\n",
      "           4       0.69      0.67      0.68       982\n",
      "           5       0.64      0.30      0.41       892\n",
      "           6       0.75      0.90      0.81       958\n",
      "           7       0.75      0.82      0.78      1028\n",
      "           8       0.54      0.58      0.56       974\n",
      "           9       0.66      0.52      0.58      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.70      0.69     10000\n",
      "weighted avg       0.71      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 822    1    2   11    0   11   88    2   42    1]\n",
      " [   0 1112    8    4    0    2    5    3    1    0]\n",
      " [  57  162  544   43   63   13   49   26   73    2]\n",
      " [   6   22   13  846    1   11   27   28   29   27]\n",
      " [   1   42    7   11  658   26   34   16   19  168]\n",
      " [  19   13    9  246   13  271   41   49  189   42]\n",
      " [  19   10   23    6   24    3  859    0   14    0]\n",
      " [  12   64   33    2   24   14    5  842   17   15]\n",
      " [   8  105   21  143    3   66   28   20  566   14]\n",
      " [  11   30    4   23  171    9   16  133   89  523]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['3' '0' '9' ... '3' '8' '9']\n",
      "probabilities: (59850, 10) \n",
      " [3 0 9 ... 3 8 9]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (160, 784) (160,)\n",
      "updated train set: (160, 784) (160,) unique(labels): [24 16 15 21  9 14 19 23 13  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59840, 784) (59840,)\n",
      "\n",
      "Train set: (160, 784) y: (160,)\n",
      "Val   set: (59840, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.147 s \n",
      "\n",
      "Accuracy rate for 69.940000 \n",
      "Classification report for classifier LogisticRegression(C=0.3125, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       980\n",
      "           1       0.71      0.98      0.83      1135\n",
      "           2       0.78      0.54      0.64      1032\n",
      "           3       0.66      0.82      0.73      1010\n",
      "           4       0.72      0.55      0.62       982\n",
      "           5       0.62      0.28      0.39       892\n",
      "           6       0.73      0.88      0.80       958\n",
      "           7       0.77      0.78      0.77      1028\n",
      "           8       0.60      0.59      0.59       974\n",
      "           9       0.56      0.67      0.61      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.69      0.68     10000\n",
      "weighted avg       0.70      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 812    1    3   13    0    8   93    2   42    6]\n",
      " [   0 1113    9    3    0    0    6    3    1    0]\n",
      " [  63  159  559   59   46    6   52   19   60    9]\n",
      " [   6   23   18  826    2   12   24   31   15   53]\n",
      " [   1   40   10    6  538   28   34   14   10  301]\n",
      " [  20   13   24  216    9  251   45   65  182   67]\n",
      " [  21    9   24    1   19   19  840    1   24    0]\n",
      " [   9   67   45    2   20    9    5  804   11   56]\n",
      " [  10  111   17  113    6   58   30   16  579   34]\n",
      " [  10   26    5   17  111   12   14   93   49  672]]\n",
      "--------------------------------\n",
      "val predicted: (59840,) ['3' '0' '9' ... '3' '8' '9']\n",
      "probabilities: (59840, 10) \n",
      " [3 0 9 ... 3 8 9]\n",
      "trainset before (160, 784) (160,)\n",
      "trainset after (170, 784) (170,)\n",
      "updated train set: (170, 784) (170,) unique(labels): [25 17 15 22  9 15 19 23 17  8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59830, 784) (59830,)\n",
      "\n",
      "Train set: (170, 784) y: (170,)\n",
      "Val   set: (59830, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.169 s \n",
      "\n",
      "Accuracy rate for 69.700000 \n",
      "Classification report for classifier LogisticRegression(C=0.29411764705882354, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       980\n",
      "           1       0.73      0.98      0.84      1135\n",
      "           2       0.80      0.52      0.63      1032\n",
      "           3       0.61      0.82      0.70      1010\n",
      "           4       0.68      0.55      0.61       982\n",
      "           5       0.69      0.28      0.40       892\n",
      "           6       0.70      0.87      0.78       958\n",
      "           7       0.74      0.77      0.76      1028\n",
      "           8       0.66      0.59      0.62       974\n",
      "           9       0.57      0.67      0.62      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.69      0.68     10000\n",
      "weighted avg       0.70      0.70      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 813    1    3   19    0    9  111    6   11    7]\n",
      " [   0 1112    6    2    0    0    6    3    6    0]\n",
      " [  57  147  540   66   67    7   59   30   57    2]\n",
      " [   5   23   11  831    2    7   30   25   31   45]\n",
      " [   1   32    9    3  543   14   32   16   18  314]\n",
      " [  17   16   26  293   14  250   62   84  103   27]\n",
      " [  18   10   27    1   23   15  833    1   29    1]\n",
      " [  13   62   30    1   18    8    6  796   10   84]\n",
      " [  13  100   16  124    2   51   35   19  571   43]\n",
      " [  15   21    9   20  132    1   14   89   27  681]]\n",
      "--------------------------------\n",
      "val predicted: (59830,) ['3' '0' '4' ... '3' '7' '9']\n",
      "probabilities: (59830, 10) \n",
      " [3 0 4 ... 3 7 9]\n",
      "trainset before (170, 784) (170,)\n",
      "trainset after (180, 784) (180,)\n",
      "updated train set: (180, 784) (180,) unique(labels): [26 17 15 22 11 16 19 26 19  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59820, 784) (59820,)\n",
      "\n",
      "Train set: (180, 784) y: (180,)\n",
      "Val   set: (59820, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.169 s \n",
      "\n",
      "Accuracy rate for 69.970000 \n",
      "Classification report for classifier LogisticRegression(C=0.2777777777777778, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84       980\n",
      "           1       0.72      0.98      0.83      1135\n",
      "           2       0.83      0.54      0.65      1032\n",
      "           3       0.60      0.82      0.69      1010\n",
      "           4       0.66      0.55      0.60       982\n",
      "           5       0.70      0.29      0.41       892\n",
      "           6       0.70      0.88      0.78       958\n",
      "           7       0.80      0.76      0.78      1028\n",
      "           8       0.65      0.59      0.62       974\n",
      "           9       0.56      0.68      0.62      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.69      0.68     10000\n",
      "weighted avg       0.71      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 815    1    3   25    0    9  113    2   11    1]\n",
      " [   0 1115    3    2    0    0    5    3    7    0]\n",
      " [  61  144  553   72   50    5   68   21   57    1]\n",
      " [   6   23   18  826    2   12   29   24   34   36]\n",
      " [   1   32    5    3  538   17   27    4   20  335]\n",
      " [  15   15   22  292   15  263   66   67  104   33]\n",
      " [  17   10   17    0   22   15  842    1   32    2]\n",
      " [  14   69   30    1   21    5    9  778   15   86]\n",
      " [   9  107   10  130    2   49   33   15  577   42]\n",
      " [  12   23    7   18  163    2    7   54   33  690]]\n",
      "--------------------------------\n",
      "val predicted: (59820,) ['3' '0' '4' ... '3' '8' '9']\n",
      "probabilities: (59820, 10) \n",
      " [3 0 4 ... 3 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (180, 784) (180,)\n",
      "trainset after (190, 784) (190,)\n",
      "updated train set: (190, 784) (190,) unique(labels): [27 18 15 24 12 18 20 28 19  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59810, 784) (59810,)\n",
      "\n",
      "Train set: (190, 784) y: (190,)\n",
      "Val   set: (59810, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.166 s \n",
      "\n",
      "Accuracy rate for 70.090000 \n",
      "Classification report for classifier LogisticRegression(C=0.2631578947368421, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       980\n",
      "           1       0.71      0.98      0.82      1135\n",
      "           2       0.79      0.54      0.64      1032\n",
      "           3       0.60      0.82      0.70      1010\n",
      "           4       0.67      0.57      0.62       982\n",
      "           5       0.74      0.29      0.41       892\n",
      "           6       0.70      0.87      0.78       958\n",
      "           7       0.82      0.76      0.79      1028\n",
      "           8       0.65      0.61      0.63       974\n",
      "           9       0.58      0.67      0.63      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.69      0.68     10000\n",
      "weighted avg       0.71      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 810    1    3   28    1    7  110    4   13    3]\n",
      " [   0 1111    6    3    0    0    6    2    7    0]\n",
      " [  68  157  558   54   47    1   66   17   61    3]\n",
      " [   3   32   17  828    3    3   29   19   35   41]\n",
      " [   1   32    6    3  558   22   29    3   30  298]\n",
      " [  16   21   43  299   17  256   70   55   85   30]\n",
      " [  18   11   20    1   22   10  833    1   41    1]\n",
      " [  15   72   34    1   21    9    7  777   17   75]\n",
      " [  11  106   12  131    3   32   31   14  597   37]\n",
      " [  12   24    7   22  158    6    8   59   32  681]]\n",
      "--------------------------------\n",
      "val predicted: (59810,) ['3' '0' '4' ... '3' '8' '9']\n",
      "probabilities: (59810, 10) \n",
      " [3 0 4 ... 3 8 9]\n",
      "trainset before (190, 784) (190,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [29 19 16 25 14 18 21 29 20  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.158 s \n",
      "\n",
      "Accuracy rate for 70.950000 \n",
      "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85       980\n",
      "           1       0.72      0.98      0.83      1135\n",
      "           2       0.80      0.53      0.64      1032\n",
      "           3       0.61      0.82      0.70      1010\n",
      "           4       0.68      0.61      0.64       982\n",
      "           5       0.73      0.30      0.42       892\n",
      "           6       0.71      0.88      0.79       958\n",
      "           7       0.82      0.77      0.79      1028\n",
      "           8       0.66      0.63      0.64       974\n",
      "           9       0.60      0.65      0.63      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.70      0.69     10000\n",
      "weighted avg       0.72      0.71      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 833    1    3   20    0    4  103    2   13    1]\n",
      " [   0 1111    8    2    0    0    6    2    6    0]\n",
      " [  59  152  552   68   45    4   79   20   53    0]\n",
      " [   6   26   17  832    2    4   24   26   34   39]\n",
      " [   1   32    9    2  600   24   23    3   29  259]\n",
      " [  15   22   35  298   15  265   65   52   93   32]\n",
      " [  19   12   10    3   23    5  845    1   35    5]\n",
      " [  16   68   41    1   20   10    8  788   16   60]\n",
      " [   8   96   12  119    5   38   34   12  612   38]\n",
      " [  12   25    7   25  169   10    7   59   38  657]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['3' '0' '4' ... '3' '8' '9']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 4 ... 3 8 9]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (210, 784) (210,)\n",
      "updated train set: (210, 784) (210,) unique(labels): [29 19 19 27 16 19 21 30 21  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59790, 784) (59790,)\n",
      "\n",
      "Train set: (210, 784) y: (210,)\n",
      "Val   set: (59790, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 21\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.165 s \n",
      "\n",
      "Accuracy rate for 71.430000 \n",
      "Classification report for classifier LogisticRegression(C=0.23809523809523808, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86       980\n",
      "           1       0.71      0.98      0.83      1135\n",
      "           2       0.85      0.57      0.69      1032\n",
      "           3       0.63      0.82      0.71      1010\n",
      "           4       0.69      0.63      0.66       982\n",
      "           5       0.73      0.29      0.42       892\n",
      "           6       0.69      0.90      0.78       958\n",
      "           7       0.83      0.77      0.80      1028\n",
      "           8       0.65      0.61      0.63       974\n",
      "           9       0.60      0.65      0.62      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.70     10000\n",
      "weighted avg       0.72      0.71      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 833    1    3   13    2    5  108    2   11    2]\n",
      " [   0 1116    3    2    0    0    7    2    5    0]\n",
      " [  57  150  591   32   35    2   86   18   56    5]\n",
      " [   6   31   18  828    2    7   27   14   42   35]\n",
      " [   1   37    6    3  616   23   24    5   21  246]\n",
      " [  15   21   19  276   14  262   76   53  115   41]\n",
      " [  19   10   12    3   19    5  862    1   23    4]\n",
      " [  14   71   30    3   23   13    9  789   11   65]\n",
      " [  10  101    9  136    5   30   38   15  594   36]\n",
      " [  10   27    1   25  179   11   11   55   38  652]]\n",
      "--------------------------------\n",
      "val predicted: (59790,) ['3' '0' '4' ... '3' '8' '9']\n",
      "probabilities: (59790, 10) \n",
      " [3 0 4 ... 3 8 9]\n",
      "trainset before (210, 784) (210,)\n",
      "trainset after (220, 784) (220,)\n",
      "updated train set: (220, 784) (220,) unique(labels): [31 19 19 29 18 19 21 32 23  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59780, 784) (59780,)\n",
      "\n",
      "Train set: (220, 784) y: (220,)\n",
      "Val   set: (59780, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 22\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.157 s \n",
      "\n",
      "Accuracy rate for 72.790000 \n",
      "Classification report for classifier LogisticRegression(C=0.22727272727272727, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85       980\n",
      "           1       0.73      0.98      0.84      1135\n",
      "           2       0.87      0.60      0.71      1032\n",
      "           3       0.63      0.82      0.71      1010\n",
      "           4       0.73      0.69      0.71       982\n",
      "           5       0.70      0.33      0.44       892\n",
      "           6       0.70      0.91      0.79       958\n",
      "           7       0.81      0.77      0.79      1028\n",
      "           8       0.65      0.59      0.62       974\n",
      "           9       0.65      0.67      0.66      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.73      0.72      0.71     10000\n",
      "weighted avg       0.73      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 839    1    3   13    5    7   84    3   23    2]\n",
      " [   0 1114    3    4    0    0    7    1    6    0]\n",
      " [  56  140  624   33   20    1   75   25   52    6]\n",
      " [   7   19   20  827    1   10   34   20   33   39]\n",
      " [   4   38    7    3  676   27   26    5   12  184]\n",
      " [  17   14   11  274   19  290   87   37  111   32]\n",
      " [  19   11   10    3   18    8  870    0   18    1]\n",
      " [  16   67   23    2   30   12    7  792   15   64]\n",
      " [  11   90   13  134    7   51   38   18  573   39]\n",
      " [  18   22    1   22  147    8   13   71   33  674]]\n",
      "--------------------------------\n",
      "val predicted: (59780,) ['3' '0' '4' ... '3' '8' '9']\n",
      "probabilities: (59780, 10) \n",
      " [3 0 4 ... 3 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (220, 784) (220,)\n",
      "trainset after (230, 784) (230,)\n",
      "updated train set: (230, 784) (230,) unique(labels): [33 19 20 29 19 20 22 34 25  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59770, 784) (59770,)\n",
      "\n",
      "Train set: (230, 784) y: (230,)\n",
      "Val   set: (59770, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 23\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.170 s \n",
      "\n",
      "Accuracy rate for 72.330000 \n",
      "Classification report for classifier LogisticRegression(C=0.21739130434782608, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86       980\n",
      "           1       0.73      0.98      0.84      1135\n",
      "           2       0.81      0.56      0.66      1032\n",
      "           3       0.62      0.82      0.71      1010\n",
      "           4       0.63      0.79      0.70       982\n",
      "           5       0.71      0.33      0.45       892\n",
      "           6       0.72      0.89      0.79       958\n",
      "           7       0.83      0.78      0.81      1028\n",
      "           8       0.66      0.59      0.62       974\n",
      "           9       0.73      0.58      0.64      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.71     10000\n",
      "weighted avg       0.73      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 825    1    4   29    6    5   92    3   15    0]\n",
      " [   0 1111    7    3    0    0    7    1    6    0]\n",
      " [  50  147  578   40   48    4   76   22   65    2]\n",
      " [   5   23   22  833    3   11   22   20   53   18]\n",
      " [   1   28    9    2  774   22   23    3   10  110]\n",
      " [  15   22   32  276   29  296   65   36   98   23]\n",
      " [  18   10   13    3   37    4  853    0   20    0]\n",
      " [  16   64   32    1   54   10    6  803    9   33]\n",
      " [   8   93   15  129   15   57   35   17  579   26]\n",
      " [  10   27    2   24  255   10   11   61   28  581]]\n",
      "--------------------------------\n",
      "val predicted: (59770,) ['3' '0' '4' ... '3' '8' '9']\n",
      "probabilities: (59770, 10) \n",
      " [3 0 4 ... 3 8 9]\n",
      "trainset before (230, 784) (230,)\n",
      "trainset after (240, 784) (240,)\n",
      "updated train set: (240, 784) (240,) unique(labels): [33 19 21 30 20 22 25 35 26  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59760, 784) (59760,)\n",
      "\n",
      "Train set: (240, 784) y: (240,)\n",
      "Val   set: (59760, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 24\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.160 s \n",
      "\n",
      "Accuracy rate for 72.780000 \n",
      "Classification report for classifier LogisticRegression(C=0.20833333333333334, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       980\n",
      "           1       0.71      0.98      0.82      1135\n",
      "           2       0.82      0.61      0.70      1032\n",
      "           3       0.64      0.81      0.71      1010\n",
      "           4       0.74      0.69      0.72       982\n",
      "           5       0.73      0.37      0.49       892\n",
      "           6       0.70      0.87      0.78       958\n",
      "           7       0.81      0.80      0.81      1028\n",
      "           8       0.67      0.56      0.61       974\n",
      "           9       0.67      0.67      0.67      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.73      0.72      0.72     10000\n",
      "weighted avg       0.73      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 834    1    3   15    0    5  103    5   14    0]\n",
      " [   0 1107   11    3    0    0    5    2    7    0]\n",
      " [  62  154  625   28   24    4   57   27   44    7]\n",
      " [   8   25   21  816    0   12   27   20   43   38]\n",
      " [   5   32    5    3  681   23   37    3   13  180]\n",
      " [  16   29   30  257   16  333   70   39   81   21]\n",
      " [  27   15   14    2   20    5  834    1   36    4]\n",
      " [  17   66   28    4   25    7    4  823    6   48]\n",
      " [   8  108   18  129    7   61   39   14  549   41]\n",
      " [  15   20    3   23  144    9   12   77   30  676]]\n",
      "--------------------------------\n",
      "val predicted: (59760,) ['3' '0' '4' ... '3' '5' '9']\n",
      "probabilities: (59760, 10) \n",
      " [3 0 4 ... 3 5 9]\n",
      "trainset before (240, 784) (240,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [33 19 21 31 22 22 28 36 28 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 25\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.174 s \n",
      "\n",
      "Accuracy rate for 72.630000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       980\n",
      "           1       0.71      0.98      0.82      1135\n",
      "           2       0.84      0.60      0.70      1032\n",
      "           3       0.64      0.82      0.71      1010\n",
      "           4       0.74      0.72      0.73       982\n",
      "           5       0.70      0.35      0.47       892\n",
      "           6       0.69      0.88      0.77       958\n",
      "           7       0.82      0.80      0.81      1028\n",
      "           8       0.66      0.58      0.62       974\n",
      "           9       0.67      0.64      0.66      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.73      0.72      0.71     10000\n",
      "weighted avg       0.73      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 828    1    5   11    0   10  101    3   19    2]\n",
      " [   0 1109    7    5    0    0    6    2    6    0]\n",
      " [  58  160  622   27   32    2   67   27   34    3]\n",
      " [   9   34   18  824    1   11   26   20   41   26]\n",
      " [   5   26    5    2  703   30   38    3   21  149]\n",
      " [  16   26   22  253   21  310   79   37   74   54]\n",
      " [  24   14    8    1   29    4  841    1   36    0]\n",
      " [  18   67   30    8   23    9    6  819   14   34]\n",
      " [   8  109   17  135    6   43   39   12  562   43]\n",
      " [  14   27    3   29  141   22   14   73   41  645]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '3' '5' '9']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 3 5 9]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (260, 784) (260,)\n",
      "updated train set: (260, 784) (260,) unique(labels): [35 20 22 33 23 22 28 37 29 11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59740, 784) (59740,)\n",
      "\n",
      "Train set: (260, 784) y: (260,)\n",
      "Val   set: (59740, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 26\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.175 s \n",
      "\n",
      "Accuracy rate for 72.950000 \n",
      "Classification report for classifier LogisticRegression(C=0.19230769230769232, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       980\n",
      "           1       0.72      0.98      0.83      1135\n",
      "           2       0.84      0.63      0.72      1032\n",
      "           3       0.65      0.82      0.72      1010\n",
      "           4       0.76      0.70      0.73       982\n",
      "           5       0.71      0.35      0.47       892\n",
      "           6       0.70      0.86      0.77       958\n",
      "           7       0.82      0.78      0.80      1028\n",
      "           8       0.65      0.60      0.63       974\n",
      "           9       0.68      0.68      0.68      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.73      0.72      0.72     10000\n",
      "weighted avg       0.73      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 817    1    3   15    3   12  101    4   18    6]\n",
      " [   0 1107    9    3    0    0    5    3    8    0]\n",
      " [  63  146  650   33   21    4   55   24   30    6]\n",
      " [   8   23   17  830    1   15   29   22   48   17]\n",
      " [  12   34    5    3  687   27   31    4   27  152]\n",
      " [  18   24   21  241   19  313   77   35   83   61]\n",
      " [  27   14   17    0   29    5  822    0   44    0]\n",
      " [  19   69   32    6   29   12    7  802   10   42]\n",
      " [   8   95   19  127    9   36   37   15  584   44]\n",
      " [  18   30    3   23  109   18   11   73   41  683]]\n",
      "--------------------------------\n",
      "val predicted: (59740,) ['3' '0' '4' ... '3' '5' '9']\n",
      "probabilities: (59740, 10) \n",
      " [3 0 4 ... 3 5 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (260, 784) (260,)\n",
      "trainset after (270, 784) (270,)\n",
      "updated train set: (270, 784) (270,) unique(labels): [35 22 23 33 25 23 29 38 30 12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59730, 784) (59730,)\n",
      "\n",
      "Train set: (270, 784) y: (270,)\n",
      "Val   set: (59730, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 27\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.171 s \n",
      "\n",
      "Accuracy rate for 73.830000 \n",
      "Classification report for classifier LogisticRegression(C=0.18518518518518517, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       980\n",
      "           1       0.72      0.98      0.83      1135\n",
      "           2       0.85      0.65      0.74      1032\n",
      "           3       0.63      0.81      0.71      1010\n",
      "           4       0.77      0.73      0.75       982\n",
      "           5       0.74      0.35      0.48       892\n",
      "           6       0.72      0.89      0.79       958\n",
      "           7       0.84      0.77      0.80      1028\n",
      "           8       0.66      0.60      0.63       974\n",
      "           9       0.68      0.70      0.69      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.73      0.73     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 823    1    4   16    1    7   99    3   18    8]\n",
      " [   0 1107    9    3    0    1    7    1    7    0]\n",
      " [  57  143  670   31   24    2   53   24   20    8]\n",
      " [   7   25   21  823    1    9   27   20   52   25]\n",
      " [  10   30    3    2  718   24   28    4   14  149]\n",
      " [  14   19   18  270   19  312   69   27  103   41]\n",
      " [  21   14   11    2   21    3  852    0   34    0]\n",
      " [  18   74   30    8   30   10    7  788    7   56]\n",
      " [   7  100   18  128   12   38   35   15  582   39]\n",
      " [  16   29    2   22  108   14   10   56   44  708]]\n",
      "--------------------------------\n",
      "val predicted: (59730,) ['3' '0' '4' ... '3' '8' '9']\n",
      "probabilities: (59730, 10) \n",
      " [3 0 4 ... 3 8 9]\n",
      "trainset before (270, 784) (270,)\n",
      "trainset after (280, 784) (280,)\n",
      "updated train set: (280, 784) (280,) unique(labels): [35 22 25 35 26 23 32 39 30 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59720, 784) (59720,)\n",
      "\n",
      "Train set: (280, 784) y: (280,)\n",
      "Val   set: (59720, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 28\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.161 s \n",
      "\n",
      "Accuracy rate for 74.380000 \n",
      "Classification report for classifier LogisticRegression(C=0.17857142857142858, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85       980\n",
      "           1       0.73      0.97      0.83      1135\n",
      "           2       0.84      0.65      0.73      1032\n",
      "           3       0.64      0.82      0.72      1010\n",
      "           4       0.76      0.76      0.76       982\n",
      "           5       0.76      0.36      0.49       892\n",
      "           6       0.72      0.89      0.80       958\n",
      "           7       0.82      0.80      0.81      1028\n",
      "           8       0.66      0.61      0.64       974\n",
      "           9       0.72      0.65      0.69      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.74      0.73     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 848    1    3   19    1    4   74    4   25    1]\n",
      " [   0 1102   15    2    1    0    6    3    6    0]\n",
      " [  59  129  669   35   23    1   61   29   21    5]\n",
      " [   8   23   15  832    1   10   26   26   47   22]\n",
      " [  10   35    4    2  742   24   27    2   15  121]\n",
      " [  15   17   17  260   18  319   72   31  105   38]\n",
      " [  31   12   11    2   30    4  851    0   17    0]\n",
      " [  17   67   40    5   29   11    6  818    6   29]\n",
      " [   6   90   23  119   13   32   41   14  599   37]\n",
      " [  17   30    2   21  119   16   12   74   60  658]]\n",
      "--------------------------------\n",
      "val predicted: (59720,) ['3' '0' '4' ... '3' '8' '9']\n",
      "probabilities: (59720, 10) \n",
      " [3 0 4 ... 3 8 9]\n",
      "trainset before (280, 784) (280,)\n",
      "trainset after (290, 784) (290,)\n",
      "updated train set: (290, 784) (290,) unique(labels): [35 22 26 38 27 25 32 40 31 14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59710, 784) (59710,)\n",
      "\n",
      "Train set: (290, 784) y: (290,)\n",
      "Val   set: (59710, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 29\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.212 s \n",
      "\n",
      "Accuracy rate for 72.790000 \n",
      "Classification report for classifier LogisticRegression(C=0.1724137931034483, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       980\n",
      "           1       0.71      0.97      0.82      1135\n",
      "           2       0.82      0.64      0.72      1032\n",
      "           3       0.61      0.83      0.70      1010\n",
      "           4       0.77      0.74      0.76       982\n",
      "           5       0.65      0.33      0.43       892\n",
      "           6       0.72      0.88      0.79       958\n",
      "           7       0.82      0.76      0.79      1028\n",
      "           8       0.67      0.56      0.61       974\n",
      "           9       0.70      0.66      0.68      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.73      0.72      0.71     10000\n",
      "weighted avg       0.73      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 828    2    4   23    2   13   79    1   21    7]\n",
      " [   0 1104   11    4    2    1    7    1    5    0]\n",
      " [  61  137  663   33   31    1   60   23   20    3]\n",
      " [   9   31   21  834    2   14   27   25   40    7]\n",
      " [  10   25    6    3  728   38   32    2   30  108]\n",
      " [  16   29   19  274   20  291   68   34   73   68]\n",
      " [  27   13   13    3   34    5  845    1   17    0]\n",
      " [  18   66   44    9   30   15    7  779   12   48]\n",
      " [   9  117   22  153    8   23   39   12  544   47]\n",
      " [  15   30    2   23   87   49   15   70   55  663]]\n",
      "--------------------------------\n",
      "val predicted: (59710,) ['3' '0' '4' ... '8' '3' '5']\n",
      "probabilities: (59710, 10) \n",
      " [3 0 4 ... 8 3 5]\n",
      "trainset before (290, 784) (290,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [35 22 29 38 29 26 33 42 31 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 30\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.164 s \n",
      "\n",
      "Accuracy rate for 73.230000 \n",
      "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       980\n",
      "           1       0.74      0.98      0.84      1135\n",
      "           2       0.84      0.65      0.73      1032\n",
      "           3       0.64      0.82      0.71      1010\n",
      "           4       0.77      0.73      0.75       982\n",
      "           5       0.79      0.29      0.43       892\n",
      "           6       0.74      0.88      0.81       958\n",
      "           7       0.87      0.72      0.79      1028\n",
      "           8       0.68      0.56      0.62       974\n",
      "           9       0.59      0.76      0.67      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.75      0.72      0.72     10000\n",
      "weighted avg       0.75      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 848    1    6   13    5    7   64    1   20   15]\n",
      " [   0 1110    7    3    0    0    6    3    6    0]\n",
      " [  72  111  669   30   33    1   53   26   22   15]\n",
      " [  12   24   38  825    2    4   17   18   39   31]\n",
      " [  13   28    1    4  715   17   34    0   19  151]\n",
      " [  20   26    9  256   29  261   62   26   81  122]\n",
      " [  39   12   13    1   21    2  841    1   27    1]\n",
      " [  22   67   31    9   32    5    6  738   10  108]\n",
      " [   9   98   18  137    8   21   37    8  547   91]\n",
      " [  20   27    1   21   88   11   10   31   31  769]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['3' '0' '4' ... '8' '3' '5']\n",
      "probabilities: (59700, 10) \n",
      " [3 0 4 ... 8 3 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (300, 784) (300,)\n",
      "trainset after (310, 784) (310,)\n",
      "updated train set: (310, 784) (310,) unique(labels): [37 23 29 39 30 28 35 43 31 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59690, 784) (59690,)\n",
      "\n",
      "Train set: (310, 784) y: (310,)\n",
      "Val   set: (59690, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 31\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.168 s \n",
      "\n",
      "Accuracy rate for 73.490000 \n",
      "Classification report for classifier LogisticRegression(C=0.16129032258064516, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       980\n",
      "           1       0.74      0.98      0.84      1135\n",
      "           2       0.85      0.59      0.70      1032\n",
      "           3       0.62      0.83      0.71      1010\n",
      "           4       0.78      0.76      0.77       982\n",
      "           5       0.68      0.34      0.45       892\n",
      "           6       0.71      0.88      0.79       958\n",
      "           7       0.82      0.78      0.80      1028\n",
      "           8       0.66      0.59      0.62       974\n",
      "           9       0.70      0.67      0.69      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.73      0.72     10000\n",
      "weighted avg       0.74      0.73      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 835    1    2   24    3   15   71    2   18    9]\n",
      " [   0 1107   10    2    1    1    7    1    6    0]\n",
      " [  67  133  612   50   33    1   74   23   34    5]\n",
      " [   6   29   12  840    2   11   26   28   47    9]\n",
      " [  10   21    5    2  750   32   33    5   28   96]\n",
      " [  18   23   13  266   18  301   70   32   82   69]\n",
      " [  30   13    9    0   26    7  845    1   26    1]\n",
      " [  15   62   41    8   21    8    5  804    7   57]\n",
      " [  10   90   10  149   12   21   48   13  575   46]\n",
      " [  14   27    3   22   91   45    9   66   52  680]]\n",
      "--------------------------------\n",
      "val predicted: (59690,) ['3' '0' '4' ... '8' '3' '5']\n",
      "probabilities: (59690, 10) \n",
      " [3 0 4 ... 8 3 5]\n",
      "trainset before (310, 784) (310,)\n",
      "trainset after (320, 784) (320,)\n",
      "updated train set: (320, 784) (320,) unique(labels): [39 26 29 39 31 28 35 44 34 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59680, 784) (59680,)\n",
      "\n",
      "Train set: (320, 784) y: (320,)\n",
      "Val   set: (59680, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 32\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.192 s \n",
      "\n",
      "Accuracy rate for 73.540000 \n",
      "Classification report for classifier LogisticRegression(C=0.15625, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83       980\n",
      "           1       0.72      0.98      0.83      1135\n",
      "           2       0.84      0.66      0.74      1032\n",
      "           3       0.65      0.80      0.72      1010\n",
      "           4       0.76      0.78      0.77       982\n",
      "           5       0.63      0.35      0.45       892\n",
      "           6       0.72      0.87      0.79       958\n",
      "           7       0.80      0.79      0.79      1028\n",
      "           8       0.66      0.61      0.64       974\n",
      "           9       0.74      0.62      0.67      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.73      0.73      0.72     10000\n",
      "weighted avg       0.74      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 825    1    3   16    4   23   77    2   21    8]\n",
      " [   0 1107   11    3    1    1    5    1    6    0]\n",
      " [  56  120  676   31   29    2   60   28   28    2]\n",
      " [   9   36   23  809    2   16   27   28   51    9]\n",
      " [  12   26    4    2  762   46   25    3   22   80]\n",
      " [  18   26    7  230   23  314   78   42   96   58]\n",
      " [  39   13   14    1   25    8  837    1   20    0]\n",
      " [  14   65   38    6   33   13    6  808   15   30]\n",
      " [   8  110   23  122    8   17   41   15  595   35]\n",
      " [  17   28    1   22  122   57   14   86   41  621]]\n",
      "--------------------------------\n",
      "val predicted: (59680,) ['3' '0' '4' ... '8' '3' '5']\n",
      "probabilities: (59680, 10) \n",
      " [3 0 4 ... 8 3 5]\n",
      "trainset before (320, 784) (320,)\n",
      "trainset after (330, 784) (330,)\n",
      "updated train set: (330, 784) (330,) unique(labels): [40 27 29 39 33 29 38 44 36 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59670, 784) (59670,)\n",
      "\n",
      "Train set: (330, 784) y: (330,)\n",
      "Val   set: (59670, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 33\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.184 s \n",
      "\n",
      "Accuracy rate for 73.630000 \n",
      "Classification report for classifier LogisticRegression(C=0.15151515151515152, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       980\n",
      "           1       0.74      0.96      0.83      1135\n",
      "           2       0.83      0.68      0.75      1032\n",
      "           3       0.62      0.83      0.71      1010\n",
      "           4       0.79      0.74      0.76       982\n",
      "           5       0.71      0.31      0.43       892\n",
      "           6       0.71      0.89      0.79       958\n",
      "           7       0.83      0.79      0.81      1028\n",
      "           8       0.67      0.56      0.61       974\n",
      "           9       0.68      0.69      0.68      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.73      0.72     10000\n",
      "weighted avg       0.74      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 828    1    4   20    5   21   75    4   14    8]\n",
      " [   0 1095   21    3    1    1    7    1    6    0]\n",
      " [  55  103  698   42   28    1   65   24   13    3]\n",
      " [   7   24   22  835    2    7   26   25   51   11]\n",
      " [  11   33    3    5  723   27   27    5   30  118]\n",
      " [  21   29   12  262   17  279   79   34   75   84]\n",
      " [  32   12   13    1   19    6  854    0   20    1]\n",
      " [  12   62   40    8   23    7    8  807    7   54]\n",
      " [   8  100   23  159    7   17   48   10  546   56]\n",
      " [  14   29    1   21   94   27   11   62   52  698]]\n",
      "--------------------------------\n",
      "val predicted: (59670,) ['3' '0' '4' ... '8' '3' '5']\n",
      "probabilities: (59670, 10) \n",
      " [3 0 4 ... 8 3 5]\n",
      "trainset before (330, 784) (330,)\n",
      "trainset after (340, 784) (340,)\n",
      "updated train set: (340, 784) (340,) unique(labels): [41 28 31 40 34 29 40 46 36 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59660, 784) (59660,)\n",
      "\n",
      "Train set: (340, 784) y: (340,)\n",
      "Val   set: (59660, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 34\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.185 s \n",
      "\n",
      "Accuracy rate for 73.410000 \n",
      "Classification report for classifier LogisticRegression(C=0.14705882352941177, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       980\n",
      "           1       0.72      0.97      0.83      1135\n",
      "           2       0.82      0.66      0.73      1032\n",
      "           3       0.63      0.82      0.71      1010\n",
      "           4       0.78      0.75      0.76       982\n",
      "           5       0.69      0.30      0.42       892\n",
      "           6       0.74      0.88      0.80       958\n",
      "           7       0.83      0.77      0.80      1028\n",
      "           8       0.66      0.60      0.63       974\n",
      "           9       0.66      0.69      0.68      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.73      0.72     10000\n",
      "weighted avg       0.74      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 827    1    6   19    3   22   73    1   16   12]\n",
      " [   0 1097   22    2    0    1    6    1    6    0]\n",
      " [  56  127  676   39   29    1   54   29   16    5]\n",
      " [   8   27   26  832    2    6   20   25   52   12]\n",
      " [  10   27    3    5  732   27   25    3   33  117]\n",
      " [  17   29   26  262   21  265   71   36   82   83]\n",
      " [  30   13   10    2   23    6  845    0   28    1]\n",
      " [  12   66   32    9   27    9    4  791    6   72]\n",
      " [   6   98   26  140    7   16   39   10  581   51]\n",
      " [  12   31    1   21   91   29   11   59   59  695]]\n",
      "--------------------------------\n",
      "val predicted: (59660,) ['3' '0' '4' ... '8' '3' '8']\n",
      "probabilities: (59660, 10) \n",
      " [3 0 4 ... 8 3 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (340, 784) (340,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [42 28 34 42 35 30 41 46 36 16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 35\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.187 s \n",
      "\n",
      "Accuracy rate for 73.610000 \n",
      "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85       980\n",
      "           1       0.73      0.95      0.83      1135\n",
      "           2       0.76      0.68      0.72      1032\n",
      "           3       0.62      0.81      0.70      1010\n",
      "           4       0.78      0.79      0.78       982\n",
      "           5       0.72      0.27      0.39       892\n",
      "           6       0.76      0.89      0.81       958\n",
      "           7       0.81      0.78      0.79      1028\n",
      "           8       0.69      0.57      0.63       974\n",
      "           9       0.68      0.69      0.69      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.73      0.72     10000\n",
      "weighted avg       0.74      0.74      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 840    1   20   12    3   21   57    2   16    8]\n",
      " [   0 1083   35    2    1    0    6    2    6    0]\n",
      " [  56  108  703   40   37    1   43   25   12    7]\n",
      " [  10   30   36  815    2    5   21   30   51   10]\n",
      " [  12   21    2    4  774   24   32    2   23   88]\n",
      " [  22   30   30  268   24  242   59   43   74  100]\n",
      " [  27   11   20    1   19    5  848    0   26    1]\n",
      " [   9   65   44    6   26    5    8  798    4   63]\n",
      " [   4  110   31  147   10   13   36   11  560   52]\n",
      " [  14   28    1   22   99   22   13   73   39  698]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['3' '0' '4' ... '8' '3' '8']\n",
      "probabilities: (59650, 10) \n",
      " [3 0 4 ... 8 3 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (360, 784) (360,)\n",
      "updated train set: (360, 784) (360,) unique(labels): [44 28 34 42 37 31 43 47 37 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59640, 784) (59640,)\n",
      "\n",
      "Train set: (360, 784) y: (360,)\n",
      "Val   set: (59640, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 36\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.186 s \n",
      "\n",
      "Accuracy rate for 72.860000 \n",
      "Classification report for classifier LogisticRegression(C=0.1388888888888889, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       980\n",
      "           1       0.72      0.96      0.82      1135\n",
      "           2       0.78      0.67      0.72      1032\n",
      "           3       0.64      0.81      0.71      1010\n",
      "           4       0.77      0.75      0.76       982\n",
      "           5       0.71      0.24      0.36       892\n",
      "           6       0.73      0.87      0.80       958\n",
      "           7       0.80      0.78      0.79      1028\n",
      "           8       0.67      0.60      0.63       974\n",
      "           9       0.67      0.66      0.66      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.73      0.72      0.71     10000\n",
      "weighted avg       0.73      0.73      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 853    1    8   12    2   20   62    2   16    4]\n",
      " [   0 1088   29    3    1    0    5    2    7    0]\n",
      " [  62  120  691   31   34    0   48   30   13    3]\n",
      " [  11   33   32  814    3    5   22   29   46   15]\n",
      " [  13   26    2    5  741   23   39    6   29   98]\n",
      " [  24   29   33  261   19  214   69   44   88  111]\n",
      " [  29   15   19    0   21    6  836    1   30    1]\n",
      " [  15   67   46    8   22    4    4  799   10   53]\n",
      " [   9  112   28  123    8   12   44    6  582   50]\n",
      " [  16   28    1   24  117   17   15   75   48  668]]\n",
      "--------------------------------\n",
      "val predicted: (59640,) ['3' '0' '4' ... '8' '3' '8']\n",
      "probabilities: (59640, 10) \n",
      " [3 0 4 ... 8 3 8]\n",
      "trainset before (360, 784) (360,)\n",
      "trainset after (370, 784) (370,)\n",
      "updated train set: (370, 784) (370,) unique(labels): [46 28 35 44 38 31 44 48 38 18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59630, 784) (59630,)\n",
      "\n",
      "Train set: (370, 784) y: (370,)\n",
      "Val   set: (59630, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 37\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.179 s \n",
      "\n",
      "Accuracy rate for 73.750000 \n",
      "Classification report for classifier LogisticRegression(C=0.13513513513513514, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85       980\n",
      "           1       0.74      0.96      0.84      1135\n",
      "           2       0.81      0.67      0.73      1032\n",
      "           3       0.62      0.82      0.71      1010\n",
      "           4       0.78      0.79      0.78       982\n",
      "           5       0.77      0.25      0.38       892\n",
      "           6       0.67      0.92      0.77       958\n",
      "           7       0.83      0.78      0.81      1028\n",
      "           8       0.74      0.54      0.62       974\n",
      "           9       0.68      0.70      0.69      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.73      0.72     10000\n",
      "weighted avg       0.75      0.74      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 839    1    5   17    3   19   82    3    9    2]\n",
      " [   0 1094   24    3    1    0    6    2    5    0]\n",
      " [  56  106  691   39   25    1   77   22    9    6]\n",
      " [   7   33   26  831    1    3   29   23   36   21]\n",
      " [  11   17    2    5  771   14   55    3   16   88]\n",
      " [  22   28   27  254   19  226  103   40   72  101]\n",
      " [  22    9   10    3   17    4  886    0    7    0]\n",
      " [  13   62   43    5   18    2   10  802    4   69]\n",
      " [   6  111   25  153   10   15   68   10  524   52]\n",
      " [  14   21    2   22  124   10   16   59   30  711]]\n",
      "--------------------------------\n",
      "val predicted: (59630,) ['3' '0' '4' ... '8' '3' '9']\n",
      "probabilities: (59630, 10) \n",
      " [3 0 4 ... 8 3 9]\n",
      "trainset before (370, 784) (370,)\n",
      "trainset after (380, 784) (380,)\n",
      "updated train set: (380, 784) (380,) unique(labels): [46 29 36 45 40 35 44 48 39 18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59620, 784) (59620,)\n",
      "\n",
      "Train set: (380, 784) y: (380,)\n",
      "Val   set: (59620, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 38\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.192 s \n",
      "\n",
      "Accuracy rate for 74.000000 \n",
      "Classification report for classifier LogisticRegression(C=0.13157894736842105, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       980\n",
      "           1       0.73      0.97      0.83      1135\n",
      "           2       0.79      0.66      0.72      1032\n",
      "           3       0.65      0.81      0.72      1010\n",
      "           4       0.71      0.80      0.75       982\n",
      "           5       0.73      0.36      0.48       892\n",
      "           6       0.74      0.86      0.79       958\n",
      "           7       0.84      0.77      0.80      1028\n",
      "           8       0.71      0.59      0.64       974\n",
      "           9       0.71      0.67      0.69      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.73      0.73     10000\n",
      "weighted avg       0.74      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 844    1   16   14    3   18   65    3   14    2]\n",
      " [   0 1099   19    2    1    0    5    2    7    0]\n",
      " [  60  115  683   32   54    2   46   24   11    5]\n",
      " [   6   32   39  818    1   16   21   24   37   16]\n",
      " [   9   23    2    3  781   20   32    2   22   88]\n",
      " [  23   28   30  247   30  317   64   32   71   50]\n",
      " [  35   12   16    1   27    7  820    0   40    0]\n",
      " [  18   67   32    6   27    4    4  789    9   72]\n",
      " [   9  102   28  122   11   36   43    8  573   42]\n",
      " [  14   25    1   23  164   15   10   59   22  676]]\n",
      "--------------------------------\n",
      "val predicted: (59620,) ['3' '0' '4' ... '8' '3' '8']\n",
      "probabilities: (59620, 10) \n",
      " [3 0 4 ... 8 3 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (380, 784) (380,)\n",
      "trainset after (390, 784) (390,)\n",
      "updated train set: (390, 784) (390,) unique(labels): [46 30 37 46 40 36 44 50 40 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59610, 784) (59610,)\n",
      "\n",
      "Train set: (390, 784) y: (390,)\n",
      "Val   set: (59610, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 39\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.198 s \n",
      "\n",
      "Accuracy rate for 74.020000 \n",
      "Classification report for classifier LogisticRegression(C=0.1282051282051282, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       980\n",
      "           1       0.74      0.97      0.84      1135\n",
      "           2       0.77      0.67      0.71      1032\n",
      "           3       0.64      0.80      0.71      1010\n",
      "           4       0.77      0.76      0.76       982\n",
      "           5       0.72      0.32      0.45       892\n",
      "           6       0.72      0.87      0.79       958\n",
      "           7       0.81      0.79      0.80      1028\n",
      "           8       0.68      0.59      0.64       974\n",
      "           9       0.74      0.68      0.71      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.73      0.73     10000\n",
      "weighted avg       0.74      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 847    1   15   11    3   23   62    2   15    1]\n",
      " [   0 1098   20    3    0    0    5    2    7    0]\n",
      " [  66  101  689   34   40    2   60   23   12    5]\n",
      " [   5   37   44  810    3   16   21   27   34   13]\n",
      " [  13   23    2    5  748   24   47    1   42   77]\n",
      " [  23   28   35  239   23  289   61   62   81   51]\n",
      " [  34   12   14    2   20    7  836    0   33    0]\n",
      " [  16   64   39    6   14    0    6  817    7   59]\n",
      " [  10   97   36  124    8   27   45    8  579   40]\n",
      " [  17   27    3   23  115   16   15   66   38  689]]\n",
      "--------------------------------\n",
      "val predicted: (59610,) ['3' '0' '4' ... '8' '3' '8']\n",
      "probabilities: (59610, 10) \n",
      " [3 0 4 ... 8 3 8]\n",
      "trainset before (390, 784) (390,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [47 32 37 47 41 36 47 50 41 22] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 40\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.197 s \n",
      "\n",
      "Accuracy rate for 74.760000 \n",
      "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       980\n",
      "           1       0.72      0.96      0.83      1135\n",
      "           2       0.79      0.67      0.73      1032\n",
      "           3       0.63      0.81      0.71      1010\n",
      "           4       0.77      0.79      0.78       982\n",
      "           5       0.73      0.37      0.49       892\n",
      "           6       0.75      0.88      0.81       958\n",
      "           7       0.80      0.78      0.79      1028\n",
      "           8       0.72      0.59      0.65       974\n",
      "           9       0.78      0.68      0.72      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.74      0.74     10000\n",
      "weighted avg       0.75      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 859    2   11   11    1   23   55    2   15    1]\n",
      " [   0 1094   25    2    0    0    5    2    7    0]\n",
      " [  64  106  694   38   38    2   50   20   14    6]\n",
      " [  10   37   31  817    3   16   20   27   40    9]\n",
      " [  12   33    1   10  774   26   36    2   28   60]\n",
      " [  28   33   30  244   27  330   60   60   60   20]\n",
      " [  33   13   13    3   20   10  839    0   27    0]\n",
      " [  16   64   37    3   19    1    7  806    8   67]\n",
      " [  11  101   34  133    9   26   38   10  578   34]\n",
      " [  18   31    3   27  114   20   12   75   24  685]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['3' '0' '4' ... '8' '3' '8']\n",
      "probabilities: (59600, 10) \n",
      " [3 0 4 ... 8 3 8]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (410, 784) (410,)\n",
      "updated train set: (410, 784) (410,) unique(labels): [48 34 37 47 43 38 47 51 41 24] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59590, 784) (59590,)\n",
      "\n",
      "Train set: (410, 784) y: (410,)\n",
      "Val   set: (59590, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 41\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.201 s \n",
      "\n",
      "Accuracy rate for 74.720000 \n",
      "Classification report for classifier LogisticRegression(C=0.12195121951219512, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       980\n",
      "           1       0.76      0.95      0.85      1135\n",
      "           2       0.74      0.69      0.71      1032\n",
      "           3       0.65      0.81      0.72      1010\n",
      "           4       0.76      0.77      0.77       982\n",
      "           5       0.74      0.37      0.49       892\n",
      "           6       0.73      0.87      0.80       958\n",
      "           7       0.80      0.77      0.79      1028\n",
      "           8       0.72      0.62      0.67       974\n",
      "           9       0.74      0.69      0.72      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.74      0.74     10000\n",
      "weighted avg       0.75      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 845    1   14   13    4   26   59    2   15    1]\n",
      " [   0 1081   36    4    0    0    4    2    8    0]\n",
      " [  64   83  707   44   36    1   53   19   17    8]\n",
      " [   5   28   32  820    3   17   19   26   48   12]\n",
      " [  13   27    2    4  758   29   47    4   27   71]\n",
      " [  19   29   48  222   30  329   56   57   56   46]\n",
      " [  27   10   25    1   20    9  832    0   33    1]\n",
      " [  16   57   48    4   24    3    6  795    9   66]\n",
      " [   8   79   37  127    8   17   44    8  608   38]\n",
      " [  22   26    5   24  110   12   14   78   21  697]]\n",
      "--------------------------------\n",
      "val predicted: (59590,) ['3' '0' '4' ... '8' '3' '5']\n",
      "probabilities: (59590, 10) \n",
      " [3 0 4 ... 8 3 5]\n",
      "trainset before (410, 784) (410,)\n",
      "trainset after (420, 784) (420,)\n",
      "updated train set: (420, 784) (420,) unique(labels): [48 35 39 48 43 38 48 54 42 25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59580, 784) (59580,)\n",
      "\n",
      "Train set: (420, 784) y: (420,)\n",
      "Val   set: (59580, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 42\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.202 s \n",
      "\n",
      "Accuracy rate for 74.530000 \n",
      "Classification report for classifier LogisticRegression(C=0.11904761904761904, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       980\n",
      "           1       0.73      0.96      0.83      1135\n",
      "           2       0.78      0.66      0.72      1032\n",
      "           3       0.66      0.79      0.72      1010\n",
      "           4       0.76      0.75      0.76       982\n",
      "           5       0.75      0.38      0.51       892\n",
      "           6       0.73      0.87      0.80       958\n",
      "           7       0.80      0.78      0.79      1028\n",
      "           8       0.69      0.63      0.66       974\n",
      "           9       0.73      0.69      0.71      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.74      0.73     10000\n",
      "weighted avg       0.75      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 851    2    8    7    5   36   54    1   15    1]\n",
      " [   0 1095   24    2    0    0    5    2    7    0]\n",
      " [  60  105  685   39   33    3   57   24   17    9]\n",
      " [   9   37   43  797    2   15   20   25   48   14]\n",
      " [  12   28    1    8  739   20   44    4   33   93]\n",
      " [  21   32   26  204   29  339   62   65   83   31]\n",
      " [  28   13   16    4   18    7  838    2   32    0]\n",
      " [  20   63   38    8   21    2    6  800    8   62]\n",
      " [   9   90   30  113    8   16   46    8  613   41]\n",
      " [  16   29    3   21  114   12   16   74   28  696]]\n",
      "--------------------------------\n",
      "val predicted: (59580,) ['3' '0' '4' ... '8' '3' '8']\n",
      "probabilities: (59580, 10) \n",
      " [3 0 4 ... 8 3 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (420, 784) (420,)\n",
      "trainset after (430, 784) (430,)\n",
      "updated train set: (430, 784) (430,) unique(labels): [49 38 40 48 45 40 48 55 42 25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59570, 784) (59570,)\n",
      "\n",
      "Train set: (430, 784) y: (430,)\n",
      "Val   set: (59570, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 43\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.206 s \n",
      "\n",
      "Accuracy rate for 74.640000 \n",
      "Classification report for classifier LogisticRegression(C=0.11627906976744186, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       980\n",
      "           1       0.74      0.96      0.84      1135\n",
      "           2       0.79      0.67      0.72      1032\n",
      "           3       0.66      0.80      0.72      1010\n",
      "           4       0.75      0.73      0.74       982\n",
      "           5       0.77      0.39      0.52       892\n",
      "           6       0.74      0.87      0.80       958\n",
      "           7       0.81      0.79      0.80      1028\n",
      "           8       0.71      0.65      0.68       974\n",
      "           9       0.72      0.67      0.69      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.74      0.74     10000\n",
      "weighted avg       0.75      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 853    1   11    9    3   21   59    4   18    1]\n",
      " [   0 1092   25    4    0    0    4    2    8    0]\n",
      " [  62   96  690   44   40    2   56   18   17    7]\n",
      " [   9   31   33  812    2   25   18   20   47   13]\n",
      " [  13   30    1    8  720   21   45    5   34  105]\n",
      " [  31   30   33  213   25  348   53   61   60   38]\n",
      " [  32   13   15    1   16    9  830    0   39    3]\n",
      " [  18   68   34    6   14    0    8  813   12   55]\n",
      " [  11   83   31  112    7   13   39    8  632   38]\n",
      " [  18   29    3   25  137   13   15   70   25  674]]\n",
      "--------------------------------\n",
      "val predicted: (59570,) ['3' '0' '4' ... '8' '3' '5']\n",
      "probabilities: (59570, 10) \n",
      " [3 0 4 ... 8 3 5]\n",
      "trainset before (430, 784) (430,)\n",
      "trainset after (440, 784) (440,)\n",
      "updated train set: (440, 784) (440,) unique(labels): [50 38 41 50 45 42 48 57 43 26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59560, 784) (59560,)\n",
      "\n",
      "Train set: (440, 784) y: (440,)\n",
      "Val   set: (59560, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 44\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.211 s \n",
      "\n",
      "Accuracy rate for 73.820000 \n",
      "Classification report for classifier LogisticRegression(C=0.11363636363636363, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       980\n",
      "           1       0.74      0.96      0.83      1135\n",
      "           2       0.76      0.67      0.72      1032\n",
      "           3       0.64      0.81      0.72      1010\n",
      "           4       0.74      0.74      0.74       982\n",
      "           5       0.78      0.31      0.45       892\n",
      "           6       0.73      0.87      0.79       958\n",
      "           7       0.80      0.80      0.80      1028\n",
      "           8       0.68      0.63      0.65       974\n",
      "           9       0.72      0.66      0.69      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.73      0.72     10000\n",
      "weighted avg       0.74      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 856    1    6    9    4   24   60    4   16    0]\n",
      " [   0 1086   32    4    0    0    4    2    7    0]\n",
      " [  66   93  696   41   43    1   49   21   16    6]\n",
      " [   9   32   41  814    2   16   16   19   47   14]\n",
      " [  13   34    1    8  726   14   45    5   36  100]\n",
      " [  21   32   40  228   28  279   60   73   81   50]\n",
      " [  28   13   20    1   16    8  830    1   37    4]\n",
      " [  23   64   42   11   12    0    4  818   12   42]\n",
      " [  11   81   30  126    9    8   48   10  612   39]\n",
      " [  21   32    3   23  137    9   15   67   37  665]]\n",
      "--------------------------------\n",
      "val predicted: (59560,) ['3' '0' '4' ... '8' '3' '8']\n",
      "probabilities: (59560, 10) \n",
      " [3 0 4 ... 8 3 8]\n",
      "trainset before (440, 784) (440,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [53 40 41 50 45 42 50 59 44 26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 45\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.246 s \n",
      "\n",
      "Accuracy rate for 74.350000 \n",
      "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       980\n",
      "           1       0.74      0.95      0.83      1135\n",
      "           2       0.76      0.68      0.72      1032\n",
      "           3       0.67      0.81      0.73      1010\n",
      "           4       0.75      0.74      0.74       982\n",
      "           5       0.75      0.39      0.51       892\n",
      "           6       0.73      0.87      0.79       958\n",
      "           7       0.80      0.79      0.79      1028\n",
      "           8       0.70      0.64      0.67       974\n",
      "           9       0.74      0.65      0.69      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.74      0.73     10000\n",
      "weighted avg       0.75      0.74      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 852    1    7    6    7   25   57    7   16    2]\n",
      " [   0 1078   39    3    0    0    4    2    9    0]\n",
      " [  65   94  698   38   43    2   50   23   14    5]\n",
      " [   9   34   37  816    2   22   18   18   42   12]\n",
      " [  12   24    2   10  722   21   49    7   39   96]\n",
      " [  20   34   35  209   28  347   59   60   63   37]\n",
      " [  24   13   20    1   17   10  830    1   37    5]\n",
      " [  27   64   45    7   14    1    3  813   11   43]\n",
      " [  12   88   32  110    4   20   45   10  625   28]\n",
      " [  22   31    4   23  125   15   17   80   38  654]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['3' '0' '4' ... '8' '3' '8']\n",
      "probabilities: (59550, 10) \n",
      " [3 0 4 ... 8 3 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (460, 784) (460,)\n",
      "updated train set: (460, 784) (460,) unique(labels): [54 40 41 52 46 45 50 60 45 27] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59540, 784) (59540,)\n",
      "\n",
      "Train set: (460, 784) y: (460,)\n",
      "Val   set: (59540, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 46\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.193 s \n",
      "\n",
      "Accuracy rate for 75.670000 \n",
      "Classification report for classifier LogisticRegression(C=0.10869565217391304, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       980\n",
      "           1       0.75      0.96      0.84      1135\n",
      "           2       0.78      0.68      0.73      1032\n",
      "           3       0.69      0.80      0.74      1010\n",
      "           4       0.78      0.73      0.75       982\n",
      "           5       0.79      0.43      0.56       892\n",
      "           6       0.73      0.88      0.80       958\n",
      "           7       0.83      0.77      0.80      1028\n",
      "           8       0.74      0.64      0.69       974\n",
      "           9       0.70      0.72      0.71      1009\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.75      0.75     10000\n",
      "weighted avg       0.76      0.76      0.75     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 876    1    4    8    2   16   52    3   16    2]\n",
      " [   0 1085   34    2    0    0    5    2    7    0]\n",
      " [  63   92  705   43   31    1   50   19   19    9]\n",
      " [   7   28   39  810    0   31   20   18   37   20]\n",
      " [  13   26    2    6  715   14   51    3   32  120]\n",
      " [  18   32   38  184   27  385   73   54   46   35]\n",
      " [  21   12   17    0   15   10  846    1   32    4]\n",
      " [  21   63   39    3   13    0    6  791   13   79]\n",
      " [  12   83   28  103    8   18   42    7  625   48]\n",
      " [  22   26    3   21  107   12   14   59   16  729]]\n",
      "--------------------------------\n",
      "val predicted: (59540,) ['5' '0' '4' ... '8' '3' '9']\n",
      "probabilities: (59540, 10) \n",
      " [5 0 4 ... 8 3 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (460, 784) (460,)\n",
      "trainset after (470, 784) (470,)\n",
      "updated train set: (470, 784) (470,) unique(labels): [57 41 43 52 47 46 50 61 45 28] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59530, 784) (59530,)\n",
      "\n",
      "Train set: (470, 784) y: (470,)\n",
      "Val   set: (59530, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 47\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.234 s \n",
      "\n",
      "Accuracy rate for 74.160000 \n",
      "Classification report for classifier LogisticRegression(C=0.10638297872340426, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       980\n",
      "           1       0.74      0.96      0.83      1135\n",
      "           2       0.78      0.67      0.72      1032\n",
      "           3       0.66      0.79      0.72      1010\n",
      "           4       0.74      0.75      0.75       982\n",
      "           5       0.74      0.40      0.52       892\n",
      "           6       0.73      0.86      0.79       958\n",
      "           7       0.79      0.78      0.78      1028\n",
      "           8       0.71      0.61      0.66       974\n",
      "           9       0.73      0.64      0.68      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.74      0.73     10000\n",
      "weighted avg       0.74      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 864    1    7    8    2   21   53    6   15    3]\n",
      " [   0 1092   24    4    0    0    4    2    9    0]\n",
      " [  64   99  692   38   34    2   60   23   15    5]\n",
      " [   8   32   46  802    3   24   18   20   39   18]\n",
      " [  12   27    1    7  741   27   46    3   37   81]\n",
      " [  22   32   31  211   35  353   58   63   55   32]\n",
      " [  26   14   16    0   21   14  827    1   38    1]\n",
      " [  23   66   38    6   14    0    4  799   14   64]\n",
      " [  13   92   27  119    9   21   46    9  599   39]\n",
      " [  21   29    4   24  145   15   15   85   24  647]]\n",
      "--------------------------------\n",
      "val predicted: (59530,) ['3' '0' '4' ... '8' '3' '5']\n",
      "probabilities: (59530, 10) \n",
      " [3 0 4 ... 8 3 5]\n",
      "trainset before (470, 784) (470,)\n",
      "trainset after (480, 784) (480,)\n",
      "updated train set: (480, 784) (480,) unique(labels): [58 42 44 54 48 48 50 61 47 28] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59520, 784) (59520,)\n",
      "\n",
      "Train set: (480, 784) y: (480,)\n",
      "Val   set: (59520, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 48\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.197 s \n",
      "\n",
      "Accuracy rate for 75.700000 \n",
      "Classification report for classifier LogisticRegression(C=0.10416666666666667, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       980\n",
      "           1       0.74      0.96      0.84      1135\n",
      "           2       0.77      0.70      0.73      1032\n",
      "           3       0.67      0.80      0.73      1010\n",
      "           4       0.76      0.77      0.76       982\n",
      "           5       0.79      0.42      0.55       892\n",
      "           6       0.74      0.88      0.81       958\n",
      "           7       0.80      0.81      0.80      1028\n",
      "           8       0.71      0.65      0.68       974\n",
      "           9       0.78      0.64      0.70      1009\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.75      0.75     10000\n",
      "weighted avg       0.76      0.76      0.75     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 881    1    7    7    0   16   45    5   16    2]\n",
      " [   0 1085   32    3    0    0    5    2    8    0]\n",
      " [  52   95  718   39   33    3   52   22   13    5]\n",
      " [   8   25   50  805    1   18   17   20   53   13]\n",
      " [   9   29    1    8  758   23   43    7   33   71]\n",
      " [  19   32   36  205   24  375   63   59   58   21]\n",
      " [  25   14   17    1   16   10  843    1   31    0]\n",
      " [  19   67   39    5   15    0    5  829   10   39]\n",
      " [   9   83   28  106    9   22   46   10  629   32]\n",
      " [  20   29    3   24  146    9   14   83   34  647]]\n",
      "--------------------------------\n",
      "val predicted: (59520,) ['3' '0' '4' ... '8' '3' '5']\n",
      "probabilities: (59520, 10) \n",
      " [3 0 4 ... 8 3 5]\n",
      "trainset before (480, 784) (480,)\n",
      "trainset after (490, 784) (490,)\n",
      "updated train set: (490, 784) (490,) unique(labels): [60 44 45 55 48 48 51 62 48 29] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59510, 784) (59510,)\n",
      "\n",
      "Train set: (490, 784) y: (490,)\n",
      "Val   set: (59510, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 49\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.202 s \n",
      "\n",
      "Accuracy rate for 75.180000 \n",
      "Classification report for classifier LogisticRegression(C=0.10204081632653061, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       980\n",
      "           1       0.73      0.97      0.83      1135\n",
      "           2       0.77      0.70      0.73      1032\n",
      "           3       0.68      0.79      0.73      1010\n",
      "           4       0.74      0.76      0.75       982\n",
      "           5       0.76      0.40      0.53       892\n",
      "           6       0.76      0.87      0.81       958\n",
      "           7       0.81      0.79      0.80      1028\n",
      "           8       0.70      0.63      0.66       974\n",
      "           9       0.75      0.64      0.69      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.75      0.74     10000\n",
      "weighted avg       0.75      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 883    2    4    7    2   17   46    1   14    4]\n",
      " [   0 1099   19    3    0    0    5    2    7    0]\n",
      " [  54  102  727   30   28    2   48   16   18    7]\n",
      " [   8   32   53  800    1   18   20   22   43   13]\n",
      " [   7   32    2    7  744   23   43    3   32   89]\n",
      " [  18   30   47  201   32  361   52   52   76   23]\n",
      " [  23   14   20    2   19   11  835    1   33    0]\n",
      " [  21   67   43    4   17    0    4  813   11   48]\n",
      " [  12   95   28  104    9   33   38    9  614   32]\n",
      " [  14   30    5   25  151   13   14   82   33  642]]\n",
      "--------------------------------\n",
      "val predicted: (59510,) ['3' '0' '4' ... '8' '3' '8']\n",
      "probabilities: (59510, 10) \n",
      " [3 0 4 ... 8 3 8]\n",
      "trainset before (490, 784) (490,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [61 46 45 55 49 49 51 62 49 33] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 50\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.222 s \n",
      "\n",
      "Accuracy rate for 74.300000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       980\n",
      "           1       0.73      0.97      0.83      1135\n",
      "           2       0.78      0.66      0.71      1032\n",
      "           3       0.67      0.79      0.72      1010\n",
      "           4       0.73      0.77      0.75       982\n",
      "           5       0.75      0.40      0.52       892\n",
      "           6       0.76      0.86      0.80       958\n",
      "           7       0.77      0.81      0.79      1028\n",
      "           8       0.68      0.64      0.66       974\n",
      "           9       0.77      0.58      0.66      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.74      0.73     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 879    2    5    8    1   19   39   12   14    1]\n",
      " [   0 1101   16    4    0    0    4    2    8    0]\n",
      " [  58  108  683   36   36    3   56   31   18    3]\n",
      " [   8   36   49  801    2   18   17   24   46    9]\n",
      " [  12   33    1    6  757   24   49    6   36   58]\n",
      " [  19   32   43  204   28  353   47   57   71   38]\n",
      " [  23   15   18    2   25   12  822    1   39    1]\n",
      " [  26   66   37    4   16    0    3  829   11   36]\n",
      " [  12   91   24  111    9   26   38   10  619   34]\n",
      " [  22   32    3   25  159   14   13  110   45  586]]\n",
      "--------------------------------\n",
      "final active learning accuracies [37.63, 50.61, 57.879999999999995, 60.150000000000006, 67.54, 65.03, 65.52, 69.19999999999999, 68.75, 67.02, 67.78999999999999, 68.7, 69.16, 70.19999999999999, 70.43, 69.94, 69.69999999999999, 69.97, 70.09, 70.95, 71.43, 72.78999999999999, 72.33000000000001, 72.78, 72.63, 72.95, 73.83, 74.38, 72.78999999999999, 73.22999999999999, 73.49, 73.54, 73.63, 73.41, 73.61, 72.86, 73.75, 74.0, 74.02, 74.76, 74.72, 74.53, 74.64, 73.82, 74.35000000000001, 75.67, 74.16, 75.7, 75.18, 74.3]\n",
      "saved Active-learning-experiment-35.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "{\n",
      "  \"LogModel\": {\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          37.63,\n",
      "          50.61,\n",
      "          57.879999999999995,\n",
      "          60.150000000000006,\n",
      "          67.54,\n",
      "          65.03,\n",
      "          65.52,\n",
      "          69.19999999999999,\n",
      "          68.75,\n",
      "          67.02,\n",
      "          67.78999999999999,\n",
      "          68.7,\n",
      "          69.16,\n",
      "          70.19999999999999,\n",
      "          70.43,\n",
      "          69.94,\n",
      "          69.69999999999999,\n",
      "          69.97,\n",
      "          70.09,\n",
      "          70.95,\n",
      "          71.43,\n",
      "          72.78999999999999,\n",
      "          72.33000000000001,\n",
      "          72.78,\n",
      "          72.63,\n",
      "          72.95,\n",
      "          73.83,\n",
      "          74.38,\n",
      "          72.78999999999999,\n",
      "          73.22999999999999,\n",
      "          73.49,\n",
      "          73.54,\n",
      "          73.63,\n",
      "          73.41,\n",
      "          73.61,\n",
      "          72.86,\n",
      "          73.75,\n",
      "          74.0,\n",
      "          74.02,\n",
      "          74.76,\n",
      "          74.72,\n",
      "          74.53,\n",
      "          74.64,\n",
      "          73.82,\n",
      "          74.35000000000001,\n",
      "          75.67,\n",
      "          74.16,\n",
      "          75.7,\n",
      "          75.18,\n",
      "          74.3\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          72.86,\n",
      "          72.11999999999999,\n",
      "          70.67999999999999,\n",
      "          71.37\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          54.279999999999994,\n",
      "          58.24,\n",
      "          61.839999999999996,\n",
      "          68.43,\n",
      "          68.44,\n",
      "          71.43,\n",
      "          74.02,\n",
      "          73.87,\n",
      "          73.4,\n",
      "          74.36,\n",
      "          75.39,\n",
      "          74.62,\n",
      "          74.85000000000001,\n",
      "          75.22999999999999,\n",
      "          73.8,\n",
      "          74.85000000000001,\n",
      "          75.14999999999999,\n",
      "          74.63,\n",
      "          74.16,\n",
      "          73.91\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          74.59,\n",
      "          75.29\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          61.739999999999995,\n",
      "          69.95,\n",
      "          75.09,\n",
      "          73.91,\n",
      "          74.17,\n",
      "          74.21,\n",
      "          74.19,\n",
      "          73.74000000000001,\n",
      "          73.92,\n",
      "          74.62\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"RfModel\": {\n",
      "    \"EntropySelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          22.34,\n",
      "          27.01,\n",
      "          32.07,\n",
      "          35.160000000000004,\n",
      "          47.72,\n",
      "          47.97,\n",
      "          52.400000000000006,\n",
      "          51.09,\n",
      "          54.459999999999994,\n",
      "          57.92,\n",
      "          57.489999999999995,\n",
      "          57.269999999999996,\n",
      "          56.65,\n",
      "          56.42,\n",
      "          56.47,\n",
      "          54.620000000000005,\n",
      "          55.11000000000001,\n",
      "          55.05,\n",
      "          55.13,\n",
      "          55.45,\n",
      "          53.769999999999996,\n",
      "          53.33,\n",
      "          53.690000000000005,\n",
      "          53.76,\n",
      "          54.55,\n",
      "          54.96,\n",
      "          55.120000000000005,\n",
      "          53.83,\n",
      "          55.1,\n",
      "          54.71,\n",
      "          55.510000000000005,\n",
      "          56.39999999999999,\n",
      "          55.379999999999995,\n",
      "          56.92,\n",
      "          55.85,\n",
      "          56.699999999999996,\n",
      "          56.21000000000001,\n",
      "          56.379999999999995,\n",
      "          57.31,\n",
      "          56.120000000000005,\n",
      "          56.44,\n",
      "          57.31,\n",
      "          58.47,\n",
      "          55.82,\n",
      "          57.37,\n",
      "          58.60999999999999,\n",
      "          58.85,\n",
      "          57.86,\n",
      "          57.36,\n",
      "          58.18\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          73.8,\n",
      "          73.65,\n",
      "          74.14,\n",
      "          74.59\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          49.919999999999995,\n",
      "          57.489999999999995,\n",
      "          63.129999999999995,\n",
      "          65.53,\n",
      "          69.39999999999999,\n",
      "          69.73,\n",
      "          69.32000000000001,\n",
      "          66.67999999999999,\n",
      "          67.25,\n",
      "          66.97999999999999,\n",
      "          66.36999999999999,\n",
      "          68.22,\n",
      "          66.18,\n",
      "          67.42,\n",
      "          67.67999999999999,\n",
      "          67.64,\n",
      "          70.99,\n",
      "          70.59,\n",
      "          70.81,\n",
      "          72.48\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          82.87,\n",
      "          81.83\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          58.25,\n",
      "          65.07,\n",
      "          65.14,\n",
      "          65.88000000000001,\n",
      "          64.94,\n",
      "          65.42999999999999,\n",
      "          66.64,\n",
      "          69.8,\n",
      "          69.13,\n",
      "          69.86\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          26.56,\n",
      "          45.550000000000004,\n",
      "          56.82000000000001,\n",
      "          67.99,\n",
      "          67.67999999999999,\n",
      "          71.17,\n",
      "          76.08,\n",
      "          78.13,\n",
      "          79.38,\n",
      "          79.69000000000001,\n",
      "          81.76,\n",
      "          82.43,\n",
      "          83.47,\n",
      "          84.99,\n",
      "          85.18,\n",
      "          86.0,\n",
      "          84.94,\n",
      "          86.07000000000001,\n",
      "          86.98,\n",
      "          86.56,\n",
      "          88.03,\n",
      "          87.92999999999999,\n",
      "          88.53,\n",
      "          89.2,\n",
      "          89.2,\n",
      "          89.71000000000001,\n",
      "          90.12,\n",
      "          90.57,\n",
      "          90.24,\n",
      "          90.49000000000001,\n",
      "          90.61,\n",
      "          91.09,\n",
      "          91.3,\n",
      "          91.07,\n",
      "          90.93,\n",
      "          91.17,\n",
      "          90.96,\n",
      "          91.38,\n",
      "          90.84,\n",
      "          91.72,\n",
      "          91.47,\n",
      "          91.56,\n",
      "          92.01,\n",
      "          91.94,\n",
      "          92.43,\n",
      "          92.43,\n",
      "          92.58999999999999,\n",
      "          92.56,\n",
      "          92.97999999999999,\n",
      "          92.80000000000001\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          73.39,\n",
      "          86.38,\n",
      "          90.11,\n",
      "          91.31\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          53.339999999999996,\n",
      "          63.85999999999999,\n",
      "          70.77,\n",
      "          75.53999999999999,\n",
      "          79.22,\n",
      "          83.19,\n",
      "          83.17999999999999,\n",
      "          84.82,\n",
      "          86.21,\n",
      "          86.72999999999999,\n",
      "          88.18,\n",
      "          89.2,\n",
      "          88.47,\n",
      "          89.64999999999999,\n",
      "          90.2,\n",
      "          90.68,\n",
      "          91.56,\n",
      "          91.64,\n",
      "          92.10000000000001,\n",
      "          92.30000000000001\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          80.64,\n",
      "          89.2\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          57.74,\n",
      "          75.92,\n",
      "          80.57,\n",
      "          86.13,\n",
      "          88.26,\n",
      "          88.62,\n",
      "          89.88000000000001,\n",
      "          90.93,\n",
      "          91.02,\n",
      "          92.17\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          28.470000000000002,\n",
      "          35.38,\n",
      "          44.85,\n",
      "          50.71,\n",
      "          58.48,\n",
      "          61.3,\n",
      "          63.739999999999995,\n",
      "          65.48,\n",
      "          70.15,\n",
      "          71.58,\n",
      "          74.52,\n",
      "          75.67,\n",
      "          77.11,\n",
      "          77.31,\n",
      "          77.44,\n",
      "          77.61,\n",
      "          78.07,\n",
      "          78.64,\n",
      "          78.99000000000001,\n",
      "          79.33,\n",
      "          79.99000000000001,\n",
      "          80.12,\n",
      "          82.24000000000001,\n",
      "          81.91000000000001,\n",
      "          82.74000000000001,\n",
      "          82.82000000000001,\n",
      "          83.21,\n",
      "          83.71,\n",
      "          83.38,\n",
      "          84.19,\n",
      "          84.61,\n",
      "          84.65,\n",
      "          84.7,\n",
      "          84.99,\n",
      "          85.13,\n",
      "          85.2,\n",
      "          85.72999999999999,\n",
      "          86.18,\n",
      "          86.25,\n",
      "          86.08,\n",
      "          85.76,\n",
      "          85.92999999999999,\n",
      "          86.33,\n",
      "          86.52,\n",
      "          86.94,\n",
      "          87.24,\n",
      "          87.26,\n",
      "          87.85,\n",
      "          87.91,\n",
      "          87.52\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          75.48,\n",
      "          83.13000000000001,\n",
      "          85.79,\n",
      "          87.78\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          35.36,\n",
      "          60.41,\n",
      "          67.99,\n",
      "          74.92,\n",
      "          78.18,\n",
      "          80.60000000000001,\n",
      "          81.69999999999999,\n",
      "          81.97,\n",
      "          82.43,\n",
      "          83.53,\n",
      "          84.89999999999999,\n",
      "          84.94,\n",
      "          85.24000000000001,\n",
      "          85.81,\n",
      "          85.96000000000001,\n",
      "          86.8,\n",
      "          87.25,\n",
      "          87.81,\n",
      "          87.9,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          79.44,\n",
      "          87.52\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          58.269999999999996,\n",
      "          71.76,\n",
      "          79.64,\n",
      "          82.54,\n",
      "          83.82,\n",
      "          83.98,\n",
      "          84.63000000000001,\n",
      "          84.89,\n",
      "          85.77,\n",
      "          86.59\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"SvmModel\": {\n",
      "    \"EntropySelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          34.22,\n",
      "          36.5,\n",
      "          41.5,\n",
      "          41.699999999999996,\n",
      "          43.05,\n",
      "          46.93,\n",
      "          50.62,\n",
      "          51.129999999999995,\n",
      "          55.74,\n",
      "          57.089999999999996,\n",
      "          56.84,\n",
      "          61.22,\n",
      "          62.029999999999994,\n",
      "          62.83,\n",
      "          62.029999999999994,\n",
      "          62.21,\n",
      "          63.28,\n",
      "          63.54,\n",
      "          65.23,\n",
      "          66.36999999999999,\n",
      "          68.42,\n",
      "          69.95,\n",
      "          69.55,\n",
      "          69.82000000000001,\n",
      "          74.8,\n",
      "          75.44,\n",
      "          74.92999999999999,\n",
      "          76.36,\n",
      "          77.23,\n",
      "          76.91,\n",
      "          75.79,\n",
      "          77.34,\n",
      "          77.81,\n",
      "          78.97,\n",
      "          80.16,\n",
      "          79.45,\n",
      "          79.65,\n",
      "          79.33,\n",
      "          79.41,\n",
      "          79.31,\n",
      "          78.95,\n",
      "          79.33,\n",
      "          78.78,\n",
      "          79.05,\n",
      "          79.11,\n",
      "          79.63,\n",
      "          79.60000000000001,\n",
      "          79.73,\n",
      "          80.13,\n",
      "          80.13\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.17,\n",
      "          79.14999999999999,\n",
      "          79.42,\n",
      "          80.08\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          52.65,\n",
      "          55.769999999999996,\n",
      "          58.5,\n",
      "          67.9,\n",
      "          68.63,\n",
      "          72.32,\n",
      "          72.37,\n",
      "          72.08,\n",
      "          72.49,\n",
      "          71.94,\n",
      "          73.11,\n",
      "          75.18,\n",
      "          76.25,\n",
      "          75.6,\n",
      "          76.79,\n",
      "          77.42999999999999,\n",
      "          77.56,\n",
      "          77.45,\n",
      "          78.3,\n",
      "          78.86\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.73,\n",
      "          84.64\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          68.25,\n",
      "          69.56,\n",
      "          71.76,\n",
      "          70.64,\n",
      "          70.59,\n",
      "          74.49,\n",
      "          76.31,\n",
      "          78.17,\n",
      "          77.95,\n",
      "          78.78\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          24.41,\n",
      "          39.12,\n",
      "          51.55,\n",
      "          58.15,\n",
      "          64.19,\n",
      "          67.33,\n",
      "          72.46000000000001,\n",
      "          73.94,\n",
      "          78.06,\n",
      "          78.57,\n",
      "          79.01,\n",
      "          78.68,\n",
      "          79.80000000000001,\n",
      "          80.78999999999999,\n",
      "          81.54,\n",
      "          82.21000000000001,\n",
      "          82.08,\n",
      "          83.17999999999999,\n",
      "          83.36,\n",
      "          83.13000000000001,\n",
      "          82.5,\n",
      "          83.24000000000001,\n",
      "          84.03,\n",
      "          84.84,\n",
      "          85.2,\n",
      "          85.17,\n",
      "          85.24000000000001,\n",
      "          85.1,\n",
      "          85.33,\n",
      "          85.00999999999999,\n",
      "          85.57000000000001,\n",
      "          85.91,\n",
      "          85.91,\n",
      "          86.4,\n",
      "          86.53999999999999,\n",
      "          86.78,\n",
      "          87.02,\n",
      "          87.18,\n",
      "          87.41,\n",
      "          87.33,\n",
      "          87.72,\n",
      "          87.8,\n",
      "          87.9,\n",
      "          88.1,\n",
      "          88.41,\n",
      "          88.22,\n",
      "          88.42999999999999,\n",
      "          88.38000000000001,\n",
      "          88.31,\n",
      "          88.6\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          76.8,\n",
      "          83.96000000000001,\n",
      "          87.08,\n",
      "          88.94\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          48.209999999999994,\n",
      "          59.870000000000005,\n",
      "          70.07,\n",
      "          73.88,\n",
      "          79.62,\n",
      "          80.99,\n",
      "          82.69999999999999,\n",
      "          83.2,\n",
      "          84.13000000000001,\n",
      "          84.61999999999999,\n",
      "          85.53,\n",
      "          86.32,\n",
      "          86.46000000000001,\n",
      "          87.16000000000001,\n",
      "          87.74,\n",
      "          87.87,\n",
      "          88.16000000000001,\n",
      "          88.24,\n",
      "          88.42,\n",
      "          88.13\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          82.87,\n",
      "          87.59\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          59.74,\n",
      "          70.57,\n",
      "          79.12,\n",
      "          83.25,\n",
      "          84.19,\n",
      "          86.44,\n",
      "          87.3,\n",
      "          87.81,\n",
      "          87.58,\n",
      "          88.63\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          30.12,\n",
      "          41.54,\n",
      "          51.15,\n",
      "          59.5,\n",
      "          64.64999999999999,\n",
      "          65.02,\n",
      "          66.7,\n",
      "          68.81,\n",
      "          70.28,\n",
      "          73.48,\n",
      "          73.83,\n",
      "          76.64,\n",
      "          76.83,\n",
      "          77.68,\n",
      "          77.38000000000001,\n",
      "          77.77,\n",
      "          79.17,\n",
      "          79.59,\n",
      "          80.86,\n",
      "          80.89,\n",
      "          81.24,\n",
      "          81.47999999999999,\n",
      "          82.23,\n",
      "          82.8,\n",
      "          82.96,\n",
      "          83.00999999999999,\n",
      "          83.64,\n",
      "          83.72,\n",
      "          83.35000000000001,\n",
      "          83.41,\n",
      "          83.69,\n",
      "          83.67999999999999,\n",
      "          84.23,\n",
      "          84.26,\n",
      "          84.48,\n",
      "          84.98,\n",
      "          85.38,\n",
      "          85.39,\n",
      "          85.63,\n",
      "          85.74000000000001,\n",
      "          86.17,\n",
      "          86.28,\n",
      "          86.38,\n",
      "          86.57000000000001,\n",
      "          86.42,\n",
      "          86.56,\n",
      "          86.38,\n",
      "          86.37,\n",
      "          86.44,\n",
      "          86.53999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.53999999999999,\n",
      "          80.67,\n",
      "          84.16,\n",
      "          86.61999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          55.489999999999995,\n",
      "          64.21,\n",
      "          71.63000000000001,\n",
      "          74.95,\n",
      "          76.49000000000001,\n",
      "          80.08999999999999,\n",
      "          82.11,\n",
      "          82.25,\n",
      "          82.65,\n",
      "          83.3,\n",
      "          84.02,\n",
      "          85.05,\n",
      "          85.15,\n",
      "          85.67,\n",
      "          86.18,\n",
      "          86.83999999999999,\n",
      "          87.41,\n",
      "          87.63,\n",
      "          87.82,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.15,\n",
      "          86.91\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          67.52,\n",
      "          75.52,\n",
      "          80.19,\n",
      "          84.26,\n",
      "          85.77,\n",
      "          86.16,\n",
      "          86.58,\n",
      "          86.65,\n",
      "          87.18,\n",
      "          87.09\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 36, using model = LogModel, selection_function = MarginSamplingSelection, k = 250, iteration = 0.\n",
      "\n",
      "initial random chosen samples (250,)\n",
      "initial train set: (250, 784) (250,) unique(labels): [23 22 26 27 24 24 17 35 29 23] [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59750, 784) (59750,) (250,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.156 s \n",
      "\n",
      "Accuracy rate for 70.020000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       980\n",
      "           1       0.73      0.98      0.83      1135\n",
      "           2       0.66      0.72      0.69      1032\n",
      "           3       0.75      0.69      0.72      1010\n",
      "           4       0.61      0.80      0.69       982\n",
      "           5       0.75      0.46      0.57       892\n",
      "           6       0.73      0.74      0.74       958\n",
      "           7       0.75      0.85      0.80      1028\n",
      "           8       0.56      0.64      0.60       974\n",
      "           9       0.75      0.21      0.33      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.69      0.68     10000\n",
      "weighted avg       0.71      0.70      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 840    2   39    5    2   10   61   15    6    0]\n",
      " [   0 1108   18    4    0    1    3    0    1    0]\n",
      " [  72   84  748    5   49    5   13   23   26    7]\n",
      " [  20   30   59  697    2   34    8   29  122    9]\n",
      " [   8   37    5    7  785    1   68    8   47   16]\n",
      " [  34   62   41   86   26  412   50   93   83    5]\n",
      " [  44   29  111    6   35    8  710    6    9    0]\n",
      " [   7   68   19   15   14    0    1  869   12   23]\n",
      " [   8   74   83   66    7   47   44   13  621   11]\n",
      " [  10   32   11   43  376   28   15   96  186  212]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '6']\n",
      "probabilities: (59750, 10) \n",
      " [5 0 4 ... 5 6 6]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [35 24 46 57 44 70 34 51 61 78] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.181 s \n",
      "\n",
      "Accuracy rate for 73.280000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85       980\n",
      "           1       0.65      0.99      0.79      1135\n",
      "           2       0.83      0.58      0.68      1032\n",
      "           3       0.69      0.69      0.69      1010\n",
      "           4       0.78      0.77      0.78       982\n",
      "           5       0.90      0.35      0.50       892\n",
      "           6       0.69      0.91      0.78       958\n",
      "           7       0.77      0.80      0.79      1028\n",
      "           8       0.76      0.57      0.65       974\n",
      "           9       0.68      0.66      0.67      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.75      0.73      0.72     10000\n",
      "weighted avg       0.75      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 924    4    5    0    1    2   31   10    3    0]\n",
      " [   0 1121    0    1    0    1    5    2    5    0]\n",
      " [  38  164  596    8   18    0  128   26   39   15]\n",
      " [  62  102   47  699    1    9   16   21   16   37]\n",
      " [   2   28    1    5  761    4   68   12   25   76]\n",
      " [  96   57   19  170   42  310   58   46   35   59]\n",
      " [  23   17   13    0   12    6  876    5    6    0]\n",
      " [  15   62    8    4   13    0    5  819   23   79]\n",
      " [  12  132   25  111   12    6   62    6  557   51]\n",
      " [  10   34    0   17  116    6   26  110   25  665]]\n",
      "--------------------------------\n",
      "final active learning accuracies [70.02000000000001, 73.28]\n",
      "saved Active-learning-experiment-36.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'README.md', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 37, using model = LogModel, selection_function = MarginSamplingSelection, k = 125, iteration = 0.\n",
      "\n",
      "initial random chosen samples (125,)\n",
      "initial train set: (125, 784) (125,) unique(labels): [19 17  9 16  8  7 13 12 11 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,) (125,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.131 s \n",
      "\n",
      "Accuracy rate for 73.470000 \n",
      "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80       980\n",
      "           1       0.76      0.97      0.85      1135\n",
      "           2       0.74      0.69      0.72      1032\n",
      "           3       0.62      0.82      0.71      1010\n",
      "           4       0.72      0.72      0.72       982\n",
      "           5       0.81      0.43      0.57       892\n",
      "           6       0.78      0.79      0.79       958\n",
      "           7       0.83      0.77      0.80      1028\n",
      "           8       0.72      0.50      0.59       974\n",
      "           9       0.69      0.70      0.70      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.73      0.72     10000\n",
      "weighted avg       0.74      0.73      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 865    2   64    6    1   15   16    7    4    0]\n",
      " [   0 1102    0   13    1    0    4    1   14    0]\n",
      " [  58   80  713   24   22    6   34   38   50    7]\n",
      " [  44   16   30  829    5    5    7   21   36   17]\n",
      " [  34   38    3    2  709    0   46    9   15  126]\n",
      " [  65   52   15  174   36  387   76   11   26   50]\n",
      " [  41   13   76    9   39   13  761    3    3    0]\n",
      " [  29   63   16   10   23    2    2  789   25   69]\n",
      " [  16   53   27  250   23   42   24   10  486   43]\n",
      " [  33   33   15   17  121    6    5   60   13  706]]\n",
      "--------------------------------\n",
      "val predicted: (59875,) ['5' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59875, 10) \n",
      " [5 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (125, 784) (125,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [25 19 23 35 19 29 20 23 26 31] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.162 s \n",
      "\n",
      "Accuracy rate for 71.320000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.83       980\n",
      "           1       0.72      0.99      0.83      1135\n",
      "           2       0.82      0.56      0.66      1032\n",
      "           3       0.68      0.71      0.70      1010\n",
      "           4       0.63      0.79      0.70       982\n",
      "           5       0.70      0.32      0.44       892\n",
      "           6       0.74      0.87      0.80       958\n",
      "           7       0.74      0.76      0.75      1028\n",
      "           8       0.61      0.65      0.63       974\n",
      "           9       0.79      0.49      0.61      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.70     10000\n",
      "weighted avg       0.72      0.71      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 919    2    1    2    1   23   22    8    2    0]\n",
      " [   0 1119    1    3    1    3    6    0    2    0]\n",
      " [  85  156  573   19   28    2   62   44   52   11]\n",
      " [  43   36   20  716    7   47   11   11  102   17]\n",
      " [  22   27    2    3  772    6   62   43    6   39]\n",
      " [  40   21   11  180   83  288   53   18  184   14]\n",
      " [  48   12   23    4   18   10  835    6    2    0]\n",
      " [  27   79   54    3   32    6    4  777   10   36]\n",
      " [  16   72   12   94   43   14   59   15  636   13]\n",
      " [  28   22    2   23  240   11   20  125   41  497]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '9' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 9 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [28 21 35 50 31 54 23 34 38 61] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.193 s \n",
      "\n",
      "Accuracy rate for 72.050000 \n",
      "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.96      0.81       980\n",
      "           1       0.73      0.98      0.83      1135\n",
      "           2       0.83      0.61      0.70      1032\n",
      "           3       0.61      0.74      0.67      1010\n",
      "           4       0.71      0.82      0.76       982\n",
      "           5       0.85      0.24      0.37       892\n",
      "           6       0.75      0.88      0.81       958\n",
      "           7       0.77      0.73      0.75      1028\n",
      "           8       0.64      0.63      0.64       974\n",
      "           9       0.78      0.54      0.64      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.71      0.70     10000\n",
      "weighted avg       0.74      0.72      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 943    2    5    1    0    4   15    8    2    0]\n",
      " [   0 1108    1    5    0    1    8    1   11    0]\n",
      " [  82  144  630   15   42    0   69   33    9    8]\n",
      " [  58   48   41  744    4    8    8   12   80    7]\n",
      " [  15   32    1    5  808    3   35   13   13   57]\n",
      " [  64   16    5  244   58  214   73   19  172   27]\n",
      " [  40   11   22    9    9   11  843    3   10    0]\n",
      " [ 102   62   34    8   21    1    4  755    6   35]\n",
      " [  18   79   18  135   20    7   52    6  616   23]\n",
      " [  32   23    3   50  169    2   16  132   38  544]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['3' '0' '4' ... '9' '6' '8']\n",
      "probabilities: (59625, 10) \n",
      " [3 0 4 ... 9 6 8]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [29 23 48 63 42 83 25 45 57 85] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.222 s \n",
      "\n",
      "Accuracy rate for 73.020000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80       980\n",
      "           1       0.67      0.99      0.80      1135\n",
      "           2       0.83      0.59      0.69      1032\n",
      "           3       0.65      0.72      0.68      1010\n",
      "           4       0.76      0.78      0.77       982\n",
      "           5       0.80      0.45      0.58       892\n",
      "           6       0.73      0.87      0.79       958\n",
      "           7       0.76      0.75      0.76      1028\n",
      "           8       0.79      0.54      0.64       974\n",
      "           9       0.81      0.58      0.68      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.75      0.72      0.72     10000\n",
      "weighted avg       0.75      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 950    3    4    1    0    1   18    2    1    0]\n",
      " [   0 1120    2    1    0    1    8    2    1    0]\n",
      " [  87  162  608   11   38    0   79   34    5    8]\n",
      " [  76   60   29  731    6   34    8   16   41    9]\n",
      " [  13   29    5   11  770   11   48   21    9   65]\n",
      " [  90   35    5  182   36  404   61   23   53    3]\n",
      " [  39   21   21    6    8   19  837    5    2    0]\n",
      " [  97   62   31    5   25    1    6  774    3   24]\n",
      " [  16  152   20  127   21   17   68    5  524   24]\n",
      " [  27   37   10   52  106   17   20  134   22  584]]\n",
      "--------------------------------\n",
      "final active learning accuracies [73.47, 71.32, 72.05, 73.02]\n",
      "saved Active-learning-experiment-37.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-37.pkl', 'README.md', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 38, using model = LogModel, selection_function = MarginSamplingSelection, k = 50, iteration = 0.\n",
      "\n",
      "initial random chosen samples (50,)\n",
      "initial train set: (50, 784) (50,) unique(labels): [5 9 4 4 6 4 5 5 6 2] [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59950, 784) (59950,) (50,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.122 s \n",
      "\n",
      "Accuracy rate for 63.560000 \n",
      "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.83      0.61       980\n",
      "           1       0.82      0.95      0.88      1135\n",
      "           2       0.56      0.63      0.59      1032\n",
      "           3       0.68      0.63      0.65      1010\n",
      "           4       0.62      0.71      0.66       982\n",
      "           5       0.26      0.12      0.16       892\n",
      "           6       0.77      0.69      0.73       958\n",
      "           7       0.81      0.74      0.77      1028\n",
      "           8       0.61      0.50      0.55       974\n",
      "           9       0.60      0.46      0.52      1009\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.62      0.63      0.61     10000\n",
      "weighted avg       0.63      0.64      0.62     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 813    0   75   42   10    7   20    5    6    2]\n",
      " [   2 1082   36    1    0    3    4    5    2    0]\n",
      " [ 194   44  652   22   39    3   29   33   16    0]\n",
      " [ 156   17   28  632    1   65   26   32   50    3]\n",
      " [  10   26   29    1  699   15   20    9   30  143]\n",
      " [ 282   29   22  169   22  107   65   34  100   62]\n",
      " [  33    3  200    2   55    0  662    1    0    2]\n",
      " [  19   50   33    4   55   26    0  760   11   70]\n",
      " [ 156   53   53   49   13   97   33   11  489   20]\n",
      " [  16   20   41   11  231   83    1   46  100  460]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['3' '0' '4' ... '8' '0' '8']\n",
      "probabilities: (59950, 10) \n",
      " [3 0 4 ... 8 0 8]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 8 10 10  9  7 10  7 14 15 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.132 s \n",
      "\n",
      "Accuracy rate for 68.590000 \n",
      "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.80      0.65       980\n",
      "           1       0.79      0.96      0.86      1135\n",
      "           2       0.63      0.79      0.70      1032\n",
      "           3       0.80      0.53      0.64      1010\n",
      "           4       0.66      0.80      0.72       982\n",
      "           5       0.73      0.22      0.33       892\n",
      "           6       0.80      0.79      0.80       958\n",
      "           7       0.76      0.82      0.79      1028\n",
      "           8       0.58      0.52      0.55       974\n",
      "           9       0.66      0.55      0.60      1009\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.68      0.66     10000\n",
      "weighted avg       0.70      0.69      0.67     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 788    2   86    5   12   27   13   24   22    1]\n",
      " [   0 1084   41    1    0    1    5    3    0    0]\n",
      " [  20   36  815   19   38    0   38   47   16    3]\n",
      " [ 145   15  105  536    1   14   14   27  143   10]\n",
      " [  10   16    2    3  781    1   49    9    5  106]\n",
      " [ 286   54   13   74   24  193   26    8  160   54]\n",
      " [  61    5   83    1   19   13  760   12    3    1]\n",
      " [   8   51   24    1   28    6    2  841    6   61]\n",
      " [ 105   98   99   20    8    3   33   45  511   52]\n",
      " [  14   18   17   13  274    8    8   85   22  550]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '4' ... '8' '6' '8']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 4 ... 8 6 8]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [12 11 10 15 10 24  8 22 24 14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.147 s \n",
      "\n",
      "Accuracy rate for 67.980000 \n",
      "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.90      0.74       980\n",
      "           1       0.78      0.95      0.86      1135\n",
      "           2       0.62      0.74      0.67      1032\n",
      "           3       0.75      0.67      0.70      1010\n",
      "           4       0.59      0.84      0.69       982\n",
      "           5       0.83      0.06      0.12       892\n",
      "           6       0.76      0.76      0.76       958\n",
      "           7       0.77      0.78      0.77      1028\n",
      "           8       0.62      0.55      0.59       974\n",
      "           9       0.60      0.45      0.52      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.69      0.67      0.64     10000\n",
      "weighted avg       0.69      0.68      0.65     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 880    2   36    0    9    1   27    7   10    8]\n",
      " [   0 1078   46    1    0    1    0    8    1    0]\n",
      " [  35   54  759   12   65    0   29   59   19    0]\n",
      " [ 115   20   71  672   11    0   22   22   71    6]\n",
      " [   4   10    8    4  825    3   49   27    4   48]\n",
      " [ 208   47   13  133   52   57   47   13  199  123]\n",
      " [  36    9  137    3   31    0  731    5    4    2]\n",
      " [  30   41   23    4   44    0    2  801    1   82]\n",
      " [  64  104  114   47   22    1   32   14  538   38]\n",
      " [  15   17   21   24  350    6   18   86   15  457]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['3' '0' '4' ... '8' '6' '8']\n",
      "probabilities: (59850, 10) \n",
      " [3 0 4 ... 8 6 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [14 11 15 19 16 37  9 29 29 21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.165 s \n",
      "\n",
      "Accuracy rate for 70.620000 \n",
      "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.94      0.78       980\n",
      "           1       0.77      0.90      0.83      1135\n",
      "           2       0.62      0.77      0.69      1032\n",
      "           3       0.60      0.71      0.65      1010\n",
      "           4       0.73      0.77      0.75       982\n",
      "           5       0.65      0.19      0.29       892\n",
      "           6       0.77      0.86      0.81       958\n",
      "           7       0.77      0.85      0.81      1028\n",
      "           8       0.78      0.44      0.56       974\n",
      "           9       0.74      0.54      0.62      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.70      0.68     10000\n",
      "weighted avg       0.71      0.71      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 924    2   12    2    2    0   25    6    5    2]\n",
      " [   0 1027  100    3    0    1    2    2    0    0]\n",
      " [  62   53  798   14   32    1   38   31    2    1]\n",
      " [  96   29   77  722    1   13   31   20   17    4]\n",
      " [  12   14    4    6  754   25   44   38   10   75]\n",
      " [ 148   40   32  266   35  166   42   31   62   70]\n",
      " [  39    7   63    2   12    1  823    3    6    2]\n",
      " [  27   41   49    2   15    1    4  876    2   11]\n",
      " [  62  109  129  144   14   10   40   13  430   23]\n",
      " [  19   17   16   50  169   37   23  119   17  542]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['3' '0' '4' ... '5' '5' '5']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 4 ... 5 5 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (200, 784) (200,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [15 13 17 25 24 43 10 33 37 33] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.174 s \n",
      "\n",
      "Accuracy rate for 72.670000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.94      0.81       980\n",
      "           1       0.69      0.97      0.80      1135\n",
      "           2       0.74      0.74      0.74      1032\n",
      "           3       0.60      0.69      0.64      1010\n",
      "           4       0.77      0.76      0.76       982\n",
      "           5       0.80      0.37      0.50       892\n",
      "           6       0.73      0.92      0.81       958\n",
      "           7       0.78      0.82      0.80      1028\n",
      "           8       0.75      0.51      0.61       974\n",
      "           9       0.87      0.49      0.62      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.72      0.71     10000\n",
      "weighted avg       0.74      0.73      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 921    2    4    1    1    2   37   10    2    0]\n",
      " [   0 1103   23    0    1    0    4    4    0    0]\n",
      " [  45  103  760   11   24    2   40   32   13    2]\n",
      " [  86   75   74  693    5   15   19    7   32    4]\n",
      " [  13   22    6   11  748   23   88   18   13   40]\n",
      " [ 125   33   11  236   35  328   43   24   54    3]\n",
      " [  24   14   15    2   10    4  884    0    5    0]\n",
      " [  35   62   31    5   24    0    8  844    5   14]\n",
      " [  40  170   81   97   33   16   26    5  493   13]\n",
      " [  19   24   16   96   96   21   67  139   38  493]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [17 13 23 28 35 51 11 34 41 47] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.162 s \n",
      "\n",
      "Accuracy rate for 74.610000 \n",
      "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82       980\n",
      "           1       0.71      0.96      0.82      1135\n",
      "           2       0.66      0.76      0.71      1032\n",
      "           3       0.62      0.82      0.71      1010\n",
      "           4       0.84      0.71      0.77       982\n",
      "           5       0.76      0.45      0.57       892\n",
      "           6       0.85      0.87      0.86       958\n",
      "           7       0.82      0.80      0.81      1028\n",
      "           8       0.83      0.42      0.55       974\n",
      "           9       0.83      0.64      0.72      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.76      0.74      0.73     10000\n",
      "weighted avg       0.76      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 953    2    4    7    0    0    9    5    0    0]\n",
      " [   0 1090   37    1    0    1    4    2    0    0]\n",
      " [  59   96  782   27   16    2   18   23    6    3]\n",
      " [  57   35   32  824    1   18    8    8   23    4]\n",
      " [  15   23   34   21  700   27   46   29   10   77]\n",
      " [ 123   44   10  236   14  403   27   22   10    3]\n",
      " [  38   13   42    4    4   18  837    1    1    0]\n",
      " [  46   64   53    6   15    0    1  818    3   22]\n",
      " [  36  148  137  133   29   38   18    6  407   22]\n",
      " [  22   21   48   67   59   22   11   79   33  647]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59700, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [18 13 23 32 40 62 14 44 50 54] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.200 s \n",
      "\n",
      "Accuracy rate for 73.740000 \n",
      "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.81       980\n",
      "           1       0.71      0.96      0.82      1135\n",
      "           2       0.73      0.69      0.71      1032\n",
      "           3       0.61      0.77      0.68      1010\n",
      "           4       0.84      0.71      0.77       982\n",
      "           5       0.70      0.43      0.53       892\n",
      "           6       0.75      0.91      0.82       958\n",
      "           7       0.78      0.83      0.80      1028\n",
      "           8       0.85      0.43      0.57       974\n",
      "           9       0.85      0.61      0.71      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.73      0.72     10000\n",
      "weighted avg       0.75      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 946    2    7    0    0    1   24    0    0    0]\n",
      " [   0 1091   32    3    0    1    6    2    0    0]\n",
      " [  66  109  717   21   16    1   72   23    4    3]\n",
      " [  96   41   26  782    0   20   10    5   25    5]\n",
      " [  12   19    9   23  702   48   58   45   12   54]\n",
      " [ 133   32   11  233   16  384   49   21   10    3]\n",
      " [  30   10   21    0    5   19  870    2    1    0]\n",
      " [  38   61   38    8    9    0    3  851    4   16]\n",
      " [  29  144  106  131   16   43   51    8  419   27]\n",
      " [  20   21   16   76   71   30   14  131   18  612]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['3' '0' '4' ... '5' '5' '8']\n",
      "probabilities: (59650, 10) \n",
      " [3 0 4 ... 5 5 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [20 14 27 39 48 70 15 44 57 66] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.181 s \n",
      "\n",
      "Accuracy rate for 74.560000 \n",
      "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.97      0.78       980\n",
      "           1       0.70      0.98      0.82      1135\n",
      "           2       0.79      0.64      0.71      1032\n",
      "           3       0.64      0.73      0.68      1010\n",
      "           4       0.81      0.78      0.80       982\n",
      "           5       0.77      0.43      0.56       892\n",
      "           6       0.76      0.89      0.82       958\n",
      "           7       0.81      0.82      0.82      1028\n",
      "           8       0.86      0.51      0.64       974\n",
      "           9       0.84      0.64      0.73      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.76      0.74      0.73     10000\n",
      "weighted avg       0.76      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 946    2    6    2    0    5   13    6    0    0]\n",
      " [   1 1112   10    2    0    1    6    2    1    0]\n",
      " [  75  137  665   11   19    2   87   23    7    6]\n",
      " [ 129   40   37  740    3   15    8    6   23    9]\n",
      " [   2   17    7    9  764   31   55   25   16   56]\n",
      " [ 156   24   12  219   18  388   46   16   10    3]\n",
      " [  47   12   18    0    6   18  854    1    2    0]\n",
      " [  36   55   34   12   19    0    3  845    3   21]\n",
      " [  45  165   42  108   17   22   43    8  496   28]\n",
      " [  15   20   12   62   94   21   12  110   17  646]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['3' '0' '4' ... '5' '5' '8']\n",
      "probabilities: (59600, 10) \n",
      " [3 0 4 ... 5 5 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (400, 784) (400,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [20 15 30 44 52 78 17 49 67 78] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.199 s \n",
      "\n",
      "Accuracy rate for 73.100000 \n",
      "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.98      0.77       980\n",
      "           1       0.74      0.97      0.84      1135\n",
      "           2       0.69      0.77      0.72      1032\n",
      "           3       0.67      0.75      0.71      1010\n",
      "           4       0.69      0.79      0.74       982\n",
      "           5       0.81      0.38      0.52       892\n",
      "           6       0.80      0.87      0.83       958\n",
      "           7       0.84      0.79      0.82      1028\n",
      "           8       0.79      0.52      0.62       974\n",
      "           9       0.84      0.43      0.57      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.75      0.72      0.71     10000\n",
      "weighted avg       0.75      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 960    3    9    1    0    1    5    1    0    0]\n",
      " [   2 1099   27    1    0    0    3    2    1    0]\n",
      " [  69   94  792   14   14    0   31   10    7    1]\n",
      " [ 116   29   52  759    1   14    7    6   23    3]\n",
      " [   4   15    9    6  776   19   67   22   28   36]\n",
      " [ 208   19   21  202   29  339   38   15   19    2]\n",
      " [  45    9   53    1    4    9  834    0    3    0]\n",
      " [  39   54   80    5    8    0    2  813    5   22]\n",
      " [  52  136   86  102    9   17   44    7  502   19]\n",
      " [  19   24   26   46  288   18   14   88   50  436]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['3' '0' '4' ... '5' '5' '8']\n",
      "probabilities: (59550, 10) \n",
      " [3 0 4 ... 5 5 8]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [20 15 33 46 55 89 18 54 74 96] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.221 s \n",
      "\n",
      "Accuracy rate for 75.060000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.82       980\n",
      "           1       0.73      0.97      0.83      1135\n",
      "           2       0.77      0.73      0.75      1032\n",
      "           3       0.63      0.79      0.70      1010\n",
      "           4       0.81      0.75      0.78       982\n",
      "           5       0.79      0.41      0.54       892\n",
      "           6       0.75      0.89      0.81       958\n",
      "           7       0.76      0.84      0.80      1028\n",
      "           8       0.81      0.53      0.64       974\n",
      "           9       0.88      0.56      0.69      1009\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.77      0.74      0.74     10000\n",
      "weighted avg       0.76      0.75      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 949    2    7    1    0    2   14    5    0    0]\n",
      " [   1 1102   23    1    0    1    4    2    1    0]\n",
      " [  54   93  753   15   16    0   58   25   17    1]\n",
      " [  77   42   38  794    2   20    6    7   17    7]\n",
      " [   3   15    8    8  737   22   73   70   21   25]\n",
      " [ 136   28    9  242   21  366   55   18   14    3]\n",
      " [  33   14   35    0    5    9  854    5    3    0]\n",
      " [  25   49   55    3    8    0    2  865    5   16]\n",
      " [  33  138   37  130   18   21   48    9  517   23]\n",
      " [  15   27   11   59  100   20   25  139   44  569]]\n",
      "--------------------------------\n",
      "final active learning accuracies [63.56, 68.58999999999999, 67.97999999999999, 70.62, 72.67, 74.61, 73.74000000000001, 74.56, 73.1, 75.06]\n",
      "saved Active-learning-experiment-38.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-37.pkl', 'README.md', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-38.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 39, using model = LogModel, selection_function = MarginSamplingSelection, k = 25, iteration = 0.\n",
      "\n",
      "initial random chosen samples (25,)\n",
      "initial train set: (25, 784) (25,) unique(labels): [4 1 4 1 1 3 2 5 0 4] [0 1 2 3 4 5 6 7 9]\n",
      "val set: (59975, 784) (59975,) (25,)\n",
      "\n",
      "Train set: (25, 784) y: (25,)\n",
      "Val   set: (59975, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.116 s \n",
      "\n",
      "Accuracy rate for 51.800000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=2.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.95      0.74       980\n",
      "           1       0.67      0.76      0.71      1135\n",
      "           2       0.75      0.50      0.60      1032\n",
      "           3       0.60      0.01      0.01      1010\n",
      "           4       0.34      0.18      0.24       982\n",
      "           5       0.35      0.64      0.45       892\n",
      "           6       0.77      0.81      0.79       958\n",
      "           7       0.69      0.61      0.65      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.30      0.70      0.42      1009\n",
      "\n",
      "    accuracy                           0.52     10000\n",
      "   macro avg       0.51      0.52      0.46     10000\n",
      "weighted avg       0.51      0.52      0.46     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[931   0   8   3   2  13  17   6   0   0]\n",
      " [  0 861  29   0   0   9   4   0   0 232]\n",
      " [114 119 521   0  77   6  34  23   0 138]\n",
      " [140  83  61   6  96 541   4  22   0  57]\n",
      " [  3  21   7   0 178  49 111  80   0 533]\n",
      " [151  28  21   1  25 575  20  32   0  39]\n",
      " [ 74  15  12   0  21  58 775   1   0   2]\n",
      " [  3  48  14   0  10   4   2 628   0 319]\n",
      " [120  86  15   0  30 329  24  14   0 356]\n",
      " [ 17  18   3   0  81  59  17 109   0 705]]\n",
      "--------------------------------\n",
      "val predicted: (59975,) ['5' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59975, 9) \n",
      " [5 0 4 ... 5 6 8]\n",
      "trainset before (25, 784) (25,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [4 3 5 5 3 9 2 6 6 7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.120 s \n",
      "\n",
      "Accuracy rate for 63.710000 \n",
      "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       980\n",
      "           1       0.71      0.97      0.82      1135\n",
      "           2       0.89      0.45      0.60      1032\n",
      "           3       0.61      0.63      0.62      1010\n",
      "           4       0.49      0.46      0.48       982\n",
      "           5       0.58      0.37      0.45       892\n",
      "           6       0.92      0.69      0.79       958\n",
      "           7       0.71      0.61      0.66      1028\n",
      "           8       0.53      0.65      0.58       974\n",
      "           9       0.38      0.60      0.47      1009\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.67      0.63      0.63     10000\n",
      "weighted avg       0.67      0.64      0.64     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 866    2   13   49    6   16    6   21    0    1]\n",
      " [   0 1096    0    5    0    0    1    0   28    5]\n",
      " [  34  155  467   32   22    1   12   45  202   62]\n",
      " [   4   64    8  637   29   91    0   12  134   31]\n",
      " [   2   22    6    4  456    2   34   33   17  406]\n",
      " [  30   60   12  203   51  326    0   23   88   99]\n",
      " [  45   18   14   55   97   25  660    0   36    8]\n",
      " [   1   47    2    4   25    1    0  624   29  295]\n",
      " [  18   82    3   36   20   85    4   11  630   85]\n",
      " [   4    8    1   12  231   13    4  106   21  609]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['3' '0' '4' ... '5' '6' '9']\n",
      "probabilities: (59950, 10) \n",
      " [3 0 4 ... 5 6 9]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (75, 784) (75,)\n",
      "updated train set: (75, 784) (75,) unique(labels): [ 7  3  7  7  4 13  4  9  9 12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59925, 784) (59925,)\n",
      "\n",
      "Train set: (75, 784) y: (75,)\n",
      "Val   set: (59925, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.122 s \n",
      "\n",
      "Accuracy rate for 68.580000 \n",
      "Classification report for classifier LogisticRegression(C=0.6666666666666666, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84       980\n",
      "           1       0.67      0.97      0.80      1135\n",
      "           2       0.86      0.50      0.63      1032\n",
      "           3       0.67      0.75      0.71      1010\n",
      "           4       0.62      0.62      0.62       982\n",
      "           5       0.56      0.40      0.47       892\n",
      "           6       0.83      0.73      0.78       958\n",
      "           7       0.74      0.82      0.78      1028\n",
      "           8       0.52      0.72      0.60       974\n",
      "           9       0.78      0.34      0.47      1009\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.70      0.68      0.67     10000\n",
      "weighted avg       0.70      0.69      0.67     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 928    2    3    6    2   31    3    4    1    0]\n",
      " [   0 1101    0    5    0    2    9    0   18    0]\n",
      " [  54  152  517   23   15    1   27   77  165    1]\n",
      " [   6   68   13  760    0   43   21    8   90    1]\n",
      " [  11   55    6   23  607   53   33   31   92   71]\n",
      " [  71   76   14  170   31  359   26   14  124    7]\n",
      " [ 106   25   43   11   28   19  701   10   15    0]\n",
      " [   6   43    1   16   44    3    5  842   59    9]\n",
      " [  28   76    2   54    9   58   21   15  702    9]\n",
      " [  17   34    4   62  250   73    1  138   89  341]]\n",
      "--------------------------------\n",
      "val predicted: (59925,) ['3' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59925, 10) \n",
      " [3 0 4 ... 5 0 8]\n",
      "trainset before (75, 784) (75,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 7  3  9 15  8 17  5 10 10 16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.133 s \n",
      "\n",
      "Accuracy rate for 68.180000 \n",
      "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82       980\n",
      "           1       0.74      0.96      0.83      1135\n",
      "           2       0.81      0.55      0.66      1032\n",
      "           3       0.80      0.54      0.65      1010\n",
      "           4       0.60      0.70      0.65       982\n",
      "           5       0.67      0.34      0.45       892\n",
      "           6       0.70      0.74      0.72       958\n",
      "           7       0.80      0.79      0.80      1028\n",
      "           8       0.49      0.75      0.59       974\n",
      "           9       0.62      0.43      0.51      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.69      0.68      0.67     10000\n",
      "weighted avg       0.70      0.68      0.67     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 933    2    3    3    0    6   27    3    2    1]\n",
      " [   0 1090    1    9    0    5    5    3    9   13]\n",
      " [  40  113  570    4   23    1   53   86  138    4]\n",
      " [  12   58   60  546    8   41   50   18  206   11]\n",
      " [  27   34    4    0  686   22   60    7   93   49]\n",
      " [  76   55    7   96   27  302   56    7  169   97]\n",
      " [ 128   13   49    2   11   21  710    7   11    6]\n",
      " [  18   39    1    1   66    5    3  815   50   30]\n",
      " [  27   55   11    8    9   15   55    6  734   54]\n",
      " [  38   19    1   12  312   35    2   64   94  432]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 4 ... 5 0 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (100, 784) (100,)\n",
      "trainset after (125, 784) (125,)\n",
      "updated train set: (125, 784) (125,) unique(labels): [ 7  6 13 18 11 18  6 13 14 19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.136 s \n",
      "\n",
      "Accuracy rate for 70.160000 \n",
      "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82       980\n",
      "           1       0.70      0.89      0.79      1135\n",
      "           2       0.80      0.67      0.73      1032\n",
      "           3       0.79      0.62      0.70      1010\n",
      "           4       0.68      0.77      0.72       982\n",
      "           5       0.73      0.30      0.43       892\n",
      "           6       0.70      0.77      0.73       958\n",
      "           7       0.77      0.81      0.79      1028\n",
      "           8       0.52      0.70      0.60       974\n",
      "           9       0.70      0.47      0.56      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.70      0.69     10000\n",
      "weighted avg       0.71      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 934    2    4    3    0    4   28    3    1    1]\n",
      " [   0 1013    2    1    0    1    7    0  111    0]\n",
      " [  52   54  689    2   26    0   42   41  123    3]\n",
      " [  23  104   53  625    7   52   46   12   70   18]\n",
      " [  24   22    2    0  760   12   58   22   65   17]\n",
      " [  81   57   22  121   37  270   63   27  114  100]\n",
      " [ 115    5   70    0   15    1  737   13    1    1]\n",
      " [  10   42   12    2   32    0    4  834   61   31]\n",
      " [  27  106    8   17   10    8   70   14  678   36]\n",
      " [  32   32    1   17  235   20    4  118   74  476]]\n",
      "--------------------------------\n",
      "val predicted: (59875,) ['3' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59875, 10) \n",
      " [3 0 4 ... 5 0 8]\n",
      "trainset before (125, 784) (125,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [ 9  6 16 20 13 23  6 16 18 23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.139 s \n",
      "\n",
      "Accuracy rate for 70.690000 \n",
      "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83       980\n",
      "           1       0.69      0.98      0.81      1135\n",
      "           2       0.82      0.65      0.72      1032\n",
      "           3       0.73      0.70      0.71      1010\n",
      "           4       0.69      0.84      0.76       982\n",
      "           5       0.66      0.29      0.40       892\n",
      "           6       0.70      0.76      0.73       958\n",
      "           7       0.83      0.76      0.80      1028\n",
      "           8       0.65      0.51      0.57       974\n",
      "           9       0.55      0.56      0.56      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.70      0.69     10000\n",
      "weighted avg       0.71      0.71      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 925    4   11    0    0   12    9    7    0   12]\n",
      " [   0 1114    0    1    0    0   11    0    9    0]\n",
      " [  66   87  670    8   25    2   49   41   73   11]\n",
      " [  28   83   26  703    6   35   41   15   42   31]\n",
      " [  15   23    5    1  822   18   50    9   24   15]\n",
      " [  55   68    8  188   37  259   63   13   37  164]\n",
      " [  90    9   72    0   43    6  727    8    0    3]\n",
      " [  11   59   17    1   20    3    9  785   33   90]\n",
      " [  38  128    7   35   24   25   85    3  499  130]\n",
      " [  26   39    2   20  207   33    2   64   51  565]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['3' '0' '4' ... '9' '0' '5']\n",
      "probabilities: (59850, 10) \n",
      " [3 0 4 ... 9 0 5]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (175, 784) (175,)\n",
      "updated train set: (175, 784) (175,) unique(labels): [10  6 18 27 14 25  6 17 23 29] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59825, 784) (59825,)\n",
      "\n",
      "Train set: (175, 784) y: (175,)\n",
      "Val   set: (59825, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.148 s \n",
      "\n",
      "Accuracy rate for 72.170000 \n",
      "Classification report for classifier LogisticRegression(C=0.2857142857142857, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.96      0.86       980\n",
      "           1       0.70      0.99      0.82      1135\n",
      "           2       0.85      0.63      0.72      1032\n",
      "           3       0.73      0.69      0.71      1010\n",
      "           4       0.66      0.82      0.73       982\n",
      "           5       0.70      0.35      0.47       892\n",
      "           6       0.68      0.81      0.74       958\n",
      "           7       0.80      0.77      0.79      1028\n",
      "           8       0.62      0.60      0.61       974\n",
      "           9       0.72      0.54      0.62      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.72      0.72      0.71     10000\n",
      "weighted avg       0.73      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 936    2    2    0    0    9   23    6    1    1]\n",
      " [   0 1118    0    2    0    1    6    1    7    0]\n",
      " [  63   96  652    5   23    1   71   50   61   10]\n",
      " [  23   77   44  699    6   41   30   21   48   21]\n",
      " [   8   24    2    2  806   24   58   10   21   27]\n",
      " [  36   58   16  157   48  316   60   21  147   33]\n",
      " [  57   11   40    1   53   13  772   10    0    1]\n",
      " [  23   62    7    0   30    2    7  791   36   70]\n",
      " [  19  109    6   69   17   18  102    5  580   49]\n",
      " [  36   39    0   20  230   25    6   68   38  547]]\n",
      "--------------------------------\n",
      "val predicted: (59825,) ['3' '0' '4' ... '5' '0' '5']\n",
      "probabilities: (59825, 10) \n",
      " [3 0 4 ... 5 0 5]\n",
      "trainset before (175, 784) (175,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [10  6 20 29 17 29  9 18 28 34] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.151 s \n",
      "\n",
      "Accuracy rate for 74.340000 \n",
      "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.82       980\n",
      "           1       0.72      0.99      0.83      1135\n",
      "           2       0.80      0.73      0.77      1032\n",
      "           3       0.78      0.59      0.67      1010\n",
      "           4       0.78      0.79      0.78       982\n",
      "           5       0.67      0.62      0.64       892\n",
      "           6       0.67      0.86      0.75       958\n",
      "           7       0.85      0.65      0.74      1028\n",
      "           8       0.81      0.63      0.71       974\n",
      "           9       0.67      0.64      0.65      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.75      0.74      0.74     10000\n",
      "weighted avg       0.75      0.74      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 897    4   11    1    0    7   56    0    1    3]\n",
      " [   0 1120    2    2    0    1    4    0    6    0]\n",
      " [  70   35  753    4   15    2   96   26   27    4]\n",
      " [  28   99   75  597    1  114   44    8   24   20]\n",
      " [  19   42    4    7  776   39   41   14   21   19]\n",
      " [  50   68   15   73   20  551   57   15   17   26]\n",
      " [  53   12   19    1   18   27  821    2    5    0]\n",
      " [  23   66   27    1    7    6    5  666   24  203]\n",
      " [  28   71   25   54   23   30   88    6  610   39]\n",
      " [  35   40    5   26  139   42   14   47   18  643]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['3' '0' '4' ... '5' '0' '5']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 4 ... 5 0 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (200, 784) (200,)\n",
      "trainset after (225, 784) (225,)\n",
      "updated train set: (225, 784) (225,) unique(labels): [10  7 21 31 23 31  9 21 32 40] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59775, 784) (59775,)\n",
      "\n",
      "Train set: (225, 784) y: (225,)\n",
      "Val   set: (59775, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.158 s \n",
      "\n",
      "Accuracy rate for 73.950000 \n",
      "Classification report for classifier LogisticRegression(C=0.2222222222222222, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.82       980\n",
      "           1       0.69      0.99      0.81      1135\n",
      "           2       0.75      0.73      0.74      1032\n",
      "           3       0.77      0.51      0.61      1010\n",
      "           4       0.76      0.80      0.78       982\n",
      "           5       0.70      0.59      0.64       892\n",
      "           6       0.74      0.87      0.80       958\n",
      "           7       0.79      0.73      0.76      1028\n",
      "           8       0.74      0.66      0.70       974\n",
      "           9       0.78      0.55      0.65      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.74      0.73     10000\n",
      "weighted avg       0.74      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 919    4    9    0    0    5   37    6    0    0]\n",
      " [   0 1120    3    1    0    1    6    0    4    0]\n",
      " [  67   51  753    3   22    2   64   24   42    4]\n",
      " [  47  110  139  513    3   90   32   15   47   14]\n",
      " [   8   42    1    8  782   31   36   18   36   20]\n",
      " [  80   63   24   72   14  523   65   17   20   14]\n",
      " [  37   15   19    3   16   33  829    4    2    0]\n",
      " [  37   74   31    1   12    6    2  754   28   83]\n",
      " [  37   99   25   47   29   25   46    2  643   21]\n",
      " [  40   42    2   20  145   34    9  114   44  559]]\n",
      "--------------------------------\n",
      "val predicted: (59775,) ['3' '0' '4' ... '5' '5' '8']\n",
      "probabilities: (59775, 10) \n",
      " [3 0 4 ... 5 5 8]\n",
      "trainset before (225, 784) (225,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [10 10 21 33 25 37  9 26 34 45] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.172 s \n",
      "\n",
      "Accuracy rate for 71.130000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.95      0.75       980\n",
      "           1       0.65      0.98      0.78      1135\n",
      "           2       0.72      0.62      0.67      1032\n",
      "           3       0.71      0.56      0.63      1010\n",
      "           4       0.75      0.76      0.76       982\n",
      "           5       0.72      0.53      0.61       892\n",
      "           6       0.72      0.85      0.78       958\n",
      "           7       0.75      0.78      0.76      1028\n",
      "           8       0.80      0.50      0.61       974\n",
      "           9       0.85      0.54      0.66      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.73      0.71      0.70     10000\n",
      "weighted avg       0.73      0.71      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 929    3   11    0    0    5   30    2    0    0]\n",
      " [   0 1117    1    6    1    1    6    0    3    0]\n",
      " [ 135  106  640    3   42    1   67   22   16    0]\n",
      " [  68   83  125  565    9   73   34   15   29    9]\n",
      " [  24   31    0   24  750   26   31   45   24   27]\n",
      " [ 116   22   25  114   20  470   71   25   13   16]\n",
      " [  58   13   18    2   20   27  813    5    2    0]\n",
      " [  49   85   40    0   18    3    4  801    8   20]\n",
      " [  66  185   27   41   43   28   70    6  484   24]\n",
      " [  58   69    2   36  101   18   10  148   23  544]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '5' '0' '5']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 0 5]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (275, 784) (275,)\n",
      "updated train set: (275, 784) (275,) unique(labels): [10 10 23 38 28 38 11 28 38 51] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59725, 784) (59725,)\n",
      "\n",
      "Train set: (275, 784) y: (275,)\n",
      "Val   set: (59725, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.159 s \n",
      "\n",
      "Accuracy rate for 74.020000 \n",
      "Classification report for classifier LogisticRegression(C=0.18181818181818182, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       980\n",
      "           1       0.66      0.99      0.79      1135\n",
      "           2       0.80      0.62      0.70      1032\n",
      "           3       0.73      0.70      0.71      1010\n",
      "           4       0.79      0.76      0.77       982\n",
      "           5       0.74      0.55      0.63       892\n",
      "           6       0.62      0.91      0.74       958\n",
      "           7       0.73      0.82      0.77      1028\n",
      "           8       0.76      0.60      0.67       974\n",
      "           9       0.85      0.59      0.70      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.76      0.74      0.73     10000\n",
      "weighted avg       0.76      0.74      0.74     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 815    3   29    1    0   14  111    6    1    0]\n",
      " [   0 1121    0    1    1    1    4    0    7    0]\n",
      " [  31  156  637    5   21    2  120   35   24    1]\n",
      " [  21   59   46  702    6   59   44   25   44    4]\n",
      " [   3   33    7   12  744   24   48   50   26   35]\n",
      " [  29   22   18  134   18  491  105   35   23   17]\n",
      " [  11   10   21    0   26    9  871    6    4    0]\n",
      " [  14   90   19    1   12    5    4  840   15   28]\n",
      " [   6  138   11   66   22   38   83    7  584   19]\n",
      " [  10   60    4   39   89   22   13  139   36  597]]\n",
      "--------------------------------\n",
      "val predicted: (59725,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59725, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (275, 784) (275,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [11 10 27 44 29 40 11 29 43 56] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.175 s \n",
      "\n",
      "Accuracy rate for 72.900000 \n",
      "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81       980\n",
      "           1       0.64      0.99      0.78      1135\n",
      "           2       0.77      0.69      0.73      1032\n",
      "           3       0.75      0.58      0.65      1010\n",
      "           4       0.71      0.82      0.76       982\n",
      "           5       0.77      0.46      0.57       892\n",
      "           6       0.67      0.90      0.77       958\n",
      "           7       0.78      0.79      0.78      1028\n",
      "           8       0.80      0.54      0.64       974\n",
      "           9       0.85      0.55      0.67      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.75      0.72      0.72     10000\n",
      "weighted avg       0.75      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 914    3   10    0    1    2   43    6    1    0]\n",
      " [   0 1123    2    1    0    1    7    0    1    0]\n",
      " [  72  102  716    6   21    3   79   26    5    2]\n",
      " [  60  114   95  582    6   46   36   19   42   10]\n",
      " [   4   38    3    3  801   21   44   31   15   22]\n",
      " [  85   26   15  125   44  407  104   30   35   21]\n",
      " [  20   16   16    3   33    8  858    4    0    0]\n",
      " [  49   91   35    1   10    2    4  808    7   21]\n",
      " [  36  172   29   41   37   24   90    1  525   19]\n",
      " [  34   71    3   13  175   13   13  107   24  556]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['3' '0' '4' ... '5' '0' '5']\n",
      "probabilities: (59700, 10) \n",
      " [3 0 4 ... 5 0 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (300, 784) (300,)\n",
      "trainset after (325, 784) (325,)\n",
      "updated train set: (325, 784) (325,) unique(labels): [12 10 28 50 34 44 12 30 46 59] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59675, 784) (59675,)\n",
      "\n",
      "Train set: (325, 784) y: (325,)\n",
      "Val   set: (59675, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.182 s \n",
      "\n",
      "Accuracy rate for 73.750000 \n",
      "Classification report for classifier LogisticRegression(C=0.15384615384615385, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.95      0.83       980\n",
      "           1       0.64      0.99      0.77      1135\n",
      "           2       0.80      0.69      0.74      1032\n",
      "           3       0.77      0.68      0.72      1010\n",
      "           4       0.75      0.76      0.76       982\n",
      "           5       0.80      0.51      0.63       892\n",
      "           6       0.69      0.89      0.78       958\n",
      "           7       0.73      0.81      0.77      1028\n",
      "           8       0.79      0.46      0.58       974\n",
      "           9       0.87      0.59      0.70      1009\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.76      0.73      0.73     10000\n",
      "weighted avg       0.76      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 929    3    9    0    0    2   33    4    0    0]\n",
      " [   0 1122    1    2    0    1    9    0    0    0]\n",
      " [  65  129  709   14   18    1   55   35    1    5]\n",
      " [  16   92   66  683    7   34   38   20   47    7]\n",
      " [  36   33    7    5  750   21   29   59   12   30]\n",
      " [  46   22   15  105   37  459  113   41   43   11]\n",
      " [  30   18   13    1   29    9  855    2    1    0]\n",
      " [  52   92   26    1   12    1    3  829    3    9]\n",
      " [  33  181   39   53   51   30  108    7  448   24]\n",
      " [  51   74    2   26   96   16    5  133   15  591]]\n",
      "--------------------------------\n",
      "val predicted: (59675,) ['3' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59675, 10) \n",
      " [3 0 4 ... 5 6 5]\n",
      "trainset before (325, 784) (325,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [12 10 33 51 35 49 12 33 56 59] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.199 s \n",
      "\n",
      "Accuracy rate for 72.550000 \n",
      "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.95      0.82       980\n",
      "           1       0.64      0.99      0.77      1135\n",
      "           2       0.79      0.69      0.74      1032\n",
      "           3       0.75      0.65      0.70      1010\n",
      "           4       0.78      0.78      0.78       982\n",
      "           5       0.79      0.31      0.45       892\n",
      "           6       0.69      0.90      0.78       958\n",
      "           7       0.78      0.80      0.79      1028\n",
      "           8       0.61      0.55      0.58       974\n",
      "           9       0.88      0.57      0.69      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.72      0.71     10000\n",
      "weighted avg       0.74      0.73      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 932    3    7    0    0    3   33    2    0    0]\n",
      " [   0 1122    1    2    0    1    9    0    0    0]\n",
      " [  70  125  713   11   18    1   62   23    5    4]\n",
      " [  23  103   66  659    8   23   39   13   68    8]\n",
      " [  49   32    3    4  762   20   33   43   14   22]\n",
      " [  53   26   21  126   36  279  116   41  180   14]\n",
      " [  29   15   17    2   25    6  859    2    3    0]\n",
      " [  57   86   35    2   12    1    3  819    7    6]\n",
      " [  32  174   30   47   35   12   84    3  536   21]\n",
      " [  62   76    5   20   82    8    7  108   67  574]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['3' '0' '4' ... '8' '6' '5']\n",
      "probabilities: (59650, 10) \n",
      " [3 0 4 ... 8 6 5]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [12 10 34 53 39 52 12 35 62 66] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.223 s \n",
      "\n",
      "Accuracy rate for 72.250000 \n",
      "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81       980\n",
      "           1       0.63      0.99      0.77      1135\n",
      "           2       0.81      0.66      0.73      1032\n",
      "           3       0.74      0.64      0.69      1010\n",
      "           4       0.78      0.72      0.75       982\n",
      "           5       0.76      0.42      0.54       892\n",
      "           6       0.69      0.89      0.78       958\n",
      "           7       0.70      0.80      0.75      1028\n",
      "           8       0.68      0.58      0.63       974\n",
      "           9       0.89      0.53      0.67      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.72      0.71     10000\n",
      "weighted avg       0.74      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 916    3    7    3    0    3   38   10    0    0]\n",
      " [   0 1120    0    2    0    1    9    0    3    0]\n",
      " [  62  156  686    9   11    3   70   23   10    2]\n",
      " [  23   91   61  648    7   42   43   18   70    7]\n",
      " [  55   38    4    6  704   21   26   85   20   23]\n",
      " [  40   22   14  134   39  376  115   54   91    7]\n",
      " [  33   17   19    1   19   14  848    4    3    0]\n",
      " [  54   88   25    0   12    1    4  821   13   10]\n",
      " [  32  157   27   55   19   22   68    6  567   21]\n",
      " [  53   76    4   17   96   11    7  152   54  539]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['3' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59625, 10) \n",
      " [3 0 4 ... 5 6 5]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [12 10 37 55 43 59 13 36 65 70] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.212 s \n",
      "\n",
      "Accuracy rate for 72.700000 \n",
      "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81       980\n",
      "           1       0.67      0.99      0.79      1135\n",
      "           2       0.77      0.61      0.68      1032\n",
      "           3       0.76      0.63      0.69      1010\n",
      "           4       0.77      0.79      0.78       982\n",
      "           5       0.80      0.41      0.54       892\n",
      "           6       0.66      0.90      0.76       958\n",
      "           7       0.73      0.79      0.76      1028\n",
      "           8       0.69      0.60      0.64       974\n",
      "           9       0.86      0.56      0.68      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.72      0.71     10000\n",
      "weighted avg       0.74      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 914    3    5    0    0    3   45    9    1    0]\n",
      " [   0 1120    3    0    0    1    8    0    3    0]\n",
      " [  95  144  632   16   17    3   85   25   12    3]\n",
      " [  29   92   54  640    3   31   54   19   78   10]\n",
      " [  19   32    9    3  774   12   29   53   21   30]\n",
      " [  63   13   27  109   28  366  139   45   92   10]\n",
      " [  21   11   16    2   30    8  861    3    6    0]\n",
      " [  71   75   37    0    7    1    3  810   13   11]\n",
      " [  28  129   31   63   20   20   69    5  584   25]\n",
      " [  36   65    6    8  130   14    6  134   41  569]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59600, 10) \n",
      " [3 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (400, 784) (400,)\n",
      "trainset after (425, 784) (425,)\n",
      "updated train set: (425, 784) (425,) unique(labels): [12 10 38 58 47 62 15 40 70 73] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59575, 784) (59575,)\n",
      "\n",
      "Train set: (425, 784) y: (425,)\n",
      "Val   set: (59575, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.232 s \n",
      "\n",
      "Accuracy rate for 71.470000 \n",
      "Classification report for classifier LogisticRegression(C=0.11764705882352941, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.96      0.80       980\n",
      "           1       0.62      0.99      0.76      1135\n",
      "           2       0.81      0.62      0.70      1032\n",
      "           3       0.74      0.66      0.70      1010\n",
      "           4       0.69      0.78      0.73       982\n",
      "           5       0.76      0.45      0.57       892\n",
      "           6       0.73      0.86      0.79       958\n",
      "           7       0.77      0.73      0.75      1028\n",
      "           8       0.69      0.60      0.64       974\n",
      "           9       0.83      0.44      0.58      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.73      0.71      0.70     10000\n",
      "weighted avg       0.73      0.71      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 940    4    5    1    0    2   21    7    0    0]\n",
      " [   0 1121    0    1    0    1    8    0    4    0]\n",
      " [  94  180  639   10   16    2   52   20   15    4]\n",
      " [  19  101   48  670    3   49   38   15   64    3]\n",
      " [  60   41    0    4  765   16   13   31   20   32]\n",
      " [  42   21   18  120   26  401  118   43   99    4]\n",
      " [  45   17   16    1   31   13  828    2    5    0]\n",
      " [  81   93   32    1   17    1    6  753   15   29]\n",
      " [  38  148   25   65   15   22   54    3  582   22]\n",
      " [  60   75    4   27  239   18    3  101   34  448]]\n",
      "--------------------------------\n",
      "val predicted: (59575,) ['3' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59575, 10) \n",
      " [3 0 4 ... 5 0 8]\n",
      "trainset before (425, 784) (425,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [13 10 40 61 48 66 15 42 76 79] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.211 s \n",
      "\n",
      "Accuracy rate for 70.380000 \n",
      "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.98      0.78       980\n",
      "           1       0.62      0.99      0.76      1135\n",
      "           2       0.83      0.62      0.71      1032\n",
      "           3       0.67      0.69      0.68      1010\n",
      "           4       0.69      0.70      0.70       982\n",
      "           5       0.79      0.35      0.49       892\n",
      "           6       0.73      0.86      0.79       958\n",
      "           7       0.75      0.77      0.76      1028\n",
      "           8       0.75      0.54      0.63       974\n",
      "           9       0.80      0.47      0.59      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.73      0.70      0.69     10000\n",
      "weighted avg       0.72      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 960    3    2    1    0    1   10    3    0    0]\n",
      " [   0 1122    0    2    0    0    8    0    3    0]\n",
      " [  79  188  636   10   18    2   67   20   10    2]\n",
      " [  62   91   50  700    3   25   28   13   35    3]\n",
      " [  42   44    1    6  689   14   17   66   21   82]\n",
      " [ 107   21   16  183   26  315  114   34   71    5]\n",
      " [  65   21   15    0   20    9  822    3    3    0]\n",
      " [  81  100   21    3    8    1    3  790   12    9]\n",
      " [  42  158   24  113   10   14   56    6  530   21]\n",
      " [  49   73    5   30  218   19    3  112   26  474]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['3' '0' '4' ... '5' '0' '0']\n",
      "probabilities: (59550, 10) \n",
      " [3 0 4 ... 5 0 0]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (475, 784) (475,)\n",
      "updated train set: (475, 784) (475,) unique(labels): [13 11 41 62 53 69 16 43 78 89] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59525, 784) (59525,)\n",
      "\n",
      "Train set: (475, 784) y: (475,)\n",
      "Val   set: (59525, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.256 s \n",
      "\n",
      "Accuracy rate for 69.800000 \n",
      "Classification report for classifier LogisticRegression(C=0.10526315789473684, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.94      0.81       980\n",
      "           1       0.62      0.99      0.76      1135\n",
      "           2       0.73      0.66      0.70      1032\n",
      "           3       0.70      0.55      0.62      1010\n",
      "           4       0.73      0.73      0.73       982\n",
      "           5       0.71      0.46      0.56       892\n",
      "           6       0.67      0.87      0.76       958\n",
      "           7       0.71      0.82      0.76      1028\n",
      "           8       0.70      0.44      0.54       974\n",
      "           9       0.83      0.46      0.59      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.69      0.68     10000\n",
      "weighted avg       0.71      0.70      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 926    4    3    1    1    2   36    7    0    0]\n",
      " [   1 1123    2    0    0    1    7    0    1    0]\n",
      " [  58  151  686    6   18    2   77   26    8    0]\n",
      " [  73  111   94  559    2   67   47   16   39    2]\n",
      " [  16   28    2    4  714   26   32   75   21   64]\n",
      " [  93   25   15  102   26  412  121   41   54    3]\n",
      " [  42   18   18    3   24   16  832    1    3    1]\n",
      " [  49   78   26    1    8    1    6  841   15    3]\n",
      " [  36  198   81   87   14   31   71    8  426   22]\n",
      " [  21   78    7   30  166   23   12  169   42  461]]\n",
      "--------------------------------\n",
      "val predicted: (59525,) ['3' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59525, 10) \n",
      " [3 0 4 ... 5 0 8]\n",
      "trainset before (475, 784) (475,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [13 11 43 64 54 74 17 44 82 98] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.279 s \n",
      "\n",
      "Accuracy rate for 70.060000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.95      0.80       980\n",
      "           1       0.64      0.99      0.78      1135\n",
      "           2       0.75      0.67      0.71      1032\n",
      "           3       0.71      0.59      0.64      1010\n",
      "           4       0.71      0.69      0.70       982\n",
      "           5       0.73      0.47      0.57       892\n",
      "           6       0.66      0.87      0.75       958\n",
      "           7       0.72      0.82      0.77      1028\n",
      "           8       0.70      0.52      0.59       974\n",
      "           9       0.88      0.38      0.53      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.72      0.70      0.68     10000\n",
      "weighted avg       0.72      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 927    5   11    0    1    1   29    6    0    0]\n",
      " [   0 1123    1    0    0    1    5    0    5    0]\n",
      " [  65  134  692    7    7    4   93   17   13    0]\n",
      " [  75   93   89  598    2   53   35   15   49    1]\n",
      " [  13   36    1   10  680   28   84   70   27   33]\n",
      " [  99   33   17  123   31  421   82   42   44    0]\n",
      " [  54   17   16    3   18   12  833    1    4    0]\n",
      " [  41   75   23    0    9    3   11  845   17    4]\n",
      " [  36  167   69   72   15   27   64    6  503   15]\n",
      " [  26   80    8   35  200   27   22  168   59  384]]\n",
      "--------------------------------\n",
      "final active learning accuracies [51.800000000000004, 63.71, 68.58, 68.17999999999999, 70.16, 70.69, 72.17, 74.33999999999999, 73.95, 71.13000000000001, 74.02, 72.89999999999999, 73.75, 72.55, 72.25, 72.7, 71.47, 70.38, 69.8, 70.06]\n",
      "saved Active-learning-experiment-39.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-37.pkl', 'README.md', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-38.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 40, using model = LogModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
      "\n",
      "initial random chosen samples (10,)\n",
      "initial train set: (10, 784) (10,) unique(labels): [2 1 2 1 1 0 0 0 0 3] [0 1 2 3 4 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59990, 784) (59990,) (10,)\n",
      "\n",
      "Train set: (10, 784) y: (10,)\n",
      "Val   set: (59990, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.106 s \n",
      "\n",
      "Accuracy rate for 37.500000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=5.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.66      0.51       980\n",
      "           1       0.70      0.82      0.76      1135\n",
      "           2       0.21      0.58      0.30      1032\n",
      "           3       0.42      0.62      0.50      1010\n",
      "           4       0.43      0.19      0.26       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.00      0.00      0.00      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.33      0.75      0.46      1009\n",
      "\n",
      "    accuracy                           0.38     10000\n",
      "   macro avg       0.25      0.36      0.28     10000\n",
      "weighted avg       0.26      0.38      0.29     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[644   0 221  57   0   0   0   0   0  58]\n",
      " [ 17 934 169   7   0   0   0   0   0   8]\n",
      " [ 51  55 598 311   1   0   0   0   0  16]\n",
      " [120  55 124 631   1   0   0   0   0  79]\n",
      " [ 81  19 198  45 187   0   0   0   0 452]\n",
      " [334  21 217 204  17   0   0   0   0  99]\n",
      " [176   5 624  38   7   0   0   0   0 108]\n",
      " [ 39 111 141  25 146   0   0   0   0 566]\n",
      " [ 56  73 518 155   0   0   0   0   0 172]\n",
      " [  8  54  94  26  71   0   0   0   0 756]]\n",
      "--------------------------------\n",
      "val predicted: (59990,) ['0' '0' '0' ... '0' '2' '2']\n",
      "probabilities: (59990, 6) \n",
      " [0 0 0 ... 0 2 2]\n",
      "trainset before (10, 784) (10,)\n",
      "trainset after (20, 784) (20,)\n",
      "updated train set: (20, 784) (20,) unique(labels): [3 3 2 1 4 2 0 2 0 3] [0 1 2 3 4 5 7 9]\n",
      "val set: (59980, 784) (59980,)\n",
      "\n",
      "Train set: (20, 784) y: (20,)\n",
      "Val   set: (59980, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.107 s \n",
      "\n",
      "Accuracy rate for 45.540000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=2.5, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.83      0.58       980\n",
      "           1       0.72      0.90      0.80      1135\n",
      "           2       0.36      0.54      0.44      1032\n",
      "           3       0.32      0.25      0.28      1010\n",
      "           4       0.41      0.41      0.41       982\n",
      "           5       0.51      0.43      0.47       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.46      0.58      0.51      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.37      0.52      0.43      1009\n",
      "\n",
      "    accuracy                           0.46     10000\n",
      "   macro avg       0.36      0.45      0.39     10000\n",
      "weighted avg       0.37      0.46      0.40     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 810    1   90   36    7   14    0   16    0    6]\n",
      " [   2 1024   65    4    0    0    0   40    0    0]\n",
      " [  63   71  562  262    8    0    0   58    0    8]\n",
      " [ 363   67   48  255   27  136    0   85    0   29]\n",
      " [   2   24   91   32  402    6    0   88    0  337]\n",
      " [ 203    8   72   78   31  385    0   94    0   21]\n",
      " [ 251   16  392   27  107   22    0    1    0  142]\n",
      " [  36   45   18    6  109    2    0  592    0  220]\n",
      " [  58  147  203   71   45  183    0  153    0  114]\n",
      " [   9   18   10   18  243   14    0  173    0  524]]\n",
      "--------------------------------\n",
      "val predicted: (59980,) ['7' '0' '0' ... '5' '2' '7']\n",
      "probabilities: (59980, 8) \n",
      " [6 0 0 ... 5 2 6]\n",
      "trainset before (20, 784) (20,)\n",
      "trainset after (30, 784) (30,)\n",
      "updated train set: (30, 784) (30,) unique(labels): [4 3 2 3 7 3 1 2 1 4] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59970, 784) (59970,)\n",
      "\n",
      "Train set: (30, 784) y: (30,)\n",
      "Val   set: (59970, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.116 s \n",
      "\n",
      "Accuracy rate for 50.170000 \n",
      "Classification report for classifier LogisticRegression(C=1.6666666666666667, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.87      0.70       980\n",
      "           1       0.76      0.89      0.82      1135\n",
      "           2       0.41      0.57      0.48      1032\n",
      "           3       0.36      0.59      0.45      1010\n",
      "           4       0.65      0.35      0.45       982\n",
      "           5       0.58      0.29      0.39       892\n",
      "           6       0.71      0.13      0.22       958\n",
      "           7       0.40      0.55      0.46      1028\n",
      "           8       0.12      0.03      0.05       974\n",
      "           9       0.49      0.64      0.56      1009\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.51      0.49      0.46     10000\n",
      "weighted avg       0.51      0.50      0.46     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 854    0   26   10    0   11   35   31   12    1]\n",
      " [   0 1015   63    6    0    0    0   49    1    1]\n",
      " [  67   77  590  106    0    3   12   72  101    4]\n",
      " [ 138   36   28  597    0   72    0   97   21   21]\n",
      " [   0   12  177   66  341    9    0  108   26  243]\n",
      " [ 179    6   46  202   24  258    4  115   33   25]\n",
      " [ 165   17  259  238   96    3  127    0    3   50]\n",
      " [   2   33   14  198   12    6    0  563    3  197]\n",
      " [  57  128  204  171    3   77    1  183   29  121]\n",
      " [  11    9   24   70   50    7    0  178   17  643]]\n",
      "--------------------------------\n",
      "val predicted: (59970,) ['7' '0' '9' ... '7' '0' '7']\n",
      "probabilities: (59970, 10) \n",
      " [7 0 9 ... 7 0 7]\n",
      "trainset before (30, 784) (30,)\n",
      "trainset after (40, 784) (40,)\n",
      "updated train set: (40, 784) (40,) unique(labels): [4 3 2 4 8 5 5 3 2 4] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59960, 784) (59960,)\n",
      "\n",
      "Train set: (40, 784) y: (40,)\n",
      "Val   set: (59960, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.115 s \n",
      "\n",
      "Accuracy rate for 58.170000 \n",
      "Classification report for classifier LogisticRegression(C=1.25, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.90      0.68       980\n",
      "           1       0.79      0.93      0.85      1135\n",
      "           2       0.54      0.52      0.53      1032\n",
      "           3       0.55      0.41      0.47      1010\n",
      "           4       0.74      0.46      0.57       982\n",
      "           5       0.41      0.18      0.25       892\n",
      "           6       0.69      0.80      0.74       958\n",
      "           7       0.49      0.75      0.59      1028\n",
      "           8       0.37      0.21      0.27       974\n",
      "           9       0.56      0.57      0.56      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.57      0.57      0.55     10000\n",
      "weighted avg       0.57      0.58      0.56     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 883    0   13    4    0    0   52   24    3    1]\n",
      " [   0 1054   40    3    0    1    9   27    1    0]\n",
      " [  93   69  536   19    2    0  159   65   84    5]\n",
      " [ 224   43   22  416    1   90   40   62   81   31]\n",
      " [   0   17  116   25  450    3   19  107   31  214]\n",
      " [ 278   17   24  116   38  160   33  115   81   30]\n",
      " [  62    8   88   14    8    1  771    2    1    3]\n",
      " [   2   37   14   44   12    0    5  767   43  104]\n",
      " [  71   74  142   83    6  131   34  156  207   70]\n",
      " [  14   14    5   38   93    9    3  226   34  573]]\n",
      "--------------------------------\n",
      "val predicted: (59960,) ['7' '0' '9' ... '7' '0' '7']\n",
      "probabilities: (59960, 10) \n",
      " [7 0 9 ... 7 0 7]\n",
      "trainset before (40, 784) (40,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [ 4  3  2  6 11  5  5  3  6  5] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.119 s \n",
      "\n",
      "Accuracy rate for 62.400000 \n",
      "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.84      0.71       980\n",
      "           1       0.81      0.92      0.86      1135\n",
      "           2       0.41      0.61      0.49      1032\n",
      "           3       0.49      0.55      0.51      1010\n",
      "           4       0.81      0.56      0.66       982\n",
      "           5       0.59      0.14      0.23       892\n",
      "           6       0.75      0.70      0.72       958\n",
      "           7       0.65      0.74      0.69      1028\n",
      "           8       0.56      0.59      0.58       974\n",
      "           9       0.72      0.49      0.58      1009\n",
      "\n",
      "    accuracy                           0.62     10000\n",
      "   macro avg       0.64      0.62      0.61     10000\n",
      "weighted avg       0.64      0.62      0.61     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 823    1   99    2    1    1   36    4   12    1]\n",
      " [   0 1047   74    6    0    0    4    3    1    0]\n",
      " [  60   79  631   26    3    2  121   40   69    1]\n",
      " [ 162   30   58  553    0   50   19   12  111   15]\n",
      " [   0   18  225   52  551    3    3   28    9   93]\n",
      " [ 203   10   63  178   47  129   21   55  181    5]\n",
      " [  48    4  146   54   29    1  672    0    4    0]\n",
      " [   7   37   29  103    2    0    3  762   12   73]\n",
      " [  23   48  171   81    4   17   16   30  577    7]\n",
      " [   4   14   60   85   45   17    3  232   54  495]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['0' '0' '4' ... '8' '2' '2']\n",
      "probabilities: (59950, 10) \n",
      " [0 0 4 ... 8 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (50, 784) (50,)\n",
      "trainset after (60, 784) (60,)\n",
      "updated train set: (60, 784) (60,) unique(labels): [ 4  3  4  8 11  6  5  4  9  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59940, 784) (59940,)\n",
      "\n",
      "Train set: (60, 784) y: (60,)\n",
      "Val   set: (59940, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.124 s \n",
      "\n",
      "Accuracy rate for 64.950000 \n",
      "Classification report for classifier LogisticRegression(C=0.8333333333333334, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.76       980\n",
      "           1       0.84      0.87      0.86      1135\n",
      "           2       0.52      0.66      0.58      1032\n",
      "           3       0.51      0.37      0.43      1010\n",
      "           4       0.74      0.66      0.70       982\n",
      "           5       0.38      0.34      0.36       892\n",
      "           6       0.75      0.76      0.75       958\n",
      "           7       0.78      0.80      0.79      1028\n",
      "           8       0.55      0.59      0.57       974\n",
      "           9       0.67      0.53      0.59      1009\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.64      0.64      0.64     10000\n",
      "weighted avg       0.65      0.65      0.64     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[835   0   5   1   4  41  68  18   7   1]\n",
      " [  0 988 128   1   0   1   4   2  10   1]\n",
      " [ 93  53 679  23  28  17  72  31  35   1]\n",
      " [ 89  25  20 375   1 292  36  18 141  13]\n",
      " [  2  19 100  29 653   8  14  15  20 122]\n",
      " [122  10  47 115  50 303  33  22 162  28]\n",
      " [ 53   3  83  40  31   8 726   1  13   0]\n",
      " [  1  32  43   5   6   7   4 823  25  82]\n",
      " [ 26  29 117  72   7 110  12  12 579  10]\n",
      " [  4  11  82  78 101  18   3 110  68 534]]\n",
      "--------------------------------\n",
      "val predicted: (59940,) ['5' '0' '4' ... '8' '0' '5']\n",
      "probabilities: (59940, 10) \n",
      " [5 0 4 ... 8 0 5]\n",
      "trainset before (60, 784) (60,)\n",
      "trainset after (70, 784) (70,)\n",
      "updated train set: (70, 784) (70,) unique(labels): [ 5  3  4  9 13  8  7  4 10  7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59930, 784) (59930,)\n",
      "\n",
      "Train set: (70, 784) y: (70,)\n",
      "Val   set: (59930, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.123 s \n",
      "\n",
      "Accuracy rate for 67.800000 \n",
      "Classification report for classifier LogisticRegression(C=0.7142857142857143, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.89      0.70       980\n",
      "           1       0.84      0.88      0.86      1135\n",
      "           2       0.56      0.70      0.62      1032\n",
      "           3       0.63      0.59      0.61      1010\n",
      "           4       0.71      0.69      0.70       982\n",
      "           5       0.59      0.34      0.43       892\n",
      "           6       0.82      0.56      0.67       958\n",
      "           7       0.79      0.82      0.80      1028\n",
      "           8       0.61      0.60      0.60       974\n",
      "           9       0.72      0.64      0.68      1009\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.68      0.67      0.67     10000\n",
      "weighted avg       0.69      0.68      0.67     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 873    1   12    2    1   46   23   21    0    1]\n",
      " [   0 1003   95    1    0    0    5    2   29    0]\n",
      " [  73   66  724   15   43    3   38   34   31    5]\n",
      " [ 162   18   25  599    2   43   16   18  118    9]\n",
      " [   1   13   61   27  674   16    9   13   22  146]\n",
      " [ 269    4   37   86   27  304   15   19  101   30]\n",
      " [  76    8  132   44  138    9  539    0   10    2]\n",
      " [  10   39   50   12    6    2    1  840   20   48]\n",
      " [  32   39  103  106    4   70   13   13  580   14]\n",
      " [  19   10   57   62   51   20    1  100   45  644]]\n",
      "--------------------------------\n",
      "val predicted: (59930,) ['3' '0' '4' ... '8' '0' '2']\n",
      "probabilities: (59930, 10) \n",
      " [3 0 4 ... 8 0 2]\n",
      "trainset before (70, 784) (70,)\n",
      "trainset after (80, 784) (80,)\n",
      "updated train set: (80, 784) (80,) unique(labels): [ 5  4  5 10 14  9  8  6 11  8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59920, 784) (59920,)\n",
      "\n",
      "Train set: (80, 784) y: (80,)\n",
      "Val   set: (59920, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.122 s \n",
      "\n",
      "Accuracy rate for 68.770000 \n",
      "Classification report for classifier LogisticRegression(C=0.625, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.72       980\n",
      "           1       0.81      0.85      0.83      1135\n",
      "           2       0.50      0.74      0.60      1032\n",
      "           3       0.73      0.60      0.66      1010\n",
      "           4       0.78      0.71      0.74       982\n",
      "           5       0.59      0.40      0.48       892\n",
      "           6       0.87      0.57      0.69       958\n",
      "           7       0.78      0.80      0.79      1028\n",
      "           8       0.66      0.57      0.61       974\n",
      "           9       0.72      0.70      0.71      1009\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.70      0.68      0.68     10000\n",
      "weighted avg       0.70      0.69      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[866   1  55   3   0  30   4  18   2   1]\n",
      " [  0 964 157   1   1   2   2   2   6   0]\n",
      " [ 81  66 760  21  23   4  18  29  26   4]\n",
      " [129  29  43 603   2  43   6  13 118  24]\n",
      " [  2  13  38  10 700  28  19  37   6 129]\n",
      " [229  19  54  55  18 357   7  31  76  46]\n",
      " [ 75   9 172  20  99  30 549   1   2   1]\n",
      " [ 13  37  80   5   4   3   0 822  22  42]\n",
      " [ 34  41 107  87   4  80  23  13 553  32]\n",
      " [ 11   9  56  25  51  27   4  93  30 703]]\n",
      "--------------------------------\n",
      "val predicted: (59920,) ['0' '0' '4' ... '9' '0' '5']\n",
      "probabilities: (59920, 10) \n",
      " [0 0 4 ... 9 0 5]\n",
      "trainset before (80, 784) (80,)\n",
      "trainset after (90, 784) (90,)\n",
      "updated train set: (90, 784) (90,) unique(labels): [ 5  4  5 13 16  9  9  6 12 11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59910, 784) (59910,)\n",
      "\n",
      "Train set: (90, 784) y: (90,)\n",
      "Val   set: (59910, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.131 s \n",
      "\n",
      "Accuracy rate for 69.850000 \n",
      "Classification report for classifier LogisticRegression(C=0.5555555555555556, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.87      0.76       980\n",
      "           1       0.79      0.85      0.82      1135\n",
      "           2       0.54      0.66      0.59      1032\n",
      "           3       0.68      0.66      0.67      1010\n",
      "           4       0.80      0.67      0.73       982\n",
      "           5       0.53      0.44      0.48       892\n",
      "           6       0.82      0.80      0.81       958\n",
      "           7       0.78      0.84      0.81      1028\n",
      "           8       0.70      0.48      0.57       974\n",
      "           9       0.69      0.67      0.68      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.69      0.69     10000\n",
      "weighted avg       0.70      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[853   2  43   2   0  49   9  20   0   2]\n",
      " [  0 965 157   2   0   1   5   1   4   0]\n",
      " [ 43  67 677 121  18   2  53  31  17   3]\n",
      " [ 84  38  33 670   5  65   6  13  83  13]\n",
      " [  0  10  46   1 657  39  23  38   8 160]\n",
      " [209  19  49  80  25 389  14  25  38  44]\n",
      " [ 39  11  77   2  32  24 770   2   0   1]\n",
      " [ 15  35  57   3   8   6   2 860  16  26]\n",
      " [ 25  59  73  98  11 120  56  11 466  55]\n",
      " [  6  13  40  13  68  44   6 106  35 678]]\n",
      "--------------------------------\n",
      "val predicted: (59910,) ['3' '0' '4' ... '5' '5' '5']\n",
      "probabilities: (59910, 10) \n",
      " [3 0 4 ... 5 5 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (90, 784) (90,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 5  5  5 14 17 10  9  6 15 14] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.137 s \n",
      "\n",
      "Accuracy rate for 70.790000 \n",
      "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77       980\n",
      "           1       0.76      0.94      0.84      1135\n",
      "           2       0.61      0.59      0.60      1032\n",
      "           3       0.71      0.69      0.70      1010\n",
      "           4       0.69      0.76      0.72       982\n",
      "           5       0.58      0.37      0.45       892\n",
      "           6       0.78      0.80      0.79       958\n",
      "           7       0.72      0.83      0.78      1028\n",
      "           8       0.70      0.64      0.67       974\n",
      "           9       0.79      0.50      0.62      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.70      0.70      0.69     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 874    2   42    1    3   24   20   14    0    0]\n",
      " [   0 1069   46    2    0    1    4    1   12    0]\n",
      " [  48  118  607   78   32    3   62   42   41    1]\n",
      " [  85   27   25  699    5   50    9   12   87   11]\n",
      " [   0   17   29    1  745   36   23   49   12   70]\n",
      " [ 202   14   49  108   46  327   24   33   67   22]\n",
      " [  35    8   75    2   36   31  766    1    4    0]\n",
      " [  17   62   33    3   12    4    5  857   12   23]\n",
      " [  19   67   53   74    8   50   56   12  626    9]\n",
      " [  13   15   35   11  187   41    9  162   27  509]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '4' ... '5' '0' '5']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 4 ... 5 0 5]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (110, 784) (110,)\n",
      "updated train set: (110, 784) (110,) unique(labels): [ 5  5  5 16 19 12 10  7 16 15] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59890, 784) (59890,)\n",
      "\n",
      "Train set: (110, 784) y: (110,)\n",
      "Val   set: (59890, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.132 s \n",
      "\n",
      "Accuracy rate for 72.050000 \n",
      "Classification report for classifier LogisticRegression(C=0.45454545454545453, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.80       980\n",
      "           1       0.74      0.95      0.83      1135\n",
      "           2       0.63      0.58      0.60      1032\n",
      "           3       0.76      0.71      0.73      1010\n",
      "           4       0.71      0.75      0.73       982\n",
      "           5       0.59      0.48      0.53       892\n",
      "           6       0.81      0.77      0.79       958\n",
      "           7       0.69      0.86      0.77      1028\n",
      "           8       0.77      0.63      0.69       974\n",
      "           9       0.82      0.52      0.63      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.72      0.72      0.71     10000\n",
      "weighted avg       0.72      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 896    2   33    1    3   23    6   13    3    0]\n",
      " [   0 1074   41    3    0    0    7    2    8    0]\n",
      " [  42  132  599   37   29    5   43  101   43    1]\n",
      " [  64   25   24  715   10   83    8   17   54   10]\n",
      " [   1   19   33    1  741   35   20   54    7   71]\n",
      " [ 171   16   47   89   45  428   26   18   40   12]\n",
      " [  52   10   81    3   33   35  735    4    5    0]\n",
      " [  16   60   22    1   12    4    7  884    3   19]\n",
      " [  18   92   35   76    7   64   47   19  611    5]\n",
      " [   9   19   39   15  166   53    3  165   18  522]]\n",
      "--------------------------------\n",
      "val predicted: (59890,) ['3' '0' '4' ... '5' '0' '5']\n",
      "probabilities: (59890, 10) \n",
      " [3 0 4 ... 5 0 5]\n",
      "trainset before (110, 784) (110,)\n",
      "trainset after (120, 784) (120,)\n",
      "updated train set: (120, 784) (120,) unique(labels): [ 5  5  6 16 20 15 10  8 18 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59880, 784) (59880,)\n",
      "\n",
      "Train set: (120, 784) y: (120,)\n",
      "Val   set: (59880, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.137 s \n",
      "\n",
      "Accuracy rate for 70.410000 \n",
      "Classification report for classifier LogisticRegression(C=0.4166666666666667, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.92      0.76       980\n",
      "           1       0.79      0.90      0.84      1135\n",
      "           2       0.58      0.68      0.62      1032\n",
      "           3       0.74      0.64      0.69      1010\n",
      "           4       0.66      0.79      0.72       982\n",
      "           5       0.70      0.30      0.42       892\n",
      "           6       0.80      0.75      0.77       958\n",
      "           7       0.74      0.82      0.78      1028\n",
      "           8       0.69      0.63      0.66       974\n",
      "           9       0.74      0.56      0.64      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.70      0.69     10000\n",
      "weighted avg       0.71      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 899    3   46    0    5    6    7   13    1    0]\n",
      " [   0 1021   92    2    0    1   12    1    6    0]\n",
      " [  55   86  697   37   40    1   35   56   20    5]\n",
      " [ 117   24   27  647   10   33   11   27  102   12]\n",
      " [   1   12   21    1  771   25   25   38    5   83]\n",
      " [ 206   11   73   97   50  266   22   27  104   36]\n",
      " [  48   12  108    4   58   10  716    2    0    0]\n",
      " [  19   56   35    1   20    1    6  844    8   38]\n",
      " [  21   56   86   77    9   20   53   19  611   22]\n",
      " [  10   13   23   11  206   19   10  119   29  569]]\n",
      "--------------------------------\n",
      "val predicted: (59880,) ['3' '0' '4' ... '9' '4' '2']\n",
      "probabilities: (59880, 10) \n",
      " [3 0 4 ... 9 4 2]\n",
      "trainset before (120, 784) (120,)\n",
      "trainset after (130, 784) (130,)\n",
      "updated train set: (130, 784) (130,) unique(labels): [ 7  5  8 17 21 17 10  9 18 18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59870, 784) (59870,)\n",
      "\n",
      "Train set: (130, 784) y: (130,)\n",
      "Val   set: (59870, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.149 s \n",
      "\n",
      "Accuracy rate for 67.300000 \n",
      "Classification report for classifier LogisticRegression(C=0.38461538461538464, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.91      0.75       980\n",
      "           1       0.79      0.92      0.85      1135\n",
      "           2       0.49      0.63      0.55      1032\n",
      "           3       0.76      0.50      0.60      1010\n",
      "           4       0.66      0.76      0.71       982\n",
      "           5       0.58      0.30      0.39       892\n",
      "           6       0.82      0.48      0.61       958\n",
      "           7       0.69      0.85      0.76      1028\n",
      "           8       0.65      0.64      0.65       974\n",
      "           9       0.74      0.65      0.69      1009\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.68      0.67      0.66     10000\n",
      "weighted avg       0.68      0.67      0.66     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 889    3   69    0    2    2    7    8    0    0]\n",
      " [   0 1047   69    1    0    2    6    1    9    0]\n",
      " [  76   92  654   12   25    1   21  116   30    5]\n",
      " [ 168   23   59  505    9   66    7   24  129   20]\n",
      " [   0   12   24    0  749   23   12   48    4  110]\n",
      " [ 165   12  118   76   47  268   10   23  133   40]\n",
      " [  63    7  209    2  149   60  464    3    1    0]\n",
      " [   3   52   23    0   22    2    6  872    5   43]\n",
      " [  23   63   87   65   10   30   28   25  625   18]\n",
      " [  11   12   14    7  123   12    7  145   21  657]]\n",
      "--------------------------------\n",
      "val predicted: (59870,) ['3' '0' '4' ... '9' '0' '2']\n",
      "probabilities: (59870, 10) \n",
      " [3 0 4 ... 9 0 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (130, 784) (130,)\n",
      "trainset after (140, 784) (140,)\n",
      "updated train set: (140, 784) (140,) unique(labels): [ 7  5 10 18 22 20 10 10 19 19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59860, 784) (59860,)\n",
      "\n",
      "Train set: (140, 784) y: (140,)\n",
      "Val   set: (59860, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.140 s \n",
      "\n",
      "Accuracy rate for 72.040000 \n",
      "Classification report for classifier LogisticRegression(C=0.35714285714285715, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83       980\n",
      "           1       0.75      0.97      0.84      1135\n",
      "           2       0.61      0.61      0.61      1032\n",
      "           3       0.78      0.56      0.65      1010\n",
      "           4       0.72      0.78      0.75       982\n",
      "           5       0.70      0.42      0.52       892\n",
      "           6       0.77      0.77      0.77       958\n",
      "           7       0.74      0.81      0.77      1028\n",
      "           8       0.62      0.64      0.63       974\n",
      "           9       0.74      0.69      0.72      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.72      0.71      0.71     10000\n",
      "weighted avg       0.72      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 880    3   36    0    3    6   23    6   21    2]\n",
      " [   0 1100   19    2    1    1    8    1    3    0]\n",
      " [  39   98  629   14   48    2   64   97   30   11]\n",
      " [  67   40   87  565    8   61    6   28  136   12]\n",
      " [   1   15    2    1  766   16   43   38    6   94]\n",
      " [  94   20   68   79   45  373   27   13  135   38]\n",
      " [  44   15   53    5   55   39  740    6    0    1]\n",
      " [   5   71   17    5   16    1    3  829   13   68]\n",
      " [  13   96  107   44    9   18   36   13  621   17]\n",
      " [   7   18    9    6  117   16    7   91   37  701]]\n",
      "--------------------------------\n",
      "val predicted: (59860,) ['3' '0' '4' ... '5' '0' '5']\n",
      "probabilities: (59860, 10) \n",
      " [3 0 4 ... 5 0 5]\n",
      "trainset before (140, 784) (140,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [ 8  6 10 18 22 21 11 10 24 20] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.140 s \n",
      "\n",
      "Accuracy rate for 71.220000 \n",
      "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.92      0.77       980\n",
      "           1       0.74      0.97      0.84      1135\n",
      "           2       0.56      0.69      0.62      1032\n",
      "           3       0.76      0.63      0.69      1010\n",
      "           4       0.76      0.77      0.77       982\n",
      "           5       0.66      0.34      0.45       892\n",
      "           6       0.74      0.77      0.75       958\n",
      "           7       0.76      0.83      0.79      1028\n",
      "           8       0.83      0.39      0.53       974\n",
      "           9       0.73      0.73      0.73      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.70      0.69     10000\n",
      "weighted avg       0.72      0.71      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 901    2   54    0    0    1   18    3    0    1]\n",
      " [   0 1105   12    5    0    1   11    1    0    0]\n",
      " [  56   95  716   13   26    2   39   71    7    7]\n",
      " [ 111   35   83  632    7   68    6   25   24   19]\n",
      " [   1   14    5    1  760   20   52   35    1   93]\n",
      " [ 173   19   88  102   43  305   42   11   40   69]\n",
      " [  50   10  100    0   33   24  736    5    0    0]\n",
      " [   7   76   21    7   17    2    6  852    1   39]\n",
      " [  39  123  193   59   12   24   75   29  380   40]\n",
      " [   9   16    9   13  100   17   13   90    7  735]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['3' '0' '4' ... '9' '0' '8']\n",
      "probabilities: (59850, 10) \n",
      " [3 0 4 ... 9 0 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (160, 784) (160,)\n",
      "updated train set: (160, 784) (160,) unique(labels): [ 8  6 10 20 22 23 12 12 27 20] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59840, 784) (59840,)\n",
      "\n",
      "Train set: (160, 784) y: (160,)\n",
      "Val   set: (59840, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.141 s \n",
      "\n",
      "Accuracy rate for 71.870000 \n",
      "Classification report for classifier LogisticRegression(C=0.3125, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.93      0.77       980\n",
      "           1       0.79      0.98      0.87      1135\n",
      "           2       0.57      0.75      0.65      1032\n",
      "           3       0.79      0.53      0.64      1010\n",
      "           4       0.75      0.77      0.76       982\n",
      "           5       0.68      0.32      0.44       892\n",
      "           6       0.78      0.73      0.75       958\n",
      "           7       0.75      0.85      0.80      1028\n",
      "           8       0.71      0.54      0.61       974\n",
      "           9       0.77      0.71      0.74      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.72      0.71      0.70     10000\n",
      "weighted avg       0.72      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 907    2   39    0    2    1   23    5    0    1]\n",
      " [   0 1108    5    7    0    1    6    1    7    0]\n",
      " [  60   64  773    3   20    1   32   63    4   12]\n",
      " [ 147   26  133  537   10   47    7   21   66   16]\n",
      " [   1   13    4    1  758   21   40   48    5   91]\n",
      " [ 171   14   91   54   52  287   29   27  115   52]\n",
      " [  46    8  111    3   53   29  700    6    2    0]\n",
      " [   6   71   20    8   12    2    3  874    2   30]\n",
      " [  22   85  174   55    6   17   52   23  522   18]\n",
      " [  12   15   12    9  102   16    7  101   14  721]]\n",
      "--------------------------------\n",
      "val predicted: (59840,) ['3' '0' '4' ... '9' '0' '5']\n",
      "probabilities: (59840, 10) \n",
      " [3 0 4 ... 9 0 5]\n",
      "trainset before (160, 784) (160,)\n",
      "trainset after (170, 784) (170,)\n",
      "updated train set: (170, 784) (170,) unique(labels): [ 8  6 10 20 22 26 14 12 29 23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59830, 784) (59830,)\n",
      "\n",
      "Train set: (170, 784) y: (170,)\n",
      "Val   set: (59830, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.153 s \n",
      "\n",
      "Accuracy rate for 69.640000 \n",
      "Classification report for classifier LogisticRegression(C=0.29411764705882354, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.94      0.76       980\n",
      "           1       0.78      0.97      0.86      1135\n",
      "           2       0.55      0.72      0.62      1032\n",
      "           3       0.80      0.51      0.62      1010\n",
      "           4       0.70      0.77      0.73       982\n",
      "           5       0.69      0.39      0.50       892\n",
      "           6       0.74      0.73      0.73       958\n",
      "           7       0.70      0.85      0.76      1028\n",
      "           8       0.77      0.42      0.55       974\n",
      "           9       0.71      0.61      0.66      1009\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.69      0.68     10000\n",
      "weighted avg       0.71      0.70      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 917    2   41    0    2    1    7    8    0    2]\n",
      " [   0 1102   10   13    0    1    8    1    0    0]\n",
      " [  61   60  743    2   30    1   42   82    5    6]\n",
      " [ 169   26  139  512   10   61    6   22   45   20]\n",
      " [   3   13    4    1  753   31   54   52    3   68]\n",
      " [ 186   17   92   42   47  350   20   16   53   69]\n",
      " [  42    8  112    0   85    8  695    8    0    0]\n",
      " [   6   66   23   10    7    2    1  869    2   42]\n",
      " [  30  108  184   46    9   18  104   25  410   40]\n",
      " [   7   16   10   17  137   34    2  161   12  613]]\n",
      "--------------------------------\n",
      "val predicted: (59830,) ['3' '0' '4' ... '5' '0' '5']\n",
      "probabilities: (59830, 10) \n",
      " [3 0 4 ... 5 0 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (170, 784) (170,)\n",
      "trainset after (180, 784) (180,)\n",
      "updated train set: (180, 784) (180,) unique(labels): [ 9  6 11 21 24 26 15 13 30 25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59820, 784) (59820,)\n",
      "\n",
      "Train set: (180, 784) y: (180,)\n",
      "Val   set: (59820, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.139 s \n",
      "\n",
      "Accuracy rate for 71.570000 \n",
      "Classification report for classifier LogisticRegression(C=0.2777777777777778, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.95      0.80       980\n",
      "           1       0.73      0.98      0.84      1135\n",
      "           2       0.57      0.70      0.63      1032\n",
      "           3       0.79      0.67      0.73      1010\n",
      "           4       0.71      0.76      0.74       982\n",
      "           5       0.75      0.44      0.56       892\n",
      "           6       0.74      0.67      0.70       958\n",
      "           7       0.72      0.85      0.78      1028\n",
      "           8       0.85      0.40      0.55       974\n",
      "           9       0.74      0.67      0.70      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.71      0.70     10000\n",
      "weighted avg       0.73      0.72      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 932    2   29    0    0    2    9    6    0    0]\n",
      " [   0 1109   10    9    0    1    5    1    0    0]\n",
      " [  52  104  720    6   23    2   27   89    1    8]\n",
      " [ 108   38   78  674    7   35    7   23   27   13]\n",
      " [   1   20    4    1  750   20   62   32    0   92]\n",
      " [ 163   17   76   83   42  396   17   18   32   48]\n",
      " [  52   13  136    2   89   18  641    7    0    0]\n",
      " [  10   71   24    6   12    1    3  869    1   31]\n",
      " [  32  121  171   56   23   22   88   27  391   43]\n",
      " [  11   21   10   12  105   31    6  132    6  675]]\n",
      "--------------------------------\n",
      "val predicted: (59820,) ['3' '0' '4' ... '5' '5' '5']\n",
      "probabilities: (59820, 10) \n",
      " [3 0 4 ... 5 5 5]\n",
      "trainset before (180, 784) (180,)\n",
      "trainset after (190, 784) (190,)\n",
      "updated train set: (190, 784) (190,) unique(labels): [10  6 11 24 24 28 16 14 32 25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59810, 784) (59810,)\n",
      "\n",
      "Train set: (190, 784) y: (190,)\n",
      "Val   set: (59810, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.158 s \n",
      "\n",
      "Accuracy rate for 71.790000 \n",
      "Classification report for classifier LogisticRegression(C=0.2631578947368421, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82       980\n",
      "           1       0.79      0.97      0.87      1135\n",
      "           2       0.57      0.70      0.63      1032\n",
      "           3       0.78      0.65      0.71      1010\n",
      "           4       0.71      0.79      0.75       982\n",
      "           5       0.64      0.41      0.50       892\n",
      "           6       0.79      0.68      0.73       958\n",
      "           7       0.69      0.86      0.77      1028\n",
      "           8       0.70      0.54      0.61       974\n",
      "           9       0.83      0.56      0.67      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.72      0.71      0.70     10000\n",
      "weighted avg       0.72      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 929    2   25    0    1    2    4   12    5    0]\n",
      " [   0 1105    4   16    0    1    6    2    1    0]\n",
      " [  38   74  722    8   31    3   34   97   16    9]\n",
      " [  75   25   93  659    4   51   13   25   59    6]\n",
      " [   3   17    7    2  775   33   51   49    3   42]\n",
      " [ 126   14   97   85   38  364   17   24  111   16]\n",
      " [  70   11  114    1   68   42  650    2    0    0]\n",
      " [  18   47   25    8   19    2    3  881    3   22]\n",
      " [  24   88  172   48    9   34   38   15  526   20]\n",
      " [  13   13   11   19  151   39    3  165   27  568]]\n",
      "--------------------------------\n",
      "val predicted: (59810,) ['3' '0' '4' ... '5' '5' '5']\n",
      "probabilities: (59810, 10) \n",
      " [3 0 4 ... 5 5 5]\n",
      "trainset before (190, 784) (190,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [10  6 13 26 27 29 17 15 32 25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.151 s \n",
      "\n",
      "Accuracy rate for 72.660000 \n",
      "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.83       980\n",
      "           1       0.73      0.98      0.83      1135\n",
      "           2       0.63      0.68      0.65      1032\n",
      "           3       0.71      0.68      0.70      1010\n",
      "           4       0.76      0.76      0.76       982\n",
      "           5       0.75      0.38      0.50       892\n",
      "           6       0.79      0.75      0.77       958\n",
      "           7       0.69      0.85      0.76      1028\n",
      "           8       0.75      0.54      0.63       974\n",
      "           9       0.80      0.61      0.69      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.73      0.72      0.71     10000\n",
      "weighted avg       0.73      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 948    2   16    0    1    2    3    6    2    0]\n",
      " [   0 1107    3   16    0    1    5    1    2    0]\n",
      " [  31  128  700    6   17    1   38   97    6    8]\n",
      " [  69   26   96  688    3   31    8   27   52   10]\n",
      " [   3   24    3    3  747   16   57   72    3   54]\n",
      " [ 129   19   85  134   38  335   19   26   80   27]\n",
      " [  76   12   86    3   29   22  723    5    2    0]\n",
      " [  21   62   20    6   14    1    0  874    4   26]\n",
      " [  22  120   97   87    8   12   61   14  528   25]\n",
      " [  15   24   10   26  123   28    3  143   21  616]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['3' '0' '4' ... '5' '5' '5']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 4 ... 5 5 5]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (210, 784) (210,)\n",
      "updated train set: (210, 784) (210,) unique(labels): [10  7 14 27 29 30 17 16 33 27] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59790, 784) (59790,)\n",
      "\n",
      "Train set: (210, 784) y: (210,)\n",
      "Val   set: (59790, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 21\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.164 s \n",
      "\n",
      "Accuracy rate for 72.860000 \n",
      "Classification report for classifier LogisticRegression(C=0.23809523809523808, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81       980\n",
      "           1       0.72      0.98      0.83      1135\n",
      "           2       0.66      0.64      0.65      1032\n",
      "           3       0.74      0.67      0.70      1010\n",
      "           4       0.75      0.77      0.76       982\n",
      "           5       0.74      0.44      0.55       892\n",
      "           6       0.78      0.77      0.77       958\n",
      "           7       0.70      0.85      0.76      1028\n",
      "           8       0.77      0.54      0.63       974\n",
      "           9       0.81      0.60      0.69      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.72      0.72     10000\n",
      "weighted avg       0.73      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 953    3    6    1    1    3    5    8    0    0]\n",
      " [   0 1111    3   12    0    1    7    1    0    0]\n",
      " [  58  107  664   12   28    3   48   90   14    8]\n",
      " [  80   36   66  677    3   39    4   31   61   13]\n",
      " [   3   33    5    4  754   14   57   46   15   51]\n",
      " [ 137   30   59  114   50  394   20   27   39   22]\n",
      " [  84   16   59    0   27   33  733    5    1    0]\n",
      " [  13   54   40    2   20    1    4  872    6   16]\n",
      " [  25  123  100   77   12   24   53   10  522   28]\n",
      " [  12   40    8   16  112   21    7  164   23  606]]\n",
      "--------------------------------\n",
      "val predicted: (59790,) ['3' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59790, 10) \n",
      " [3 0 4 ... 5 0 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (210, 784) (210,)\n",
      "trainset after (220, 784) (220,)\n",
      "updated train set: (220, 784) (220,) unique(labels): [10  7 15 27 30 31 18 16 36 30] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59780, 784) (59780,)\n",
      "\n",
      "Train set: (220, 784) y: (220,)\n",
      "Val   set: (59780, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 22\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.155 s \n",
      "\n",
      "Accuracy rate for 73.130000 \n",
      "Classification report for classifier LogisticRegression(C=0.22727272727272727, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84       980\n",
      "           1       0.71      0.98      0.83      1135\n",
      "           2       0.68      0.68      0.68      1032\n",
      "           3       0.71      0.72      0.72      1010\n",
      "           4       0.70      0.78      0.74       982\n",
      "           5       0.84      0.38      0.53       892\n",
      "           6       0.76      0.79      0.78       958\n",
      "           7       0.68      0.86      0.76      1028\n",
      "           8       0.80      0.53      0.64       974\n",
      "           9       0.83      0.55      0.66      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.75      0.72      0.72     10000\n",
      "weighted avg       0.74      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 949    3    5    1    2    0    9   11    0    0]\n",
      " [   0 1112    4    9    0    0    6    1    3    0]\n",
      " [  27  106  706   11   22    1   52   93    9    5]\n",
      " [  70   28   67  729    7   21    7   27   43   11]\n",
      " [   1   32    2    5  764    8   70   62    8   30]\n",
      " [ 127   26   54  159   65  341   27   31   37   25]\n",
      " [  69   14   60    3   23   18  756    6    9    0]\n",
      " [  11   60   26    4   21    0    5  884    5   12]\n",
      " [  23  132  103   77   19   12   48   12  514   34]\n",
      " [  11   44    4   25  164    5    9  173   16  558]]\n",
      "--------------------------------\n",
      "val predicted: (59780,) ['3' '0' '4' ... '5' '5' '5']\n",
      "probabilities: (59780, 10) \n",
      " [3 0 4 ... 5 5 5]\n",
      "trainset before (220, 784) (220,)\n",
      "trainset after (230, 784) (230,)\n",
      "updated train set: (230, 784) (230,) unique(labels): [10  7 17 28 31 32 18 17 39 31] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59770, 784) (59770,)\n",
      "\n",
      "Train set: (230, 784) y: (230,)\n",
      "Val   set: (59770, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 23\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.163 s \n",
      "\n",
      "Accuracy rate for 71.530000 \n",
      "Classification report for classifier LogisticRegression(C=0.21739130434782608, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.73       980\n",
      "           1       0.68      0.98      0.80      1135\n",
      "           2       0.76      0.54      0.63      1032\n",
      "           3       0.75      0.68      0.71      1010\n",
      "           4       0.70      0.81      0.75       982\n",
      "           5       0.68      0.44      0.53       892\n",
      "           6       0.75      0.74      0.74       958\n",
      "           7       0.76      0.80      0.78      1028\n",
      "           8       0.85      0.51      0.64       974\n",
      "           9       0.82      0.61      0.70      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.71      0.70     10000\n",
      "weighted avg       0.73      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 967    2    1    1    1    1    3    4    0    0]\n",
      " [   1 1112    1   11    0    1    7    1    1    0]\n",
      " [  87  157  555    7   45    2   82   85    8    4]\n",
      " [ 114   35   49  683    4   46    9   15   40   15]\n",
      " [   8   30    1    4  798   18   52   31    4   36]\n",
      " [ 218   33   14  107   48  389   30    8   23   22]\n",
      " [ 140   13   22    3   19   43  711    4    3    0]\n",
      " [  49   74   18    3   26    1    3  826    5   23]\n",
      " [  39  139   70   76   14   42   47   11  498   38]\n",
      " [  29   42    2   11  177   25    8   95    6  614]]\n",
      "--------------------------------\n",
      "val predicted: (59770,) ['3' '0' '4' ... '5' '0' '5']\n",
      "probabilities: (59770, 10) \n",
      " [3 0 4 ... 5 0 5]\n",
      "trainset before (230, 784) (230,)\n",
      "trainset after (240, 784) (240,)\n",
      "updated train set: (240, 784) (240,) unique(labels): [10  7 17 32 31 36 18 17 41 31] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59760, 784) (59760,)\n",
      "\n",
      "Train set: (240, 784) y: (240,)\n",
      "Val   set: (59760, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 24\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.160 s \n",
      "\n",
      "Accuracy rate for 72.170000 \n",
      "Classification report for classifier LogisticRegression(C=0.20833333333333334, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82       980\n",
      "           1       0.68      0.98      0.80      1135\n",
      "           2       0.65      0.62      0.63      1032\n",
      "           3       0.70      0.65      0.68      1010\n",
      "           4       0.73      0.79      0.76       982\n",
      "           5       0.87      0.28      0.43       892\n",
      "           6       0.76      0.82      0.79       958\n",
      "           7       0.73      0.85      0.78      1028\n",
      "           8       0.71      0.59      0.64       974\n",
      "           9       0.84      0.59      0.70      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.71      0.70     10000\n",
      "weighted avg       0.74      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 948    3    9    0    2    1    9    8    0    0]\n",
      " [   1 1115    3    5    0    0    6    1    4    0]\n",
      " [  41  155  641    5   26    0   63   82   14    5]\n",
      " [  76   45  108  659    4   14    9   25   59   11]\n",
      " [   2   31    3    6  777    4   63   48    8   40]\n",
      " [ 136   33   84  157   52  251   30   22  111   16]\n",
      " [  79   16   47    1   14   10  782    4    5    0]\n",
      " [  17   69   24    3   15    0    3  874    7   16]\n",
      " [  26  131   63   80   11    3   52   12  573   23]\n",
      " [  15   44    6   20  163    4    8  126   26  597]]\n",
      "--------------------------------\n",
      "val predicted: (59760,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59760, 10) \n",
      " [3 0 4 ... 5 0 9]\n",
      "trainset before (240, 784) (240,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [10  7 17 33 32 38 18 18 44 33] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 25\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.155 s \n",
      "\n",
      "Accuracy rate for 71.790000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.85       980\n",
      "           1       0.68      0.98      0.80      1135\n",
      "           2       0.66      0.60      0.63      1032\n",
      "           3       0.70      0.65      0.68      1010\n",
      "           4       0.66      0.82      0.73       982\n",
      "           5       0.85      0.35      0.50       892\n",
      "           6       0.77      0.81      0.79       958\n",
      "           7       0.71      0.85      0.77      1028\n",
      "           8       0.71      0.59      0.64       974\n",
      "           9       0.83      0.49      0.62      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.71      0.70     10000\n",
      "weighted avg       0.73      0.72      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 943    3    9    0    2    3   11    9    0    0]\n",
      " [   1 1114    1    7    0    0    4    2    6    0]\n",
      " [  31  146  619    7   30    2   63  109   21    4]\n",
      " [  57   52   97  661    6   18    8   33   59   19]\n",
      " [   1   41    3    5  806    3   56   31   16   20]\n",
      " [ 100   37   69  146   52  315   32   26   91   24]\n",
      " [  54   17   61    1   27   18  772    3    4    1]\n",
      " [  10   61   19    2   32    0    1  876   11   16]\n",
      " [  17  129   60   91   15    5   49   11  577   20]\n",
      " [  12   47    4   18  250    5    9  135   33  496]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '5' '4' '9']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 4 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (250, 784) (250,)\n",
      "trainset after (260, 784) (260,)\n",
      "updated train set: (260, 784) (260,) unique(labels): [10  7 17 34 32 41 18 18 46 37] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59740, 784) (59740,)\n",
      "\n",
      "Train set: (260, 784) y: (260,)\n",
      "Val   set: (59740, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 26\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.167 s \n",
      "\n",
      "Accuracy rate for 71.740000 \n",
      "Classification report for classifier LogisticRegression(C=0.19230769230769232, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81       980\n",
      "           1       0.67      0.98      0.80      1135\n",
      "           2       0.66      0.58      0.62      1032\n",
      "           3       0.81      0.58      0.67      1010\n",
      "           4       0.66      0.84      0.74       982\n",
      "           5       0.74      0.42      0.54       892\n",
      "           6       0.76      0.82      0.79       958\n",
      "           7       0.73      0.82      0.77      1028\n",
      "           8       0.76      0.59      0.66       974\n",
      "           9       0.82      0.51      0.63      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.71      0.70     10000\n",
      "weighted avg       0.73      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 957    3    3    1    1    3    6    6    0    0]\n",
      " [   1 1113    3    6    0    0    6    2    4    0]\n",
      " [  53  163  601    1   35    1   74   88   11    5]\n",
      " [ 106   43   94  582    7   63   12   26   63   14]\n",
      " [   1   34    2    4  828    5   54   26    5   23]\n",
      " [ 146   25   77   62   59  378   29   20   71   25]\n",
      " [  73   14   41    0   17   23  785    3    2    0]\n",
      " [  21   74   24    2   38    3    3  842    7   14]\n",
      " [  24  141   65   40   16   22   56    7  571   32]\n",
      " [  13   47    4   17  247   10   10  127   17  517]]\n",
      "--------------------------------\n",
      "val predicted: (59740,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59740, 10) \n",
      " [3 0 4 ... 5 0 9]\n",
      "trainset before (260, 784) (260,)\n",
      "trainset after (270, 784) (270,)\n",
      "updated train set: (270, 784) (270,) unique(labels): [10  7 19 35 34 43 18 19 47 38] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59730, 784) (59730,)\n",
      "\n",
      "Train set: (270, 784) y: (270,)\n",
      "Val   set: (59730, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 27\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.167 s \n",
      "\n",
      "Accuracy rate for 70.550000 \n",
      "Classification report for classifier LogisticRegression(C=0.18518518518518517, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.83       980\n",
      "           1       0.66      0.98      0.79      1135\n",
      "           2       0.74      0.55      0.63      1032\n",
      "           3       0.71      0.70      0.71      1010\n",
      "           4       0.60      0.85      0.70       982\n",
      "           5       0.83      0.25      0.39       892\n",
      "           6       0.70      0.82      0.76       958\n",
      "           7       0.79      0.80      0.79      1028\n",
      "           8       0.70      0.60      0.65       974\n",
      "           9       0.82      0.45      0.58      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.73      0.70      0.68     10000\n",
      "weighted avg       0.73      0.71      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 951    3    2    1    3    1   12    7    0    0]\n",
      " [   1 1116    1    7    0    0    8    0    2    0]\n",
      " [  41  173  563    8   36    0  109   74   18   10]\n",
      " [  74   45   55  710   12   16   12   17   61    8]\n",
      " [   1   38    1    7  836    3   56   16    8   16]\n",
      " [ 127   37   35  155   90  227   56   21  117   27]\n",
      " [  79   19   26    4   20   13  789    2    6    0]\n",
      " [  10   74   33    3   52    0    7  821   10   18]\n",
      " [  24  134   40   75   21    6   63    5  586   20]\n",
      " [  13   50    2   30  333    6    9   79   31  456]]\n",
      "--------------------------------\n",
      "val predicted: (59730,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59730, 10) \n",
      " [3 0 4 ... 5 0 9]\n",
      "trainset before (270, 784) (270,)\n",
      "trainset after (280, 784) (280,)\n",
      "updated train set: (280, 784) (280,) unique(labels): [10  7 21 36 34 45 19 19 48 41] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59720, 784) (59720,)\n",
      "\n",
      "Train set: (280, 784) y: (280,)\n",
      "Val   set: (59720, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 28\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.169 s \n",
      "\n",
      "Accuracy rate for 72.330000 \n",
      "Classification report for classifier LogisticRegression(C=0.17857142857142858, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83       980\n",
      "           1       0.67      0.98      0.80      1135\n",
      "           2       0.78      0.59      0.67      1032\n",
      "           3       0.69      0.71      0.70      1010\n",
      "           4       0.68      0.79      0.73       982\n",
      "           5       0.78      0.39      0.52       892\n",
      "           6       0.69      0.81      0.75       958\n",
      "           7       0.76      0.82      0.79      1028\n",
      "           8       0.78      0.55      0.64       974\n",
      "           9       0.82      0.55      0.66      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.72      0.71     10000\n",
      "weighted avg       0.74      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 959    3    1    1    1    2   10    3    0    0]\n",
      " [   1 1115    1    9    0    0    8    1    0    0]\n",
      " [  42  155  606    9   22    1  109   63   11   14]\n",
      " [  60   36   73  722    6   24    4   19   49   17]\n",
      " [   2   40    1    8  772   12   72   36    5   34]\n",
      " [ 120   32   10  166   63  346   49   22   68   16]\n",
      " [ 102   15   19    3   12   24  780    3    0    0]\n",
      " [  19   78   23    8   33    1    6  839    6   15]\n",
      " [  22  136   39   91   13   22   81    9  536   25]\n",
      " [  13   49    0   26  220   13   13  102   15  558]]\n",
      "--------------------------------\n",
      "val predicted: (59720,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59720, 10) \n",
      " [3 0 4 ... 5 0 9]\n",
      "trainset before (280, 784) (280,)\n",
      "trainset after (290, 784) (290,)\n",
      "updated train set: (290, 784) (290,) unique(labels): [10  7 22 37 34 47 19 21 50 43] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59710, 784) (59710,)\n",
      "\n",
      "Train set: (290, 784) y: (290,)\n",
      "Val   set: (59710, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 29\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.185 s \n",
      "\n",
      "Accuracy rate for 70.540000 \n",
      "Classification report for classifier LogisticRegression(C=0.1724137931034483, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82       980\n",
      "           1       0.65      0.98      0.79      1135\n",
      "           2       0.77      0.55      0.64      1032\n",
      "           3       0.70      0.70      0.70      1010\n",
      "           4       0.63      0.82      0.71       982\n",
      "           5       0.86      0.27      0.41       892\n",
      "           6       0.68      0.82      0.74       958\n",
      "           7       0.75      0.81      0.78      1028\n",
      "           8       0.72      0.57      0.63       974\n",
      "           9       0.81      0.49      0.61      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.73      0.70      0.68     10000\n",
      "weighted avg       0.73      0.71      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 946    3    2    1    1    1   20    6    0    0]\n",
      " [   0 1116    1    7    0    0   10    1    0    0]\n",
      " [  42  174  572    6   34    0  114   74   11    5]\n",
      " [  80   48   60  710   13   11    9   17   56    6]\n",
      " [   1   39    0    7  801    8   56   31    8   31]\n",
      " [ 132   35   15  161   69  244   65   27  108   36]\n",
      " [  90   13   24    4   23   10  787    3    4    0]\n",
      " [  13   75   33    5   41    1    7  833    5   15]\n",
      " [  23  151   33   83   20    6   75    9  551   23]\n",
      " [  12   50    2   33  266    3   15  114   20  494]]\n",
      "--------------------------------\n",
      "val predicted: (59710,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59710, 10) \n",
      " [3 0 4 ... 5 0 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (290, 784) (290,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [10  7 22 37 34 49 20 21 53 47] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 30\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.162 s \n",
      "\n",
      "Accuracy rate for 70.610000 \n",
      "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82       980\n",
      "           1       0.65      0.98      0.79      1135\n",
      "           2       0.77      0.55      0.64      1032\n",
      "           3       0.69      0.67      0.68      1010\n",
      "           4       0.70      0.77      0.74       982\n",
      "           5       0.82      0.15      0.25       892\n",
      "           6       0.66      0.86      0.74       958\n",
      "           7       0.79      0.82      0.81      1028\n",
      "           8       0.70      0.53      0.61       974\n",
      "           9       0.71      0.67      0.69      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.70      0.68     10000\n",
      "weighted avg       0.72      0.71      0.68     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 952    3    2    1    0    0   15    6    0    1]\n",
      " [   0 1116    2    4    0    0    9    1    3    0]\n",
      " [  39  163  567    5   21    0  143   60   11   23]\n",
      " [  67   48   69  681   11   14   14   17   64   25]\n",
      " [   1   41    1    5  757    4   76   21    3   73]\n",
      " [ 149   39   15  194   76  130   48   26  118   97]\n",
      " [  81   15   19    2   11    8  820    2    0    0]\n",
      " [  14   77   20    3   32    0    7  847    5   23]\n",
      " [  25  156   37   76   24    3   99    6  520   28]\n",
      " [  11   46    0   19  143    0   17   83   19  671]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['3' '0' '4' ... '9' '0' '9']\n",
      "probabilities: (59700, 10) \n",
      " [3 0 4 ... 9 0 9]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (310, 784) (310,)\n",
      "updated train set: (310, 784) (310,) unique(labels): [10  7 24 37 35 52 20 21 56 48] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59690, 784) (59690,)\n",
      "\n",
      "Train set: (310, 784) y: (310,)\n",
      "Val   set: (59690, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 31\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.190 s \n",
      "\n",
      "Accuracy rate for 71.730000 \n",
      "Classification report for classifier LogisticRegression(C=0.16129032258064516, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.96      0.80       980\n",
      "           1       0.67      0.98      0.80      1135\n",
      "           2       0.80      0.58      0.67      1032\n",
      "           3       0.70      0.72      0.71      1010\n",
      "           4       0.67      0.79      0.72       982\n",
      "           5       0.81      0.27      0.40       892\n",
      "           6       0.68      0.83      0.75       958\n",
      "           7       0.79      0.80      0.79      1028\n",
      "           8       0.72      0.57      0.64       974\n",
      "           9       0.82      0.58      0.68      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.71      0.70     10000\n",
      "weighted avg       0.73      0.72      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 943    3    1    1    1    2   19    9    1    0]\n",
      " [   0 1113    2    9    0    1    9    1    0    0]\n",
      " [  51  152  600    9   23    0  119   57   10   11]\n",
      " [  77   46   42  732    8   23   11   12   43   16]\n",
      " [   4   36    2    9  778    6   66   26   13   42]\n",
      " [ 150   34    9  154   77  240   59   26  114   29]\n",
      " [  96   12   16    5   15   11  797    4    2    0]\n",
      " [  13   72   25    6   52    0    6  823   11   20]\n",
      " [  27  137   47   90   21   10   66    4  559   13]\n",
      " [  13   46    6   34  192    5   15   86   24  588]]\n",
      "--------------------------------\n",
      "val predicted: (59690,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59690, 10) \n",
      " [3 0 4 ... 5 0 9]\n",
      "trainset before (310, 784) (310,)\n",
      "trainset after (320, 784) (320,)\n",
      "updated train set: (320, 784) (320,) unique(labels): [10  7 26 37 37 53 20 23 57 50] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59680, 784) (59680,)\n",
      "\n",
      "Train set: (320, 784) y: (320,)\n",
      "Val   set: (59680, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 32\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.191 s \n",
      "\n",
      "Accuracy rate for 72.490000 \n",
      "Classification report for classifier LogisticRegression(C=0.15625, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.81       980\n",
      "           1       0.65      0.98      0.79      1135\n",
      "           2       0.85      0.55      0.67      1032\n",
      "           3       0.72      0.76      0.74      1010\n",
      "           4       0.71      0.76      0.73       982\n",
      "           5       0.82      0.30      0.44       892\n",
      "           6       0.66      0.85      0.74       958\n",
      "           7       0.79      0.80      0.79      1028\n",
      "           8       0.74      0.60      0.66       974\n",
      "           9       0.79      0.61      0.69      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.72      0.71     10000\n",
      "weighted avg       0.74      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 944    3    1    1    2    2   19    8    0    0]\n",
      " [   1 1116    0    9    0    0    9    0    0    0]\n",
      " [  50  176  567    8   16    0  142   49    9   15]\n",
      " [  58   49   17  771    6   22   15   11   47   14]\n",
      " [   3   37    5    7  750    3   85   28   12   52]\n",
      " [ 140   37    9  150   62  272   52   32   95   43]\n",
      " [  89   15   11    3    9   12  811    4    4    0]\n",
      " [  14   79   19    8   41    1    6  821   12   27]\n",
      " [  25  143   32   76   15   14   67    7  581   14]\n",
      " [  14   52    3   38  162    6   14   78   26  616]]\n",
      "--------------------------------\n",
      "val predicted: (59680,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59680, 10) \n",
      " [3 0 4 ... 5 0 9]\n",
      "trainset before (320, 784) (320,)\n",
      "trainset after (330, 784) (330,)\n",
      "updated train set: (330, 784) (330,) unique(labels): [10  7 27 37 37 56 20 24 57 55] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59670, 784) (59670,)\n",
      "\n",
      "Train set: (330, 784) y: (330,)\n",
      "Val   set: (59670, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 33\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.201 s \n",
      "\n",
      "Accuracy rate for 73.000000 \n",
      "Classification report for classifier LogisticRegression(C=0.15151515151515152, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81       980\n",
      "           1       0.66      0.98      0.79      1135\n",
      "           2       0.76      0.65      0.70      1032\n",
      "           3       0.69      0.73      0.71      1010\n",
      "           4       0.72      0.77      0.74       982\n",
      "           5       0.82      0.42      0.56       892\n",
      "           6       0.70      0.82      0.75       958\n",
      "           7       0.83      0.73      0.77      1028\n",
      "           8       0.79      0.57      0.66       974\n",
      "           9       0.79      0.61      0.69      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.75      0.72      0.72     10000\n",
      "weighted avg       0.74      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 955    3    3    1    0    2   13    2    0    1]\n",
      " [   1 1112    3   10    0    0    8    0    1    0]\n",
      " [  50  157  666   10   15    1   85   36    6    6]\n",
      " [  74   46   51  738    2   25   10    9   44   11]\n",
      " [   2   40   11    9  755    8   80   25   10   42]\n",
      " [ 133   30   16  153   44  375   51   16   46   28]\n",
      " [  91   16   36    1   10   18  783    1    2    0]\n",
      " [  25   83   34    8   50    2    9  746   11   60]\n",
      " [  25  138   53   84   14   15   72    6  555   12]\n",
      " [  15   51    5   51  163   10   13   61   25  615]]\n",
      "--------------------------------\n",
      "val predicted: (59670,) ['3' '0' '4' ... '5' '0' '2']\n",
      "probabilities: (59670, 10) \n",
      " [3 0 4 ... 5 0 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (330, 784) (330,)\n",
      "trainset after (340, 784) (340,)\n",
      "updated train set: (340, 784) (340,) unique(labels): [10  7 28 39 38 56 21 24 59 58] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59660, 784) (59660,)\n",
      "\n",
      "Train set: (340, 784) y: (340,)\n",
      "Val   set: (59660, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 34\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.183 s \n",
      "\n",
      "Accuracy rate for 71.630000 \n",
      "Classification report for classifier LogisticRegression(C=0.14705882352941177, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.97      0.77       980\n",
      "           1       0.64      0.98      0.77      1135\n",
      "           2       0.71      0.63      0.67      1032\n",
      "           3       0.72      0.66      0.69      1010\n",
      "           4       0.73      0.76      0.75       982\n",
      "           5       0.83      0.45      0.58       892\n",
      "           6       0.67      0.81      0.74       958\n",
      "           7       0.81      0.76      0.79      1028\n",
      "           8       0.83      0.47      0.60       974\n",
      "           9       0.81      0.62      0.71      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.71      0.71     10000\n",
      "weighted avg       0.74      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 948    3    9    1    0    2   14    3    0    0]\n",
      " [   1 1111    7    7    0    0    9    0    0    0]\n",
      " [  70  163  648    7   13    1   88   35    0    7]\n",
      " [ 112   68   58  662    5   33   11   12   34   15]\n",
      " [   5   42    7    8  747    5   88   30    6   44]\n",
      " [ 176   31   33   92   46  398   45   21   27   23]\n",
      " [ 102   14   39    1   11   13  776    1    1    0]\n",
      " [  29   87   40    6   32    1    6  782    7   38]\n",
      " [  31  158   63   94   24   19   96    8  461   20]\n",
      " [  20   56    7   39  140   10   18   71   18  630]]\n",
      "--------------------------------\n",
      "val predicted: (59660,) ['5' '0' '4' ... '5' '0' '2']\n",
      "probabilities: (59660, 10) \n",
      " [5 0 4 ... 5 0 2]\n",
      "trainset before (340, 784) (340,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [10  7 28 41 40 59 21 24 61 59] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 35\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.173 s \n",
      "\n",
      "Accuracy rate for 73.170000 \n",
      "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.79       980\n",
      "           1       0.68      0.97      0.80      1135\n",
      "           2       0.72      0.65      0.68      1032\n",
      "           3       0.71      0.72      0.71      1010\n",
      "           4       0.71      0.78      0.75       982\n",
      "           5       0.88      0.44      0.59       892\n",
      "           6       0.68      0.85      0.75       958\n",
      "           7       0.82      0.76      0.79      1028\n",
      "           8       0.85      0.52      0.65       974\n",
      "           9       0.82      0.58      0.68      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.75      0.73      0.72     10000\n",
      "weighted avg       0.75      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 958    3    4    1    1    1    8    4    0    0]\n",
      " [   1 1106    9   10    0    0    9    0    0    0]\n",
      " [  60  138  666   15   15    1   97   30    1    9]\n",
      " [  98   41   58  727    6   17   14   10   24   15]\n",
      " [   1   32    6    9  770    7   92   28    6   31]\n",
      " [ 164   29   39  118   42  394   43   12   32   19]\n",
      " [  72   11   40    3   11    9  811    1    0    0]\n",
      " [  38   68   37   11   40    0    8  786    5   35]\n",
      " [  31  146   55   90   12   13   92    6  511   18]\n",
      " [  14   42    6   40  187    7   22   81   22  588]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59650, 10) \n",
      " [3 0 4 ... 5 0 9]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (360, 784) (360,)\n",
      "updated train set: (360, 784) (360,) unique(labels): [10  7 29 43 42 62 21 25 61 60] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59640, 784) (59640,)\n",
      "\n",
      "Train set: (360, 784) y: (360,)\n",
      "Val   set: (59640, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 36\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.172 s \n",
      "\n",
      "Accuracy rate for 71.580000 \n",
      "Classification report for classifier LogisticRegression(C=0.1388888888888889, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.99      0.75       980\n",
      "           1       0.64      0.98      0.78      1135\n",
      "           2       0.78      0.59      0.67      1032\n",
      "           3       0.74      0.69      0.72      1010\n",
      "           4       0.66      0.80      0.72       982\n",
      "           5       0.88      0.38      0.53       892\n",
      "           6       0.71      0.80      0.75       958\n",
      "           7       0.83      0.77      0.80      1028\n",
      "           8       0.77      0.58      0.66       974\n",
      "           9       0.88      0.51      0.65      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.75      0.71      0.70     10000\n",
      "weighted avg       0.75      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 966    3    0    1    0    1    6    2    1    0]\n",
      " [   0 1116    3    8    0    0    8    0    0    0]\n",
      " [  82  181  609   10   18    1   86   30   11    4]\n",
      " [ 129   58   35  701    7   19    9   14   31    7]\n",
      " [   9   40    8    6  785    3   85   22   14   10]\n",
      " [ 188   41   21   99   65  343   37   25   68    5]\n",
      " [ 124   16   28    1    8   10  766    1    4    0]\n",
      " [  26   86   34   13   35    0    6  789    6   33]\n",
      " [  35  148   40   73   17    9   66    6  565   15]\n",
      " [  24   50    6   36  260    5   16   64   30  518]]\n",
      "--------------------------------\n",
      "val predicted: (59640,) ['3' '0' '4' ... '5' '0' '2']\n",
      "probabilities: (59640, 10) \n",
      " [3 0 4 ... 5 0 2]\n",
      "trainset before (360, 784) (360,)\n",
      "trainset after (370, 784) (370,)\n",
      "updated train set: (370, 784) (370,) unique(labels): [10  7 30 44 44 65 22 25 61 62] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59630, 784) (59630,)\n",
      "\n",
      "Train set: (370, 784) y: (370,)\n",
      "Val   set: (59630, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 37\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.206 s \n",
      "\n",
      "Accuracy rate for 72.500000 \n",
      "Classification report for classifier LogisticRegression(C=0.13513513513513514, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.98      0.77       980\n",
      "           1       0.68      0.98      0.80      1135\n",
      "           2       0.74      0.66      0.70      1032\n",
      "           3       0.74      0.70      0.72      1010\n",
      "           4       0.69      0.79      0.74       982\n",
      "           5       0.86      0.38      0.52       892\n",
      "           6       0.76      0.78      0.77       958\n",
      "           7       0.78      0.74      0.76      1028\n",
      "           8       0.78      0.59      0.67       974\n",
      "           9       0.82      0.59      0.68      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.75      0.72      0.71     10000\n",
      "weighted avg       0.74      0.72      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 962    3    3    1    0    1    3    7    0    0]\n",
      " [   2 1110    5   10    0    1    5    0    1    1]\n",
      " [  64  152  680    9   18    0   60   32    9    8]\n",
      " [ 107   38   59  710    7   21    8   10   34   16]\n",
      " [  14   34    5    7  779    7   57   40   16   23]\n",
      " [ 181   33   29  109   60  335   36   42   63    4]\n",
      " [ 115   17   56    0   16    5  746    2    1    0]\n",
      " [  23   72   36   18   46    0    2  765   12   54]\n",
      " [  37  139   47   67   14   11   56    9  572   22]\n",
      " [  19   46    4   33  194    8   13   77   24  591]]\n",
      "--------------------------------\n",
      "val predicted: (59630,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59630, 10) \n",
      " [3 0 4 ... 5 0 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (370, 784) (370,)\n",
      "trainset after (380, 784) (380,)\n",
      "updated train set: (380, 784) (380,) unique(labels): [10  7 32 46 45 68 23 25 62 62] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59620, 784) (59620,)\n",
      "\n",
      "Train set: (380, 784) y: (380,)\n",
      "Val   set: (59620, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 38\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.187 s \n",
      "\n",
      "Accuracy rate for 72.710000 \n",
      "Classification report for classifier LogisticRegression(C=0.13157894736842105, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84       980\n",
      "           1       0.68      0.98      0.80      1135\n",
      "           2       0.80      0.62      0.69      1032\n",
      "           3       0.61      0.84      0.70      1010\n",
      "           4       0.66      0.82      0.73       982\n",
      "           5       0.87      0.38      0.53       892\n",
      "           6       0.71      0.84      0.77       958\n",
      "           7       0.76      0.78      0.77      1028\n",
      "           8       0.85      0.48      0.61       974\n",
      "           9       0.88      0.52      0.65      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.76      0.72      0.71     10000\n",
      "weighted avg       0.76      0.73      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 931    3    8    4    1    3   16   13    1    0]\n",
      " [   1 1114    2   10    0    1    6    1    0    0]\n",
      " [  36  169  635   39   23    1   80   42    6    1]\n",
      " [  57   38   15  845    7   15    7   14    8    4]\n",
      " [   1   36   12    8  807    4   67   30    4   13]\n",
      " [ 107   36   27  190   66  343   36   41   43    3]\n",
      " [  57   20   37    1   27   10  803    2    1    0]\n",
      " [  12   65   31   31   45    0    3  802    3   36]\n",
      " [  15  126   24  206   16   12   83   10  469   13]\n",
      " [  11   42    6   55  228    7   23   97   18  522]]\n",
      "--------------------------------\n",
      "val predicted: (59620,) ['3' '0' '4' ... '5' '4' '2']\n",
      "probabilities: (59620, 10) \n",
      " [3 0 4 ... 5 4 2]\n",
      "trainset before (380, 784) (380,)\n",
      "trainset after (390, 784) (390,)\n",
      "updated train set: (390, 784) (390,) unique(labels): [10  7 33 47 45 71 23 27 63 64] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59610, 784) (59610,)\n",
      "\n",
      "Train set: (390, 784) y: (390,)\n",
      "Val   set: (59610, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 39\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.211 s \n",
      "\n",
      "Accuracy rate for 72.050000 \n",
      "Classification report for classifier LogisticRegression(C=0.1282051282051282, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.79       980\n",
      "           1       0.64      0.98      0.77      1135\n",
      "           2       0.76      0.59      0.66      1032\n",
      "           3       0.76      0.64      0.70      1010\n",
      "           4       0.69      0.78      0.73       982\n",
      "           5       0.82      0.41      0.55       892\n",
      "           6       0.69      0.84      0.76       958\n",
      "           7       0.77      0.79      0.78      1028\n",
      "           8       0.81      0.55      0.65       974\n",
      "           9       0.83      0.58      0.68      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.71      0.71     10000\n",
      "weighted avg       0.74      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 959    3    2    0    0    2    8    6    0    0]\n",
      " [   1 1115    1    9    0    0    8    1    0    0]\n",
      " [  53  182  608    6   22    1   97   57    3    3]\n",
      " [ 115   66   48  651   11   29   16   21   38   15]\n",
      " [   5   40    9    3  765   11   74   27    9   39]\n",
      " [ 157   36   37   95   50  367   44   36   51   19]\n",
      " [  79   16   27    0   14   13  808    1    0    0]\n",
      " [  22   78   25   11   48    0    6  814    6   18]\n",
      " [  30  157   42   59   14   12   89   10  534   27]\n",
      " [  18   56    4   18  189   10   19   89   22  584]]\n",
      "--------------------------------\n",
      "val predicted: (59610,) ['3' '0' '4' ... '5' '0' '2']\n",
      "probabilities: (59610, 10) \n",
      " [3 0 4 ... 5 0 2]\n",
      "trainset before (390, 784) (390,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [10  7 33 48 46 75 23 27 67 64] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 40\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.213 s \n",
      "\n",
      "Accuracy rate for 72.300000 \n",
      "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.79       980\n",
      "           1       0.65      0.98      0.78      1135\n",
      "           2       0.73      0.60      0.66      1032\n",
      "           3       0.71      0.69      0.70      1010\n",
      "           4       0.72      0.78      0.75       982\n",
      "           5       0.83      0.40      0.54       892\n",
      "           6       0.70      0.80      0.75       958\n",
      "           7       0.77      0.79      0.78      1028\n",
      "           8       0.82      0.53      0.64       974\n",
      "           9       0.83      0.62      0.71      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.72      0.71     10000\n",
      "weighted avg       0.74      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 956    3    2    0    1    3    7    8    0    0]\n",
      " [   2 1114    2   11    0    0    6    0    0    0]\n",
      " [  57  174  619    7   18    2   89   58    4    4]\n",
      " [  97   61   43  696    8   24   14   21   29   17]\n",
      " [   4   39   12    5  763    9   74   27   13   36]\n",
      " [ 152   31   46  136   51  355   40   28   37   16]\n",
      " [ 102   17   41    1   16    9  769    2    1    0]\n",
      " [  20   74   27   10   41    0    6  817    6   27]\n",
      " [  30  147   50   92   14   15   80    8  512   26]\n",
      " [  17   52    5   29  145    9   17   87   19  629]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['3' '0' '4' ... '5' '0' '2']\n",
      "probabilities: (59600, 10) \n",
      " [3 0 4 ... 5 0 2]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (410, 784) (410,)\n",
      "updated train set: (410, 784) (410,) unique(labels): [10  8 33 49 47 77 24 27 67 68] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59590, 784) (59590,)\n",
      "\n",
      "Train set: (410, 784) y: (410,)\n",
      "Val   set: (59590, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 41\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.215 s \n",
      "\n",
      "Accuracy rate for 72.050000 \n",
      "Classification report for classifier LogisticRegression(C=0.12195121951219512, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.97      0.78       980\n",
      "           1       0.63      0.98      0.77      1135\n",
      "           2       0.74      0.63      0.68      1032\n",
      "           3       0.74      0.66      0.70      1010\n",
      "           4       0.72      0.79      0.76       982\n",
      "           5       0.86      0.38      0.53       892\n",
      "           6       0.69      0.83      0.76       958\n",
      "           7       0.77      0.79      0.78      1028\n",
      "           8       0.79      0.49      0.60       974\n",
      "           9       0.84      0.61      0.71      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.71      0.71     10000\n",
      "weighted avg       0.74      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 946    3    5    0    1    2   12   11    0    0]\n",
      " [   1 1115    6    3    0    1    5    1    3    0]\n",
      " [  46  164  654    7   20    1   89   40    3    8]\n",
      " [ 119   61   54  667   10   22   13   16   32   16]\n",
      " [   1   33    4    7  778    8   73   28   15   35]\n",
      " [ 164   53   47  104   53  343   43   33   42   10]\n",
      " [  92   17   32    0   16    5  792    2    2    0]\n",
      " [  23   59   33   13   43    0    3  814   11   29]\n",
      " [  35  205   42   75   14    9   93    7  476   18]\n",
      " [  16   50    5   30  143    7   17  101   20  620]]\n",
      "--------------------------------\n",
      "val predicted: (59590,) ['3' '0' '4' ... '5' '0' '9']\n",
      "probabilities: (59590, 10) \n",
      " [3 0 4 ... 5 0 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (410, 784) (410,)\n",
      "trainset after (420, 784) (420,)\n",
      "updated train set: (420, 784) (420,) unique(labels): [10  8 34 50 47 80 25 27 70 69] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59580, 784) (59580,)\n",
      "\n",
      "Train set: (420, 784) y: (420,)\n",
      "Val   set: (59580, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 42\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.218 s \n",
      "\n",
      "Accuracy rate for 71.500000 \n",
      "Classification report for classifier LogisticRegression(C=0.11904761904761904, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.97      0.76       980\n",
      "           1       0.63      0.99      0.77      1135\n",
      "           2       0.71      0.62      0.66      1032\n",
      "           3       0.78      0.56      0.65      1010\n",
      "           4       0.71      0.81      0.76       982\n",
      "           5       0.83      0.40      0.54       892\n",
      "           6       0.70      0.82      0.75       958\n",
      "           7       0.80      0.79      0.79      1028\n",
      "           8       0.81      0.51      0.62       974\n",
      "           9       0.83      0.63      0.72      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.74      0.71      0.70     10000\n",
      "weighted avg       0.74      0.71      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 955    3    4    0    1    2   10    5    0    0]\n",
      " [   1 1119    3    1    0    1    5    1    4    0]\n",
      " [  55  163  642    3   27    2   88   42    3    7]\n",
      " [ 162   79   74  561   12   34   13   19   37   19]\n",
      " [   3   40    4    1  795    6   67   16   10   40]\n",
      " [ 187   55   51   77   53  360   36   24   33   16]\n",
      " [  94   17   37    0   18    7  781    2    2    0]\n",
      " [  25   65   23    8   57    0    6  807   10   27]\n",
      " [  33  190   58   52   19   11   86   10  493   22]\n",
      " [  18   55    7   17  139    9   20   87   20  637]]\n",
      "--------------------------------\n",
      "val predicted: (59580,) ['3' '0' '4' ... '5' '0' '2']\n",
      "probabilities: (59580, 10) \n",
      " [3 0 4 ... 5 0 2]\n",
      "trainset before (420, 784) (420,)\n",
      "trainset after (430, 784) (430,)\n",
      "updated train set: (430, 784) (430,) unique(labels): [11  8 36 50 48 83 27 27 70 70] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59570, 784) (59570,)\n",
      "\n",
      "Train set: (430, 784) y: (430,)\n",
      "Val   set: (59570, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 43\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.223 s \n",
      "\n",
      "Accuracy rate for 70.680000 \n",
      "Classification report for classifier LogisticRegression(C=0.11627906976744186, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.99      0.79       980\n",
      "           1       0.63      0.98      0.76      1135\n",
      "           2       0.62      0.61      0.62      1032\n",
      "           3       0.77      0.55      0.64      1010\n",
      "           4       0.69      0.81      0.75       982\n",
      "           5       0.79      0.44      0.56       892\n",
      "           6       0.71      0.80      0.75       958\n",
      "           7       0.78      0.76      0.77      1028\n",
      "           8       0.77      0.47      0.59       974\n",
      "           9       0.86      0.61      0.71      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.73      0.70      0.69     10000\n",
      "weighted avg       0.73      0.71      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 969    3    1    0    0    0    4    2    1    0]\n",
      " [   3 1114    7    4    0    1    3    1    2    0]\n",
      " [  49  175  630    3   18    2   95   44    9    7]\n",
      " [ 119   77  111  554   13   51   15   17   37   16]\n",
      " [   5   38    8    2  793    6   57   27   15   31]\n",
      " [ 163   49   84   67   46  391   33   21   28   10]\n",
      " [  75   14   63    0   21   11  763    2    9    0]\n",
      " [  39   65   25   12   70    0    7  778   13   19]\n",
      " [  29  192   78   59   22   21   84   11  461   17]\n",
      " [  21   55    6   16  162   12   11   90   21  615]]\n",
      "--------------------------------\n",
      "val predicted: (59570,) ['5' '0' '9' ... '5' '0' '2']\n",
      "probabilities: (59570, 10) \n",
      " [5 0 9 ... 5 0 2]\n",
      "trainset before (430, 784) (430,)\n",
      "trainset after (440, 784) (440,)\n",
      "updated train set: (440, 784) (440,) unique(labels): [11  8 36 51 49 85 28 28 72 72] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59560, 784) (59560,)\n",
      "\n",
      "Train set: (440, 784) y: (440,)\n",
      "Val   set: (59560, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 44\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.190 s \n",
      "\n",
      "Accuracy rate for 66.370000 \n",
      "Classification report for classifier LogisticRegression(C=0.11363636363636363, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.41      0.56       980\n",
      "           1       0.64      0.99      0.78      1135\n",
      "           2       0.41      0.75      0.53      1032\n",
      "           3       0.66      0.69      0.67      1010\n",
      "           4       0.68      0.79      0.74       982\n",
      "           5       0.79      0.37      0.51       892\n",
      "           6       0.72      0.83      0.77       958\n",
      "           7       0.73      0.81      0.77      1028\n",
      "           8       0.81      0.41      0.55       974\n",
      "           9       0.91      0.50      0.65      1009\n",
      "\n",
      "    accuracy                           0.66     10000\n",
      "   macro avg       0.72      0.66      0.65     10000\n",
      "weighted avg       0.72      0.66      0.65     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 402    3  461    7    2   35   37   27    5    1]\n",
      " [   0 1118    8    2    0    0    4    1    2    0]\n",
      " [   1  142  769    6   11    3   63   31    2    4]\n",
      " [   5   63  167  699    4   23   14   14   18    3]\n",
      " [   0   41    9    2  780    2   74   50   11   13]\n",
      " [  22   54  148  175   55  333   37   34   23   11]\n",
      " [  11   13  109    1   16    9  794    1    4    0]\n",
      " [   4   69   35   16   45    0    5  836   11    7]\n",
      " [   1  178  163  120   15   12   64   11  402    8]\n",
      " [   2   58   17   37  212    7   17  136   19  504]]\n",
      "--------------------------------\n",
      "val predicted: (59560,) ['3' '0' '4' ... '5' '4' '2']\n",
      "probabilities: (59560, 10) \n",
      " [3 0 4 ... 5 4 2]\n",
      "trainset before (440, 784) (440,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [12  8 37 51 49 87 28 30 74 74] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 45\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.211 s \n",
      "\n",
      "Accuracy rate for 71.600000 \n",
      "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.99      0.78       980\n",
      "           1       0.62      0.99      0.76      1135\n",
      "           2       0.74      0.56      0.63      1032\n",
      "           3       0.82      0.59      0.68      1010\n",
      "           4       0.69      0.77      0.73       982\n",
      "           5       0.82      0.46      0.59       892\n",
      "           6       0.71      0.84      0.77       958\n",
      "           7       0.75      0.77      0.76      1028\n",
      "           8       0.79      0.52      0.63       974\n",
      "           9       0.83      0.63      0.71      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.71      0.71     10000\n",
      "weighted avg       0.74      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 971    2    1    0    0    0    4    1    1    0]\n",
      " [   3 1121    1    1    0    1    4    1    3    0]\n",
      " [  54  178  574    2   14    4   97   87   11   11]\n",
      " [ 125   89   69  593   13   36   13   17   39   16]\n",
      " [   7   39    9    0  756    3   68   36   16   48]\n",
      " [ 190   55   18   64   57  410   46   15   22   15]\n",
      " [  64   15   33    0   16   15  803    2   10    0]\n",
      " [  48   66   18    4   61    0    4  792   13   22]\n",
      " [  26  193   50   48   21   23   76   12  508   17]\n",
      " [  16   55    5   11  150   10   11   98   21  632]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['5' '0' '9' ... '5' '0' '9']\n",
      "probabilities: (59550, 10) \n",
      " [5 0 9 ... 5 0 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (450, 784) (450,)\n",
      "trainset after (460, 784) (460,)\n",
      "updated train set: (460, 784) (460,) unique(labels): [12  8 38 52 50 88 28 32 74 78] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59540, 784) (59540,)\n",
      "\n",
      "Train set: (460, 784) y: (460,)\n",
      "Val   set: (59540, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 46\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.193 s \n",
      "\n",
      "Accuracy rate for 72.770000 \n",
      "Classification report for classifier LogisticRegression(C=0.10869565217391304, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.99      0.78       980\n",
      "           1       0.65      0.98      0.78      1135\n",
      "           2       0.69      0.66      0.68      1032\n",
      "           3       0.80      0.61      0.69      1010\n",
      "           4       0.68      0.80      0.73       982\n",
      "           5       0.76      0.50      0.61       892\n",
      "           6       0.82      0.77      0.80       958\n",
      "           7       0.78      0.74      0.76      1028\n",
      "           8       0.80      0.57      0.66       974\n",
      "           9       0.85      0.60      0.71      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.75      0.72      0.72     10000\n",
      "weighted avg       0.75      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 966    2    4    0    1    3    2    1    1    0]\n",
      " [   0 1116    5    2    0    1    4    1    6    0]\n",
      " [  43  165  684    4   17    6   49   47   11    6]\n",
      " [ 115   66   83  618    8   43    9   12   44   12]\n",
      " [   6   42   14    1  786   10   30   44   11   38]\n",
      " [ 167   51   38   66   54  447   25   11   17   16]\n",
      " [  62   21   61    0   36   28  739    1   10    0]\n",
      " [  86   58   31    6   46    1    2  760   15   23]\n",
      " [  24  160   60   68   26   29   35   10  552   10]\n",
      " [  22   49    7   11  186   17    6   82   20  609]]\n",
      "--------------------------------\n",
      "val predicted: (59540,) ['5' '0' '4' ... '5' '5' '2']\n",
      "probabilities: (59540, 10) \n",
      " [5 0 4 ... 5 5 2]\n",
      "trainset before (460, 784) (460,)\n",
      "trainset after (470, 784) (470,)\n",
      "updated train set: (470, 784) (470,) unique(labels): [12  8 39 52 53 88 29 32 76 81] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59530, 784) (59530,)\n",
      "\n",
      "Train set: (470, 784) y: (470,)\n",
      "Val   set: (59530, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 47\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.233 s \n",
      "\n",
      "Accuracy rate for 72.380000 \n",
      "Classification report for classifier LogisticRegression(C=0.10638297872340426, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.80       980\n",
      "           1       0.64      0.98      0.78      1135\n",
      "           2       0.72      0.64      0.68      1032\n",
      "           3       0.77      0.61      0.68      1010\n",
      "           4       0.71      0.75      0.73       982\n",
      "           5       0.81      0.46      0.59       892\n",
      "           6       0.71      0.87      0.78       958\n",
      "           7       0.75      0.76      0.75      1028\n",
      "           8       0.81      0.52      0.63       974\n",
      "           9       0.83      0.61      0.71      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.72      0.71     10000\n",
      "weighted avg       0.74      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 963    3    3    0    1    1    7    1    1    0]\n",
      " [   2 1116    6    1    0    0    5    1    4    0]\n",
      " [  40  157  659    2   13    2  100   42    4   13]\n",
      " [ 102   66   98  615    6   35   17   14   46   11]\n",
      " [   2   41    8    1  739    5   51   63    9   63]\n",
      " [ 156   53   30   81   56  411   57   14   21   13]\n",
      " [  46   14   28    0   21   14  831    2    2    0]\n",
      " [  77   60   31    8   46    1    3  779   10   13]\n",
      " [  19  171   48   75   19   26   80   16  507   13]\n",
      " [  20   54    6   12  138   12   17  107   25  618]]\n",
      "--------------------------------\n",
      "val predicted: (59530,) ['5' '0' '4' ... '5' '4' '9']\n",
      "probabilities: (59530, 10) \n",
      " [5 0 4 ... 5 4 9]\n",
      "trainset before (470, 784) (470,)\n",
      "trainset after (480, 784) (480,)\n",
      "updated train set: (480, 784) (480,) unique(labels): [12  8 39 53 53 89 29 34 79 84] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59520, 784) (59520,)\n",
      "\n",
      "Train set: (480, 784) y: (480,)\n",
      "Val   set: (59520, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 48\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.234 s \n",
      "\n",
      "Accuracy rate for 73.040000 \n",
      "Classification report for classifier LogisticRegression(C=0.10416666666666667, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.99      0.79       980\n",
      "           1       0.69      0.98      0.81      1135\n",
      "           2       0.72      0.65      0.69      1032\n",
      "           3       0.74      0.66      0.70      1010\n",
      "           4       0.70      0.72      0.71       982\n",
      "           5       0.83      0.47      0.60       892\n",
      "           6       0.72      0.86      0.78       958\n",
      "           7       0.81      0.70      0.75      1028\n",
      "           8       0.77      0.61      0.68       974\n",
      "           9       0.80      0.62      0.70      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.73      0.72     10000\n",
      "weighted avg       0.74      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 966    3    2    0    0    2    4    0    3    0]\n",
      " [   2 1114    2    6    0    0    5    0    6    0]\n",
      " [  58  145  674    6   11    2   92   25    9   10]\n",
      " [ 104   44   87  666    6   21   14    8   50   10]\n",
      " [   4   40    7    5  706    9   70   38   21   82]\n",
      " [ 156   26   37   98   61  415   48   12   29   10]\n",
      " [  58   13   32    2   13   13  820    1    6    0]\n",
      " [  86   59   39   16   52    1    5  721   16   33]\n",
      " [  16  111   44   77   20   23   64   13  597    9]\n",
      " [  19   52    8   24  142   12   19   72   36  625]]\n",
      "--------------------------------\n",
      "val predicted: (59520,) ['5' '0' '9' ... '5' '4' '9']\n",
      "probabilities: (59520, 10) \n",
      " [5 0 9 ... 5 4 9]\n",
      "trainset before (480, 784) (480,)\n",
      "trainset after (490, 784) (490,)\n",
      "updated train set: (490, 784) (490,) unique(labels): [12  8 40 53 54 93 31 35 79 85] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59510, 784) (59510,)\n",
      "\n",
      "Train set: (490, 784) y: (490,)\n",
      "Val   set: (59510, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 49\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.221 s \n",
      "\n",
      "Accuracy rate for 71.840000 \n",
      "Classification report for classifier LogisticRegression(C=0.10204081632653061, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.82       980\n",
      "           1       0.63      0.99      0.77      1135\n",
      "           2       0.71      0.63      0.67      1032\n",
      "           3       0.77      0.63      0.70      1010\n",
      "           4       0.65      0.72      0.68       982\n",
      "           5       0.88      0.41      0.56       892\n",
      "           6       0.73      0.84      0.78       958\n",
      "           7       0.79      0.75      0.77      1028\n",
      "           8       0.75      0.56      0.64       974\n",
      "           9       0.77      0.60      0.68      1009\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.74      0.71      0.71     10000\n",
      "weighted avg       0.74      0.72      0.71     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 961    3    4    0    0    1    7    1    3    0]\n",
      " [   0 1120    2    3    1    0    6    0    3    0]\n",
      " [  43  165  653    6   11    1   97   30    8   18]\n",
      " [  80   78   98  637   14   17   16    6   50   14]\n",
      " [   7   34    9    3  710    5   48   58   22   86]\n",
      " [ 133   53   38   99   77  369   48   19   43   13]\n",
      " [  52   20   37    0   23    8  809    4    5    0]\n",
      " [  41   64   37    6   50    0    5  774   17   34]\n",
      " [  18  188   43   56   21   14   62   14  544   14]\n",
      " [  17   55    4   12  191    5   16   74   28  607]]\n",
      "--------------------------------\n",
      "val predicted: (59510,) ['5' '0' '9' ... '5' '4' '9']\n",
      "probabilities: (59510, 10) \n",
      " [5 0 9 ... 5 4 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (490, 784) (490,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [13  8 41 53 55 95 31 36 80 88] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 50\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.257 s \n",
      "\n",
      "Accuracy rate for 69.450000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.99      0.71       980\n",
      "           1       0.62      0.99      0.76      1135\n",
      "           2       0.74      0.55      0.63      1032\n",
      "           3       0.78      0.58      0.67      1010\n",
      "           4       0.73      0.70      0.72       982\n",
      "           5       0.81      0.39      0.53       892\n",
      "           6       0.69      0.85      0.76       958\n",
      "           7       0.76      0.66      0.71      1028\n",
      "           8       0.76      0.55      0.64       974\n",
      "           9       0.79      0.62      0.70      1009\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.73      0.69      0.68     10000\n",
      "weighted avg       0.72      0.69      0.69     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 972    3    2    0    1    0    2    0    0    0]\n",
      " [   2 1119    3    3    0    0    8    0    0    0]\n",
      " [  78  197  569    7   15    1  109   21   12   23]\n",
      " [ 159   69   59  588    6   33   19    8   57   12]\n",
      " [   8   37    3    2  692    7   75   54   20   84]\n",
      " [ 228   53   33   69   50  351   52   14   31   11]\n",
      " [  73   19   25    1    9   12  813    4    2    0]\n",
      " [ 151   69   46    9   33    0    6  682   14   18]\n",
      " [  42  179   21   62   19   19   69   12  532   19]\n",
      " [  28   54    5   13  120   10   22   97   33  627]]\n",
      "--------------------------------\n",
      "final active learning accuracies [37.5, 45.540000000000006, 50.17, 58.17, 62.4, 64.95, 67.80000000000001, 68.77, 69.85, 70.78999999999999, 72.05, 70.41, 67.30000000000001, 72.04, 71.22, 71.87, 69.64, 71.57, 71.78999999999999, 72.66, 72.86, 73.13, 71.53, 72.17, 71.78999999999999, 71.74000000000001, 70.55, 72.33000000000001, 70.54, 70.61, 71.73, 72.49, 73.0, 71.63000000000001, 73.17, 71.58, 72.5, 72.71, 72.05, 72.3, 72.05, 71.5, 70.67999999999999, 66.36999999999999, 71.6, 72.77, 72.38, 73.04, 71.84, 69.45]\n",
      "saved Active-learning-experiment-40.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-37.pkl', 'README.md', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-38.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "{\n",
      "  \"LogModel\": {\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          37.5,\n",
      "          45.540000000000006,\n",
      "          50.17,\n",
      "          58.17,\n",
      "          62.4,\n",
      "          64.95,\n",
      "          67.80000000000001,\n",
      "          68.77,\n",
      "          69.85,\n",
      "          70.78999999999999,\n",
      "          72.05,\n",
      "          70.41,\n",
      "          67.30000000000001,\n",
      "          72.04,\n",
      "          71.22,\n",
      "          71.87,\n",
      "          69.64,\n",
      "          71.57,\n",
      "          71.78999999999999,\n",
      "          72.66,\n",
      "          72.86,\n",
      "          73.13,\n",
      "          71.53,\n",
      "          72.17,\n",
      "          71.78999999999999,\n",
      "          71.74000000000001,\n",
      "          70.55,\n",
      "          72.33000000000001,\n",
      "          70.54,\n",
      "          70.61,\n",
      "          71.73,\n",
      "          72.49,\n",
      "          73.0,\n",
      "          71.63000000000001,\n",
      "          73.17,\n",
      "          71.58,\n",
      "          72.5,\n",
      "          72.71,\n",
      "          72.05,\n",
      "          72.3,\n",
      "          72.05,\n",
      "          71.5,\n",
      "          70.67999999999999,\n",
      "          66.36999999999999,\n",
      "          71.6,\n",
      "          72.77,\n",
      "          72.38,\n",
      "          73.04,\n",
      "          71.84,\n",
      "          69.45\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          73.47,\n",
      "          71.32,\n",
      "          72.05,\n",
      "          73.02\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          51.800000000000004,\n",
      "          63.71,\n",
      "          68.58,\n",
      "          68.17999999999999,\n",
      "          70.16,\n",
      "          70.69,\n",
      "          72.17,\n",
      "          74.33999999999999,\n",
      "          73.95,\n",
      "          71.13000000000001,\n",
      "          74.02,\n",
      "          72.89999999999999,\n",
      "          73.75,\n",
      "          72.55,\n",
      "          72.25,\n",
      "          72.7,\n",
      "          71.47,\n",
      "          70.38,\n",
      "          69.8,\n",
      "          70.06\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          70.02000000000001,\n",
      "          73.28\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          63.56,\n",
      "          68.58999999999999,\n",
      "          67.97999999999999,\n",
      "          70.62,\n",
      "          72.67,\n",
      "          74.61,\n",
      "          73.74000000000001,\n",
      "          74.56,\n",
      "          73.1,\n",
      "          75.06\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          37.63,\n",
      "          50.61,\n",
      "          57.879999999999995,\n",
      "          60.150000000000006,\n",
      "          67.54,\n",
      "          65.03,\n",
      "          65.52,\n",
      "          69.19999999999999,\n",
      "          68.75,\n",
      "          67.02,\n",
      "          67.78999999999999,\n",
      "          68.7,\n",
      "          69.16,\n",
      "          70.19999999999999,\n",
      "          70.43,\n",
      "          69.94,\n",
      "          69.69999999999999,\n",
      "          69.97,\n",
      "          70.09,\n",
      "          70.95,\n",
      "          71.43,\n",
      "          72.78999999999999,\n",
      "          72.33000000000001,\n",
      "          72.78,\n",
      "          72.63,\n",
      "          72.95,\n",
      "          73.83,\n",
      "          74.38,\n",
      "          72.78999999999999,\n",
      "          73.22999999999999,\n",
      "          73.49,\n",
      "          73.54,\n",
      "          73.63,\n",
      "          73.41,\n",
      "          73.61,\n",
      "          72.86,\n",
      "          73.75,\n",
      "          74.0,\n",
      "          74.02,\n",
      "          74.76,\n",
      "          74.72,\n",
      "          74.53,\n",
      "          74.64,\n",
      "          73.82,\n",
      "          74.35000000000001,\n",
      "          75.67,\n",
      "          74.16,\n",
      "          75.7,\n",
      "          75.18,\n",
      "          74.3\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          72.86,\n",
      "          72.11999999999999,\n",
      "          70.67999999999999,\n",
      "          71.37\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          54.279999999999994,\n",
      "          58.24,\n",
      "          61.839999999999996,\n",
      "          68.43,\n",
      "          68.44,\n",
      "          71.43,\n",
      "          74.02,\n",
      "          73.87,\n",
      "          73.4,\n",
      "          74.36,\n",
      "          75.39,\n",
      "          74.62,\n",
      "          74.85000000000001,\n",
      "          75.22999999999999,\n",
      "          73.8,\n",
      "          74.85000000000001,\n",
      "          75.14999999999999,\n",
      "          74.63,\n",
      "          74.16,\n",
      "          73.91\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          74.59,\n",
      "          75.29\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          61.739999999999995,\n",
      "          69.95,\n",
      "          75.09,\n",
      "          73.91,\n",
      "          74.17,\n",
      "          74.21,\n",
      "          74.19,\n",
      "          73.74000000000001,\n",
      "          73.92,\n",
      "          74.62\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"RfModel\": {\n",
      "    \"EntropySelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          22.34,\n",
      "          27.01,\n",
      "          32.07,\n",
      "          35.160000000000004,\n",
      "          47.72,\n",
      "          47.97,\n",
      "          52.400000000000006,\n",
      "          51.09,\n",
      "          54.459999999999994,\n",
      "          57.92,\n",
      "          57.489999999999995,\n",
      "          57.269999999999996,\n",
      "          56.65,\n",
      "          56.42,\n",
      "          56.47,\n",
      "          54.620000000000005,\n",
      "          55.11000000000001,\n",
      "          55.05,\n",
      "          55.13,\n",
      "          55.45,\n",
      "          53.769999999999996,\n",
      "          53.33,\n",
      "          53.690000000000005,\n",
      "          53.76,\n",
      "          54.55,\n",
      "          54.96,\n",
      "          55.120000000000005,\n",
      "          53.83,\n",
      "          55.1,\n",
      "          54.71,\n",
      "          55.510000000000005,\n",
      "          56.39999999999999,\n",
      "          55.379999999999995,\n",
      "          56.92,\n",
      "          55.85,\n",
      "          56.699999999999996,\n",
      "          56.21000000000001,\n",
      "          56.379999999999995,\n",
      "          57.31,\n",
      "          56.120000000000005,\n",
      "          56.44,\n",
      "          57.31,\n",
      "          58.47,\n",
      "          55.82,\n",
      "          57.37,\n",
      "          58.60999999999999,\n",
      "          58.85,\n",
      "          57.86,\n",
      "          57.36,\n",
      "          58.18\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          73.8,\n",
      "          73.65,\n",
      "          74.14,\n",
      "          74.59\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          49.919999999999995,\n",
      "          57.489999999999995,\n",
      "          63.129999999999995,\n",
      "          65.53,\n",
      "          69.39999999999999,\n",
      "          69.73,\n",
      "          69.32000000000001,\n",
      "          66.67999999999999,\n",
      "          67.25,\n",
      "          66.97999999999999,\n",
      "          66.36999999999999,\n",
      "          68.22,\n",
      "          66.18,\n",
      "          67.42,\n",
      "          67.67999999999999,\n",
      "          67.64,\n",
      "          70.99,\n",
      "          70.59,\n",
      "          70.81,\n",
      "          72.48\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          82.87,\n",
      "          81.83\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          58.25,\n",
      "          65.07,\n",
      "          65.14,\n",
      "          65.88000000000001,\n",
      "          64.94,\n",
      "          65.42999999999999,\n",
      "          66.64,\n",
      "          69.8,\n",
      "          69.13,\n",
      "          69.86\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          26.56,\n",
      "          45.550000000000004,\n",
      "          56.82000000000001,\n",
      "          67.99,\n",
      "          67.67999999999999,\n",
      "          71.17,\n",
      "          76.08,\n",
      "          78.13,\n",
      "          79.38,\n",
      "          79.69000000000001,\n",
      "          81.76,\n",
      "          82.43,\n",
      "          83.47,\n",
      "          84.99,\n",
      "          85.18,\n",
      "          86.0,\n",
      "          84.94,\n",
      "          86.07000000000001,\n",
      "          86.98,\n",
      "          86.56,\n",
      "          88.03,\n",
      "          87.92999999999999,\n",
      "          88.53,\n",
      "          89.2,\n",
      "          89.2,\n",
      "          89.71000000000001,\n",
      "          90.12,\n",
      "          90.57,\n",
      "          90.24,\n",
      "          90.49000000000001,\n",
      "          90.61,\n",
      "          91.09,\n",
      "          91.3,\n",
      "          91.07,\n",
      "          90.93,\n",
      "          91.17,\n",
      "          90.96,\n",
      "          91.38,\n",
      "          90.84,\n",
      "          91.72,\n",
      "          91.47,\n",
      "          91.56,\n",
      "          92.01,\n",
      "          91.94,\n",
      "          92.43,\n",
      "          92.43,\n",
      "          92.58999999999999,\n",
      "          92.56,\n",
      "          92.97999999999999,\n",
      "          92.80000000000001\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          73.39,\n",
      "          86.38,\n",
      "          90.11,\n",
      "          91.31\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          53.339999999999996,\n",
      "          63.85999999999999,\n",
      "          70.77,\n",
      "          75.53999999999999,\n",
      "          79.22,\n",
      "          83.19,\n",
      "          83.17999999999999,\n",
      "          84.82,\n",
      "          86.21,\n",
      "          86.72999999999999,\n",
      "          88.18,\n",
      "          89.2,\n",
      "          88.47,\n",
      "          89.64999999999999,\n",
      "          90.2,\n",
      "          90.68,\n",
      "          91.56,\n",
      "          91.64,\n",
      "          92.10000000000001,\n",
      "          92.30000000000001\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          80.64,\n",
      "          89.2\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          57.74,\n",
      "          75.92,\n",
      "          80.57,\n",
      "          86.13,\n",
      "          88.26,\n",
      "          88.62,\n",
      "          89.88000000000001,\n",
      "          90.93,\n",
      "          91.02,\n",
      "          92.17\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          28.470000000000002,\n",
      "          35.38,\n",
      "          44.85,\n",
      "          50.71,\n",
      "          58.48,\n",
      "          61.3,\n",
      "          63.739999999999995,\n",
      "          65.48,\n",
      "          70.15,\n",
      "          71.58,\n",
      "          74.52,\n",
      "          75.67,\n",
      "          77.11,\n",
      "          77.31,\n",
      "          77.44,\n",
      "          77.61,\n",
      "          78.07,\n",
      "          78.64,\n",
      "          78.99000000000001,\n",
      "          79.33,\n",
      "          79.99000000000001,\n",
      "          80.12,\n",
      "          82.24000000000001,\n",
      "          81.91000000000001,\n",
      "          82.74000000000001,\n",
      "          82.82000000000001,\n",
      "          83.21,\n",
      "          83.71,\n",
      "          83.38,\n",
      "          84.19,\n",
      "          84.61,\n",
      "          84.65,\n",
      "          84.7,\n",
      "          84.99,\n",
      "          85.13,\n",
      "          85.2,\n",
      "          85.72999999999999,\n",
      "          86.18,\n",
      "          86.25,\n",
      "          86.08,\n",
      "          85.76,\n",
      "          85.92999999999999,\n",
      "          86.33,\n",
      "          86.52,\n",
      "          86.94,\n",
      "          87.24,\n",
      "          87.26,\n",
      "          87.85,\n",
      "          87.91,\n",
      "          87.52\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          75.48,\n",
      "          83.13000000000001,\n",
      "          85.79,\n",
      "          87.78\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          35.36,\n",
      "          60.41,\n",
      "          67.99,\n",
      "          74.92,\n",
      "          78.18,\n",
      "          80.60000000000001,\n",
      "          81.69999999999999,\n",
      "          81.97,\n",
      "          82.43,\n",
      "          83.53,\n",
      "          84.89999999999999,\n",
      "          84.94,\n",
      "          85.24000000000001,\n",
      "          85.81,\n",
      "          85.96000000000001,\n",
      "          86.8,\n",
      "          87.25,\n",
      "          87.81,\n",
      "          87.9,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          79.44,\n",
      "          87.52\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          58.269999999999996,\n",
      "          71.76,\n",
      "          79.64,\n",
      "          82.54,\n",
      "          83.82,\n",
      "          83.98,\n",
      "          84.63000000000001,\n",
      "          84.89,\n",
      "          85.77,\n",
      "          86.59\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"SvmModel\": {\n",
      "    \"EntropySelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          34.22,\n",
      "          36.5,\n",
      "          41.5,\n",
      "          41.699999999999996,\n",
      "          43.05,\n",
      "          46.93,\n",
      "          50.62,\n",
      "          51.129999999999995,\n",
      "          55.74,\n",
      "          57.089999999999996,\n",
      "          56.84,\n",
      "          61.22,\n",
      "          62.029999999999994,\n",
      "          62.83,\n",
      "          62.029999999999994,\n",
      "          62.21,\n",
      "          63.28,\n",
      "          63.54,\n",
      "          65.23,\n",
      "          66.36999999999999,\n",
      "          68.42,\n",
      "          69.95,\n",
      "          69.55,\n",
      "          69.82000000000001,\n",
      "          74.8,\n",
      "          75.44,\n",
      "          74.92999999999999,\n",
      "          76.36,\n",
      "          77.23,\n",
      "          76.91,\n",
      "          75.79,\n",
      "          77.34,\n",
      "          77.81,\n",
      "          78.97,\n",
      "          80.16,\n",
      "          79.45,\n",
      "          79.65,\n",
      "          79.33,\n",
      "          79.41,\n",
      "          79.31,\n",
      "          78.95,\n",
      "          79.33,\n",
      "          78.78,\n",
      "          79.05,\n",
      "          79.11,\n",
      "          79.63,\n",
      "          79.60000000000001,\n",
      "          79.73,\n",
      "          80.13,\n",
      "          80.13\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.17,\n",
      "          79.14999999999999,\n",
      "          79.42,\n",
      "          80.08\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          52.65,\n",
      "          55.769999999999996,\n",
      "          58.5,\n",
      "          67.9,\n",
      "          68.63,\n",
      "          72.32,\n",
      "          72.37,\n",
      "          72.08,\n",
      "          72.49,\n",
      "          71.94,\n",
      "          73.11,\n",
      "          75.18,\n",
      "          76.25,\n",
      "          75.6,\n",
      "          76.79,\n",
      "          77.42999999999999,\n",
      "          77.56,\n",
      "          77.45,\n",
      "          78.3,\n",
      "          78.86\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.73,\n",
      "          84.64\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          68.25,\n",
      "          69.56,\n",
      "          71.76,\n",
      "          70.64,\n",
      "          70.59,\n",
      "          74.49,\n",
      "          76.31,\n",
      "          78.17,\n",
      "          77.95,\n",
      "          78.78\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          24.41,\n",
      "          39.12,\n",
      "          51.55,\n",
      "          58.15,\n",
      "          64.19,\n",
      "          67.33,\n",
      "          72.46000000000001,\n",
      "          73.94,\n",
      "          78.06,\n",
      "          78.57,\n",
      "          79.01,\n",
      "          78.68,\n",
      "          79.80000000000001,\n",
      "          80.78999999999999,\n",
      "          81.54,\n",
      "          82.21000000000001,\n",
      "          82.08,\n",
      "          83.17999999999999,\n",
      "          83.36,\n",
      "          83.13000000000001,\n",
      "          82.5,\n",
      "          83.24000000000001,\n",
      "          84.03,\n",
      "          84.84,\n",
      "          85.2,\n",
      "          85.17,\n",
      "          85.24000000000001,\n",
      "          85.1,\n",
      "          85.33,\n",
      "          85.00999999999999,\n",
      "          85.57000000000001,\n",
      "          85.91,\n",
      "          85.91,\n",
      "          86.4,\n",
      "          86.53999999999999,\n",
      "          86.78,\n",
      "          87.02,\n",
      "          87.18,\n",
      "          87.41,\n",
      "          87.33,\n",
      "          87.72,\n",
      "          87.8,\n",
      "          87.9,\n",
      "          88.1,\n",
      "          88.41,\n",
      "          88.22,\n",
      "          88.42999999999999,\n",
      "          88.38000000000001,\n",
      "          88.31,\n",
      "          88.6\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          76.8,\n",
      "          83.96000000000001,\n",
      "          87.08,\n",
      "          88.94\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          48.209999999999994,\n",
      "          59.870000000000005,\n",
      "          70.07,\n",
      "          73.88,\n",
      "          79.62,\n",
      "          80.99,\n",
      "          82.69999999999999,\n",
      "          83.2,\n",
      "          84.13000000000001,\n",
      "          84.61999999999999,\n",
      "          85.53,\n",
      "          86.32,\n",
      "          86.46000000000001,\n",
      "          87.16000000000001,\n",
      "          87.74,\n",
      "          87.87,\n",
      "          88.16000000000001,\n",
      "          88.24,\n",
      "          88.42,\n",
      "          88.13\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          82.87,\n",
      "          87.59\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          59.74,\n",
      "          70.57,\n",
      "          79.12,\n",
      "          83.25,\n",
      "          84.19,\n",
      "          86.44,\n",
      "          87.3,\n",
      "          87.81,\n",
      "          87.58,\n",
      "          88.63\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          30.12,\n",
      "          41.54,\n",
      "          51.15,\n",
      "          59.5,\n",
      "          64.64999999999999,\n",
      "          65.02,\n",
      "          66.7,\n",
      "          68.81,\n",
      "          70.28,\n",
      "          73.48,\n",
      "          73.83,\n",
      "          76.64,\n",
      "          76.83,\n",
      "          77.68,\n",
      "          77.38000000000001,\n",
      "          77.77,\n",
      "          79.17,\n",
      "          79.59,\n",
      "          80.86,\n",
      "          80.89,\n",
      "          81.24,\n",
      "          81.47999999999999,\n",
      "          82.23,\n",
      "          82.8,\n",
      "          82.96,\n",
      "          83.00999999999999,\n",
      "          83.64,\n",
      "          83.72,\n",
      "          83.35000000000001,\n",
      "          83.41,\n",
      "          83.69,\n",
      "          83.67999999999999,\n",
      "          84.23,\n",
      "          84.26,\n",
      "          84.48,\n",
      "          84.98,\n",
      "          85.38,\n",
      "          85.39,\n",
      "          85.63,\n",
      "          85.74000000000001,\n",
      "          86.17,\n",
      "          86.28,\n",
      "          86.38,\n",
      "          86.57000000000001,\n",
      "          86.42,\n",
      "          86.56,\n",
      "          86.38,\n",
      "          86.37,\n",
      "          86.44,\n",
      "          86.53999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.53999999999999,\n",
      "          80.67,\n",
      "          84.16,\n",
      "          86.61999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          55.489999999999995,\n",
      "          64.21,\n",
      "          71.63000000000001,\n",
      "          74.95,\n",
      "          76.49000000000001,\n",
      "          80.08999999999999,\n",
      "          82.11,\n",
      "          82.25,\n",
      "          82.65,\n",
      "          83.3,\n",
      "          84.02,\n",
      "          85.05,\n",
      "          85.15,\n",
      "          85.67,\n",
      "          86.18,\n",
      "          86.83999999999999,\n",
      "          87.41,\n",
      "          87.63,\n",
      "          87.82,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.15,\n",
      "          86.91\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          67.52,\n",
      "          75.52,\n",
      "          80.19,\n",
      "          84.26,\n",
      "          85.77,\n",
      "          86.16,\n",
      "          86.58,\n",
      "          86.65,\n",
      "          87.18,\n",
      "          87.09\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 41, using model = LogModel, selection_function = EntropySelection, k = 250, iteration = 0.\n",
      "\n",
      "initial random chosen samples (250,)\n",
      "initial train set: (250, 784) (250,) unique(labels): [18 34 33 25 23 29 17 29 20 22] [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59750, 784) (59750,) (250,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.177 s \n",
      "\n",
      "Accuracy rate for 73.340000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83       980\n",
      "           1       0.78      0.97      0.86      1135\n",
      "           2       0.77      0.70      0.73      1032\n",
      "           3       0.65      0.86      0.74      1010\n",
      "           4       0.75      0.75      0.75       982\n",
      "           5       0.80      0.40      0.53       892\n",
      "           6       0.71      0.80      0.75       958\n",
      "           7       0.72      0.75      0.73      1028\n",
      "           8       0.71      0.55      0.62       974\n",
      "           9       0.70      0.58      0.64      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.73      0.72     10000\n",
      "weighted avg       0.74      0.73      0.72     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 888    2    4   10    1   15   38    7   15    0]\n",
      " [   0 1096   15    9    0    0    8    2    5    0]\n",
      " [  59   61  726   28   39    3   58   15   29   14]\n",
      " [  15   21   15  864    6   11   12   19   22   25]\n",
      " [  23   36   11    9  741   12   40   12   53   45]\n",
      " [  42   30   14  208   51  355   65   73   24   30]\n",
      " [  65   10   54    6   27    9  766    1   20    0]\n",
      " [  14   51   50    8   17    1    7  768   14   98]\n",
      " [  13   72   35  153   29   21   63    4  540   44]\n",
      " [  29   21   20   34   73   15   20  171   36  590]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [ 22  44  56  46  75 107  33  39  31  47] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.200 s \n",
      "\n",
      "Accuracy rate for 66.690000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.95      0.83       980\n",
      "           1       0.63      0.98      0.76      1135\n",
      "           2       0.83      0.50      0.62      1032\n",
      "           3       0.52      0.77      0.62      1010\n",
      "           4       0.80      0.64      0.71       982\n",
      "           5       0.63      0.16      0.26       892\n",
      "           6       0.68      0.75      0.71       958\n",
      "           7       0.78      0.73      0.75      1028\n",
      "           8       0.55      0.47      0.51       974\n",
      "           9       0.64      0.63      0.63      1009\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.68      0.66      0.64     10000\n",
      "weighted avg       0.68      0.67      0.65     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 932    1    2    2    0    3   26    5    6    3]\n",
      " [   0 1113    1    6    0    0    3    1   11    0]\n",
      " [  75  234  511   38    6    2   62   19   45   40]\n",
      " [  52   20    8  777    1   47   11   12   57   25]\n",
      " [   9   32   17   28  631   16   58   28   91   72]\n",
      " [  82   48    8  295   23  145  136   35   56   64]\n",
      " [  56   43   39   11   51    1  717    3   35    2]\n",
      " [  15   96   15   14    5    1    1  748   15  118]\n",
      " [  16  150   11  248    7    6   32    6  455   43]\n",
      " [  16   42    5   68   63    8    8  106   53  640]]\n",
      "--------------------------------\n",
      "final active learning accuracies [73.34, 66.69]\n",
      "saved Active-learning-experiment-41.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-37.pkl', 'README.md', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-38.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 42, using model = LogModel, selection_function = EntropySelection, k = 125, iteration = 0.\n",
      "\n",
      "initial random chosen samples (125,)\n",
      "initial train set: (125, 784) (125,) unique(labels): [20 12 12 10 18  6  7 10 12 18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,) (125,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.135 s \n",
      "\n",
      "Accuracy rate for 70.860000 \n",
      "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81       980\n",
      "           1       0.80      0.91      0.85      1135\n",
      "           2       0.61      0.74      0.67      1032\n",
      "           3       0.77      0.62      0.69      1010\n",
      "           4       0.67      0.71      0.69       982\n",
      "           5       0.85      0.40      0.55       892\n",
      "           6       0.71      0.74      0.72       958\n",
      "           7       0.85      0.72      0.78      1028\n",
      "           8       0.57      0.64      0.60       974\n",
      "           9       0.65      0.64      0.64      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.70      0.70     10000\n",
      "weighted avg       0.72      0.71      0.70     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 887    1   27    0    1    0   56    0    8    0]\n",
      " [   0 1037   83    2    0    0    4    2    7    0]\n",
      " [  56   67  766   16   22    2   15   38   43    7]\n",
      " [  74   20   59  631    1   13   18   26  147   21]\n",
      " [  10   36   12    9  695    0   84    7   24  105]\n",
      " [  88   23   53   88   14  359   48    7  200   12]\n",
      " [  26    8  142    1   48    3  711    3   14    2]\n",
      " [  32   53   49    1   33    7    1  736    0  116]\n",
      " [  21   39   49   42   23   26   49   17  620   88]\n",
      " [  26   17    9   26  205   11   19   32   20  644]]\n",
      "--------------------------------\n",
      "val predicted: (59875,) ['3' '0' '4' ... '8' '6' '6']\n",
      "probabilities: (59875, 10) \n",
      " [3 0 4 ... 8 6 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (125, 784) (125,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [20 12 16 36 21 70 11 16 22 26] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.173 s \n",
      "\n",
      "Accuracy rate for 61.030000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.94      0.73       980\n",
      "           1       0.68      0.94      0.79      1135\n",
      "           2       0.52      0.68      0.59      1032\n",
      "           3       0.64      0.24      0.35      1010\n",
      "           4       0.60      0.78      0.68       982\n",
      "           5       0.83      0.03      0.06       892\n",
      "           6       0.65      0.69      0.67       958\n",
      "           7       0.88      0.57      0.69      1028\n",
      "           8       0.50      0.48      0.49       974\n",
      "           9       0.53      0.65      0.58      1009\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.64      0.60      0.56     10000\n",
      "weighted avg       0.64      0.61      0.57     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 926    1   24    0    1    1   11    2   12    2]\n",
      " [   0 1069   56    1    2    0    4    0    2    1]\n",
      " [  58  113  699    2   64    0   25   28   27   16]\n",
      " [ 204  111   98  245    8    1   33   10  231   69]\n",
      " [   8   37   12    1  766    0   46    3    1  108]\n",
      " [ 238   33   77  103   33   29  182    7  178   12]\n",
      " [  25   22  150    0   81    2  664    1    1   12]\n",
      " [  38   74   31    8   63    1    2  587    0  224]\n",
      " [  35   92  175   11   30    0   32    3  465  131]\n",
      " [  24   23   16   10  226    1   19   25   12  653]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['6' '0' '4' ... '6' '6' '2']\n",
      "probabilities: (59750, 10) \n",
      " [6 0 4 ... 6 6 2]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [ 21  13  22  44  24 145  22  19  31  34] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.195 s \n",
      "\n",
      "Accuracy rate for 58.930000 \n",
      "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.93      0.71       980\n",
      "           1       0.64      0.99      0.78      1135\n",
      "           2       0.71      0.53      0.60      1032\n",
      "           3       0.59      0.20      0.30      1010\n",
      "           4       0.46      0.86      0.60       982\n",
      "           5       0.96      0.12      0.21       892\n",
      "           6       0.73      0.80      0.76       958\n",
      "           7       0.81      0.71      0.76      1028\n",
      "           8       0.38      0.56      0.46       974\n",
      "           9       0.62      0.12      0.20      1009\n",
      "\n",
      "    accuracy                           0.59     10000\n",
      "   macro avg       0.65      0.58      0.54     10000\n",
      "weighted avg       0.64      0.59      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 916    2    5    0    0    1   49    5    2    0]\n",
      " [   0 1123    3    0    0    1    4    3    1    0]\n",
      " [ 106  207  542    0   67    1   44   62    3    0]\n",
      " [ 238   68   44  205   16    1   12   21  394   11]\n",
      " [   8   40    5    6  841    0   50    4   18   10]\n",
      " [ 212   24   43   84   42  107   41   14  323    2]\n",
      " [  39   27   60    1   53    1  762    6    9    0]\n",
      " [  22   72   19    6  147    0    3  731    1   27]\n",
      " [  57  164   34   11   45    0   71   23  545   24]\n",
      " [  17   30    7   37  627    0   14   35  121  121]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['7' '0' '4' ... '8' '6' '9']\n",
      "probabilities: (59625, 10) \n",
      " [7 0 4 ... 8 6 9]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [ 24  14  35  55  30 182  25  21  67  47] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.220 s \n",
      "\n",
      "Accuracy rate for 58.800000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.94      0.73       980\n",
      "           1       0.61      0.98      0.75      1135\n",
      "           2       0.87      0.24      0.38      1032\n",
      "           3       0.65      0.44      0.52      1010\n",
      "           4       0.43      0.83      0.57       982\n",
      "           5       0.83      0.23      0.36       892\n",
      "           6       0.65      0.81      0.72       958\n",
      "           7       0.87      0.54      0.67      1028\n",
      "           8       0.46      0.69      0.56       974\n",
      "           9       0.50      0.12      0.19      1009\n",
      "\n",
      "    accuracy                           0.59     10000\n",
      "   macro avg       0.65      0.58      0.55     10000\n",
      "weighted avg       0.65      0.59      0.55     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 923    1    2    0    1    1   46    0    4    2]\n",
      " [   0 1107    0    2    0    1    3    1   21    0]\n",
      " [ 157  228  251    1  123    2   55   39  167    9]\n",
      " [ 134  104   14  440    8   15   46   10  220   19]\n",
      " [  12   56    0   10  819    3   41    0   34    7]\n",
      " [ 150   26    4  109   43  207  143   12  197    1]\n",
      " [  61   20    9    2   63    2  780    5   16    0]\n",
      " [  33   88    1    8  245    3    1  560   30   59]\n",
      " [  35  130    6   19   21    6   51    8  675   23]\n",
      " [  27   49    2   86  586    9   32   10   90  118]]\n",
      "--------------------------------\n",
      "final active learning accuracies [70.86, 61.029999999999994, 58.93000000000001, 58.8]\n",
      "saved Active-learning-experiment-42.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-42.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-37.pkl', 'README.md', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-38.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 43, using model = LogModel, selection_function = EntropySelection, k = 50, iteration = 0.\n",
      "\n",
      "initial random chosen samples (50,)\n",
      "initial train set: (50, 784) (50,) unique(labels): [7 7 5 3 8 4 5 5 3 3] [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59950, 784) (59950,) (50,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.120 s \n",
      "\n",
      "Accuracy rate for 60.810000 \n",
      "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       980\n",
      "           1       0.72      0.90      0.80      1135\n",
      "           2       0.67      0.39      0.49      1032\n",
      "           3       0.63      0.45      0.53      1010\n",
      "           4       0.57      0.62      0.60       982\n",
      "           5       0.31      0.46      0.37       892\n",
      "           6       0.85      0.69      0.76       958\n",
      "           7       0.59      0.58      0.59      1028\n",
      "           8       0.49      0.33      0.39       974\n",
      "           9       0.54      0.67      0.60      1009\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.62      0.60      0.60     10000\n",
      "weighted avg       0.62      0.61      0.60     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 919    1    4   18    4    9   17    2    3    3]\n",
      " [   0 1017    1    0    1   98    1    5   12    0]\n",
      " [  18  172  406  142   55   23   26   88   76   26]\n",
      " [   1   20   28  456    9  314    1   98   51   32]\n",
      " [   3   41   90    3  613   21   17    6   10  178]\n",
      " [  66    8    3   51   45  413   40   70  141   55]\n",
      " [  62   16   37   17   91   54  660    1    3   17]\n",
      " [  29   38   11   15   79   27    0  598   18  213]\n",
      " [  11   68   18   15   44  356   17   67  318   60]\n",
      " [  19   32   12    6  128   35    1   79   16  681]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['7' '0' '2' ... '5' '6' '8']\n",
      "probabilities: (59950, 10) \n",
      " [7 0 2 ... 5 6 8]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 7  7 14 12  8 11 25  5  7  4] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.127 s \n",
      "\n",
      "Accuracy rate for 61.450000 \n",
      "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.90      0.77       980\n",
      "           1       0.70      0.97      0.81      1135\n",
      "           2       0.70      0.56      0.62      1032\n",
      "           3       0.60      0.56      0.58      1010\n",
      "           4       0.57      0.76      0.65       982\n",
      "           5       0.42      0.28      0.34       892\n",
      "           6       0.70      0.30      0.41       958\n",
      "           7       0.58      0.65      0.61      1028\n",
      "           8       0.61      0.51      0.55       974\n",
      "           9       0.53      0.57      0.55      1009\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.61      0.61      0.59     10000\n",
      "weighted avg       0.61      0.61      0.60     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 883    2    0   30    0   21   28    4    3    9]\n",
      " [   0 1101    0    1    0    4    0    7   22    0]\n",
      " [  33  152  576   43   46    4   23   54   52   49]\n",
      " [  30   36   32  569    4  112    1  140   77    9]\n",
      " [   9   53   14   11  745    5   31    7    6  101]\n",
      " [ 125   30   17  178   46  253   13   59   94   77]\n",
      " [ 149   10   98   33  192  177  283    1    7    8]\n",
      " [  38   46    7    2   43    1    7  667    7  210]\n",
      " [  18   96   72   55   62   20   16   96  494   45]\n",
      " [  18   49    6   23  160   10    4  120   45  574]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 4 ... 5 0 8]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [ 7  8 19 14 13 31 25 14 12  7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.135 s \n",
      "\n",
      "Accuracy rate for 56.710000 \n",
      "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.94      0.73       980\n",
      "           1       0.59      0.99      0.74      1135\n",
      "           2       0.65      0.45      0.53      1032\n",
      "           3       0.60      0.52      0.56      1010\n",
      "           4       0.57      0.76      0.65       982\n",
      "           5       0.27      0.00      0.01       892\n",
      "           6       0.68      0.34      0.45       958\n",
      "           7       0.89      0.23      0.36      1028\n",
      "           8       0.46      0.70      0.56       974\n",
      "           9       0.45      0.63      0.53      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.58      0.56      0.51     10000\n",
      "weighted avg       0.58      0.57      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 924    2    1    8    1    0   37    0    4    3]\n",
      " [   0 1122    0    2    0    0    0    0   11    0]\n",
      " [  83  220  466   36   23    0   37    6  120   41]\n",
      " [  51  123    7  529    6    3    2    7  240   42]\n",
      " [   4   72   28    3  743    0   41    6    9   76]\n",
      " [ 222   46    6  177   49    3   19    5  297   68]\n",
      " [  94   15  163   65  196    5  327    0   56   37]\n",
      " [ 114  114   14    4   53    0    3  233   22  471]\n",
      " [  27  112   28   49   22    0   13    3  686   34]\n",
      " [  21   69    2   15  213    0    3    2   46  638]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['3' '0' '7' ... '8' '0' '8']\n",
      "probabilities: (59850, 10) \n",
      " [3 0 7 ... 8 0 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [ 7  8 21 17 13 50 38 25 14  7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.158 s \n",
      "\n",
      "Accuracy rate for 58.860000 \n",
      "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.95      0.80       980\n",
      "           1       0.55      0.98      0.70      1135\n",
      "           2       0.75      0.42      0.54      1032\n",
      "           3       0.51      0.42      0.46      1010\n",
      "           4       0.55      0.87      0.67       982\n",
      "           5       0.38      0.00      0.01       892\n",
      "           6       0.72      0.66      0.69       958\n",
      "           7       0.88      0.43      0.57      1028\n",
      "           8       0.44      0.65      0.52       974\n",
      "           9       0.52      0.42      0.47      1009\n",
      "\n",
      "    accuracy                           0.59     10000\n",
      "   macro avg       0.60      0.58      0.54     10000\n",
      "weighted avg       0.60      0.59      0.55     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 927    3    5   12    2    1   15    1   11    3]\n",
      " [   0 1114    5    3    0    0    6    0    7    0]\n",
      " [  72  250  436   31   33    0   79   27   90   14]\n",
      " [  29  195    8  427    7    1   23    7  283   30]\n",
      " [   4   66    8    6  850    0   18    2    9   19]\n",
      " [ 131   52    6  217   61    3   46    4  315   57]\n",
      " [ 105   19   45   32   84    1  633    0   30    9]\n",
      " [  39  124   23   27  113    2   11  438    7  244]\n",
      " [  20  155   40   35   27    0   43    4  630   20]\n",
      " [  15   57    7   47  371    0    5   17   62  428]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['3' '0' '6' ... '3' '8' '0']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 6 ... 3 8 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (200, 784) (200,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [ 9  8 25 23 14 66 42 35 18 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.173 s \n",
      "\n",
      "Accuracy rate for 55.700000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82       980\n",
      "           1       0.49      0.94      0.64      1135\n",
      "           2       0.78      0.40      0.53      1032\n",
      "           3       0.54      0.52      0.53      1010\n",
      "           4       0.43      0.86      0.58       982\n",
      "           5       0.89      0.01      0.02       892\n",
      "           6       0.68      0.69      0.68       958\n",
      "           7       0.94      0.36      0.52      1028\n",
      "           8       0.54      0.46      0.50       974\n",
      "           9       0.35      0.30      0.32      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.64      0.55      0.51     10000\n",
      "weighted avg       0.63      0.56      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 928    3    9    9    1    1    9    2    2   16]\n",
      " [   0 1070    0    2    0    0    5    0   22   36]\n",
      " [  49  310  408   19   45    0  111    6   45   39]\n",
      " [  29  225   17  524   34    0   23    3   88   67]\n",
      " [  23   69   13    0  842    0   17    7    2    9]\n",
      " [ 101   34    3  289  148    8   48    3  154  104]\n",
      " [  95   21   20   34   91    0  663    0   23   11]\n",
      " [  29  131   19   10  180    0    6  373   19  261]\n",
      " [  14  257   29   62   45    0   94    1  451   21]\n",
      " [  20   84    3   15  553    0    3    1   27  303]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['3' '0' '7' ... '3' '8' '4']\n",
      "probabilities: (59750, 10) \n",
      " [3 0 7 ... 3 8 4]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [ 9  8 30 27 18 84 43 43 21 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.171 s \n",
      "\n",
      "Accuracy rate for 53.180000 \n",
      "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.96      0.78       980\n",
      "           1       0.44      0.99      0.61      1135\n",
      "           2       0.43      0.32      0.37      1032\n",
      "           3       0.62      0.38      0.47      1010\n",
      "           4       0.46      0.81      0.59       982\n",
      "           5       0.55      0.09      0.16       892\n",
      "           6       0.63      0.73      0.67       958\n",
      "           7       0.94      0.33      0.48      1028\n",
      "           8       0.48      0.49      0.49       974\n",
      "           9       0.56      0.14      0.23      1009\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.58      0.52      0.48     10000\n",
      "weighted avg       0.58      0.53      0.49     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 944    3    3    2    0    6    8    1    1   12]\n",
      " [   0 1118    0    0    0    0    6    0   11    0]\n",
      " [  99  335  331    3   45    3  194    4   14    4]\n",
      " [  59  331   21  388   24   19   20    6  141    1]\n",
      " [   8   97   14    0  798    4   23    0   14   24]\n",
      " [ 136   65   39  191   76   84   65    8  211   17]\n",
      " [ 110   24   22   13   59   12  696    0   18    4]\n",
      " [  37  164  277    3  130   10   13  335   14   45]\n",
      " [  24  301   40   15   24    3   82    0  482    3]\n",
      " [  16  122   24    9  578   11    4    2  101  142]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['3' '0' '4' ... '3' '5' '0']\n",
      "probabilities: (59700, 10) \n",
      " [3 0 4 ... 3 5 0]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [ 10   8  41  30  18 107  46  46  24  20] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.174 s \n",
      "\n",
      "Accuracy rate for 53.200000 \n",
      "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83       980\n",
      "           1       0.45      0.98      0.61      1135\n",
      "           2       0.65      0.17      0.27      1032\n",
      "           3       0.59      0.37      0.46      1010\n",
      "           4       0.39      0.85      0.53       982\n",
      "           5       0.49      0.03      0.06       892\n",
      "           6       0.56      0.81      0.66       958\n",
      "           7       0.95      0.51      0.66      1028\n",
      "           8       0.48      0.54      0.51       974\n",
      "           9       0.39      0.07      0.12      1009\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.57      0.52      0.47     10000\n",
      "weighted avg       0.57      0.53      0.48     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 889    3    3    4    0    7   56    0    5   13]\n",
      " [   0 1117    0    1    0    3    4    0   10    0]\n",
      " [  74  314  179    2  100    1  292   10   58    2]\n",
      " [  36  345   10  378   53    7   51    8  122    0]\n",
      " [   3   82    8    0  832    1   19    1   12   24]\n",
      " [  82   69   14  216  129   27   95    3  232   25]\n",
      " [  37   15    6    8   78    4  773    2   31    4]\n",
      " [  14  159   32    2  211    4   13  526   24   43]\n",
      " [  14  284   10   11   45    0   81    1  526    2]\n",
      " [   8  121   12   15  690    1    4    3   82   73]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['3' '0' '4' ... '3' '4' '6']\n",
      "probabilities: (59650, 10) \n",
      " [3 0 4 ... 3 4 6]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [ 11  11  45  32  18 142  46  47  27  21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.196 s \n",
      "\n",
      "Accuracy rate for 53.340000 \n",
      "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       980\n",
      "           1       0.50      0.99      0.66      1135\n",
      "           2       0.48      0.05      0.10      1032\n",
      "           3       0.63      0.46      0.53      1010\n",
      "           4       0.39      0.85      0.54       982\n",
      "           5       0.44      0.05      0.09       892\n",
      "           6       0.53      0.81      0.64       958\n",
      "           7       0.93      0.46      0.61      1028\n",
      "           8       0.43      0.59      0.50       974\n",
      "           9       0.47      0.09      0.15      1009\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.56      0.53      0.47     10000\n",
      "weighted avg       0.56      0.53      0.47     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 887    2    1    0    3    1   51    1   31    3]\n",
      " [   0 1126    0    1    0    0    7    0    1    0]\n",
      " [  64  306   56    4  192    2  344    9   49    6]\n",
      " [  36  126    9  468   37    4   49   10  270    1]\n",
      " [   3   77    5    0  834   11   21    2    8   21]\n",
      " [  63  138    2  204   52   46   90    3  276   18]\n",
      " [  31   27    2    9   82    7  776    1   18    5]\n",
      " [  29  151   28    9  251    8   13  470   18   51]\n",
      " [  10  213    4   13   34    5  116    0  579    0]\n",
      " [   8   94    9   36  633   21    4    7  105   92]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['3' '0' '4' ... '3' '8' '4']\n",
      "probabilities: (59600, 10) \n",
      " [3 0 4 ... 3 8 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (400, 784) (400,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [ 11  11  71  32  19 154  47  50  32  23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.211 s \n",
      "\n",
      "Accuracy rate for 55.840000 \n",
      "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.83       980\n",
      "           1       0.47      0.99      0.64      1135\n",
      "           2       0.62      0.18      0.28      1032\n",
      "           3       0.65      0.57      0.60      1010\n",
      "           4       0.39      0.86      0.54       982\n",
      "           5       0.55      0.04      0.07       892\n",
      "           6       0.56      0.83      0.67       958\n",
      "           7       0.93      0.51      0.66      1028\n",
      "           8       0.59      0.50      0.54       974\n",
      "           9       0.57      0.08      0.14      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.61      0.55      0.50     10000\n",
      "weighted avg       0.61      0.56      0.50     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 942    3    1    0    2    2   19    1    7    3]\n",
      " [   0 1125    0    0    0    0    6    0    4    0]\n",
      " [  64  317  184    2  113    1  287   15   44    5]\n",
      " [  63  165   18  571   67    3   45    7   69    2]\n",
      " [   3   90    3    1  840    5   29    2    5    4]\n",
      " [ 106  141   49  188  134   34   98    3  123   16]\n",
      " [  40   22    2    7   59    4  798    1   22    3]\n",
      " [  32  166   25   22  197    1    9  524   25   27]\n",
      " [  19  244    6   53   41    2  120    2  485    2]\n",
      " [   9  112    7   40  690   10    7    8   45   81]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['3' '0' '4' ... '3' '8' '6']\n",
      "probabilities: (59550, 10) \n",
      " [3 0 4 ... 3 8 6]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [ 14  11  77  38  20 181  51  51  34  23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.205 s \n",
      "\n",
      "Accuracy rate for 57.100000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.95      0.81       980\n",
      "           1       0.47      0.99      0.63      1135\n",
      "           2       0.45      0.23      0.31      1032\n",
      "           3       0.56      0.68      0.61      1010\n",
      "           4       0.51      0.79      0.62       982\n",
      "           5       0.46      0.02      0.04       892\n",
      "           6       0.62      0.81      0.70       958\n",
      "           7       0.92      0.53      0.67      1028\n",
      "           8       0.55      0.40      0.46       974\n",
      "           9       0.58      0.22      0.32      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.58      0.56      0.52     10000\n",
      "weighted avg       0.58      0.57      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 931    3    0    4    2    2   12    0    6   20]\n",
      " [   0 1122    0    1    0    0    4    0    8    0]\n",
      " [ 134  333  242    8   50    1  201   15   39    9]\n",
      " [  48  144   19  689   22    0   33    9   42    4]\n",
      " [   5   93   13    5  771    5   30    4   28   28]\n",
      " [  84  150   44  339   70   21   71    7   76   30]\n",
      " [  65   26    3   13   44    2  775    1   24    5]\n",
      " [  39  153  127   15   65    5    5  547   19   53]\n",
      " [  13  277   34  106   19    2  121    4  386   12]\n",
      " [  10  105   54   58  460    8    3    9   76  226]]\n",
      "--------------------------------\n",
      "final active learning accuracies [60.809999999999995, 61.45, 56.71000000000001, 58.86, 55.7, 53.18000000000001, 53.2, 53.339999999999996, 55.84, 57.099999999999994]\n",
      "saved Active-learning-experiment-43.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-42.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-37.pkl', 'README.md', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-43.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-38.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 44, using model = LogModel, selection_function = EntropySelection, k = 25, iteration = 0.\n",
      "\n",
      "initial random chosen samples (25,)\n",
      "initial train set: (25, 784) (25,) unique(labels): [1 6 2 4 1 4 0 2 3 2] [0 1 2 3 4 5 7 8 9]\n",
      "val set: (59975, 784) (59975,) (25,)\n",
      "\n",
      "Train set: (25, 784) y: (25,)\n",
      "Val   set: (59975, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.115 s \n",
      "\n",
      "Accuracy rate for 41.870000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=2.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.27      0.39       980\n",
      "           1       0.57      0.59      0.58      1135\n",
      "           2       0.66      0.40      0.50      1032\n",
      "           3       0.69      0.42      0.52      1010\n",
      "           4       0.25      0.27      0.26       982\n",
      "           5       0.27      0.63      0.38       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.46      0.74      0.57      1028\n",
      "           8       0.40      0.44      0.42       974\n",
      "           9       0.29      0.38      0.33      1009\n",
      "\n",
      "    accuracy                           0.42     10000\n",
      "   macro avg       0.43      0.42      0.40     10000\n",
      "weighted avg       0.44      0.42      0.40     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[269   1  16  15 104 263   0   5 114 193]\n",
      " [  4 672   3   1   0 312   0 138   4   1]\n",
      " [ 18 180 415  31  71  20   0  13 185  99]\n",
      " [ 26   7  50 425   0 296   0  46 112  48]\n",
      " [  2  52  30   1 261  67   0 132  25 412]\n",
      " [ 11  46  16  93  11 562   0  66  61  26]\n",
      " [  6  51  88   0 458 243   0   2  73  37]\n",
      " [ 26  50   3   1   9  30   0 765  55  89]\n",
      " [ 14 115   6  38  38 197   0  70 431  65]\n",
      " [  9   9   1   7  92  59   0 430  15 387]]\n",
      "--------------------------------\n",
      "val predicted: (59975,) ['0' '0' '9' ... '5' '5' '8']\n",
      "probabilities: (59975, 9) \n",
      " [0 0 8 ... 5 5 7]\n",
      "trainset before (25, 784) (25,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [ 2 15  4  4  2 10  2  2  6  3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.124 s \n",
      "\n",
      "Accuracy rate for 48.920000 \n",
      "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.55      0.67       980\n",
      "           1       0.72      0.94      0.82      1135\n",
      "           2       0.76      0.29      0.42      1032\n",
      "           3       0.64      0.62      0.63      1010\n",
      "           4       0.32      0.40      0.35       982\n",
      "           5       0.29      0.45      0.36       892\n",
      "           6       0.26      0.04      0.08       958\n",
      "           7       0.47      0.79      0.59      1028\n",
      "           8       0.46      0.50      0.48       974\n",
      "           9       0.23      0.21      0.22      1009\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.50      0.48      0.46     10000\n",
      "weighted avg       0.51      0.49      0.47     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 543    1    3   37  112  138   16    8    7  115]\n",
      " [   0 1066    1    0    0   17    1    4   46    0]\n",
      " [  19  117  299   54   57   24   66   33  259  104]\n",
      " [  16   53    8  629    2  176    0   55   51   20]\n",
      " [   3   49   15    3  396   89    1  138   17  271]\n",
      " [  12   59    3  159   28  404   37  126   35   29]\n",
      " [  21   24   52    7  485  152   43    2  125   47]\n",
      " [  11   37   10    5   11   44    0  814   12   84]\n",
      " [   2   56    3   77   25  215    0   75  485   36]\n",
      " [   8    9    2   11  140  124    1  488   13  213]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['0' '0' '4' ... '5' '0' '8']\n",
      "probabilities: (59950, 10) \n",
      " [0 0 4 ... 5 0 8]\n",
      "trainset before (50, 784) (50,)\n",
      "trainset after (75, 784) (75,)\n",
      "updated train set: (75, 784) (75,) unique(labels): [ 3 15  7  9  3 19  2  3 10  4] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59925, 784) (59925,)\n",
      "\n",
      "Train set: (75, 784) y: (75,)\n",
      "Val   set: (59925, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.136 s \n",
      "\n",
      "Accuracy rate for 52.470000 \n",
      "Classification report for classifier LogisticRegression(C=0.6666666666666666, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76       980\n",
      "           1       0.74      0.94      0.83      1135\n",
      "           2       0.75      0.25      0.37      1032\n",
      "           3       0.53      0.70      0.60      1010\n",
      "           4       0.41      0.52      0.46       982\n",
      "           5       0.31      0.48      0.37       892\n",
      "           6       0.19      0.05      0.08       958\n",
      "           7       0.55      0.80      0.65      1028\n",
      "           8       0.55      0.36      0.43       974\n",
      "           9       0.36      0.31      0.33      1009\n",
      "\n",
      "    accuracy                           0.52     10000\n",
      "   macro avg       0.51      0.52      0.49     10000\n",
      "weighted avg       0.52      0.52      0.50     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 750    0    2   25    7  158   10    7    9   12]\n",
      " [   0 1064    2    2    1   60    2    4    0    0]\n",
      " [  68  153  254  124   21   31  108   32  165   76]\n",
      " [   6   27   18  708    1  126    6   71   20   27]\n",
      " [  28   36    5    0  511   80    8   55   36  223]\n",
      " [  28   32    5  197   40  431   67   54   14   24]\n",
      " [  94   22   46    1  428  289   48    0    7   23]\n",
      " [   3   33    5   14   13   14    0  826   17  103]\n",
      " [   8   70    0  254   41  127    8   64  347   55]\n",
      " [   8    5    1   21  172   94    1  384   15  308]]\n",
      "--------------------------------\n",
      "val predicted: (59925,) ['5' '0' '4' ... '5' '5' '5']\n",
      "probabilities: (59925, 10) \n",
      " [5 0 4 ... 5 5 5]\n",
      "trainset before (75, 784) (75,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 4 15  7  9  6 39  2  3 10  5] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.131 s \n",
      "\n",
      "Accuracy rate for 51.810000 \n",
      "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.70      0.79       980\n",
      "           1       0.73      0.98      0.84      1135\n",
      "           2       0.61      0.20      0.30      1032\n",
      "           3       0.44      0.78      0.56      1010\n",
      "           4       0.42      0.67      0.52       982\n",
      "           5       0.42      0.28      0.34       892\n",
      "           6       0.41      0.05      0.09       958\n",
      "           7       0.52      0.75      0.61      1028\n",
      "           8       0.47      0.38      0.42       974\n",
      "           9       0.28      0.29      0.28      1009\n",
      "\n",
      "    accuracy                           0.52     10000\n",
      "   macro avg       0.52      0.51      0.48     10000\n",
      "weighted avg       0.53      0.52      0.48     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 684    1    6   74    1   47   15   10   13  129]\n",
      " [   0 1112    4    7    1    2    1    5    3    0]\n",
      " [   9  166  207  132  168   11   22   33  245   39]\n",
      " [   2   12   19  787    9   70    1   76   24   10]\n",
      " [   1   28    5    2  658   22    0   59    8  199]\n",
      " [  10   25    7  355   29  250   28   69   46   73]\n",
      " [  38   40   88   23  445  138   48    1   27  110]\n",
      " [   0   39    2   13   24    5    0  768   27  150]\n",
      " [   5   76    0  342   30   30    2   69  374   46]\n",
      " [   3   14    1   60  197   24    0  394   23  293]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '4' ... '5' '5' '8']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 4 ... 5 5 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (100, 784) (100,)\n",
      "trainset after (125, 784) (125,)\n",
      "updated train set: (125, 784) (125,) unique(labels): [ 6 15 11 10  6 52  5  4 10  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59875, 784) (59875,)\n",
      "\n",
      "Train set: (125, 784) y: (125,)\n",
      "Val   set: (59875, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.137 s \n",
      "\n",
      "Accuracy rate for 52.890000 \n",
      "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.52      0.66       980\n",
      "           1       0.73      0.98      0.84      1135\n",
      "           2       0.38      0.22      0.28      1032\n",
      "           3       0.51      0.80      0.63      1010\n",
      "           4       0.69      0.47      0.55       982\n",
      "           5       0.45      0.25      0.32       892\n",
      "           6       0.41      0.25      0.31       958\n",
      "           7       0.56      0.73      0.64      1028\n",
      "           8       0.36      0.57      0.44       974\n",
      "           9       0.36      0.41      0.38      1009\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.54      0.52      0.50     10000\n",
      "weighted avg       0.54      0.53      0.51     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 509    2    9  114    0   37   95    6   94  114]\n",
      " [   0 1111    1    4    1    3    0    1   14    0]\n",
      " [   6  171  226   36   47    6  129   30  365   16]\n",
      " [   4   14   17  811    1   32   13   48   56   14]\n",
      " [   2   28   29    0  457   43    0   55   92  276]\n",
      " [   7   29   35  325    5  223   77   43   93   55]\n",
      " [  21   44  257   16   89   85  237    0  135   74]\n",
      " [   0   41    6   11   15   13    0  753   24  165]\n",
      " [   3   63    9  219    2   18   29   52  551   28]\n",
      " [   1   15    5   47   50   41    0  352   87  411]]\n",
      "--------------------------------\n",
      "val predicted: (59875,) ['3' '0' '4' ... '5' '6' '5']\n",
      "probabilities: (59875, 10) \n",
      " [3 0 4 ... 5 6 5]\n",
      "trainset before (125, 784) (125,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [ 6 15 15 14  7 57 11  4 15  6] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.133 s \n",
      "\n",
      "Accuracy rate for 57.300000 \n",
      "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.77       980\n",
      "           1       0.67      0.99      0.80      1135\n",
      "           2       0.63      0.11      0.19      1032\n",
      "           3       0.49      0.67      0.57      1010\n",
      "           4       0.54      0.76      0.63       982\n",
      "           5       0.41      0.19      0.26       892\n",
      "           6       0.55      0.58      0.57       958\n",
      "           7       0.53      0.81      0.64      1028\n",
      "           8       0.57      0.53      0.55       974\n",
      "           9       0.45      0.32      0.37      1009\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.57      0.56      0.53     10000\n",
      "weighted avg       0.57      0.57      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 678    2    4   36    2   26  112   24   24   72]\n",
      " [   0 1121    0    3    2    2    3    2    2    0]\n",
      " [  32  232  116  149  112    5  203   62  112    9]\n",
      " [  11   73    6  678   24   77   31   83   17   10]\n",
      " [   5   15   10    1  747   20    2   52   30  100]\n",
      " [  20   40   12  291   24  167   73   59  144   62]\n",
      " [  15   39   33    4  175   80  560    6   29   17]\n",
      " [   0   37    3   10   38    7    0  828    8   97]\n",
      " [   9  114    0  155   40   13   27   70  515   31]\n",
      " [   1   12    0   57  215   15    2  365   22  320]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['3' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59850, 10) \n",
      " [3 0 4 ... 5 6 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (175, 784) (175,)\n",
      "updated train set: (175, 784) (175,) unique(labels): [ 7 15 16 19  7 70 11  5 18  7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59825, 784) (59825,)\n",
      "\n",
      "Train set: (175, 784) y: (175,)\n",
      "Val   set: (59825, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.149 s \n",
      "\n",
      "Accuracy rate for 56.130000 \n",
      "Classification report for classifier LogisticRegression(C=0.2857142857142857, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.69      0.77       980\n",
      "           1       0.62      0.99      0.76      1135\n",
      "           2       0.53      0.21      0.30      1032\n",
      "           3       0.55      0.73      0.62      1010\n",
      "           4       0.46      0.80      0.58       982\n",
      "           5       0.83      0.04      0.07       892\n",
      "           6       0.50      0.67      0.57       958\n",
      "           7       0.58      0.76      0.66      1028\n",
      "           8       0.57      0.47      0.52       974\n",
      "           9       0.34      0.16      0.22      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.59      0.55      0.51     10000\n",
      "weighted avg       0.58      0.56      0.51     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 675    3    5   35    1    1  160   12   50   38]\n",
      " [   0 1123    1    3    2    0    3    1    2    0]\n",
      " [  20  261  214   48  106    1  259   12  103    8]\n",
      " [   6   71   22  735   42    1   53   47   26    7]\n",
      " [   5   19   26    0  788    1    8   32   10   93]\n",
      " [  31   51   28  349   60   35  104   91  109   34]\n",
      " [  11   45   73    1  142    1  642    1   25   17]\n",
      " [   3   48   10   23   64    1    0  781   11   87]\n",
      " [   6  170    3  109   83    1   61   61  462   18]\n",
      " [   5   21   21   40  441    0    5  306   12  158]]\n",
      "--------------------------------\n",
      "val predicted: (59825,) ['3' '0' '4' ... '4' '6' '8']\n",
      "probabilities: (59825, 10) \n",
      " [3 0 4 ... 4 6 8]\n",
      "trainset before (175, 784) (175,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [ 7 15 21 20  7 87 12  6 18  7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.150 s \n",
      "\n",
      "Accuracy rate for 53.490000 \n",
      "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       980\n",
      "           1       0.61      0.99      0.75      1135\n",
      "           2       0.63      0.30      0.41      1032\n",
      "           3       0.63      0.70      0.66      1010\n",
      "           4       0.36      0.82      0.50       982\n",
      "           5       0.90      0.07      0.14       892\n",
      "           6       0.64      0.58      0.61       958\n",
      "           7       0.84      0.14      0.25      1028\n",
      "           8       0.51      0.60      0.55       974\n",
      "           9       0.24      0.22      0.23      1009\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.61      0.53      0.49     10000\n",
      "weighted avg       0.61      0.53      0.49     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 831    2    0   16    1    0   26    3   61   40]\n",
      " [   0 1118    0    5    5    0    3    1    3    0]\n",
      " [  81  241  312   23   97    0  119    2  151    6]\n",
      " [  35   98   22  704   56    0   33    6   50    6]\n",
      " [   8   22   15    0  806    2    2    1   13  113]\n",
      " [  53   52   58  280   54   66   93    6  172   58]\n",
      " [  47   45   40    1  187    0  560    2   54   22]\n",
      " [   9   60   23   34  287    1    0  148   24  442]\n",
      " [  14  178   13   35   87    0   38    1  584   24]\n",
      " [   9   27    9   22  686    4    1    6   25  220]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['3' '0' '7' ... '4' '0' '8']\n",
      "probabilities: (59800, 10) \n",
      " [3 0 7 ... 4 0 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (200, 784) (200,)\n",
      "trainset after (225, 784) (225,)\n",
      "updated train set: (225, 784) (225,) unique(labels): [  7  15  23  25   7 100  14   6  20   8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59775, 784) (59775,)\n",
      "\n",
      "Train set: (225, 784) y: (225,)\n",
      "Val   set: (59775, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.158 s \n",
      "\n",
      "Accuracy rate for 54.540000 \n",
      "Classification report for classifier LogisticRegression(C=0.2222222222222222, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.82      0.78       980\n",
      "           1       0.57      0.99      0.73      1135\n",
      "           2       0.78      0.15      0.25      1032\n",
      "           3       0.73      0.57      0.64      1010\n",
      "           4       0.35      0.86      0.50       982\n",
      "           5       0.91      0.09      0.17       892\n",
      "           6       0.56      0.78      0.65       958\n",
      "           7       0.76      0.46      0.57      1028\n",
      "           8       0.58      0.48      0.53       974\n",
      "           9       0.26      0.18      0.21      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.62      0.54      0.50     10000\n",
      "weighted avg       0.62      0.55      0.51     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 807    3    0    1    2    0  105   23   24   15]\n",
      " [   0 1122    0    0    3    0    5    2    3    0]\n",
      " [ 127  275  152    8  167    2  197   25   46   33]\n",
      " [  39  127    4  574  101    2   66   28   51   18]\n",
      " [   7   23    2    0  840    2    8   10    0   90]\n",
      " [  57   56    9  175  118   84  152   30  185   26]\n",
      " [  27   28    9    0  112    0  749    5   23    5]\n",
      " [   4   65    5    0  192    0    0  470    0  292]\n",
      " [  22  232   14   16  108    2   49    6  472   53]\n",
      " [   9   26    1    7  739    0    4   23   16  184]]\n",
      "--------------------------------\n",
      "val predicted: (59775,) ['6' '0' '7' ... '4' '0' '8']\n",
      "probabilities: (59775, 10) \n",
      " [6 0 7 ... 4 0 8]\n",
      "trainset before (225, 784) (225,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [  8  15  24  25   8 118  14   7  22   9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.162 s \n",
      "\n",
      "Accuracy rate for 50.220000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72       980\n",
      "           1       0.56      0.99      0.72      1135\n",
      "           2       0.61      0.09      0.15      1032\n",
      "           3       0.75      0.54      0.63      1010\n",
      "           4       0.37      0.86      0.52       982\n",
      "           5       0.74      0.08      0.14       892\n",
      "           6       0.51      0.81      0.63       958\n",
      "           7       0.60      0.06      0.10      1028\n",
      "           8       0.49      0.49      0.49       974\n",
      "           9       0.28      0.30      0.29      1009\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.56      0.50      0.44     10000\n",
      "weighted avg       0.56      0.50      0.44     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 743    3    1    2    0    2  162   13   41   13]\n",
      " [   0 1122    0    1    4    1    4    0    3    0]\n",
      " [ 137  246   90    6  209    3  253    5   69   14]\n",
      " [  47  165    0  546   58    2   75    6   78   33]\n",
      " [   4   24    4    0  844    4   11    1    2   88]\n",
      " [  81   60    5  151   78   68  153    6  239   51]\n",
      " [  22   25    8    0   78    4  775    1   41    4]\n",
      " [  17   68   20    3  306    6    2   57    7  542]\n",
      " [  20  248   12   13   95    1   66    1  477   41]\n",
      " [  11   27    7    6  622    1    6    5   24  300]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['6' '0' '7' ... '4' '6' '8']\n",
      "probabilities: (59750, 10) \n",
      " [6 0 7 ... 4 6 8]\n",
      "trainset before (250, 784) (250,)\n",
      "trainset after (275, 784) (275,)\n",
      "updated train set: (275, 784) (275,) unique(labels): [  8  16  31  26  10 128  14   9  23  10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59725, 784) (59725,)\n",
      "\n",
      "Train set: (275, 784) y: (275,)\n",
      "Val   set: (59725, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.159 s \n",
      "\n",
      "Accuracy rate for 52.300000 \n",
      "Classification report for classifier LogisticRegression(C=0.18181818181818182, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.84      0.72       980\n",
      "           1       0.56      0.99      0.71      1135\n",
      "           2       0.42      0.26      0.32      1032\n",
      "           3       0.75      0.25      0.38      1010\n",
      "           4       0.40      0.86      0.55       982\n",
      "           5       0.86      0.07      0.13       892\n",
      "           6       0.61      0.80      0.69       958\n",
      "           7       0.61      0.40      0.48      1028\n",
      "           8       0.56      0.45      0.50       974\n",
      "           9       0.29      0.23      0.26      1009\n",
      "\n",
      "    accuracy                           0.52     10000\n",
      "   macro avg       0.57      0.52      0.47     10000\n",
      "weighted avg       0.57      0.52      0.48     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 826    3   21    0    1    0   66   21   19   23]\n",
      " [   0 1123    0    0    3    0    5    2    2    0]\n",
      " [ 164  285  271    1  115    2  135   25   32    2]\n",
      " [  80  165  236  254   53    2   73  101   23   23]\n",
      " [  12   16    2    0  844    1   10   20   13   64]\n",
      " [ 124   49   56   76   73   62  150   52  196   54]\n",
      " [  48   28    6    0   71    2  768    8   26    1]\n",
      " [  11   67    5    2  167    1    2  412   11  350]\n",
      " [  35  259   32    2  112    2   46    6  440   40]\n",
      " [  10   23   11    3  674    0    4   32   22  230]]\n",
      "--------------------------------\n",
      "val predicted: (59725,) ['6' '0' '4' ... '4' '0' '8']\n",
      "probabilities: (59725, 10) \n",
      " [6 0 4 ... 4 0 8]\n",
      "trainset before (275, 784) (275,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [  9  16  36  32  10 137  15  10  24  11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.161 s \n",
      "\n",
      "Accuracy rate for 57.620000 \n",
      "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.91      0.69       980\n",
      "           1       0.57      0.99      0.73      1135\n",
      "           2       0.73      0.09      0.16      1032\n",
      "           3       0.63      0.40      0.49      1010\n",
      "           4       0.47      0.81      0.59       982\n",
      "           5       0.71      0.05      0.10       892\n",
      "           6       0.59      0.87      0.70       958\n",
      "           7       0.79      0.77      0.78      1028\n",
      "           8       0.52      0.52      0.52       974\n",
      "           9       0.54      0.29      0.38      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.61      0.57      0.51     10000\n",
      "weighted avg       0.61      0.58      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 888    2    0    0    0    0   43    8   38    1]\n",
      " [   0 1119    0    2    1    1    9    0    3    0]\n",
      " [ 259  287   90    1  102    3  154   87   46    3]\n",
      " [ 162  141   13  401   34    6  109   37   87   20]\n",
      " [  11   21    5    4  795    3   32   16   25   70]\n",
      " [ 180   41    7  134   52   49  174   16  179   60]\n",
      " [  13   18    5    0   56    3  837    7   19    0]\n",
      " [  16   71    0    3   92    0    3  789   16   38]\n",
      " [  49  225    2    9   58    4   62   10  504   51]\n",
      " [  12   25    2   78  513    0    5   35   49  290]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['6' '0' '4' ... '5' '6' '4']\n",
      "probabilities: (59700, 10) \n",
      " [6 0 4 ... 5 6 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (300, 784) (300,)\n",
      "trainset after (325, 784) (325,)\n",
      "updated train set: (325, 784) (325,) unique(labels): [  9  16  38  39  10 147  15  10  30  11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59675, 784) (59675,)\n",
      "\n",
      "Train set: (325, 784) y: (325,)\n",
      "Val   set: (59675, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.181 s \n",
      "\n",
      "Accuracy rate for 56.190000 \n",
      "Classification report for classifier LogisticRegression(C=0.15384615384615385, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       980\n",
      "           1       0.53      0.99      0.69      1135\n",
      "           2       0.74      0.27      0.39      1032\n",
      "           3       0.59      0.48      0.53      1010\n",
      "           4       0.42      0.85      0.56       982\n",
      "           5       0.82      0.07      0.12       892\n",
      "           6       0.50      0.88      0.64       958\n",
      "           7       0.78      0.77      0.77      1028\n",
      "           8       0.62      0.35      0.45       974\n",
      "           9       0.40      0.14      0.20      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.61      0.55      0.51     10000\n",
      "weighted avg       0.61      0.56      0.51     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 732    3    6    0    2    0  173   21   23   20]\n",
      " [   0 1120    0    1    1    1    9    0    3    0]\n",
      " [  82  283  278    3   92    3  208   68   14    1]\n",
      " [  70  201   26  480   40    2  113   38   29   11]\n",
      " [   3   22    9   14  836    1   31   16   13   37]\n",
      " [  91   58   17  187   83   58  201   32   97   68]\n",
      " [   8   19    3    0   58    1  841    9   18    1]\n",
      " [   5   74    6    8   96    0    5  791    5   38]\n",
      " [  21  318   26   19  104    3   91   12  344   36]\n",
      " [   7   27    5   97  676    2   16   31    9  139]]\n",
      "--------------------------------\n",
      "val predicted: (59675,) ['6' '0' '4' ... '5' '6' '8']\n",
      "probabilities: (59675, 10) \n",
      " [6 0 4 ... 5 6 8]\n",
      "trainset before (325, 784) (325,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [ 11  16  44  41  10 158  16  11  32  11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.172 s \n",
      "\n",
      "Accuracy rate for 58.100000 \n",
      "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       980\n",
      "           1       0.58      0.99      0.73      1135\n",
      "           2       0.90      0.17      0.28      1032\n",
      "           3       0.59      0.57      0.58      1010\n",
      "           4       0.45      0.80      0.58       982\n",
      "           5       0.68      0.07      0.13       892\n",
      "           6       0.56      0.88      0.69       958\n",
      "           7       0.77      0.67      0.72      1028\n",
      "           8       0.54      0.44      0.49       974\n",
      "           9       0.38      0.30      0.33      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.62      0.57      0.53     10000\n",
      "weighted avg       0.62      0.58      0.54     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 834    3    0    0    0    1   84    8   38   12]\n",
      " [   0 1118    0    0    1    1    9    2    4    0]\n",
      " [ 103  290  172    4  109    3  219  108   10   14]\n",
      " [  50  134    5  577   28    3   65   32   93   23]\n",
      " [   6   17    2   15  786    5   41    1   12   97]\n",
      " [  56   41    9  233   68   64  142   21  166   92]\n",
      " [  13   18    2    1   51    2  843    5   20    3]\n",
      " [  14   60    1    2   92    3    5  687    6  158]\n",
      " [  18  234    1   42   75    6   82    7  431   78]\n",
      " [   5   20    0  102  529    6   10   17   22  298]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['6' '0' '9' ... '8' '6' '4']\n",
      "probabilities: (59650, 10) \n",
      " [6 0 9 ... 8 6 4]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (375, 784) (375,)\n",
      "updated train set: (375, 784) (375,) unique(labels): [ 14  16  52  42  10 166  18  11  35  11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59625, 784) (59625,)\n",
      "\n",
      "Train set: (375, 784) y: (375,)\n",
      "Val   set: (59625, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.193 s \n",
      "\n",
      "Accuracy rate for 52.950000 \n",
      "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       980\n",
      "           1       0.54      0.98      0.69      1135\n",
      "           2       0.78      0.15      0.25      1032\n",
      "           3       0.59      0.57      0.58      1010\n",
      "           4       0.40      0.86      0.54       982\n",
      "           5       0.75      0.05      0.10       892\n",
      "           6       0.44      0.89      0.59       958\n",
      "           7       0.90      0.48      0.62      1028\n",
      "           8       0.61      0.29      0.39       974\n",
      "           9       0.28      0.16      0.20      1009\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.60      0.52      0.47     10000\n",
      "weighted avg       0.60      0.53      0.48     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 777    3    5    0    0    1  158    4   27    5]\n",
      " [   0 1117    0    1    1    0   13    0    3    0]\n",
      " [  19  276  154    4  153    2  351   34   31    8]\n",
      " [  22  180    2  575   42    6  144    7   12   20]\n",
      " [  35   21    7    6  842    1   28    0    5   37]\n",
      " [  68   49   15  255   88   48  231    6   70   62]\n",
      " [  15   16    4    2   50    1  849    0   20    1]\n",
      " [  56   68    5   10  139    0   24  489    7  230]\n",
      " [  11  328    5   43  114    4  126    1  281   61]\n",
      " [  33   23    0   77  696    1   10    4    2  163]]\n",
      "--------------------------------\n",
      "val predicted: (59625,) ['6' '0' '4' ... '3' '6' '8']\n",
      "probabilities: (59625, 10) \n",
      " [6 0 4 ... 3 6 8]\n",
      "trainset before (375, 784) (375,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [ 14  16  52  47  10 183  20  12  35  11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.181 s \n",
      "\n",
      "Accuracy rate for 53.160000 \n",
      "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       980\n",
      "           1       0.55      0.99      0.71      1135\n",
      "           2       0.84      0.12      0.21      1032\n",
      "           3       0.65      0.57      0.61      1010\n",
      "           4       0.35      0.88      0.51       982\n",
      "           5       0.73      0.13      0.23       892\n",
      "           6       0.50      0.77      0.61       958\n",
      "           7       0.74      0.40      0.52      1028\n",
      "           8       0.60      0.27      0.37       974\n",
      "           9       0.33      0.25      0.29      1009\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.61      0.52      0.49     10000\n",
      "weighted avg       0.61      0.53      0.49     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 846    4    1    0    0    1   97    9   13    9]\n",
      " [   0 1120    0    3    1    1    6    2    2    0]\n",
      " [  32  286  126    1  214    3  291   53   18    8]\n",
      " [  29  157    4  579   53   16   86   36   28   22]\n",
      " [  17   18    1    0  863    3   20    3    1   56]\n",
      " [  68   38    3  215  105  119  125   26   89  104]\n",
      " [  20   21    3    2  145    9  739    3   13    3]\n",
      " [  42   71    7    2  246    0    4  407    2  247]\n",
      " [  13  287    5   61  144    9  114    7  261   73]\n",
      " [  17   23    0   32  663    2    2    5    9  256]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['6' '0' '4' ... '4' '6' '4']\n",
      "probabilities: (59600, 10) \n",
      " [6 0 4 ... 4 6 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (400, 784) (400,)\n",
      "trainset after (425, 784) (425,)\n",
      "updated train set: (425, 784) (425,) unique(labels): [ 14  17  58  51  10 194  21  12  37  11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59575, 784) (59575,)\n",
      "\n",
      "Train set: (425, 784) y: (425,)\n",
      "Val   set: (59575, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.205 s \n",
      "\n",
      "Accuracy rate for 54.620000 \n",
      "Classification report for classifier LogisticRegression(C=0.11764705882352941, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81       980\n",
      "           1       0.54      0.99      0.70      1135\n",
      "           2       0.85      0.15      0.25      1032\n",
      "           3       0.71      0.53      0.61      1010\n",
      "           4       0.40      0.83      0.54       982\n",
      "           5       0.81      0.07      0.12       892\n",
      "           6       0.51      0.79      0.62       958\n",
      "           7       0.72      0.57      0.64      1028\n",
      "           8       0.46      0.26      0.33       974\n",
      "           9       0.37      0.36      0.36      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.61      0.54      0.50     10000\n",
      "weighted avg       0.61      0.55      0.50     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 823    3    0    1    0    1   93   19   33    7]\n",
      " [   0 1124    0    1    2    0    4    3    0    1]\n",
      " [  29  317  150    1  158    0  251   95   13   18]\n",
      " [  23  154    5  533   30    2   75   49   56   83]\n",
      " [  24   16    0    1  817    4   38    5    0   77]\n",
      " [  66   46   15  172   85   58  131   33  168  118]\n",
      " [  21   24    3    0  128    4  756    4   15    3]\n",
      " [  35   71    4    2   94    0    2  585    0  235]\n",
      " [  11  310    0   27  149    2  130    6  250   89]\n",
      " [  15   22    0    8  568    1    5   14   10  366]]\n",
      "--------------------------------\n",
      "val predicted: (59575,) ['6' '0' '9' ... '8' '6' '4']\n",
      "probabilities: (59575, 10) \n",
      " [6 0 9 ... 8 6 4]\n",
      "trainset before (425, 784) (425,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [ 15  17  61  54  13 206  22  12  39  11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.190 s \n",
      "\n",
      "Accuracy rate for 56.500000 \n",
      "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       980\n",
      "           1       0.55      0.99      0.70      1135\n",
      "           2       0.61      0.12      0.21      1032\n",
      "           3       0.56      0.62      0.59      1010\n",
      "           4       0.45      0.79      0.58       982\n",
      "           5       0.63      0.08      0.14       892\n",
      "           6       0.56      0.74      0.64       958\n",
      "           7       0.63      0.70      0.66      1028\n",
      "           8       0.48      0.28      0.36       974\n",
      "           9       0.48      0.41      0.44      1009\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.58      0.56      0.52     10000\n",
      "weighted avg       0.58      0.56      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 798    4    1    0    1    3   73   70   21    9]\n",
      " [   0 1125    0    2    1    0    2    4    1    0]\n",
      " [  23  305  129    9  265    1  204   80    9    7]\n",
      " [   2  125   10  625   19    3   49  123   35   19]\n",
      " [  21   24    1   24  777   12   10    5   24   84]\n",
      " [  23   37   50  278   56   73   95   80  131   69]\n",
      " [  54   25    8    5  129    5  713    8   11    0]\n",
      " [   5   77    8    1   33    1    6  721    4  172]\n",
      " [   7  316    5   88   55    5  113   27  277   81]\n",
      " [  10   25    1   81  373   12    2   30   63  412]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['3' '0' '4' ... '3' '0' '4']\n",
      "probabilities: (59550, 10) \n",
      " [3 0 4 ... 3 0 4]\n",
      "trainset before (450, 784) (450,)\n",
      "trainset after (475, 784) (475,)\n",
      "updated train set: (475, 784) (475,) unique(labels): [ 17  17  64  55  15 208  25  15  42  17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59525, 784) (59525,)\n",
      "\n",
      "Train set: (475, 784) y: (475,)\n",
      "Val   set: (59525, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.197 s \n",
      "\n",
      "Accuracy rate for 59.100000 \n",
      "Classification report for classifier LogisticRegression(C=0.10526315789473684, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81       980\n",
      "           1       0.57      0.99      0.73      1135\n",
      "           2       0.58      0.28      0.37      1032\n",
      "           3       0.64      0.59      0.62      1010\n",
      "           4       0.49      0.69      0.57       982\n",
      "           5       0.71      0.09      0.16       892\n",
      "           6       0.56      0.75      0.64       958\n",
      "           7       0.72      0.75      0.73      1028\n",
      "           8       0.50      0.37      0.42       974\n",
      "           9       0.48      0.51      0.49      1009\n",
      "\n",
      "    accuracy                           0.59     10000\n",
      "   macro avg       0.61      0.58      0.55     10000\n",
      "weighted avg       0.60      0.59      0.56     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 788    4   19    1    0    2   86   24   53    3]\n",
      " [   0 1122    1    3    1    1    3    2    2    0]\n",
      " [  33  296  286    5  132    1  164   87   22    6]\n",
      " [  11  111   29  596   20    6   55   56   61   65]\n",
      " [  29   16    8    5  679    9   19   16    7  194]\n",
      " [  36   31   95  188   32   78  100   43  154  135]\n",
      " [  37   24   19    1  114    1  719    9   11   23]\n",
      " [   9   68   18    3   72    4    2  773    4   75]\n",
      " [   8  267   12   86   37    6  143   11  358   46]\n",
      " [  22   21    7   39  307    2    3   58   39  511]]\n",
      "--------------------------------\n",
      "val predicted: (59525,) ['3' '0' '9' ... '5' '0' '4']\n",
      "probabilities: (59525, 10) \n",
      " [3 0 9 ... 5 0 4]\n",
      "trainset before (475, 784) (475,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [ 19  17  66  56  17 218  26  19  42  20] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.199 s \n",
      "\n",
      "Accuracy rate for 57.550000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78       980\n",
      "           1       0.52      0.99      0.68      1135\n",
      "           2       0.59      0.25      0.35      1032\n",
      "           3       0.56      0.60      0.58      1010\n",
      "           4       0.55      0.84      0.67       982\n",
      "           5       0.40      0.13      0.20       892\n",
      "           6       0.53      0.73      0.61       958\n",
      "           7       0.80      0.67      0.73      1028\n",
      "           8       0.41      0.35      0.38       974\n",
      "           9       0.64      0.32      0.42      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.58      0.57      0.54     10000\n",
      "weighted avg       0.58      0.58      0.55     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 765    4   18    0    4    4  114   33   34    4]\n",
      " [   0 1126    0    3    0    1    4    0    1    0]\n",
      " [  36  327  261    2  129    2  213   42   18    2]\n",
      " [  15  147   25  606    6   20   69   27   94    1]\n",
      " [  21   23    5   19  820   31   10    2   15   36]\n",
      " [  40   43   73  254   36  117   94   29  171   35]\n",
      " [  37   37   19   10  113   20  704    5   13    0]\n",
      " [   8   93   20    8   56   29    7  692   22   93]\n",
      " [  27  358   11   51   30   22  120    4  344    7]\n",
      " [  31   25   10  123  288   48    4   29  131  320]]\n",
      "--------------------------------\n",
      "final active learning accuracies [41.870000000000005, 48.92, 52.470000000000006, 51.81, 52.89, 57.3, 56.13, 53.49, 54.54, 50.22, 52.300000000000004, 57.620000000000005, 56.19, 58.099999999999994, 52.949999999999996, 53.16, 54.620000000000005, 56.49999999999999, 59.099999999999994, 57.550000000000004]\n",
      "saved Active-learning-experiment-44.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-42.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-37.pkl', 'README.md', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-43.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-44.pkl', 'Active-learning-experiment-38.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 45, using model = LogModel, selection_function = EntropySelection, k = 10, iteration = 0.\n",
      "\n",
      "initial random chosen samples (10,)\n",
      "initial train set: (10, 784) (10,) unique(labels): [2 1 0 2 0 1 3 1] [0 1 3 5 6 7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (59990, 784) (59990,) (10,)\n",
      "\n",
      "Train set: (10, 784) y: (10,)\n",
      "Val   set: (59990, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.104 s \n",
      "\n",
      "Accuracy rate for 34.140000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=5.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.56      0.33       980\n",
      "           1       0.88      0.50      0.64      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.33      0.74      0.46      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.20      0.31      0.25       892\n",
      "           6       0.48      0.67      0.56       958\n",
      "           7       0.31      0.60      0.41      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.34     10000\n",
      "   macro avg       0.24      0.34      0.26     10000\n",
      "weighted avg       0.25      0.34      0.27     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[548   0   0 190   0 185  55   2   0   0]\n",
      " [  4 573   0 163   0  69  80 246   0   0]\n",
      " [122   2   0 399   0  43 355 111   0   0]\n",
      " [ 54   6   0 748   0 112  13  77   0   0]\n",
      " [333  16   0  42   0 308 119 164   0   0]\n",
      " [307  12   0 250   0 280  12  31   0   0]\n",
      " [ 67   2   0 235   0   8 645   1   0   0]\n",
      " [356   8   0  11   0  16  17 620   0   0]\n",
      " [219  27   0 217   0 243  29 239   0   0]\n",
      " [346   6   0  14   0 116  10 517   0   0]]\n",
      "--------------------------------\n",
      "val predicted: (59990,) ['3' '0' '0' ... '5' '3' '0']\n",
      "probabilities: (59990, 6) \n",
      " [2 0 0 ... 3 2 0]\n",
      "trainset before (10, 784) (10,)\n",
      "trainset after (20, 784) (20,)\n",
      "updated train set: (20, 784) (20,) unique(labels): [2 3 1 2 0 1 3 3 3 2] [0 1 2 3 5 6 7 8 9]\n",
      "val set: (59980, 784) (59980,)\n",
      "\n",
      "Train set: (20, 784) y: (20,)\n",
      "Val   set: (59980, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.113 s \n",
      "\n",
      "Accuracy rate for 41.870000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=2.5, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.49      0.34       980\n",
      "           1       0.93      0.73      0.82      1135\n",
      "           2       0.77      0.22      0.34      1032\n",
      "           3       0.35      0.65      0.46      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.23      0.43      0.30       892\n",
      "           6       0.56      0.65      0.60       958\n",
      "           7       0.44      0.36      0.40      1028\n",
      "           8       0.50      0.46      0.48       974\n",
      "           9       0.26      0.17      0.21      1009\n",
      "\n",
      "    accuracy                           0.42     10000\n",
      "   macro avg       0.43      0.42      0.39     10000\n",
      "weighted avg       0.44      0.42      0.40     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[476   1   0 159   0 265  76   0   3   0]\n",
      " [  2 832  13 107   0   5   5  15 134  22]\n",
      " [ 85   9 225 332   0  61 274   2  31  13]\n",
      " [ 49   7   1 659   0 204  11  21  43  15]\n",
      " [207   9  24  42   0 331  59  58 132 120]\n",
      " [261   5   0 206   0 386  12   6  14   2]\n",
      " [ 77   4   2 237   0   9 620   0   6   3]\n",
      " [315  14   6   6   0  10  13 373  12 279]\n",
      " [ 82  11   3 121   0 240  17  28 444  28]\n",
      " [252   1  19  10   0 142  11 339  63 172]]\n",
      "--------------------------------\n",
      "val predicted: (59980,) ['3' '0' '0' ... '5' '3' '0']\n",
      "probabilities: (59980, 9) \n",
      " [3 0 0 ... 4 3 0]\n",
      "trainset before (20, 784) (20,)\n",
      "trainset after (30, 784) (30,)\n",
      "updated train set: (30, 784) (30,) unique(labels): [2 4 1 2 7 1 3 4 4 2] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59970, 784) (59970,)\n",
      "\n",
      "Train set: (30, 784) y: (30,)\n",
      "Val   set: (59970, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 3\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.116 s \n",
      "\n",
      "Accuracy rate for 52.250000 \n",
      "Classification report for classifier LogisticRegression(C=1.6666666666666667, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.54      0.45       980\n",
      "           1       0.91      0.85      0.88      1135\n",
      "           2       0.83      0.36      0.50      1032\n",
      "           3       0.48      0.75      0.59      1010\n",
      "           4       0.40      0.69      0.50       982\n",
      "           5       0.41      0.34      0.37       892\n",
      "           6       0.57      0.71      0.63       958\n",
      "           7       0.54      0.32      0.41      1028\n",
      "           8       0.78      0.49      0.60       974\n",
      "           9       0.19      0.13      0.16      1009\n",
      "\n",
      "    accuracy                           0.52     10000\n",
      "   macro avg       0.55      0.52      0.51     10000\n",
      "weighted avg       0.56      0.52      0.51     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[534   1   5 178   0 178  81   0   2   1]\n",
      " [  0 961  22   9  63   5   9   0  47  19]\n",
      " [ 46  22 372 213  45  25 279   1  12  17]\n",
      " [ 37  12   9 759  40  67  10  30  32  14]\n",
      " [ 66   2   2   6 676  51  52  18   3 106]\n",
      " [244   8   3 244  26 302  15  12  28  10]\n",
      " [192   4   7  29  31  14 676   0   4   1]\n",
      " [162  12   4   8 193   2   7 333   0 307]\n",
      " [ 54  36  14 115  52  84  34  33 480  72]\n",
      " [ 56   1   8  17 572  16  13 186   8 132]]\n",
      "--------------------------------\n",
      "val predicted: (59970,) ['3' '0' '0' ... '5' '0' '0']\n",
      "probabilities: (59970, 10) \n",
      " [3 0 0 ... 5 0 0]\n",
      "trainset before (30, 784) (30,)\n",
      "trainset after (40, 784) (40,)\n",
      "updated train set: (40, 784) (40,) unique(labels): [2 5 5 3 8 3 3 4 5 2] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59960, 784) (59960,)\n",
      "\n",
      "Train set: (40, 784) y: (40,)\n",
      "Val   set: (59960, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 4\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.116 s \n",
      "\n",
      "Accuracy rate for 48.090000 \n",
      "Classification report for classifier LogisticRegression(C=1.25, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.82      0.40       980\n",
      "           1       0.91      0.87      0.89      1135\n",
      "           2       0.65      0.39      0.49      1032\n",
      "           3       0.64      0.63      0.64      1010\n",
      "           4       0.48      0.50      0.49       982\n",
      "           5       0.36      0.29      0.32       892\n",
      "           6       0.61      0.55      0.58       958\n",
      "           7       0.37      0.18      0.25      1028\n",
      "           8       0.68      0.42      0.52       974\n",
      "           9       0.21      0.11      0.14      1009\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.52      0.48      0.47     10000\n",
      "weighted avg       0.52      0.48      0.48     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[805   0   5  15   0 131  24   0   0   0]\n",
      " [  7 983  43   7  36   0   5   0  42  12]\n",
      " [216  28 407 105  20   1 225   1  25   4]\n",
      " [162  12   6 640  20  63   4  17  70  16]\n",
      " [256   5  10   3 488  16  44  42  14 104]\n",
      " [447   4   2 143   2 255   9   7  18   5]\n",
      " [359   2  16  21  14  10 528   0   8   0]\n",
      " [346  19  56   5 159  11   5 190   1 236]\n",
      " [224  32  69  58  16 100  16  18 405  36]\n",
      " [257   1  12   5 257 114   5 240  10 108]]\n",
      "--------------------------------\n",
      "val predicted: (59960,) ['3' '0' '0' ... '5' '0' '0']\n",
      "probabilities: (59960, 10) \n",
      " [3 0 0 ... 5 0 0]\n",
      "trainset before (40, 784) (40,)\n",
      "trainset after (50, 784) (50,)\n",
      "updated train set: (50, 784) (50,) unique(labels): [ 2  6  5  3 12  3  5  4  7  3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59950, 784) (59950,)\n",
      "\n",
      "Train set: (50, 784) y: (50,)\n",
      "Val   set: (59950, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 5\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.124 s \n",
      "\n",
      "Accuracy rate for 52.340000 \n",
      "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.56      0.45       980\n",
      "           1       0.84      0.89      0.87      1135\n",
      "           2       0.48      0.53      0.50      1032\n",
      "           3       0.52      0.66      0.59      1010\n",
      "           4       0.68      0.55      0.61       982\n",
      "           5       0.31      0.41      0.35       892\n",
      "           6       0.72      0.65      0.68       958\n",
      "           7       0.54      0.21      0.31      1028\n",
      "           8       0.52      0.41      0.46       974\n",
      "           9       0.36      0.30      0.33      1009\n",
      "\n",
      "    accuracy                           0.52     10000\n",
      "   macro avg       0.53      0.52      0.51     10000\n",
      "weighted avg       0.54      0.52      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 551    2   45   43    0  319   19    0    1    0]\n",
      " [   0 1014   78    9    0    0    4    0   28    2]\n",
      " [  46   44  551  216   13    4  119    1   26   12]\n",
      " [  53   23   26  671    3   61    2    4  136   31]\n",
      " [  94    8   44   10  538   33   53   28   60  114]\n",
      " [ 231   16   37  173    7  364   13    0   44    7]\n",
      " [ 173    6   48   71    6   20  624    0   10    0]\n",
      " [ 209   30  137   10   37   39    4  219    7  336]\n",
      " [  57   52  172   68    4  145   25    9  399   43]\n",
      " [  75   10   21    8  183  198    5  147   59  303]]\n",
      "--------------------------------\n",
      "val predicted: (59950,) ['3' '0' '0' ... '5' '0' '9']\n",
      "probabilities: (59950, 10) \n",
      " [3 0 0 ... 5 0 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (50, 784) (50,)\n",
      "trainset after (60, 784) (60,)\n",
      "updated train set: (60, 784) (60,) unique(labels): [ 2  6  6  3 12  4  6 11  7  3] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59940, 784) (59940,)\n",
      "\n",
      "Train set: (60, 784) y: (60,)\n",
      "Val   set: (59940, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 6\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.120 s \n",
      "\n",
      "Accuracy rate for 48.430000 \n",
      "Classification report for classifier LogisticRegression(C=0.8333333333333334, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.67      0.41       980\n",
      "           1       0.92      0.76      0.84      1135\n",
      "           2       0.53      0.38      0.44      1032\n",
      "           3       0.48      0.61      0.54      1010\n",
      "           4       0.54      0.67      0.60       982\n",
      "           5       0.31      0.33      0.32       892\n",
      "           6       0.85      0.48      0.61       958\n",
      "           7       0.94      0.05      0.09      1028\n",
      "           8       0.47      0.56      0.51       974\n",
      "           9       0.34      0.32      0.33      1009\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.57      0.48      0.47     10000\n",
      "weighted avg       0.58      0.48      0.47     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[656   0   2  48   0 269   4   0   1   0]\n",
      " [  3 866  88  10   1   5   2   0 149  11]\n",
      " [176  22 389 243  35  20  49   1  71  26]\n",
      " [ 98   3  25 612   4  77   0   1 166  24]\n",
      " [100   2  20   6 662   6  10   0  62 114]\n",
      " [356   3  15 164  14 290   6   0  38   6]\n",
      " [282   4  37  86  22  44 459   0  15   9]\n",
      " [327  20  56  15 118  53   3  47  18 371]\n",
      " [125  13  93  69  10  72   3   0 542  47]\n",
      " [130   5   5  14 349  92   1   1  92 320]]\n",
      "--------------------------------\n",
      "val predicted: (59940,) ['3' '0' '4' ... '3' '0' '0']\n",
      "probabilities: (59940, 10) \n",
      " [3 0 4 ... 3 0 0]\n",
      "trainset before (60, 784) (60,)\n",
      "trainset after (70, 784) (70,)\n",
      "updated train set: (70, 784) (70,) unique(labels): [ 2  7  6  3 12  4  6 19  7  4] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59930, 784) (59930,)\n",
      "\n",
      "Train set: (70, 784) y: (70,)\n",
      "Val   set: (59930, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 7\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.126 s \n",
      "\n",
      "Accuracy rate for 51.110000 \n",
      "Classification report for classifier LogisticRegression(C=0.7142857142857143, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.68      0.47       980\n",
      "           1       0.84      0.84      0.84      1135\n",
      "           2       0.41      0.49      0.45      1032\n",
      "           3       0.54      0.63      0.58      1010\n",
      "           4       0.59      0.57      0.58       982\n",
      "           5       0.33      0.33      0.33       892\n",
      "           6       0.81      0.56      0.66       958\n",
      "           7       0.91      0.24      0.38      1028\n",
      "           8       0.41      0.56      0.47       974\n",
      "           9       0.35      0.17      0.22      1009\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.55      0.51      0.50     10000\n",
      "weighted avg       0.56      0.51      0.50     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[663   0  20  43   0 241   9   0   2   2]\n",
      " [  0 950  56   6   0   2   2   0 119   0]\n",
      " [126  46 510 162   9  13  54   1  90  21]\n",
      " [ 67  10  40 636   3  71   1   3 167  12]\n",
      " [ 80  12  75  12 560   1  37   4 138  63]\n",
      " [337   6  12 168  10 292   8   0  55   4]\n",
      " [234   7  55  53   4  26 540   0  31   8]\n",
      " [152  46 288  20  29  34   3 249  13 194]\n",
      " [ 94  33 149  73   4  58  10   1 544   8]\n",
      " [ 85  26  46  12 327 160   4  17 165 167]]\n",
      "--------------------------------\n",
      "val predicted: (59930,) ['3' '0' '4' ... '3' '0' '0']\n",
      "probabilities: (59930, 10) \n",
      " [3 0 4 ... 3 0 0]\n",
      "trainset before (70, 784) (70,)\n",
      "trainset after (80, 784) (80,)\n",
      "updated train set: (80, 784) (80,) unique(labels): [ 2  7  6  3 13  5  6 24  7  7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59920, 784) (59920,)\n",
      "\n",
      "Train set: (80, 784) y: (80,)\n",
      "Val   set: (59920, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 8\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.130 s \n",
      "\n",
      "Accuracy rate for 53.310000 \n",
      "Classification report for classifier LogisticRegression(C=0.625, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.37      0.48       980\n",
      "           1       0.78      0.87      0.82      1135\n",
      "           2       0.40      0.59      0.47      1032\n",
      "           3       0.56      0.59      0.57      1010\n",
      "           4       0.56      0.62      0.59       982\n",
      "           5       0.33      0.42      0.37       892\n",
      "           6       0.71      0.76      0.73       958\n",
      "           7       0.92      0.18      0.31      1028\n",
      "           8       0.38      0.64      0.47       974\n",
      "           9       0.49      0.26      0.34      1009\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.58      0.53      0.52     10000\n",
      "weighted avg       0.59      0.53      0.52     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[360   2 144  90   0 341  35   0   6   2]\n",
      " [  0 984  48   2   0   5   4   0  92   0]\n",
      " [  6  67 611  50  15  16 115   2 147   3]\n",
      " [ 10  26  45 594   3  63   7   3 251   8]\n",
      " [ 12  19  43   4 610  37  88   1 155  13]\n",
      " [ 44  10  56 234  15 372  16   3 137   5]\n",
      " [ 64  12  73  13  13  28 725   0  30   0]\n",
      " [  9  78 307  11  62 112   9 190  13 237]\n",
      " [  7  31 165  51   4  76  15   0 620   5]\n",
      " [  3  36  50  10 359  70  14   7 195 265]]\n",
      "--------------------------------\n",
      "val predicted: (59920,) ['3' '5' '4' ... '3' '2' '2']\n",
      "probabilities: (59920, 10) \n",
      " [3 5 4 ... 3 2 2]\n",
      "trainset before (80, 784) (80,)\n",
      "trainset after (90, 784) (90,)\n",
      "updated train set: (90, 784) (90,) unique(labels): [ 4  7  6  5 13  7  6 28  7  7] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59910, 784) (59910,)\n",
      "\n",
      "Train set: (90, 784) y: (90,)\n",
      "Val   set: (59910, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 9\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.131 s \n",
      "\n",
      "Accuracy rate for 50.570000 \n",
      "Classification report for classifier LogisticRegression(C=0.5555555555555556, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.77      0.57       980\n",
      "           1       0.85      0.79      0.82      1135\n",
      "           2       0.38      0.56      0.45      1032\n",
      "           3       0.42      0.62      0.51      1010\n",
      "           4       0.59      0.57      0.58       982\n",
      "           5       0.58      0.06      0.12       892\n",
      "           6       0.78      0.66      0.72       958\n",
      "           7       0.94      0.04      0.08      1028\n",
      "           8       0.35      0.64      0.45       974\n",
      "           9       0.49      0.28      0.36      1009\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.58      0.50      0.46     10000\n",
      "weighted avg       0.59      0.51      0.47     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[752   2  88 115   0  12   6   0   3   2]\n",
      " [  1 891  66  37   0   0   1   0 138   1]\n",
      " [ 22  40 576 168  15   1  81   1 124   4]\n",
      " [ 35   6  52 631   5  14   2   0 249  16]\n",
      " [ 69   8  60  30 562   1  60   1 180  11]\n",
      " [243   6  84 277  17  57  11   0 192   5]\n",
      " [171  10  60  33  13   0 636   0  35   0]\n",
      " [277  52 301  63  24   4   3  44  17 243]\n",
      " [ 17  21 167 118   3   2  11   1 626   8]\n",
      " [ 77  15  59  15 316   7   9   0 229 282]]\n",
      "--------------------------------\n",
      "val predicted: (59910,) ['5' '0' '4' ... '3' '0' '2']\n",
      "probabilities: (59910, 10) \n",
      " [5 0 4 ... 3 0 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (90, 784) (90,)\n",
      "trainset after (100, 784) (100,)\n",
      "updated train set: (100, 784) (100,) unique(labels): [ 6  7  8  6 13  9  7 29  7  8] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59900, 784) (59900,)\n",
      "\n",
      "Train set: (100, 784) y: (100,)\n",
      "Val   set: (59900, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 10\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.135 s \n",
      "\n",
      "Accuracy rate for 52.020000 \n",
      "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.87      0.76       980\n",
      "           1       0.82      0.84      0.83      1135\n",
      "           2       0.43      0.28      0.34      1032\n",
      "           3       0.42      0.62      0.50      1010\n",
      "           4       0.50      0.71      0.59       982\n",
      "           5       0.58      0.11      0.18       892\n",
      "           6       0.62      0.65      0.64       958\n",
      "           7       0.97      0.09      0.17      1028\n",
      "           8       0.36      0.75      0.49       974\n",
      "           9       0.33      0.22      0.27      1009\n",
      "\n",
      "    accuracy                           0.52     10000\n",
      "   macro avg       0.57      0.52      0.48     10000\n",
      "weighted avg       0.57      0.52      0.48     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[857   2   1  93   0   5  13   0   6   3]\n",
      " [  0 959  13  17   0   1   5   0 140   0]\n",
      " [ 43  68 286 214  38   1 201   0 176   5]\n",
      " [ 15   6   6 625   5  37  12   0 276  28]\n",
      " [ 12   5  13  24 697   2  82   1 134  12]\n",
      " [100   8   4 273  47  98  20   0 327  15]\n",
      " [187  16  23  32  40   0 626   0  34   0]\n",
      " [ 38  71 255  87  63  10   9  94  17 384]\n",
      " [ 14  13  47 108   9   4  34   0 734  11]\n",
      " [ 12  19  18  26 492  11  10   2 193 226]]\n",
      "--------------------------------\n",
      "val predicted: (59900,) ['3' '0' '4' ... '8' '0' '6']\n",
      "probabilities: (59900, 10) \n",
      " [3 0 4 ... 8 0 6]\n",
      "trainset before (100, 784) (100,)\n",
      "trainset after (110, 784) (110,)\n",
      "updated train set: (110, 784) (110,) unique(labels): [ 8  7  9  8 13 10  9 29  8  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59890, 784) (59890,)\n",
      "\n",
      "Train set: (110, 784) y: (110,)\n",
      "Val   set: (59890, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 11\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.127 s \n",
      "\n",
      "Accuracy rate for 53.000000 \n",
      "Classification report for classifier LogisticRegression(C=0.45454545454545453, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.94      0.76       980\n",
      "           1       0.71      0.93      0.81      1135\n",
      "           2       0.45      0.47      0.46      1032\n",
      "           3       0.58      0.55      0.56      1010\n",
      "           4       0.45      0.77      0.56       982\n",
      "           5       0.83      0.13      0.22       892\n",
      "           6       0.91      0.45      0.60       958\n",
      "           7       0.98      0.11      0.20      1028\n",
      "           8       0.34      0.79      0.48       974\n",
      "           9       0.27      0.10      0.14      1009\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.62      0.52      0.48     10000\n",
      "weighted avg       0.61      0.53      0.48     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 926    3    8   21    1    3    1    0   16    1]\n",
      " [   0 1058    0    7    0    0    1    0   69    0]\n",
      " [  46  168  482  109   52    0   27    0  148    0]\n",
      " [  25   20   18  556    9    8    0    0  368    6]\n",
      " [  35   15   44    1  755    1    6    0  122    3]\n",
      " [ 123   16   17  192   69  115    4    0  351    5]\n",
      " [ 188   14   21   11  132    1  428    0  162    1]\n",
      " [  71  107  375   15   85    3    3  115   14  240]\n",
      " [  13   51   67   41   24    5    1    0  766    6]\n",
      " [  33   38   44    9  567    3    0    2  214   99]]\n",
      "--------------------------------\n",
      "val predicted: (59890,) ['3' '0' '4' ... '8' '0' '2']\n",
      "probabilities: (59890, 10) \n",
      " [3 0 4 ... 8 0 2]\n",
      "trainset before (110, 784) (110,)\n",
      "trainset after (120, 784) (120,)\n",
      "updated train set: (120, 784) (120,) unique(labels): [ 8  7 10  8 13 15  9 33  8  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59880, 784) (59880,)\n",
      "\n",
      "Train set: (120, 784) y: (120,)\n",
      "Val   set: (59880, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 12\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.136 s \n",
      "\n",
      "Accuracy rate for 49.270000 \n",
      "Classification report for classifier LogisticRegression(C=0.4166666666666667, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       980\n",
      "           1       0.80      0.86      0.83      1135\n",
      "           2       0.48      0.37      0.42      1032\n",
      "           3       0.50      0.54      0.52      1010\n",
      "           4       0.44      0.68      0.54       982\n",
      "           5       0.50      0.01      0.02       892\n",
      "           6       0.76      0.58      0.66       958\n",
      "           7       0.93      0.01      0.03      1028\n",
      "           8       0.29      0.85      0.44       974\n",
      "           9       0.16      0.11      0.13      1009\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.56      0.49      0.44     10000\n",
      "weighted avg       0.57      0.49      0.44     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[837   2  41  57   0   2  22   0  17   2]\n",
      " [  0 971   5   3   0   0   3   0 153   0]\n",
      " [ 12  98 378 172  75   0  84   0 210   3]\n",
      " [ 12   4  24 547   7   0   3   0 404   9]\n",
      " [ 21   6   3   0 672   0  32   0 237  11]\n",
      " [ 48   6 100 209  50   7  16   0 436  20]\n",
      " [ 67  13  54   6  98   1 559   0 157   3]\n",
      " [ 87  78 129  32 101   3   3  14  26 555]\n",
      " [  4  18  45  47  18   0   4   0 829   9]\n",
      " [ 17  15   4  14 493   1   5   1 346 113]]\n",
      "--------------------------------\n",
      "val predicted: (59880,) ['3' '0' '8' ... '8' '2' '9']\n",
      "probabilities: (59880, 10) \n",
      " [3 0 8 ... 8 2 9]\n",
      "trainset before (120, 784) (120,)\n",
      "trainset after (130, 784) (130,)\n",
      "updated train set: (130, 784) (130,) unique(labels): [ 8  7 10  9 14 21 11 33  8  9] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59870, 784) (59870,)\n",
      "\n",
      "Train set: (130, 784) y: (130,)\n",
      "Val   set: (59870, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 13\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.141 s \n",
      "\n",
      "Accuracy rate for 50.030000 \n",
      "Classification report for classifier LogisticRegression(C=0.38461538461538464, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78       980\n",
      "           1       0.78      0.88      0.83      1135\n",
      "           2       0.49      0.47      0.48      1032\n",
      "           3       0.64      0.36      0.46      1010\n",
      "           4       0.50      0.66      0.57       982\n",
      "           5       0.78      0.01      0.02       892\n",
      "           6       0.74      0.68      0.71       958\n",
      "           7       0.97      0.03      0.06      1028\n",
      "           8       0.27      0.86      0.42       974\n",
      "           9       0.19      0.13      0.15      1009\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.61      0.49      0.45     10000\n",
      "weighted avg       0.61      0.50      0.45     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[857   2  43  15   0   0  37   0  24   2]\n",
      " [  0 999   6   4   0   0   4   0 122   0]\n",
      " [ 15 114 481  34  20   0  84   0 280   4]\n",
      " [ 24  18  36 361   5   1  15   0 536  14]\n",
      " [ 32   5  24   0 648   0  20   0 242  11]\n",
      " [ 86  10 107 109  36   7  43   0 463  31]\n",
      " [ 57   9  36   4  45   0 647   0 160   0]\n",
      " [122  79 175  14  81   1   5  34  33 484]\n",
      " [  5  28  60  14   8   0   9   0 840  10]\n",
      " [ 29  18   7   5 454   0   6   1 360 129]]\n",
      "--------------------------------\n",
      "val predicted: (59870,) ['3' '0' '8' ... '9' '2' '9']\n",
      "probabilities: (59870, 10) \n",
      " [3 0 8 ... 9 2 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (130, 784) (130,)\n",
      "trainset after (140, 784) (140,)\n",
      "updated train set: (140, 784) (140,) unique(labels): [ 8  7 10 10 14 28 11 34  8 10] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59860, 784) (59860,)\n",
      "\n",
      "Train set: (140, 784) y: (140,)\n",
      "Val   set: (59860, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 14\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.144 s \n",
      "\n",
      "Accuracy rate for 49.570000 \n",
      "Classification report for classifier LogisticRegression(C=0.35714285714285715, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.91      0.78       980\n",
      "           1       0.75      0.90      0.82      1135\n",
      "           2       0.45      0.37      0.41      1032\n",
      "           3       0.60      0.41      0.49      1010\n",
      "           4       0.43      0.75      0.55       982\n",
      "           5       0.60      0.05      0.10       892\n",
      "           6       0.78      0.55      0.64       958\n",
      "           7       1.00      0.06      0.11      1028\n",
      "           8       0.28      0.84      0.42       974\n",
      "           9       0.15      0.06      0.09      1009\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.57      0.49      0.44     10000\n",
      "weighted avg       0.58      0.50      0.45     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 888    2   13   19    0    8   24    0   25    1]\n",
      " [   0 1020    1   13    0    0    1    0  100    0]\n",
      " [  36  151  383   43   65    1   72    0  277    4]\n",
      " [  13   23   23  417    7    5    9    0  503   10]\n",
      " [  30    7   10    0  735    2    5    0  188    5]\n",
      " [  75    8   68  148   53   49   32    0  435   24]\n",
      " [  78   12   31    3  111    0  524    0  199    0]\n",
      " [ 133   79  272   25  141   11    3   59   26  279]\n",
      " [   6   35   52   23   24    1    3    0  822    8]\n",
      " [  30   18    3    8  560    4    1    0  325   60]]\n",
      "--------------------------------\n",
      "val predicted: (59860,) ['2' '0' '8' ... '9' '2' '9']\n",
      "probabilities: (59860, 10) \n",
      " [2 0 8 ... 9 2 9]\n",
      "trainset before (140, 784) (140,)\n",
      "trainset after (150, 784) (150,)\n",
      "updated train set: (150, 784) (150,) unique(labels): [ 8  7 10 10 14 31 12 38  9 11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59850, 784) (59850,)\n",
      "\n",
      "Train set: (150, 784) y: (150,)\n",
      "Val   set: (59850, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 15\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.152 s \n",
      "\n",
      "Accuracy rate for 48.560000 \n",
      "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75       980\n",
      "           1       0.82      0.77      0.80      1135\n",
      "           2       0.40      0.47      0.43      1032\n",
      "           3       0.63      0.37      0.47      1010\n",
      "           4       0.45      0.74      0.56       982\n",
      "           5       0.55      0.07      0.12       892\n",
      "           6       0.83      0.49      0.62       958\n",
      "           7       0.87      0.10      0.18      1028\n",
      "           8       0.28      0.88      0.42       974\n",
      "           9       0.13      0.03      0.05      1009\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.56      0.48      0.44     10000\n",
      "weighted avg       0.56      0.49      0.44     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[873   2  37  14   0   5  28   0  20   1]\n",
      " [  0 874  13  26   0   0   0   0 222   0]\n",
      " [ 29  79 488  45  58   2  38   3 289   1]\n",
      " [ 16  10  40 373   7  19   3   2 535   5]\n",
      " [ 37   5  26   0 727   4   7   0 170   6]\n",
      " [100   4 125 101  64  60  13   1 415   9]\n",
      " [101   9  55   4 113   2 468   0 206   0]\n",
      " [146  52 366   9 105   8   1 102  46 193]\n",
      " [  6  13  58  19  17   0   2   0 858   1]\n",
      " [ 37  15  18   3 535   9   2   9 348  33]]\n",
      "--------------------------------\n",
      "val predicted: (59850,) ['5' '0' '8' ... '8' '2' '8']\n",
      "probabilities: (59850, 10) \n",
      " [5 0 8 ... 8 2 8]\n",
      "trainset before (150, 784) (150,)\n",
      "trainset after (160, 784) (160,)\n",
      "updated train set: (160, 784) (160,) unique(labels): [ 8  7 11 10 14 35 12 39 13 11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59840, 784) (59840,)\n",
      "\n",
      "Train set: (160, 784) y: (160,)\n",
      "Val   set: (59840, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 16\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.153 s \n",
      "\n",
      "Accuracy rate for 51.510000 \n",
      "Classification report for classifier LogisticRegression(C=0.3125, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.93      0.75       980\n",
      "           1       0.66      0.95      0.78      1135\n",
      "           2       0.45      0.46      0.45      1032\n",
      "           3       0.62      0.39      0.48      1010\n",
      "           4       0.48      0.70      0.57       982\n",
      "           5       0.55      0.06      0.11       892\n",
      "           6       0.82      0.68      0.74       958\n",
      "           7       0.96      0.05      0.10      1028\n",
      "           8       0.31      0.74      0.43       974\n",
      "           9       0.26      0.13      0.17      1009\n",
      "\n",
      "    accuracy                           0.52     10000\n",
      "   macro avg       0.57      0.51      0.46     10000\n",
      "weighted avg       0.57      0.52      0.46     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 907    3   13    2    0    3   13    0   38    1]\n",
      " [   0 1081    5   26    0    1    1    0   21    0]\n",
      " [  48  206  475   45   39    2   71    0  139    7]\n",
      " [  30   68   28  394    8   16    5    1  444   16]\n",
      " [  44   17   28    1  686    4   11    0  178   13]\n",
      " [ 123   16   89  102   48   54   33    0  412   15]\n",
      " [  99   14   41    7   51    0  650    0   96    0]\n",
      " [ 140   82  307   21   80   10    3   55   14  316]\n",
      " [   9  107   63   38   25    1    6    0  717    8]\n",
      " [  28   39   17    4  505    7    3    1  273  132]]\n",
      "--------------------------------\n",
      "val predicted: (59840,) ['3' '0' '8' ... '5' '2' '9']\n",
      "probabilities: (59840, 10) \n",
      " [3 0 8 ... 5 2 9]\n",
      "trainset before (160, 784) (160,)\n",
      "trainset after (170, 784) (170,)\n",
      "updated train set: (170, 784) (170,) unique(labels): [ 8  7 12 10 14 42 12 41 13 11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59830, 784) (59830,)\n",
      "\n",
      "Train set: (170, 784) y: (170,)\n",
      "Val   set: (59830, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 17\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.145 s \n",
      "\n",
      "Accuracy rate for 52.710000 \n",
      "Classification report for classifier LogisticRegression(C=0.29411764705882354, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.91      0.78       980\n",
      "           1       0.62      0.97      0.76      1135\n",
      "           2       0.56      0.43      0.49      1032\n",
      "           3       0.60      0.48      0.53      1010\n",
      "           4       0.46      0.76      0.57       982\n",
      "           5       0.66      0.04      0.07       892\n",
      "           6       0.75      0.76      0.76       958\n",
      "           7       0.95      0.02      0.03      1028\n",
      "           8       0.35      0.68      0.46       974\n",
      "           9       0.22      0.16      0.19      1009\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.58      0.52      0.46     10000\n",
      "weighted avg       0.59      0.53      0.47     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 895    3   10   11    0    2   31    0   28    0]\n",
      " [   0 1097    0   24    0    0    3    0   11    0]\n",
      " [  38  243  442   60   35    1  118    0   88    7]\n",
      " [  22   79    8  483   21    5    8    1  368   15]\n",
      " [  30   23   54    0  745    0   10    0   99   21]\n",
      " [ 111   19   29  155   78   33   39    0  412   16]\n",
      " [  82   12   26    6   55    0  728    0   49    0]\n",
      " [ 110  101  166   16   82    3    3   18   10  519]\n",
      " [  10  135   37   47   40    1   25    0  666   13]\n",
      " [  27   44   12    4  567    5    3    0  183  164]]\n",
      "--------------------------------\n",
      "val predicted: (59830,) ['3' '0' '4' ... '5' '2' '9']\n",
      "probabilities: (59830, 10) \n",
      " [3 0 4 ... 5 2 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (170, 784) (170,)\n",
      "trainset after (180, 784) (180,)\n",
      "updated train set: (180, 784) (180,) unique(labels): [ 8  8 12 11 14 47 12 43 14 11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59820, 784) (59820,)\n",
      "\n",
      "Train set: (180, 784) y: (180,)\n",
      "Val   set: (59820, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 18\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.150 s \n",
      "\n",
      "Accuracy rate for 53.910000 \n",
      "Classification report for classifier LogisticRegression(C=0.2777777777777778, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77       980\n",
      "           1       0.65      0.96      0.77      1135\n",
      "           2       0.47      0.49      0.48      1032\n",
      "           3       0.66      0.50      0.57      1010\n",
      "           4       0.43      0.79      0.56       982\n",
      "           5       0.57      0.08      0.13       892\n",
      "           6       0.78      0.62      0.69       958\n",
      "           7       0.92      0.18      0.29      1028\n",
      "           8       0.36      0.75      0.48       974\n",
      "           9       0.25      0.07      0.10      1009\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.58      0.53      0.49     10000\n",
      "weighted avg       0.58      0.54      0.49     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 871    1   12    6    1    3   22    0   63    1]\n",
      " [   0 1094    0    8    0    1    3    0   29    0]\n",
      " [  27  194  502   22   34    2   70    1  177    3]\n",
      " [  21   52   13  510   20    9   11    4  362    8]\n",
      " [  36   34   54    2  780    5    5    0   57    9]\n",
      " [  98   38   47  164   76   67   38    1  356    7]\n",
      " [  91   16   39    3  113    4  594    0   98    0]\n",
      " [ 107  102  328    9  101   15    5  180   10  171]\n",
      " [   7  111   41   35   42    1    9    0  726    2]\n",
      " [  31   54   29   15  627   10    3   10  163   67]]\n",
      "--------------------------------\n",
      "val predicted: (59820,) ['6' '0' '4' ... '5' '2' '9']\n",
      "probabilities: (59820, 10) \n",
      " [6 0 4 ... 5 2 9]\n",
      "trainset before (180, 784) (180,)\n",
      "trainset after (190, 784) (190,)\n",
      "updated train set: (190, 784) (190,) unique(labels): [ 9  8 13 11 14 55 12 43 14 11] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59810, 784) (59810,)\n",
      "\n",
      "Train set: (190, 784) y: (190,)\n",
      "Val   set: (59810, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 19\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.151 s \n",
      "\n",
      "Accuracy rate for 54.640000 \n",
      "Classification report for classifier LogisticRegression(C=0.2631578947368421, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76       980\n",
      "           1       0.66      0.96      0.78      1135\n",
      "           2       0.54      0.46      0.50      1032\n",
      "           3       0.62      0.48      0.54      1010\n",
      "           4       0.45      0.80      0.58       982\n",
      "           5       0.61      0.07      0.12       892\n",
      "           6       0.73      0.75      0.74       958\n",
      "           7       0.95      0.14      0.24      1028\n",
      "           8       0.38      0.75      0.50       974\n",
      "           9       0.23      0.10      0.14      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.58      0.54      0.49     10000\n",
      "weighted avg       0.58      0.55      0.50     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 861    2   21    7    0    7   41    1   37    3]\n",
      " [   0 1090    0   20    0    1    4    0   20    0]\n",
      " [  23  205  479   44   28    1  133    0  116    3]\n",
      " [  18   54   12  482   15   10   16    2  389   12]\n",
      " [  21   27   63    0  790    1    7    0   67    6]\n",
      " [ 130   34   25  142   85   62   54    0  354    6]\n",
      " [  44   12   42    5   85    0  722    0   47    1]\n",
      " [ 155   89  196   22   90   11    3  143   12  307]\n",
      " [   9  103   29   48   37    0   12    0  734    2]\n",
      " [  23   40   21   10  619    9    2    5  179  101]]\n",
      "--------------------------------\n",
      "val predicted: (59810,) ['6' '0' '4' ... '5' '2' '9']\n",
      "probabilities: (59810, 10) \n",
      " [6 0 4 ... 5 2 9]\n",
      "trainset before (190, 784) (190,)\n",
      "trainset after (200, 784) (200,)\n",
      "updated train set: (200, 784) (200,) unique(labels): [ 9  8 14 11 16 60 12 44 14 12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59800, 784) (59800,)\n",
      "\n",
      "Train set: (200, 784) y: (200,)\n",
      "Val   set: (59800, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 20\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.150 s \n",
      "\n",
      "Accuracy rate for 55.140000 \n",
      "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76       980\n",
      "           1       0.69      0.95      0.80      1135\n",
      "           2       0.44      0.43      0.43      1032\n",
      "           3       0.69      0.42      0.52      1010\n",
      "           4       0.49      0.76      0.60       982\n",
      "           5       0.51      0.02      0.05       892\n",
      "           6       0.71      0.78      0.74       958\n",
      "           7       0.92      0.31      0.46      1028\n",
      "           8       0.33      0.81      0.47       974\n",
      "           9       0.48      0.09      0.15      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.59      0.54      0.50     10000\n",
      "weighted avg       0.59      0.55      0.50     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 866    1   17    1    0    2   37    1   53    2]\n",
      " [   0 1079    1   20    0    0    4    0   31    0]\n",
      " [  22  164  440   26   20    1  167    3  188    1]\n",
      " [  26   35   11  420   11    3   18    8  472    6]\n",
      " [  26   27   90    1  746    1    5    0   84    2]\n",
      " [ 132   36   43  101   40   21   58    2  453    6]\n",
      " [  59   11   22    1   70    0  748    0   46    1]\n",
      " [ 123   96  302    5   82    6    2  317   17   78]\n",
      " [   7   73   30   31   23    0   19    3  787    1]\n",
      " [  33   51   50    4  525    7    2   12  235   90]]\n",
      "--------------------------------\n",
      "val predicted: (59800,) ['6' '0' '4' ... '8' '2' '9']\n",
      "probabilities: (59800, 10) \n",
      " [6 0 4 ... 8 2 9]\n",
      "trainset before (200, 784) (200,)\n",
      "trainset after (210, 784) (210,)\n",
      "updated train set: (210, 784) (210,) unique(labels): [ 9  8 16 12 16 66 12 45 14 12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59790, 784) (59790,)\n",
      "\n",
      "Train set: (210, 784) y: (210,)\n",
      "Val   set: (59790, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 21\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.163 s \n",
      "\n",
      "Accuracy rate for 51.260000 \n",
      "Classification report for classifier LogisticRegression(C=0.23809523809523808, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.91      0.75       980\n",
      "           1       0.63      0.97      0.76      1135\n",
      "           2       0.29      0.24      0.26      1032\n",
      "           3       0.63      0.47      0.54      1010\n",
      "           4       0.48      0.60      0.53       982\n",
      "           5       0.61      0.05      0.10       892\n",
      "           6       0.68      0.81      0.74       958\n",
      "           7       0.93      0.17      0.28      1028\n",
      "           8       0.32      0.79      0.46       974\n",
      "           9       0.31      0.06      0.10      1009\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.55      0.51      0.45     10000\n",
      "weighted avg       0.55      0.51      0.46     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 892    2    7    4    0    6   36    1   31    1]\n",
      " [   0 1100    0    7    0    0    4    1   23    0]\n",
      " [  45  200  245   30   10    1  226    0  273    2]\n",
      " [  37   53    7  473    5    5   13    1  409    7]\n",
      " [  17   52  155    6  588    2   20    0  141    1]\n",
      " [ 151   45   18  158   31   48   41    0  394    6]\n",
      " [  51   15   18    5   32    1  777    0   59    0]\n",
      " [ 177  120  322   16   63    8    4  171   24  123]\n",
      " [  12  110   12   37   13    1   18    0  770    1]\n",
      " [  22   57   75   14  490    7    2    9  271   62]]\n",
      "--------------------------------\n",
      "val predicted: (59790,) ['6' '0' '4' ... '5' '2' '9']\n",
      "probabilities: (59790, 10) \n",
      " [6 0 4 ... 5 2 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (210, 784) (210,)\n",
      "trainset after (220, 784) (220,)\n",
      "updated train set: (220, 784) (220,) unique(labels): [10  8 19 13 17 70 12 45 14 12] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59780, 784) (59780,)\n",
      "\n",
      "Train set: (220, 784) y: (220,)\n",
      "Val   set: (59780, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 22\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.165 s \n",
      "\n",
      "Accuracy rate for 51.010000 \n",
      "Classification report for classifier LogisticRegression(C=0.22727272727272727, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.88      0.77       980\n",
      "           1       0.68      0.95      0.80      1135\n",
      "           2       0.47      0.11      0.18      1032\n",
      "           3       0.57      0.42      0.49      1010\n",
      "           4       0.45      0.77      0.57       982\n",
      "           5       0.62      0.03      0.05       892\n",
      "           6       0.64      0.61      0.62       958\n",
      "           7       0.90      0.31      0.46      1028\n",
      "           8       0.30      0.82      0.43       974\n",
      "           9       0.29      0.15      0.20      1009\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.56      0.50      0.46     10000\n",
      "weighted avg       0.56      0.51      0.46     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 858    1    0    5    0    3   33    1   71    8]\n",
      " [   0 1081    0   10    0    0    3    0   40    1]\n",
      " [  31  180  113   71   40    2  213    9  350   23]\n",
      " [  26   31    0  428    8    3   14    7  479   14]\n",
      " [  26   28   13   11  753    1   13    0  128    9]\n",
      " [ 118   37    3  153   52   23   37    4  429   36]\n",
      " [  67   14    5   14  130    1  581    0  146    0]\n",
      " [  95   93   96   13  109    4    3  318   26  271]\n",
      " [   7   78    8   37   33    0    5    0  796   10]\n",
      " [  25   38    3   11  536    0    2   13  231  150]]\n",
      "--------------------------------\n",
      "val predicted: (59780,) ['9' '0' '8' ... '9' '6' '9']\n",
      "probabilities: (59780, 10) \n",
      " [9 0 8 ... 9 6 9]\n",
      "trainset before (220, 784) (220,)\n",
      "trainset after (230, 784) (230,)\n",
      "updated train set: (230, 784) (230,) unique(labels): [10  9 20 16 17 73 12 46 14 13] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59770, 784) (59770,)\n",
      "\n",
      "Train set: (230, 784) y: (230,)\n",
      "Val   set: (59770, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 23\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.167 s \n",
      "\n",
      "Accuracy rate for 50.700000 \n",
      "Classification report for classifier LogisticRegression(C=0.21739130434782608, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.72       980\n",
      "           1       0.67      0.94      0.78      1135\n",
      "           2       0.38      0.22      0.28      1032\n",
      "           3       0.65      0.41      0.50      1010\n",
      "           4       0.47      0.74      0.57       982\n",
      "           5       0.75      0.01      0.02       892\n",
      "           6       0.66      0.78      0.71       958\n",
      "           7       0.97      0.12      0.22      1028\n",
      "           8       0.31      0.83      0.45       974\n",
      "           9       0.22      0.06      0.10      1009\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.57      0.50      0.44     10000\n",
      "weighted avg       0.57      0.51      0.44     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 873    1    1    1    0    1   44    1   54    4]\n",
      " [   0 1071    0    5    0    0    4    0   55    0]\n",
      " [  26  139  229  107   17    0  229    0  283    2]\n",
      " [  36   33    4  416   10    0   14    1  477   19]\n",
      " [  37   32   43    0  731    0   12    0  125    2]\n",
      " [ 206   46   10   77   41    9   51    0  435   17]\n",
      " [  43   16    9    6   57    0  743    0   84    0]\n",
      " [ 172  130  258    1  130    2    4  128   27  176]\n",
      " [  10   63   26   26   21    0   18    0  807    3]\n",
      " [  39   69   20    5  565    0    5    2  241   63]]\n",
      "--------------------------------\n",
      "val predicted: (59770,) ['3' '0' '4' ... '8' '6' '8']\n",
      "probabilities: (59770, 10) \n",
      " [3 0 4 ... 8 6 8]\n",
      "trainset before (230, 784) (230,)\n",
      "trainset after (240, 784) (240,)\n",
      "updated train set: (240, 784) (240,) unique(labels): [10  9 20 17 18 76 12 47 15 16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59760, 784) (59760,)\n",
      "\n",
      "Train set: (240, 784) y: (240,)\n",
      "Val   set: (59760, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 24\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.160 s \n",
      "\n",
      "Accuracy rate for 53.670000 \n",
      "Classification report for classifier LogisticRegression(C=0.20833333333333334, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79       980\n",
      "           1       0.69      0.95      0.80      1135\n",
      "           2       0.59      0.27      0.37      1032\n",
      "           3       0.69      0.45      0.55      1010\n",
      "           4       0.44      0.70      0.54       982\n",
      "           5       0.83      0.02      0.04       892\n",
      "           6       0.67      0.84      0.74       958\n",
      "           7       0.93      0.22      0.36      1028\n",
      "           8       0.33      0.83      0.48       974\n",
      "           9       0.24      0.15      0.18      1009\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.61      0.53      0.48     10000\n",
      "weighted avg       0.61      0.54      0.49     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 861    1    3    1    0    2   65    1   44    2]\n",
      " [   0 1073    0    7    0    0    5    0   49    1]\n",
      " [  25  160  274   58   16    0  221    2  256   20]\n",
      " [  23   26    4  458    9    0   20    4  445   21]\n",
      " [  23   27   66    2  692    0   10    0  150   12]\n",
      " [ 116   62   10   92   87   19   57    3  413   33]\n",
      " [  39   16   16    6   37    0  800    0   44    0]\n",
      " [  71  101   63    3  146    2    2  229   40  371]\n",
      " [   8   51   14   25   37    0   19    0  813    7]\n",
      " [  27   46   15    8  564    0    4    6  191  148]]\n",
      "--------------------------------\n",
      "val predicted: (59760,) ['3' '0' '8' ... '8' '2' '9']\n",
      "probabilities: (59760, 10) \n",
      " [3 0 8 ... 8 2 9]\n",
      "trainset before (240, 784) (240,)\n",
      "trainset after (250, 784) (250,)\n",
      "updated train set: (250, 784) (250,) unique(labels): [11  9 20 20 18 82 12 47 15 16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59750, 784) (59750,)\n",
      "\n",
      "Train set: (250, 784) y: (250,)\n",
      "Val   set: (59750, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 25\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.173 s \n",
      "\n",
      "Accuracy rate for 49.840000 \n",
      "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80       980\n",
      "           1       0.69      0.96      0.80      1135\n",
      "           2       0.62      0.16      0.26      1032\n",
      "           3       0.58      0.27      0.37      1010\n",
      "           4       0.42      0.74      0.53       982\n",
      "           5       0.78      0.04      0.07       892\n",
      "           6       0.64      0.79      0.71       958\n",
      "           7       0.96      0.09      0.17      1028\n",
      "           8       0.31      0.85      0.45       974\n",
      "           9       0.22      0.17      0.19      1009\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.60      0.49      0.44     10000\n",
      "weighted avg       0.60      0.50      0.44     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 844    1    2    6    4    4   69    0   49    1]\n",
      " [   0 1084    0    3    0    0    4    0   43    1]\n",
      " [  43  181  168  119   25    0  237    0  228   31]\n",
      " [  33   28    1  272   16    1   13    3  611   32]\n",
      " [   5   22   13    0  724    1   48    0  152   17]\n",
      " [  95   44   13   46   93   32   35    0  505   29]\n",
      " [  41   17    9    5   70    0  761    0   55    0]\n",
      " [  37   97   51    1  205    2    2   96   36  501]\n",
      " [   9   51   10   15   31    0   18    0  832    8]\n",
      " [  15   39    4    1  559    1    6    1  212  171]]\n",
      "--------------------------------\n",
      "val predicted: (59750,) ['9' '0' '4' ... '8' '6' '9']\n",
      "probabilities: (59750, 10) \n",
      " [9 0 4 ... 8 6 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (250, 784) (250,)\n",
      "trainset after (260, 784) (260,)\n",
      "updated train set: (260, 784) (260,) unique(labels): [12 10 22 24 18 84 12 47 15 16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59740, 784) (59740,)\n",
      "\n",
      "Train set: (260, 784) y: (260,)\n",
      "Val   set: (59740, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 26\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.184 s \n",
      "\n",
      "Accuracy rate for 48.250000 \n",
      "Classification report for classifier LogisticRegression(C=0.19230769230769232, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.91      0.75       980\n",
      "           1       0.68      0.89      0.77      1135\n",
      "           2       0.50      0.19      0.28      1032\n",
      "           3       0.58      0.28      0.38      1010\n",
      "           4       0.43      0.69      0.53       982\n",
      "           5       1.00      0.03      0.07       892\n",
      "           6       0.70      0.75      0.72       958\n",
      "           7       0.97      0.03      0.06      1028\n",
      "           8       0.30      0.89      0.44       974\n",
      "           9       0.19      0.12      0.15      1009\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.60      0.48      0.41     10000\n",
      "weighted avg       0.60      0.48      0.42     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 889    1    0    3    2    0   47    0   37    1]\n",
      " [   0 1011    0   50    0    0    3    0   71    0]\n",
      " [ 129  194  196   29   34    0  182    1  256   11]\n",
      " [  82   30    2  279   10    0   13    0  575   19]\n",
      " [   7   18   27    1  682    0   22    0  204   21]\n",
      " [ 145   20    6   88   61   30   31    0  499   12]\n",
      " [  36   20   13    6   99    0  719    0   65    0]\n",
      " [  81  116  121    4  169    0    3   30   48  456]\n",
      " [  14   30   15   13   27    0    8    0  864    3]\n",
      " [  23   39   12    5  508    0    4    0  293  125]]\n",
      "--------------------------------\n",
      "val predicted: (59740,) ['3' '0' '8' ... '8' '6' '9']\n",
      "probabilities: (59740, 10) \n",
      " [3 0 8 ... 8 6 9]\n",
      "trainset before (260, 784) (260,)\n",
      "trainset after (270, 784) (270,)\n",
      "updated train set: (270, 784) (270,) unique(labels): [13 10 25 24 18 86 13 50 15 16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59730, 784) (59730,)\n",
      "\n",
      "Train set: (270, 784) y: (270,)\n",
      "Val   set: (59730, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 27\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.168 s \n",
      "\n",
      "Accuracy rate for 47.700000 \n",
      "Classification report for classifier LogisticRegression(C=0.18518518518518517, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.92      0.70       980\n",
      "           1       0.71      0.91      0.79      1135\n",
      "           2       0.66      0.14      0.23      1032\n",
      "           3       0.59      0.23      0.33      1010\n",
      "           4       0.41      0.75      0.53       982\n",
      "           5       0.97      0.04      0.08       892\n",
      "           6       0.75      0.64      0.69       958\n",
      "           7       1.00      0.02      0.04      1028\n",
      "           8       0.30      0.89      0.45       974\n",
      "           9       0.23      0.18      0.20      1009\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.62      0.47      0.41     10000\n",
      "weighted avg       0.62      0.48      0.41     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 901    1    0    1    8    0   34    0   33    2]\n",
      " [   0 1029    0   33    0    0    3    0   70    0]\n",
      " [ 238  183  147   25   31    0  103    0  283   22]\n",
      " [ 133   24    0  233   13    0   14    0  573   20]\n",
      " [   5   17   17    1  738    0   13    0  163   28]\n",
      " [ 147   18    1   75   91   38   28    0  484   10]\n",
      " [  50   15    9   11  165    0  613    0   95    0]\n",
      " [  64  102   37    2  208    0    1   22   54  538]\n",
      " [  20   34    5   11   27    1    4    0  867    5]\n",
      " [  23   31    6    2  525    0    1    0  239  182]]\n",
      "--------------------------------\n",
      "val predicted: (59730,) ['3' '0' '6' ... '8' '6' '9']\n",
      "probabilities: (59730, 10) \n",
      " [3 0 6 ... 8 6 9]\n",
      "trainset before (270, 784) (270,)\n",
      "trainset after (280, 784) (280,)\n",
      "updated train set: (280, 784) (280,) unique(labels): [14 10 26 28 18 89 14 50 15 16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59720, 784) (59720,)\n",
      "\n",
      "Train set: (280, 784) y: (280,)\n",
      "Val   set: (59720, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 28\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.169 s \n",
      "\n",
      "Accuracy rate for 47.580000 \n",
      "Classification report for classifier LogisticRegression(C=0.17857142857142858, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78       980\n",
      "           1       0.66      0.95      0.78      1135\n",
      "           2       0.69      0.16      0.26      1032\n",
      "           3       0.77      0.17      0.27      1010\n",
      "           4       0.41      0.74      0.53       982\n",
      "           5       0.90      0.06      0.11       892\n",
      "           6       0.67      0.72      0.69       958\n",
      "           7       1.00      0.00      0.01      1028\n",
      "           8       0.28      0.89      0.43       974\n",
      "           9       0.20      0.17      0.18      1009\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.63      0.47      0.40     10000\n",
      "weighted avg       0.63      0.48      0.41     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 845    3    1    1   20    2   50    0   57    1]\n",
      " [   0 1079    0    0    0    0    5    0   51    0]\n",
      " [  75  231  166    9   30    1  182    0  285   53]\n",
      " [  75   30    0  168   16    1   26    0  675   19]\n",
      " [   3   19   20    0  728    0   11    0  173   28]\n",
      " [  72   41    8   33   94   52   52    0  520   20]\n",
      " [  21   21   11    2  132    0  685    0   86    0]\n",
      " [  78  115   27    1  218    1    1    4   51  532]\n",
      " [  11   49    4    3   29    1   10    0  863    4]\n",
      " [  18   38    2    0  507    0    1    0  275  168]]\n",
      "--------------------------------\n",
      "val predicted: (59720,) ['6' '0' '8' ... '8' '6' '9']\n",
      "probabilities: (59720, 10) \n",
      " [6 0 8 ... 8 6 9]\n",
      "trainset before (280, 784) (280,)\n",
      "trainset after (290, 784) (290,)\n",
      "updated train set: (290, 784) (290,) unique(labels): [18 10 27 29 19 90 14 52 15 16] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59710, 784) (59710,)\n",
      "\n",
      "Train set: (290, 784) y: (290,)\n",
      "Val   set: (59710, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 29\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.185 s \n",
      "\n",
      "Accuracy rate for 45.690000 \n",
      "Classification report for classifier LogisticRegression(C=0.1724137931034483, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.80      0.72       980\n",
      "           1       0.64      0.95      0.77      1135\n",
      "           2       0.65      0.22      0.33      1032\n",
      "           3       0.77      0.17      0.27      1010\n",
      "           4       0.39      0.70      0.50       982\n",
      "           5       0.81      0.07      0.13       892\n",
      "           6       0.69      0.54      0.61       958\n",
      "           7       0.83      0.00      0.01      1028\n",
      "           8       0.28      0.87      0.42       974\n",
      "           9       0.20      0.18      0.19      1009\n",
      "\n",
      "    accuracy                           0.46     10000\n",
      "   macro avg       0.59      0.45      0.40     10000\n",
      "weighted avg       0.59      0.46      0.40     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 784    2    1    0   11    3   39    0  128   12]\n",
      " [   0 1080    0    4    0    0    3    0   48    0]\n",
      " [ 122  233  231   13   22    2   95    0  268   46]\n",
      " [  82   39    1  167   13    2   28    0  648   30]\n",
      " [   6   32   36    0  685    1    4    0  165   53]\n",
      " [ 113   24    6   24   78   65   53    0  515   14]\n",
      " [  30   28   27    2  202    4  519    0  142    4]\n",
      " [  26  128   44    0  210    1    3    5   37  574]\n",
      " [  13   61    3    6   24    2    6    0  850    9]\n",
      " [  11   53    4    1  510    0    0    1  246  183]]\n",
      "--------------------------------\n",
      "val predicted: (59710,) ['6' '0' '9' ... '8' '6' '9']\n",
      "probabilities: (59710, 10) \n",
      " [6 0 9 ... 8 6 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (290, 784) (290,)\n",
      "trainset after (300, 784) (300,)\n",
      "updated train set: (300, 784) (300,) unique(labels): [22 11 27 29 19 90 16 54 15 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59700, 784) (59700,)\n",
      "\n",
      "Train set: (300, 784) y: (300,)\n",
      "Val   set: (59700, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 30\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.172 s \n",
      "\n",
      "Accuracy rate for 48.000000 \n",
      "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.77       980\n",
      "           1       0.70      0.92      0.79      1135\n",
      "           2       0.46      0.25      0.32      1032\n",
      "           3       0.85      0.19      0.31      1010\n",
      "           4       0.41      0.76      0.53       982\n",
      "           5       0.76      0.08      0.14       892\n",
      "           6       0.67      0.56      0.61       958\n",
      "           7       0.99      0.08      0.15      1028\n",
      "           8       0.28      0.91      0.43       974\n",
      "           9       0.26      0.11      0.16      1009\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.60      0.47      0.42     10000\n",
      "weighted avg       0.60      0.48      0.43     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 877    1    5    0    1   14   21    0   58    3]\n",
      " [   0 1046    0    0    0    0    5    0   84    0]\n",
      " [  62  175  254    6   23    0  158    0  340   14]\n",
      " [  88   31    3  192   14    4   15    1  648   14]\n",
      " [   8   13   28    0  742    0   16    0  165   10]\n",
      " [ 132   38   10   21   70   67   44    0  496   14]\n",
      " [  77   26   20    1  159    2  541    0  132    0]\n",
      " [  40   99  212    1  272    1    3   84   50  266]\n",
      " [  10   34    6    5   25    0    8    0  883    3]\n",
      " [  15   35   13    1  525    0    2    0  304  114]]\n",
      "--------------------------------\n",
      "val predicted: (59700,) ['5' '0' '8' ... '8' '0' '9']\n",
      "probabilities: (59700, 10) \n",
      " [5 0 8 ... 8 0 9]\n",
      "trainset before (300, 784) (300,)\n",
      "trainset after (310, 784) (310,)\n",
      "updated train set: (310, 784) (310,) unique(labels): [22 11 29 30 20 96 16 54 15 17] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59690, 784) (59690,)\n",
      "\n",
      "Train set: (310, 784) y: (310,)\n",
      "Val   set: (59690, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 31\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.202 s \n",
      "\n",
      "Accuracy rate for 46.360000 \n",
      "Classification report for classifier LogisticRegression(C=0.16129032258064516, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.89      0.76       980\n",
      "           1       0.73      0.90      0.81      1135\n",
      "           2       0.61      0.22      0.32      1032\n",
      "           3       0.76      0.19      0.30      1010\n",
      "           4       0.42      0.69      0.52       982\n",
      "           5       0.80      0.02      0.04       892\n",
      "           6       0.68      0.63      0.66       958\n",
      "           7       1.00      0.02      0.04      1028\n",
      "           8       0.26      0.93      0.40       974\n",
      "           9       0.17      0.11      0.13      1009\n",
      "\n",
      "    accuracy                           0.46     10000\n",
      "   macro avg       0.61      0.46      0.40     10000\n",
      "weighted avg       0.61      0.46      0.40     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 868    1    0    0    0    2   26    0   80    3]\n",
      " [   0 1025    0    0    0    0    8    0  102    0]\n",
      " [  57  150  222   14   45    0  148    0  381   15]\n",
      " [  73   19    0  188   14    1   27    0  675   13]\n",
      " [  11   10   28    0  677    0    5    0  235   16]\n",
      " [ 131   42    3   35   41   16   58    0  554   12]\n",
      " [  73   19   17    1  115    1  607    0  125    0]\n",
      " [  61   99   82    1  244    0    4   23   66  448]\n",
      " [  14   20    5    6   17    0    6    0  903    3]\n",
      " [  25   26    7    1  455    0    1    0  387  107]]\n",
      "--------------------------------\n",
      "val predicted: (59690,) ['6' '0' '8' ... '8' '0' '9']\n",
      "probabilities: (59690, 10) \n",
      " [6 0 8 ... 8 0 9]\n",
      "trainset before (310, 784) (310,)\n",
      "trainset after (320, 784) (320,)\n",
      "updated train set: (320, 784) (320,) unique(labels): [ 23  11  30  31  20 100  17  55  15  18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59680, 784) (59680,)\n",
      "\n",
      "Train set: (320, 784) y: (320,)\n",
      "Val   set: (59680, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 32\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.190 s \n",
      "\n",
      "Accuracy rate for 44.570000 \n",
      "Classification report for classifier LogisticRegression(C=0.15625, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.90      0.77       980\n",
      "           1       0.77      0.75      0.76      1135\n",
      "           2       0.71      0.20      0.31      1032\n",
      "           3       0.70      0.20      0.32      1010\n",
      "           4       0.40      0.70      0.51       982\n",
      "           5       0.78      0.05      0.10       892\n",
      "           6       0.68      0.56      0.62       958\n",
      "           7       0.95      0.03      0.07      1028\n",
      "           8       0.24      0.94      0.38       974\n",
      "           9       0.16      0.10      0.12      1009\n",
      "\n",
      "    accuracy                           0.45     10000\n",
      "   macro avg       0.61      0.44      0.40     10000\n",
      "weighted avg       0.61      0.45      0.40     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[878   1   1   0   0   9   9   1  81   0]\n",
      " [  0 847   0  20   0   0   9   0 259   0]\n",
      " [ 58 111 203   8  60   0 155   1 420  16]\n",
      " [ 65   9   2 207  10   3  11   0 692  11]\n",
      " [  6   3  20   0 692   0  16   0 233  12]\n",
      " [111   9   3  46  39  49  33   0 588  14]\n",
      " [ 87  11   9   2 167   1 536   0 145   0]\n",
      " [ 64  76  42   3 280   1   5  35  82 440]\n",
      " [  9   6   1   9  24   0   9   0 913   3]\n",
      " [ 18  20   6   1 470   0   1   0 396  97]]\n",
      "--------------------------------\n",
      "val predicted: (59680,) ['3' '0' '8' ... '8' '0' '9']\n",
      "probabilities: (59680, 10) \n",
      " [3 0 8 ... 8 0 9]\n",
      "trainset before (320, 784) (320,)\n",
      "trainset after (330, 784) (330,)\n",
      "updated train set: (330, 784) (330,) unique(labels): [ 23  17  31  31  20 103  17  55  15  18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59670, 784) (59670,)\n",
      "\n",
      "Train set: (330, 784) y: (330,)\n",
      "Val   set: (59670, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 33\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.208 s \n",
      "\n",
      "Accuracy rate for 44.030000 \n",
      "Classification report for classifier LogisticRegression(C=0.15151515151515152, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.75       980\n",
      "           1       0.71      0.89      0.79      1135\n",
      "           2       0.58      0.19      0.28      1032\n",
      "           3       0.83      0.11      0.20      1010\n",
      "           4       0.37      0.62      0.47       982\n",
      "           5       0.63      0.07      0.13       892\n",
      "           6       0.70      0.53      0.60       958\n",
      "           7       0.95      0.05      0.10      1028\n",
      "           8       0.24      0.92      0.38       974\n",
      "           9       0.15      0.08      0.10      1009\n",
      "\n",
      "    accuracy                           0.44     10000\n",
      "   macro avg       0.58      0.44      0.38     10000\n",
      "weighted avg       0.58      0.44      0.38     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 884    1    0    0    1    7    6    0   81    0]\n",
      " [   0 1005    1    0    1    0    4    0  123    1]\n",
      " [  94  141  192    2   35    3  127    1  426   11]\n",
      " [  88   24    4  115   18   10   22    0  716   13]\n",
      " [   6   13   53    0  609    2   10    0  282    7]\n",
      " [ 122   72    1   14   50   63   35    1  526    8]\n",
      " [  94   21   11    1  125    1  506    0  199    0]\n",
      " [  54   79   55    1  306   10    5   52   73  393]\n",
      " [   9   34    2    3   21    1    2    0  900    2]\n",
      " [  20   20   14    2  463    3    1    1  408   77]]\n",
      "--------------------------------\n",
      "val predicted: (59670,) ['3' '0' '8' ... '8' '0' '9']\n",
      "probabilities: (59670, 10) \n",
      " [3 0 8 ... 8 0 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (330, 784) (330,)\n",
      "trainset after (340, 784) (340,)\n",
      "updated train set: (340, 784) (340,) unique(labels): [ 23  17  36  31  20 107  17  56  15  18] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59660, 784) (59660,)\n",
      "\n",
      "Train set: (340, 784) y: (340,)\n",
      "Val   set: (59660, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 34\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.182 s \n",
      "\n",
      "Accuracy rate for 46.580000 \n",
      "Classification report for classifier LogisticRegression(C=0.14705882352941177, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.92      0.77       980\n",
      "           1       0.74      0.90      0.81      1135\n",
      "           2       0.44      0.26      0.33      1032\n",
      "           3       0.78      0.19      0.30      1010\n",
      "           4       0.38      0.67      0.48       982\n",
      "           5       0.78      0.08      0.14       892\n",
      "           6       0.73      0.58      0.65       958\n",
      "           7       0.96      0.05      0.10      1028\n",
      "           8       0.26      0.91      0.40       974\n",
      "           9       0.17      0.05      0.08      1009\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.59      0.46      0.41     10000\n",
      "weighted avg       0.59      0.47      0.41     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 900    1    1    0    1    8    7    0   62    0]\n",
      " [   0 1019    1    2    0    0    3    0  110    0]\n",
      " [  76  141  271    4   28    1  143    1  363    4]\n",
      " [  81   19    6  190   14    4    8    1  680    7]\n",
      " [   8    9   48    0  658    1   12    0  240    6]\n",
      " [ 129   70    4   37   50   69   25    0  506    2]\n",
      " [  80   19   21    1  151    0  557    0  129    0]\n",
      " [  45   62  242    2  318    3    3   54   71  228]\n",
      " [   9   29    8    6   27    2    2    0  888    3]\n",
      " [  20   17   17    2  498    1    3    0  399   52]]\n",
      "--------------------------------\n",
      "val predicted: (59660,) ['3' '0' '8' ... '8' '2' '8']\n",
      "probabilities: (59660, 10) \n",
      " [3 0 8 ... 8 2 8]\n",
      "trainset before (340, 784) (340,)\n",
      "trainset after (350, 784) (350,)\n",
      "updated train set: (350, 784) (350,) unique(labels): [ 23  17  39  33  21 108  17  58  15  19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59650, 784) (59650,)\n",
      "\n",
      "Train set: (350, 784) y: (350,)\n",
      "Val   set: (59650, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 35\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.188 s \n",
      "\n",
      "Accuracy rate for 46.080000 \n",
      "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.80       980\n",
      "           1       0.76      0.76      0.76      1135\n",
      "           2       0.44      0.27      0.34      1032\n",
      "           3       0.74      0.21      0.33      1010\n",
      "           4       0.41      0.62      0.50       982\n",
      "           5       0.75      0.05      0.10       892\n",
      "           6       0.73      0.60      0.66       958\n",
      "           7       0.97      0.13      0.23      1028\n",
      "           8       0.24      0.94      0.38       974\n",
      "           9       0.19      0.07      0.10      1009\n",
      "\n",
      "    accuracy                           0.46     10000\n",
      "   macro avg       0.60      0.46      0.42     10000\n",
      "weighted avg       0.60      0.46      0.42     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[896   1   5   0   1   4  14   0  59   0]\n",
      " [  0 862   1   1   1   0   5   0 264   1]\n",
      " [ 53  78 283   2  18   0 121   1 473   3]\n",
      " [ 79  12   3 217  12   3  15   2 655  12]\n",
      " [  4   9  70   1 609   1   9   0 275   4]\n",
      " [108  55   6  54  47  48  41   1 520  12]\n",
      " [ 51  19  20   1  83   1 575   0 208   0]\n",
      " [ 32  67 225   4 239   5   4 131  65 256]\n",
      " [ 10  14   5   5  16   1   2   0 919   2]\n",
      " [ 15  15  25   8 443   1   3   0 431  68]]\n",
      "--------------------------------\n",
      "val predicted: (59650,) ['3' '0' '8' ... '8' '0' '8']\n",
      "probabilities: (59650, 10) \n",
      " [3 0 8 ... 8 0 8]\n",
      "trainset before (350, 784) (350,)\n",
      "trainset after (360, 784) (360,)\n",
      "updated train set: (360, 784) (360,) unique(labels): [ 24  17  41  36  21 111  17  58  16  19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59640, 784) (59640,)\n",
      "\n",
      "Train set: (360, 784) y: (360,)\n",
      "Val   set: (59640, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 36\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.216 s \n",
      "\n",
      "Accuracy rate for 43.190000 \n",
      "Classification report for classifier LogisticRegression(C=0.1388888888888889, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.95      0.78       980\n",
      "           1       0.73      0.84      0.78      1135\n",
      "           2       0.33      0.27      0.30      1032\n",
      "           3       0.85      0.20      0.32      1010\n",
      "           4       0.40      0.53      0.46       982\n",
      "           5       0.80      0.04      0.07       892\n",
      "           6       0.70      0.35      0.47       958\n",
      "           7       0.96      0.10      0.18      1028\n",
      "           8       0.23      0.94      0.36       974\n",
      "           9       0.22      0.04      0.07      1009\n",
      "\n",
      "    accuracy                           0.43     10000\n",
      "   macro avg       0.59      0.43      0.38     10000\n",
      "weighted avg       0.59      0.43      0.39     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[935   1   5   0   2   2   3   0  32   0]\n",
      " [  0 949   1   0   0   0   4   0 180   1]\n",
      " [ 60 105 281   7  12   0  85   1 480   1]\n",
      " [ 60  25  10 198  10   1   7   0 678  21]\n",
      " [ 11  12  75   0 523   0   6   0 353   2]\n",
      " [112  71   7  23  52  35  28   1 547  16]\n",
      " [143  25  18   0  73   0 334   0 365   0]\n",
      " [ 75  66 404   1 198   5   3 105  66 105]\n",
      " [ 10  25   9   2   6   0   3   0 918   1]\n",
      " [ 22  22  39   2 419   1   2   2 459  41]]\n",
      "--------------------------------\n",
      "val predicted: (59640,) ['0' '8' '1' ... '8' '2' '8']\n",
      "probabilities: (59640, 10) \n",
      " [0 8 1 ... 8 2 8]\n",
      "trainset before (360, 784) (360,)\n",
      "trainset after (370, 784) (370,)\n",
      "updated train set: (370, 784) (370,) unique(labels): [ 24  17  44  38  21 115  18  58  16  19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59630, 784) (59630,)\n",
      "\n",
      "Train set: (370, 784) y: (370,)\n",
      "Val   set: (59630, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 37\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.206 s \n",
      "\n",
      "Accuracy rate for 39.190000 \n",
      "Classification report for classifier LogisticRegression(C=0.13513513513513514, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.92      0.76       980\n",
      "           1       0.80      0.68      0.73      1135\n",
      "           2       0.27      0.08      0.13      1032\n",
      "           3       0.67      0.15      0.25      1010\n",
      "           4       0.40      0.59      0.48       982\n",
      "           5       0.49      0.04      0.07       892\n",
      "           6       0.64      0.16      0.26       958\n",
      "           7       0.95      0.25      0.40      1028\n",
      "           8       0.19      0.98      0.32       974\n",
      "           9       0.16      0.02      0.04      1009\n",
      "\n",
      "    accuracy                           0.39     10000\n",
      "   macro avg       0.52      0.39      0.34     10000\n",
      "weighted avg       0.53      0.39      0.35     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[906   1   1   0   0   7   1   0  64   0]\n",
      " [  0 770   1   0   1   0   4   0 359   0]\n",
      " [ 82  45  87  49  57   3  47   3 658   1]\n",
      " [ 52  11   3 155  12   1   6   2 751  17]\n",
      " [ 17   4  17   0 579   3   5   1 355   1]\n",
      " [ 81  40   2  26  30  35  16   3 646  13]\n",
      " [154  13   5   0 139   3 153   0 491   0]\n",
      " [ 79  64 197   0 188  15   7 258 125  95]\n",
      " [  9   3   1   0   8   1   0   0 951   1]\n",
      " [ 25  12  12   1 438   3   0   5 488  25]]\n",
      "--------------------------------\n",
      "val predicted: (59630,) ['0' '8' '8' ... '8' '5' '8']\n",
      "probabilities: (59630, 10) \n",
      " [0 8 8 ... 8 5 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (370, 784) (370,)\n",
      "trainset after (380, 784) (380,)\n",
      "updated train set: (380, 784) (380,) unique(labels): [ 24  17  48  39  22 115  20  59  17  19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59620, 784) (59620,)\n",
      "\n",
      "Train set: (380, 784) y: (380,)\n",
      "Val   set: (59620, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 38\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.191 s \n",
      "\n",
      "Accuracy rate for 48.080000 \n",
      "Classification report for classifier LogisticRegression(C=0.13157894736842105, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.90      0.79       980\n",
      "           1       0.68      0.89      0.77      1135\n",
      "           2       0.46      0.27      0.34      1032\n",
      "           3       0.82      0.13      0.22      1010\n",
      "           4       0.40      0.77      0.53       982\n",
      "           5       0.59      0.05      0.09       892\n",
      "           6       0.70      0.57      0.63       958\n",
      "           7       0.98      0.20      0.34      1028\n",
      "           8       0.27      0.90      0.41       974\n",
      "           9       0.29      0.07      0.11      1009\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.59      0.48      0.42     10000\n",
      "weighted avg       0.59      0.48      0.43     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 886    1    5    0    2   10   31    0   45    0]\n",
      " [   0 1010    3    0    0    0    3    0  119    0]\n",
      " [  36  132  283   14   19    1  104    0  437    6]\n",
      " [  80   43    5  129   23   13   36    2  659   20]\n",
      " [   8   26   28    0  761    2    7    0  137   13]\n",
      " [ 110  106    4   13   84   46   47    3  463   16]\n",
      " [  72   13   10    0  107    0  544    0  212    0]\n",
      " [  55   74  261    0  238    4    1  210   75  110]\n",
      " [   7   54    3    1   26    1    7    0  872    3]\n",
      " [  20   36   16    1  652    1    2    0  214   67]]\n",
      "--------------------------------\n",
      "val predicted: (59620,) ['0' '8' '1' ... '8' '2' '8']\n",
      "probabilities: (59620, 10) \n",
      " [0 8 1 ... 8 2 8]\n",
      "trainset before (380, 784) (380,)\n",
      "trainset after (390, 784) (390,)\n",
      "updated train set: (390, 784) (390,) unique(labels): [ 24  18  49  42  22 118  20  59  19  19] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59610, 784) (59610,)\n",
      "\n",
      "Train set: (390, 784) y: (390,)\n",
      "Val   set: (59610, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 39\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.198 s \n",
      "\n",
      "Accuracy rate for 49.540000 \n",
      "Classification report for classifier LogisticRegression(C=0.1282051282051282, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.93      0.77       980\n",
      "           1       0.62      0.82      0.71      1135\n",
      "           2       0.37      0.18      0.24      1032\n",
      "           3       0.81      0.40      0.54      1010\n",
      "           4       0.38      0.82      0.52       982\n",
      "           5       0.63      0.09      0.15       892\n",
      "           6       0.65      0.65      0.65       958\n",
      "           7       0.97      0.16      0.28      1028\n",
      "           8       0.31      0.79      0.45       974\n",
      "           9       0.31      0.08      0.13      1009\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.57      0.49      0.44     10000\n",
      "weighted avg       0.57      0.50      0.45     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[913   1   4   0   2   5  46   0   9   0]\n",
      " [  0 930   0   0   0   0   5   0 200   0]\n",
      " [ 61 116 184  14  27   1 144   1 481   3]\n",
      " [ 82  76  10 407  44  14  39   1 283  54]\n",
      " [ 12  23  27   0 805   5  23   1  74  12]\n",
      " [125 138   5  62  97  76  45   1 313  30]\n",
      " [ 64  14   4   0  87   2 619   1 167   0]\n",
      " [ 95  77 241   0 287  10   2 167  79  70]\n",
      " [ 15  74   9  15  45   1  31   0 771  13]\n",
      " [ 27  54  16   3 724   6   3   0  94  82]]\n",
      "--------------------------------\n",
      "val predicted: (59610,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59610, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (390, 784) (390,)\n",
      "trainset after (400, 784) (400,)\n",
      "updated train set: (400, 784) (400,) unique(labels): [ 24  18  53  42  22 121  20  60  19  21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59600, 784) (59600,)\n",
      "\n",
      "Train set: (400, 784) y: (400,)\n",
      "Val   set: (59600, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 40\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.196 s \n",
      "\n",
      "Accuracy rate for 47.940000 \n",
      "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.93      0.79       980\n",
      "           1       0.66      0.83      0.73      1135\n",
      "           2       0.42      0.12      0.19      1032\n",
      "           3       0.85      0.30      0.44      1010\n",
      "           4       0.42      0.75      0.54       982\n",
      "           5       0.62      0.10      0.17       892\n",
      "           6       0.69      0.59      0.63       958\n",
      "           7       0.87      0.14      0.24      1028\n",
      "           8       0.27      0.86      0.41       974\n",
      "           9       0.27      0.16      0.20      1009\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.57      0.48      0.43     10000\n",
      "weighted avg       0.58      0.48      0.44     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[908   1   2   0   1   8  14   0  46   0]\n",
      " [  0 943   0   0   1   0   4   1 186   0]\n",
      " [ 58  86 123   0  21   4 102   4 630   4]\n",
      " [111  79   2 298  34  32  50   6 368  30]\n",
      " [  3  19  14   0 739   4  10   1 168  24]\n",
      " [134 116   6  45  70  89  42   3 368  19]\n",
      " [ 56  13   7   0  74   1 561   0 244   2]\n",
      " [ 36  69 119   1 222   1   1 141  94 344]\n",
      " [ 11  65   7   6  20   1  25   0 833   6]\n",
      " [ 16  46  13   1 589   3   0   7 175 159]]\n",
      "--------------------------------\n",
      "val predicted: (59600,) ['0' '4' '1' ... '5' '0' '8']\n",
      "probabilities: (59600, 10) \n",
      " [0 4 1 ... 5 0 8]\n",
      "trainset before (400, 784) (400,)\n",
      "trainset after (410, 784) (410,)\n",
      "updated train set: (410, 784) (410,) unique(labels): [ 24  18  55  46  23 124  20  60  19  21] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59590, 784) (59590,)\n",
      "\n",
      "Train set: (410, 784) y: (410,)\n",
      "Val   set: (59590, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 41\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.207 s \n",
      "\n",
      "Accuracy rate for 48.170000 \n",
      "Classification report for classifier LogisticRegression(C=0.12195121951219512, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.96      0.77       980\n",
      "           1       0.65      0.87      0.74      1135\n",
      "           2       0.36      0.10      0.15      1032\n",
      "           3       0.75      0.49      0.60      1010\n",
      "           4       0.46      0.70      0.56       982\n",
      "           5       0.62      0.08      0.14       892\n",
      "           6       0.69      0.47      0.56       958\n",
      "           7       0.84      0.06      0.12      1028\n",
      "           8       0.28      0.85      0.42       974\n",
      "           9       0.26      0.19      0.22      1009\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.55      0.48      0.43     10000\n",
      "weighted avg       0.56      0.48      0.43     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[939   1   1   0   1   5  10   0  20   3]\n",
      " [  0 984   0   1   0   0   5   0 145   0]\n",
      " [ 71 108  99  27  10   3  84   1 617  12]\n",
      " [102  72   2 499  14  20  41   1 226  33]\n",
      " [ 13  26  13   0 687   8   6   1 199  29]\n",
      " [143 114   4 102  65  72  43   3 320  26]\n",
      " [ 94  17   9   1  70   2 448   0 315   2]\n",
      " [ 73  79 137   0 133   3   2  65  85 451]\n",
      " [ 15  66   6  26  15   0   9   0 828   9]\n",
      " [ 24  52   7   5 494   4   1   6 220 196]]\n",
      "--------------------------------\n",
      "val predicted: (59590,) ['0' '9' '1' ... '9' '0' '8']\n",
      "probabilities: (59590, 10) \n",
      " [0 9 1 ... 9 0 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (410, 784) (410,)\n",
      "trainset after (420, 784) (420,)\n",
      "updated train set: (420, 784) (420,) unique(labels): [ 24  18  59  46  24 127  20  60  19  23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59580, 784) (59580,)\n",
      "\n",
      "Train set: (420, 784) y: (420,)\n",
      "Val   set: (59580, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 42\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.217 s \n",
      "\n",
      "Accuracy rate for 47.710000 \n",
      "Classification report for classifier LogisticRegression(C=0.11904761904761904, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.94      0.75       980\n",
      "           1       0.73      0.81      0.77      1135\n",
      "           2       0.37      0.15      0.22      1032\n",
      "           3       0.77      0.42      0.55      1010\n",
      "           4       0.56      0.52      0.54       982\n",
      "           5       0.66      0.06      0.11       892\n",
      "           6       0.67      0.59      0.63       958\n",
      "           7       0.82      0.07      0.14      1028\n",
      "           8       0.25      0.87      0.39       974\n",
      "           9       0.30      0.29      0.30      1009\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.57      0.47      0.44     10000\n",
      "weighted avg       0.58      0.48      0.44     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[924   1   4   0   0   2  22   0  26   1]\n",
      " [  0 921   2   1   1   1   6   1 202   0]\n",
      " [ 53  56 157  11   4   1 106   1 636   7]\n",
      " [103  55  16 427   6  15  54   2 278  54]\n",
      " [ 21  14  35   1 507   4  11   2 334  53]\n",
      " [145  88  11  92  31  54  63   2 385  21]\n",
      " [ 87   5  17   0  19   1 565   0 264   0]\n",
      " [108  43 136   0  38   2   1  76  94 530]\n",
      " [ 15  44  19  14   4   0  18   0 848  12]\n",
      " [ 37  30  31   7 298   2   0   9 303 292]]\n",
      "--------------------------------\n",
      "val predicted: (59580,) ['0' '9' '1' ... '5' '0' '8']\n",
      "probabilities: (59580, 10) \n",
      " [0 9 1 ... 5 0 8]\n",
      "trainset before (420, 784) (420,)\n",
      "trainset after (430, 784) (430,)\n",
      "updated train set: (430, 784) (430,) unique(labels): [ 25  18  59  47  24 134  20  60  20  23] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59570, 784) (59570,)\n",
      "\n",
      "Train set: (430, 784) y: (430,)\n",
      "Val   set: (59570, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 43\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.223 s \n",
      "\n",
      "Accuracy rate for 48.660000 \n",
      "Classification report for classifier LogisticRegression(C=0.11627906976744186, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.92      0.74       980\n",
      "           1       0.65      0.85      0.74      1135\n",
      "           2       0.44      0.11      0.17      1032\n",
      "           3       0.78      0.44      0.56      1010\n",
      "           4       0.49      0.75      0.59       982\n",
      "           5       0.79      0.09      0.16       892\n",
      "           6       0.66      0.58      0.62       958\n",
      "           7       0.90      0.08      0.15      1028\n",
      "           8       0.27      0.84      0.41       974\n",
      "           9       0.24      0.18      0.20      1009\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.59      0.48      0.43     10000\n",
      "weighted avg       0.58      0.49      0.44     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[906   1   4   0   0   3  29   0  37   0]\n",
      " [  0 966   0   0   1   0   5   0 163   0]\n",
      " [ 56  80 112  16  10   1  94   1 657   5]\n",
      " [140  68   3 441  11  12  59   0 247  29]\n",
      " [ 10  24  16   0 738   1   8   0 163  22]\n",
      " [180 118   6  80  55  77  66   2 287  21]\n",
      " [ 64  14   7   0  55   1 552   0 265   0]\n",
      " [ 64  86  77   0 159   0   3  83  93 463]\n",
      " [ 20  64   8  24  13   1  17   0 814  13]\n",
      " [ 33  56  22   6 458   1   2   6 248 177]]\n",
      "--------------------------------\n",
      "val predicted: (59570,) ['0' '4' '1' ... '5' '6' '8']\n",
      "probabilities: (59570, 10) \n",
      " [0 4 1 ... 5 6 8]\n",
      "trainset before (430, 784) (430,)\n",
      "trainset after (440, 784) (440,)\n",
      "updated train set: (440, 784) (440,) unique(labels): [ 26  18  60  49  26 136  20  60  20  25] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59560, 784) (59560,)\n",
      "\n",
      "Train set: (440, 784) y: (440,)\n",
      "Val   set: (59560, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 44\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.221 s \n",
      "\n",
      "Accuracy rate for 46.870000 \n",
      "Classification report for classifier LogisticRegression(C=0.11363636363636363, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.93      0.76       980\n",
      "           1       0.67      0.83      0.74      1135\n",
      "           2       0.32      0.12      0.18      1032\n",
      "           3       0.74      0.47      0.58      1010\n",
      "           4       0.38      0.47      0.42       982\n",
      "           5       0.85      0.06      0.12       892\n",
      "           6       0.63      0.56      0.59       958\n",
      "           7       0.80      0.26      0.40      1028\n",
      "           8       0.24      0.87      0.38       974\n",
      "           9       0.36      0.06      0.10      1009\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.56      0.46      0.43     10000\n",
      "weighted avg       0.56      0.47      0.43     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[912   1   4   0   1   2  33   0  27   0]\n",
      " [  0 946   1   0   0   0   5   1 182   0]\n",
      " [ 57  81 129  15   3   0  99  10 638   0]\n",
      " [ 81  73  11 479  19   4  52  30 254   7]\n",
      " [ 44  14  36   3 457   1  23   1 399   4]\n",
      " [102 137   3 129  51  57  78  16 308  11]\n",
      " [ 84  14  11   0  11   0 535   0 303   0]\n",
      " [ 84  58 179   0 239   1   3 270 114  80]\n",
      " [ 15  52   7  12  21   0  21   2 843   1]\n",
      " [ 44  37  22   9 398   2   4   6 428  59]]\n",
      "--------------------------------\n",
      "val predicted: (59560,) ['0' '4' '1' ... '4' '0' '8']\n",
      "probabilities: (59560, 10) \n",
      " [0 4 1 ... 4 0 8]\n",
      "trainset before (440, 784) (440,)\n",
      "trainset after (450, 784) (450,)\n",
      "updated train set: (450, 784) (450,) unique(labels): [ 26  18  61  49  27 142  20  60  20  27] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59550, 784) (59550,)\n",
      "\n",
      "Train set: (450, 784) y: (450,)\n",
      "Val   set: (59550, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 45\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.245 s \n",
      "\n",
      "Accuracy rate for 47.200000 \n",
      "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.92      0.74       980\n",
      "           1       0.67      0.81      0.73      1135\n",
      "           2       0.70      0.07      0.13      1032\n",
      "           3       0.74      0.54      0.63      1010\n",
      "           4       0.39      0.66      0.49       982\n",
      "           5       0.91      0.08      0.15       892\n",
      "           6       0.63      0.56      0.59       958\n",
      "           7       0.66      0.03      0.06      1028\n",
      "           8       0.27      0.83      0.41       974\n",
      "           9       0.24      0.17      0.20      1009\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.58      0.47      0.41     10000\n",
      "weighted avg       0.58      0.47      0.42     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[904   1   0   1   2   2  36   0  32   2]\n",
      " [  0 924   0   0   1   0   6   0 204   0]\n",
      " [ 51  75  76  16  12   0 105   5 675  17]\n",
      " [103  65   2 550  23   3  55   6 184  19]\n",
      " [ 25  16   9   5 646   0   6   0 239  36]\n",
      " [145 122   0 126  90  73  83   1 223  29]\n",
      " [ 91  11   4   0  36   1 537   0 276   2]\n",
      " [ 84  73  10   4 273   0   2  31 110 441]\n",
      " [ 21  57   4  29  27   0  19   0 805  12]\n",
      " [ 39  37   3  12 532   1   2   4 205 174]]\n",
      "--------------------------------\n",
      "val predicted: (59550,) ['0' '9' '1' ... '9' '0' '8']\n",
      "probabilities: (59550, 10) \n",
      " [0 9 1 ... 9 0 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (450, 784) (450,)\n",
      "trainset after (460, 784) (460,)\n",
      "updated train set: (460, 784) (460,) unique(labels): [ 26  18  63  52  28 146  20  60  20  27] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59540, 784) (59540,)\n",
      "\n",
      "Train set: (460, 784) y: (460,)\n",
      "Val   set: (59540, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 46\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.229 s \n",
      "\n",
      "Accuracy rate for 49.710000 \n",
      "Classification report for classifier LogisticRegression(C=0.10869565217391304, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.88      0.73       980\n",
      "           1       0.66      0.83      0.73      1135\n",
      "           2       0.45      0.11      0.18      1032\n",
      "           3       0.81      0.50      0.61      1010\n",
      "           4       0.54      0.68      0.60       982\n",
      "           5       0.79      0.10      0.18       892\n",
      "           6       0.61      0.57      0.59       958\n",
      "           7       0.91      0.17      0.29      1028\n",
      "           8       0.26      0.85      0.40       974\n",
      "           9       0.34      0.25      0.29      1009\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.60      0.49      0.46     10000\n",
      "weighted avg       0.60      0.50      0.46     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[860   1   4   0   1   5  60   0  49   0]\n",
      " [  0 947   0   0   1   0   5   0 182   0]\n",
      " [ 33  75 112  16  10   1 101   2 676   6]\n",
      " [100  63   5 500   6  13  70   8 214  31]\n",
      " [ 23  27  12   1 665   1   5   0 214  34]\n",
      " [138 129   6  80  47  88  85   4 270  45]\n",
      " [ 86  12   5   0  45   0 543   0 266   1]\n",
      " [ 80  78  86   0 148   0   2 176 103 355]\n",
      " [ 17  57   6  17  15   2  20   0 825  15]\n",
      " [ 51  53  11   6 297   1   2   4 329 255]]\n",
      "--------------------------------\n",
      "val predicted: (59540,) ['0' '4' '1' ... '5' '0' '8']\n",
      "probabilities: (59540, 10) \n",
      " [0 4 1 ... 5 0 8]\n",
      "trainset before (460, 784) (460,)\n",
      "trainset after (470, 784) (470,)\n",
      "updated train set: (470, 784) (470,) unique(labels): [ 26  19  65  52  28 151  22  60  20  27] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59530, 784) (59530,)\n",
      "\n",
      "Train set: (470, 784) y: (470,)\n",
      "Val   set: (59530, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 47\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.244 s \n",
      "\n",
      "Accuracy rate for 48.570000 \n",
      "Classification report for classifier LogisticRegression(C=0.10638297872340426, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75       980\n",
      "           1       0.75      0.71      0.73      1135\n",
      "           2       0.51      0.04      0.08      1032\n",
      "           3       0.71      0.53      0.61      1010\n",
      "           4       0.46      0.71      0.56       982\n",
      "           5       0.76      0.10      0.18       892\n",
      "           6       0.60      0.60      0.60       958\n",
      "           7       0.87      0.23      0.36      1028\n",
      "           8       0.26      0.88      0.40       974\n",
      "           9       0.27      0.15      0.19      1009\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.58      0.48      0.45     10000\n",
      "weighted avg       0.58      0.49      0.45     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[871   1   3   1   0   4  50   0  50   0]\n",
      " [  0 807   0   6   1   1   6   0 314   0]\n",
      " [ 29  30  42  55  16   1 146   4 702   7]\n",
      " [ 71  38   4 535   5  14  62  12 256  13]\n",
      " [ 31  11   8   6 695   4   7   0 195  25]\n",
      " [110  84   1 103  62  91  92   9 322  18]\n",
      " [ 76   5   2   0  43   0 575   0 257   0]\n",
      " [ 80  49  17   6 190   1   5 237 115 328]\n",
      " [ 13  20   5  35  19   2  15   0 857   8]\n",
      " [ 56  27   1  10 486   1   3  11 267 147]]\n",
      "--------------------------------\n",
      "val predicted: (59530,) ['0' '9' '8' ... '5' '6' '8']\n",
      "probabilities: (59530, 10) \n",
      " [0 9 8 ... 5 6 8]\n",
      "trainset before (470, 784) (470,)\n",
      "trainset after (480, 784) (480,)\n",
      "updated train set: (480, 784) (480,) unique(labels): [ 26  19  66  52  29 156  23  60  21  28] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59520, 784) (59520,)\n",
      "\n",
      "Train set: (480, 784) y: (480,)\n",
      "Val   set: (59520, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 48\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.251 s \n",
      "\n",
      "Accuracy rate for 44.200000 \n",
      "Classification report for classifier LogisticRegression(C=0.10416666666666667, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.85      0.69       980\n",
      "           1       0.76      0.56      0.65      1135\n",
      "           2       0.46      0.03      0.06      1032\n",
      "           3       0.78      0.47      0.58      1010\n",
      "           4       0.46      0.67      0.55       982\n",
      "           5       0.84      0.11      0.19       892\n",
      "           6       0.52      0.46      0.49       958\n",
      "           7       0.83      0.05      0.09      1028\n",
      "           8       0.25      0.89      0.39       974\n",
      "           9       0.29      0.32      0.31      1009\n",
      "\n",
      "    accuracy                           0.44     10000\n",
      "   macro avg       0.58      0.44      0.40     10000\n",
      "weighted avg       0.58      0.44      0.40     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[836   1   1   0   0   9  79   0  50   4]\n",
      " [  0 640   0   3   1   0   7   0 483   1]\n",
      " [ 33  20  35  16  15   1 142   0 753  17]\n",
      " [ 91  29   2 470  18   3  78   3 261  55]\n",
      " [ 42   3   1   0 658   2   3   1 177  95]\n",
      " [148  71   3  84  57  95  88   3 291  52]\n",
      " [142   1   0   1  31   1 441   0 338   3]\n",
      " [ 79  50  31   1 169   0   3  50 110 535]\n",
      " [ 23  10   2  21  17   0   8   0 871  22]\n",
      " [ 52  20   1   6 466   2   1   3 134 324]]\n",
      "--------------------------------\n",
      "val predicted: (59520,) ['0' '9' '8' ... '4' '6' '8']\n",
      "probabilities: (59520, 10) \n",
      " [0 9 8 ... 4 6 8]\n",
      "trainset before (480, 784) (480,)\n",
      "trainset after (490, 784) (490,)\n",
      "updated train set: (490, 784) (490,) unique(labels): [ 26  19  69  55  29 158  24  61  21  28] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59510, 784) (59510,)\n",
      "\n",
      "Train set: (490, 784) y: (490,)\n",
      "Val   set: (59510, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 49\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.231 s \n",
      "\n",
      "Accuracy rate for 47.070000 \n",
      "Classification report for classifier LogisticRegression(C=0.10204081632653061, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       980\n",
      "           1       0.72      0.58      0.64      1135\n",
      "           2       0.46      0.05      0.09      1032\n",
      "           3       0.76      0.54      0.63      1010\n",
      "           4       0.52      0.65      0.58       982\n",
      "           5       0.79      0.19      0.30       892\n",
      "           6       0.54      0.46      0.50       958\n",
      "           7       0.92      0.09      0.17      1028\n",
      "           8       0.26      0.87      0.39       974\n",
      "           9       0.34      0.38      0.36      1009\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.59      0.47      0.44     10000\n",
      "weighted avg       0.59      0.47      0.44     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[881   1   2   0   0  10  47   0  36   3]\n",
      " [  0 662   0   2   1   0   5   0 464   1]\n",
      " [ 43  20  53  20   6   2 120   1 748  19]\n",
      " [ 90  39   2 541   4  11  78   2 183  60]\n",
      " [ 35   9  15   9 643  15   4   0 186  66]\n",
      " [129  64   3  92  54 168  99   2 230  51]\n",
      " [126   5   5   0  34   2 437   0 347   2]\n",
      " [ 83  68  22   3 101   0   2  94 126 529]\n",
      " [ 23  17  12  26  14   2  12   0 844  24]\n",
      " [ 49  35   2  15 371   3   3   3 144 384]]\n",
      "--------------------------------\n",
      "val predicted: (59510,) ['0' '9' '8' ... '5' '6' '8']\n",
      "probabilities: (59510, 10) \n",
      " [0 9 8 ... 5 6 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset before (490, 784) (490,)\n",
      "trainset after (500, 784) (500,)\n",
      "updated train set: (500, 784) (500,) unique(labels): [ 26  19  69  55  29 165  24  61  23  29] [0 1 2 3 4 5 6 7 8 9]\n",
      "val set: (59500, 784) (59500,)\n",
      "\n",
      "Train set: (500, 784) y: (500,)\n",
      "Val   set: (59500, 784)\n",
      "Test  set: (10000, 784)\n",
      "training multinomial logistic regression\n",
      "--------------------------------\n",
      "Iteration: 50\n",
      "--------------------------------\n",
      "y-test set: (10000,)\n",
      "Example run in 0.261 s \n",
      "\n",
      "Accuracy rate for 42.420000 \n",
      "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
      "                   verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.92      0.71       980\n",
      "           1       0.75      0.62      0.68      1135\n",
      "           2       0.49      0.05      0.10      1032\n",
      "           3       0.74      0.45      0.56      1010\n",
      "           4       0.39      0.70      0.50       982\n",
      "           5       0.90      0.04      0.08       892\n",
      "           6       0.47      0.33      0.39       958\n",
      "           7       0.82      0.09      0.16      1028\n",
      "           8       0.24      0.90      0.38       974\n",
      "           9       0.26      0.13      0.17      1009\n",
      "\n",
      "    accuracy                           0.42     10000\n",
      "   macro avg       0.56      0.42      0.37     10000\n",
      "weighted avg       0.56      0.42      0.38     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[898   1   4   0   0   2  48   0  27   0]\n",
      " [  0 700   0   2   1   0   5   0 427   0]\n",
      " [ 47  28  55  20  17   1 121   3 733   7]\n",
      " [ 85  41   3 456  25   0  82   4 299  15]\n",
      " [ 56   4  12   5 685   0   4   1 188  27]\n",
      " [127  54   3 111  55  35  76   9 393  29]\n",
      " [164   5   2   1  28   0 315   0 443   0]\n",
      " [ 97  72  14   1 338   0   5  92 107 302]\n",
      " [ 22  13  10  15  24   0   9   0 872   9]\n",
      " [ 67  21   9   9 602   1   3   3 160 134]]\n",
      "--------------------------------\n",
      "final active learning accuracies [34.14, 41.870000000000005, 52.25, 48.089999999999996, 52.339999999999996, 48.43, 51.11, 53.31, 50.57000000000001, 52.019999999999996, 53.0, 49.27, 50.029999999999994, 49.57, 48.559999999999995, 51.51, 52.71, 53.910000000000004, 54.64, 55.14, 51.25999999999999, 51.01, 50.7, 53.669999999999995, 49.84, 48.25, 47.699999999999996, 47.58, 45.69, 48.0, 46.36, 44.57, 44.03, 46.58, 46.08, 43.19, 39.190000000000005, 48.08, 49.54, 47.94, 48.17, 47.71, 48.66, 46.87, 47.199999999999996, 49.71, 48.57, 44.2, 47.07, 42.42]\n",
      "saved Active-learning-experiment-45.pkl /home/ruslan/Desktop/DoEdu/thirdparty/ActiveLearningFrameworkTutorial ['Active-learning-experiment-7.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-42.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-37.pkl', 'README.md', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-45.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-43.pkl', 'Active_Learning_Tutorial.ipynb', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-17.pkl', '.ipynb_checkpoints', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-28.pkl', 'LICENSE', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-44.pkl', 'Active-learning-experiment-38.pkl', '.git', 'Active-learning-experiment-30.pkl']\n",
      "{\n",
      "  \"LogModel\": {\n",
      "    \"EntropySelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          34.14,\n",
      "          41.870000000000005,\n",
      "          52.25,\n",
      "          48.089999999999996,\n",
      "          52.339999999999996,\n",
      "          48.43,\n",
      "          51.11,\n",
      "          53.31,\n",
      "          50.57000000000001,\n",
      "          52.019999999999996,\n",
      "          53.0,\n",
      "          49.27,\n",
      "          50.029999999999994,\n",
      "          49.57,\n",
      "          48.559999999999995,\n",
      "          51.51,\n",
      "          52.71,\n",
      "          53.910000000000004,\n",
      "          54.64,\n",
      "          55.14,\n",
      "          51.25999999999999,\n",
      "          51.01,\n",
      "          50.7,\n",
      "          53.669999999999995,\n",
      "          49.84,\n",
      "          48.25,\n",
      "          47.699999999999996,\n",
      "          47.58,\n",
      "          45.69,\n",
      "          48.0,\n",
      "          46.36,\n",
      "          44.57,\n",
      "          44.03,\n",
      "          46.58,\n",
      "          46.08,\n",
      "          43.19,\n",
      "          39.190000000000005,\n",
      "          48.08,\n",
      "          49.54,\n",
      "          47.94,\n",
      "          48.17,\n",
      "          47.71,\n",
      "          48.66,\n",
      "          46.87,\n",
      "          47.199999999999996,\n",
      "          49.71,\n",
      "          48.57,\n",
      "          44.2,\n",
      "          47.07,\n",
      "          42.42\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          70.86,\n",
      "          61.029999999999994,\n",
      "          58.93000000000001,\n",
      "          58.8\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          41.870000000000005,\n",
      "          48.92,\n",
      "          52.470000000000006,\n",
      "          51.81,\n",
      "          52.89,\n",
      "          57.3,\n",
      "          56.13,\n",
      "          53.49,\n",
      "          54.54,\n",
      "          50.22,\n",
      "          52.300000000000004,\n",
      "          57.620000000000005,\n",
      "          56.19,\n",
      "          58.099999999999994,\n",
      "          52.949999999999996,\n",
      "          53.16,\n",
      "          54.620000000000005,\n",
      "          56.49999999999999,\n",
      "          59.099999999999994,\n",
      "          57.550000000000004\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          73.34,\n",
      "          66.69\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          60.809999999999995,\n",
      "          61.45,\n",
      "          56.71000000000001,\n",
      "          58.86,\n",
      "          55.7,\n",
      "          53.18000000000001,\n",
      "          53.2,\n",
      "          53.339999999999996,\n",
      "          55.84,\n",
      "          57.099999999999994\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          37.5,\n",
      "          45.540000000000006,\n",
      "          50.17,\n",
      "          58.17,\n",
      "          62.4,\n",
      "          64.95,\n",
      "          67.80000000000001,\n",
      "          68.77,\n",
      "          69.85,\n",
      "          70.78999999999999,\n",
      "          72.05,\n",
      "          70.41,\n",
      "          67.30000000000001,\n",
      "          72.04,\n",
      "          71.22,\n",
      "          71.87,\n",
      "          69.64,\n",
      "          71.57,\n",
      "          71.78999999999999,\n",
      "          72.66,\n",
      "          72.86,\n",
      "          73.13,\n",
      "          71.53,\n",
      "          72.17,\n",
      "          71.78999999999999,\n",
      "          71.74000000000001,\n",
      "          70.55,\n",
      "          72.33000000000001,\n",
      "          70.54,\n",
      "          70.61,\n",
      "          71.73,\n",
      "          72.49,\n",
      "          73.0,\n",
      "          71.63000000000001,\n",
      "          73.17,\n",
      "          71.58,\n",
      "          72.5,\n",
      "          72.71,\n",
      "          72.05,\n",
      "          72.3,\n",
      "          72.05,\n",
      "          71.5,\n",
      "          70.67999999999999,\n",
      "          66.36999999999999,\n",
      "          71.6,\n",
      "          72.77,\n",
      "          72.38,\n",
      "          73.04,\n",
      "          71.84,\n",
      "          69.45\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          73.47,\n",
      "          71.32,\n",
      "          72.05,\n",
      "          73.02\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          51.800000000000004,\n",
      "          63.71,\n",
      "          68.58,\n",
      "          68.17999999999999,\n",
      "          70.16,\n",
      "          70.69,\n",
      "          72.17,\n",
      "          74.33999999999999,\n",
      "          73.95,\n",
      "          71.13000000000001,\n",
      "          74.02,\n",
      "          72.89999999999999,\n",
      "          73.75,\n",
      "          72.55,\n",
      "          72.25,\n",
      "          72.7,\n",
      "          71.47,\n",
      "          70.38,\n",
      "          69.8,\n",
      "          70.06\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          70.02000000000001,\n",
      "          73.28\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          63.56,\n",
      "          68.58999999999999,\n",
      "          67.97999999999999,\n",
      "          70.62,\n",
      "          72.67,\n",
      "          74.61,\n",
      "          73.74000000000001,\n",
      "          74.56,\n",
      "          73.1,\n",
      "          75.06\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          37.63,\n",
      "          50.61,\n",
      "          57.879999999999995,\n",
      "          60.150000000000006,\n",
      "          67.54,\n",
      "          65.03,\n",
      "          65.52,\n",
      "          69.19999999999999,\n",
      "          68.75,\n",
      "          67.02,\n",
      "          67.78999999999999,\n",
      "          68.7,\n",
      "          69.16,\n",
      "          70.19999999999999,\n",
      "          70.43,\n",
      "          69.94,\n",
      "          69.69999999999999,\n",
      "          69.97,\n",
      "          70.09,\n",
      "          70.95,\n",
      "          71.43,\n",
      "          72.78999999999999,\n",
      "          72.33000000000001,\n",
      "          72.78,\n",
      "          72.63,\n",
      "          72.95,\n",
      "          73.83,\n",
      "          74.38,\n",
      "          72.78999999999999,\n",
      "          73.22999999999999,\n",
      "          73.49,\n",
      "          73.54,\n",
      "          73.63,\n",
      "          73.41,\n",
      "          73.61,\n",
      "          72.86,\n",
      "          73.75,\n",
      "          74.0,\n",
      "          74.02,\n",
      "          74.76,\n",
      "          74.72,\n",
      "          74.53,\n",
      "          74.64,\n",
      "          73.82,\n",
      "          74.35000000000001,\n",
      "          75.67,\n",
      "          74.16,\n",
      "          75.7,\n",
      "          75.18,\n",
      "          74.3\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          72.86,\n",
      "          72.11999999999999,\n",
      "          70.67999999999999,\n",
      "          71.37\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          54.279999999999994,\n",
      "          58.24,\n",
      "          61.839999999999996,\n",
      "          68.43,\n",
      "          68.44,\n",
      "          71.43,\n",
      "          74.02,\n",
      "          73.87,\n",
      "          73.4,\n",
      "          74.36,\n",
      "          75.39,\n",
      "          74.62,\n",
      "          74.85000000000001,\n",
      "          75.22999999999999,\n",
      "          73.8,\n",
      "          74.85000000000001,\n",
      "          75.14999999999999,\n",
      "          74.63,\n",
      "          74.16,\n",
      "          73.91\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          74.59,\n",
      "          75.29\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          61.739999999999995,\n",
      "          69.95,\n",
      "          75.09,\n",
      "          73.91,\n",
      "          74.17,\n",
      "          74.21,\n",
      "          74.19,\n",
      "          73.74000000000001,\n",
      "          73.92,\n",
      "          74.62\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"RfModel\": {\n",
      "    \"EntropySelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          22.34,\n",
      "          27.01,\n",
      "          32.07,\n",
      "          35.160000000000004,\n",
      "          47.72,\n",
      "          47.97,\n",
      "          52.400000000000006,\n",
      "          51.09,\n",
      "          54.459999999999994,\n",
      "          57.92,\n",
      "          57.489999999999995,\n",
      "          57.269999999999996,\n",
      "          56.65,\n",
      "          56.42,\n",
      "          56.47,\n",
      "          54.620000000000005,\n",
      "          55.11000000000001,\n",
      "          55.05,\n",
      "          55.13,\n",
      "          55.45,\n",
      "          53.769999999999996,\n",
      "          53.33,\n",
      "          53.690000000000005,\n",
      "          53.76,\n",
      "          54.55,\n",
      "          54.96,\n",
      "          55.120000000000005,\n",
      "          53.83,\n",
      "          55.1,\n",
      "          54.71,\n",
      "          55.510000000000005,\n",
      "          56.39999999999999,\n",
      "          55.379999999999995,\n",
      "          56.92,\n",
      "          55.85,\n",
      "          56.699999999999996,\n",
      "          56.21000000000001,\n",
      "          56.379999999999995,\n",
      "          57.31,\n",
      "          56.120000000000005,\n",
      "          56.44,\n",
      "          57.31,\n",
      "          58.47,\n",
      "          55.82,\n",
      "          57.37,\n",
      "          58.60999999999999,\n",
      "          58.85,\n",
      "          57.86,\n",
      "          57.36,\n",
      "          58.18\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          73.8,\n",
      "          73.65,\n",
      "          74.14,\n",
      "          74.59\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          49.919999999999995,\n",
      "          57.489999999999995,\n",
      "          63.129999999999995,\n",
      "          65.53,\n",
      "          69.39999999999999,\n",
      "          69.73,\n",
      "          69.32000000000001,\n",
      "          66.67999999999999,\n",
      "          67.25,\n",
      "          66.97999999999999,\n",
      "          66.36999999999999,\n",
      "          68.22,\n",
      "          66.18,\n",
      "          67.42,\n",
      "          67.67999999999999,\n",
      "          67.64,\n",
      "          70.99,\n",
      "          70.59,\n",
      "          70.81,\n",
      "          72.48\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          82.87,\n",
      "          81.83\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          58.25,\n",
      "          65.07,\n",
      "          65.14,\n",
      "          65.88000000000001,\n",
      "          64.94,\n",
      "          65.42999999999999,\n",
      "          66.64,\n",
      "          69.8,\n",
      "          69.13,\n",
      "          69.86\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          26.56,\n",
      "          45.550000000000004,\n",
      "          56.82000000000001,\n",
      "          67.99,\n",
      "          67.67999999999999,\n",
      "          71.17,\n",
      "          76.08,\n",
      "          78.13,\n",
      "          79.38,\n",
      "          79.69000000000001,\n",
      "          81.76,\n",
      "          82.43,\n",
      "          83.47,\n",
      "          84.99,\n",
      "          85.18,\n",
      "          86.0,\n",
      "          84.94,\n",
      "          86.07000000000001,\n",
      "          86.98,\n",
      "          86.56,\n",
      "          88.03,\n",
      "          87.92999999999999,\n",
      "          88.53,\n",
      "          89.2,\n",
      "          89.2,\n",
      "          89.71000000000001,\n",
      "          90.12,\n",
      "          90.57,\n",
      "          90.24,\n",
      "          90.49000000000001,\n",
      "          90.61,\n",
      "          91.09,\n",
      "          91.3,\n",
      "          91.07,\n",
      "          90.93,\n",
      "          91.17,\n",
      "          90.96,\n",
      "          91.38,\n",
      "          90.84,\n",
      "          91.72,\n",
      "          91.47,\n",
      "          91.56,\n",
      "          92.01,\n",
      "          91.94,\n",
      "          92.43,\n",
      "          92.43,\n",
      "          92.58999999999999,\n",
      "          92.56,\n",
      "          92.97999999999999,\n",
      "          92.80000000000001\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          73.39,\n",
      "          86.38,\n",
      "          90.11,\n",
      "          91.31\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          53.339999999999996,\n",
      "          63.85999999999999,\n",
      "          70.77,\n",
      "          75.53999999999999,\n",
      "          79.22,\n",
      "          83.19,\n",
      "          83.17999999999999,\n",
      "          84.82,\n",
      "          86.21,\n",
      "          86.72999999999999,\n",
      "          88.18,\n",
      "          89.2,\n",
      "          88.47,\n",
      "          89.64999999999999,\n",
      "          90.2,\n",
      "          90.68,\n",
      "          91.56,\n",
      "          91.64,\n",
      "          92.10000000000001,\n",
      "          92.30000000000001\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          80.64,\n",
      "          89.2\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          57.74,\n",
      "          75.92,\n",
      "          80.57,\n",
      "          86.13,\n",
      "          88.26,\n",
      "          88.62,\n",
      "          89.88000000000001,\n",
      "          90.93,\n",
      "          91.02,\n",
      "          92.17\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          28.470000000000002,\n",
      "          35.38,\n",
      "          44.85,\n",
      "          50.71,\n",
      "          58.48,\n",
      "          61.3,\n",
      "          63.739999999999995,\n",
      "          65.48,\n",
      "          70.15,\n",
      "          71.58,\n",
      "          74.52,\n",
      "          75.67,\n",
      "          77.11,\n",
      "          77.31,\n",
      "          77.44,\n",
      "          77.61,\n",
      "          78.07,\n",
      "          78.64,\n",
      "          78.99000000000001,\n",
      "          79.33,\n",
      "          79.99000000000001,\n",
      "          80.12,\n",
      "          82.24000000000001,\n",
      "          81.91000000000001,\n",
      "          82.74000000000001,\n",
      "          82.82000000000001,\n",
      "          83.21,\n",
      "          83.71,\n",
      "          83.38,\n",
      "          84.19,\n",
      "          84.61,\n",
      "          84.65,\n",
      "          84.7,\n",
      "          84.99,\n",
      "          85.13,\n",
      "          85.2,\n",
      "          85.72999999999999,\n",
      "          86.18,\n",
      "          86.25,\n",
      "          86.08,\n",
      "          85.76,\n",
      "          85.92999999999999,\n",
      "          86.33,\n",
      "          86.52,\n",
      "          86.94,\n",
      "          87.24,\n",
      "          87.26,\n",
      "          87.85,\n",
      "          87.91,\n",
      "          87.52\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          75.48,\n",
      "          83.13000000000001,\n",
      "          85.79,\n",
      "          87.78\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          35.36,\n",
      "          60.41,\n",
      "          67.99,\n",
      "          74.92,\n",
      "          78.18,\n",
      "          80.60000000000001,\n",
      "          81.69999999999999,\n",
      "          81.97,\n",
      "          82.43,\n",
      "          83.53,\n",
      "          84.89999999999999,\n",
      "          84.94,\n",
      "          85.24000000000001,\n",
      "          85.81,\n",
      "          85.96000000000001,\n",
      "          86.8,\n",
      "          87.25,\n",
      "          87.81,\n",
      "          87.9,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          79.44,\n",
      "          87.52\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          58.269999999999996,\n",
      "          71.76,\n",
      "          79.64,\n",
      "          82.54,\n",
      "          83.82,\n",
      "          83.98,\n",
      "          84.63000000000001,\n",
      "          84.89,\n",
      "          85.77,\n",
      "          86.59\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"SvmModel\": {\n",
      "    \"EntropySelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          34.22,\n",
      "          36.5,\n",
      "          41.5,\n",
      "          41.699999999999996,\n",
      "          43.05,\n",
      "          46.93,\n",
      "          50.62,\n",
      "          51.129999999999995,\n",
      "          55.74,\n",
      "          57.089999999999996,\n",
      "          56.84,\n",
      "          61.22,\n",
      "          62.029999999999994,\n",
      "          62.83,\n",
      "          62.029999999999994,\n",
      "          62.21,\n",
      "          63.28,\n",
      "          63.54,\n",
      "          65.23,\n",
      "          66.36999999999999,\n",
      "          68.42,\n",
      "          69.95,\n",
      "          69.55,\n",
      "          69.82000000000001,\n",
      "          74.8,\n",
      "          75.44,\n",
      "          74.92999999999999,\n",
      "          76.36,\n",
      "          77.23,\n",
      "          76.91,\n",
      "          75.79,\n",
      "          77.34,\n",
      "          77.81,\n",
      "          78.97,\n",
      "          80.16,\n",
      "          79.45,\n",
      "          79.65,\n",
      "          79.33,\n",
      "          79.41,\n",
      "          79.31,\n",
      "          78.95,\n",
      "          79.33,\n",
      "          78.78,\n",
      "          79.05,\n",
      "          79.11,\n",
      "          79.63,\n",
      "          79.60000000000001,\n",
      "          79.73,\n",
      "          80.13,\n",
      "          80.13\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.17,\n",
      "          79.14999999999999,\n",
      "          79.42,\n",
      "          80.08\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          52.65,\n",
      "          55.769999999999996,\n",
      "          58.5,\n",
      "          67.9,\n",
      "          68.63,\n",
      "          72.32,\n",
      "          72.37,\n",
      "          72.08,\n",
      "          72.49,\n",
      "          71.94,\n",
      "          73.11,\n",
      "          75.18,\n",
      "          76.25,\n",
      "          75.6,\n",
      "          76.79,\n",
      "          77.42999999999999,\n",
      "          77.56,\n",
      "          77.45,\n",
      "          78.3,\n",
      "          78.86\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.73,\n",
      "          84.64\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          68.25,\n",
      "          69.56,\n",
      "          71.76,\n",
      "          70.64,\n",
      "          70.59,\n",
      "          74.49,\n",
      "          76.31,\n",
      "          78.17,\n",
      "          77.95,\n",
      "          78.78\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"MarginSamplingSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          24.41,\n",
      "          39.12,\n",
      "          51.55,\n",
      "          58.15,\n",
      "          64.19,\n",
      "          67.33,\n",
      "          72.46000000000001,\n",
      "          73.94,\n",
      "          78.06,\n",
      "          78.57,\n",
      "          79.01,\n",
      "          78.68,\n",
      "          79.80000000000001,\n",
      "          80.78999999999999,\n",
      "          81.54,\n",
      "          82.21000000000001,\n",
      "          82.08,\n",
      "          83.17999999999999,\n",
      "          83.36,\n",
      "          83.13000000000001,\n",
      "          82.5,\n",
      "          83.24000000000001,\n",
      "          84.03,\n",
      "          84.84,\n",
      "          85.2,\n",
      "          85.17,\n",
      "          85.24000000000001,\n",
      "          85.1,\n",
      "          85.33,\n",
      "          85.00999999999999,\n",
      "          85.57000000000001,\n",
      "          85.91,\n",
      "          85.91,\n",
      "          86.4,\n",
      "          86.53999999999999,\n",
      "          86.78,\n",
      "          87.02,\n",
      "          87.18,\n",
      "          87.41,\n",
      "          87.33,\n",
      "          87.72,\n",
      "          87.8,\n",
      "          87.9,\n",
      "          88.1,\n",
      "          88.41,\n",
      "          88.22,\n",
      "          88.42999999999999,\n",
      "          88.38000000000001,\n",
      "          88.31,\n",
      "          88.6\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          76.8,\n",
      "          83.96000000000001,\n",
      "          87.08,\n",
      "          88.94\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          48.209999999999994,\n",
      "          59.870000000000005,\n",
      "          70.07,\n",
      "          73.88,\n",
      "          79.62,\n",
      "          80.99,\n",
      "          82.69999999999999,\n",
      "          83.2,\n",
      "          84.13000000000001,\n",
      "          84.61999999999999,\n",
      "          85.53,\n",
      "          86.32,\n",
      "          86.46000000000001,\n",
      "          87.16000000000001,\n",
      "          87.74,\n",
      "          87.87,\n",
      "          88.16000000000001,\n",
      "          88.24,\n",
      "          88.42,\n",
      "          88.13\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          82.87,\n",
      "          87.59\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          59.74,\n",
      "          70.57,\n",
      "          79.12,\n",
      "          83.25,\n",
      "          84.19,\n",
      "          86.44,\n",
      "          87.3,\n",
      "          87.81,\n",
      "          87.58,\n",
      "          88.63\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"RandomSelection\": {\n",
      "      \"10\": [\n",
      "        [\n",
      "          30.12,\n",
      "          41.54,\n",
      "          51.15,\n",
      "          59.5,\n",
      "          64.64999999999999,\n",
      "          65.02,\n",
      "          66.7,\n",
      "          68.81,\n",
      "          70.28,\n",
      "          73.48,\n",
      "          73.83,\n",
      "          76.64,\n",
      "          76.83,\n",
      "          77.68,\n",
      "          77.38000000000001,\n",
      "          77.77,\n",
      "          79.17,\n",
      "          79.59,\n",
      "          80.86,\n",
      "          80.89,\n",
      "          81.24,\n",
      "          81.47999999999999,\n",
      "          82.23,\n",
      "          82.8,\n",
      "          82.96,\n",
      "          83.00999999999999,\n",
      "          83.64,\n",
      "          83.72,\n",
      "          83.35000000000001,\n",
      "          83.41,\n",
      "          83.69,\n",
      "          83.67999999999999,\n",
      "          84.23,\n",
      "          84.26,\n",
      "          84.48,\n",
      "          84.98,\n",
      "          85.38,\n",
      "          85.39,\n",
      "          85.63,\n",
      "          85.74000000000001,\n",
      "          86.17,\n",
      "          86.28,\n",
      "          86.38,\n",
      "          86.57000000000001,\n",
      "          86.42,\n",
      "          86.56,\n",
      "          86.38,\n",
      "          86.37,\n",
      "          86.44,\n",
      "          86.53999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"125\": [\n",
      "        [\n",
      "          74.53999999999999,\n",
      "          80.67,\n",
      "          84.16,\n",
      "          86.61999999999999\n",
      "        ]\n",
      "      ],\n",
      "      \"25\": [\n",
      "        [\n",
      "          55.489999999999995,\n",
      "          64.21,\n",
      "          71.63000000000001,\n",
      "          74.95,\n",
      "          76.49000000000001,\n",
      "          80.08999999999999,\n",
      "          82.11,\n",
      "          82.25,\n",
      "          82.65,\n",
      "          83.3,\n",
      "          84.02,\n",
      "          85.05,\n",
      "          85.15,\n",
      "          85.67,\n",
      "          86.18,\n",
      "          86.83999999999999,\n",
      "          87.41,\n",
      "          87.63,\n",
      "          87.82,\n",
      "          87.83\n",
      "        ]\n",
      "      ],\n",
      "      \"250\": [\n",
      "        [\n",
      "          84.15,\n",
      "          86.91\n",
      "        ]\n",
      "      ],\n",
      "      \"50\": [\n",
      "        [\n",
      "          67.52,\n",
      "          75.52,\n",
      "          80.19,\n",
      "          84.26,\n",
      "          85.77,\n",
      "          86.16,\n",
      "          86.58,\n",
      "          86.65,\n",
      "          87.18,\n",
      "          87.09\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "{'SvmModel': {'RandomSelection': {'250': [[84.15, 86.91]], '125': [[74.53999999999999, 80.67, 84.16, 86.61999999999999]], '50': [[67.52, 75.52, 80.19, 84.26, 85.77, 86.16, 86.58, 86.65, 87.18, 87.09]], '25': [[55.489999999999995, 64.21, 71.63000000000001, 74.95, 76.49000000000001, 80.08999999999999, 82.11, 82.25, 82.65, 83.3, 84.02, 85.05, 85.15, 85.67, 86.18, 86.83999999999999, 87.41, 87.63, 87.82, 87.83]], '10': [[30.12, 41.54, 51.15, 59.5, 64.64999999999999, 65.02, 66.7, 68.81, 70.28, 73.48, 73.83, 76.64, 76.83, 77.68, 77.38000000000001, 77.77, 79.17, 79.59, 80.86, 80.89, 81.24, 81.47999999999999, 82.23, 82.8, 82.96, 83.00999999999999, 83.64, 83.72, 83.35000000000001, 83.41, 83.69, 83.67999999999999, 84.23, 84.26, 84.48, 84.98, 85.38, 85.39, 85.63, 85.74000000000001, 86.17, 86.28, 86.38, 86.57000000000001, 86.42, 86.56, 86.38, 86.37, 86.44, 86.53999999999999]]}, 'MarginSamplingSelection': {'250': [[82.87, 87.59]], '125': [[76.8, 83.96000000000001, 87.08, 88.94]], '50': [[59.74, 70.57, 79.12, 83.25, 84.19, 86.44, 87.3, 87.81, 87.58, 88.63]], '25': [[48.209999999999994, 59.870000000000005, 70.07, 73.88, 79.62, 80.99, 82.69999999999999, 83.2, 84.13000000000001, 84.61999999999999, 85.53, 86.32, 86.46000000000001, 87.16000000000001, 87.74, 87.87, 88.16000000000001, 88.24, 88.42, 88.13]], '10': [[24.41, 39.12, 51.55, 58.15, 64.19, 67.33, 72.46000000000001, 73.94, 78.06, 78.57, 79.01, 78.68, 79.80000000000001, 80.78999999999999, 81.54, 82.21000000000001, 82.08, 83.17999999999999, 83.36, 83.13000000000001, 82.5, 83.24000000000001, 84.03, 84.84, 85.2, 85.17, 85.24000000000001, 85.1, 85.33, 85.00999999999999, 85.57000000000001, 85.91, 85.91, 86.4, 86.53999999999999, 86.78, 87.02, 87.18, 87.41, 87.33, 87.72, 87.8, 87.9, 88.1, 88.41, 88.22, 88.42999999999999, 88.38000000000001, 88.31, 88.6]]}, 'EntropySelection': {'250': [[84.73, 84.64]], '125': [[74.17, 79.14999999999999, 79.42, 80.08]], '50': [[68.25, 69.56, 71.76, 70.64, 70.59, 74.49, 76.31, 78.17, 77.95, 78.78]], '25': [[52.65, 55.769999999999996, 58.5, 67.9, 68.63, 72.32, 72.37, 72.08, 72.49, 71.94, 73.11, 75.18, 76.25, 75.6, 76.79, 77.42999999999999, 77.56, 77.45, 78.3, 78.86]], '10': [[34.22, 36.5, 41.5, 41.699999999999996, 43.05, 46.93, 50.62, 51.129999999999995, 55.74, 57.089999999999996, 56.84, 61.22, 62.029999999999994, 62.83, 62.029999999999994, 62.21, 63.28, 63.54, 65.23, 66.36999999999999, 68.42, 69.95, 69.55, 69.82000000000001, 74.8, 75.44, 74.92999999999999, 76.36, 77.23, 76.91, 75.79, 77.34, 77.81, 78.97, 80.16, 79.45, 79.65, 79.33, 79.41, 79.31, 78.95, 79.33, 78.78, 79.05, 79.11, 79.63, 79.60000000000001, 79.73, 80.13, 80.13]]}}, 'RfModel': {'RandomSelection': {'250': [[79.44, 87.52]], '125': [[75.48, 83.13000000000001, 85.79, 87.78]], '50': [[58.269999999999996, 71.76, 79.64, 82.54, 83.82, 83.98, 84.63000000000001, 84.89, 85.77, 86.59]], '25': [[35.36, 60.41, 67.99, 74.92, 78.18, 80.60000000000001, 81.69999999999999, 81.97, 82.43, 83.53, 84.89999999999999, 84.94, 85.24000000000001, 85.81, 85.96000000000001, 86.8, 87.25, 87.81, 87.9, 87.83]], '10': [[28.470000000000002, 35.38, 44.85, 50.71, 58.48, 61.3, 63.739999999999995, 65.48, 70.15, 71.58, 74.52, 75.67, 77.11, 77.31, 77.44, 77.61, 78.07, 78.64, 78.99000000000001, 79.33, 79.99000000000001, 80.12, 82.24000000000001, 81.91000000000001, 82.74000000000001, 82.82000000000001, 83.21, 83.71, 83.38, 84.19, 84.61, 84.65, 84.7, 84.99, 85.13, 85.2, 85.72999999999999, 86.18, 86.25, 86.08, 85.76, 85.92999999999999, 86.33, 86.52, 86.94, 87.24, 87.26, 87.85, 87.91, 87.52]]}, 'MarginSamplingSelection': {'250': [[80.64, 89.2]], '125': [[73.39, 86.38, 90.11, 91.31]], '50': [[57.74, 75.92, 80.57, 86.13, 88.26, 88.62, 89.88000000000001, 90.93, 91.02, 92.17]], '25': [[53.339999999999996, 63.85999999999999, 70.77, 75.53999999999999, 79.22, 83.19, 83.17999999999999, 84.82, 86.21, 86.72999999999999, 88.18, 89.2, 88.47, 89.64999999999999, 90.2, 90.68, 91.56, 91.64, 92.10000000000001, 92.30000000000001]], '10': [[26.56, 45.550000000000004, 56.82000000000001, 67.99, 67.67999999999999, 71.17, 76.08, 78.13, 79.38, 79.69000000000001, 81.76, 82.43, 83.47, 84.99, 85.18, 86.0, 84.94, 86.07000000000001, 86.98, 86.56, 88.03, 87.92999999999999, 88.53, 89.2, 89.2, 89.71000000000001, 90.12, 90.57, 90.24, 90.49000000000001, 90.61, 91.09, 91.3, 91.07, 90.93, 91.17, 90.96, 91.38, 90.84, 91.72, 91.47, 91.56, 92.01, 91.94, 92.43, 92.43, 92.58999999999999, 92.56, 92.97999999999999, 92.80000000000001]]}, 'EntropySelection': {'250': [[82.87, 81.83]], '125': [[73.8, 73.65, 74.14, 74.59]], '50': [[58.25, 65.07, 65.14, 65.88000000000001, 64.94, 65.42999999999999, 66.64, 69.8, 69.13, 69.86]], '25': [[49.919999999999995, 57.489999999999995, 63.129999999999995, 65.53, 69.39999999999999, 69.73, 69.32000000000001, 66.67999999999999, 67.25, 66.97999999999999, 66.36999999999999, 68.22, 66.18, 67.42, 67.67999999999999, 67.64, 70.99, 70.59, 70.81, 72.48]], '10': [[22.34, 27.01, 32.07, 35.160000000000004, 47.72, 47.97, 52.400000000000006, 51.09, 54.459999999999994, 57.92, 57.489999999999995, 57.269999999999996, 56.65, 56.42, 56.47, 54.620000000000005, 55.11000000000001, 55.05, 55.13, 55.45, 53.769999999999996, 53.33, 53.690000000000005, 53.76, 54.55, 54.96, 55.120000000000005, 53.83, 55.1, 54.71, 55.510000000000005, 56.39999999999999, 55.379999999999995, 56.92, 55.85, 56.699999999999996, 56.21000000000001, 56.379999999999995, 57.31, 56.120000000000005, 56.44, 57.31, 58.47, 55.82, 57.37, 58.60999999999999, 58.85, 57.86, 57.36, 58.18]]}}, 'LogModel': {'RandomSelection': {'250': [[74.59, 75.29]], '125': [[72.86, 72.11999999999999, 70.67999999999999, 71.37]], '50': [[61.739999999999995, 69.95, 75.09, 73.91, 74.17, 74.21, 74.19, 73.74000000000001, 73.92, 74.62]], '25': [[54.279999999999994, 58.24, 61.839999999999996, 68.43, 68.44, 71.43, 74.02, 73.87, 73.4, 74.36, 75.39, 74.62, 74.85000000000001, 75.22999999999999, 73.8, 74.85000000000001, 75.14999999999999, 74.63, 74.16, 73.91]], '10': [[37.63, 50.61, 57.879999999999995, 60.150000000000006, 67.54, 65.03, 65.52, 69.19999999999999, 68.75, 67.02, 67.78999999999999, 68.7, 69.16, 70.19999999999999, 70.43, 69.94, 69.69999999999999, 69.97, 70.09, 70.95, 71.43, 72.78999999999999, 72.33000000000001, 72.78, 72.63, 72.95, 73.83, 74.38, 72.78999999999999, 73.22999999999999, 73.49, 73.54, 73.63, 73.41, 73.61, 72.86, 73.75, 74.0, 74.02, 74.76, 74.72, 74.53, 74.64, 73.82, 74.35000000000001, 75.67, 74.16, 75.7, 75.18, 74.3]]}, 'MarginSamplingSelection': {'250': [[70.02000000000001, 73.28]], '125': [[73.47, 71.32, 72.05, 73.02]], '50': [[63.56, 68.58999999999999, 67.97999999999999, 70.62, 72.67, 74.61, 73.74000000000001, 74.56, 73.1, 75.06]], '25': [[51.800000000000004, 63.71, 68.58, 68.17999999999999, 70.16, 70.69, 72.17, 74.33999999999999, 73.95, 71.13000000000001, 74.02, 72.89999999999999, 73.75, 72.55, 72.25, 72.7, 71.47, 70.38, 69.8, 70.06]], '10': [[37.5, 45.540000000000006, 50.17, 58.17, 62.4, 64.95, 67.80000000000001, 68.77, 69.85, 70.78999999999999, 72.05, 70.41, 67.30000000000001, 72.04, 71.22, 71.87, 69.64, 71.57, 71.78999999999999, 72.66, 72.86, 73.13, 71.53, 72.17, 71.78999999999999, 71.74000000000001, 70.55, 72.33000000000001, 70.54, 70.61, 71.73, 72.49, 73.0, 71.63000000000001, 73.17, 71.58, 72.5, 72.71, 72.05, 72.3, 72.05, 71.5, 70.67999999999999, 66.36999999999999, 71.6, 72.77, 72.38, 73.04, 71.84, 69.45]]}, 'EntropySelection': {'250': [[73.34, 66.69]], '125': [[70.86, 61.029999999999994, 58.93000000000001, 58.8]], '50': [[60.809999999999995, 61.45, 56.71000000000001, 58.86, 55.7, 53.18000000000001, 53.2, 53.339999999999996, 55.84, 57.099999999999994]], '25': [[41.870000000000005, 48.92, 52.470000000000006, 51.81, 52.89, 57.3, 56.13, 53.49, 54.54, 50.22, 52.300000000000004, 57.620000000000005, 56.19, 58.099999999999994, 52.949999999999996, 53.16, 54.620000000000005, 56.49999999999999, 59.099999999999994, 57.550000000000004]], '10': [[34.14, 41.870000000000005, 52.25, 48.089999999999996, 52.339999999999996, 48.43, 51.11, 53.31, 50.57000000000001, 52.019999999999996, 53.0, 49.27, 50.029999999999994, 49.57, 48.559999999999995, 51.51, 52.71, 53.910000000000004, 54.64, 55.14, 51.25999999999999, 51.01, 50.7, 53.669999999999995, 49.84, 48.25, 47.699999999999996, 47.58, 45.69, 48.0, 46.36, 44.57, 44.03, 46.58, 46.08, 43.19, 39.190000000000005, 48.08, 49.54, 47.94, 48.17, 47.71, 48.66, 46.87, 47.199999999999996, 49.71, 48.57, 44.2, 47.07, 42.42]]}}}\n",
      "{'LogModel': {'EntropySelection': {'10': [[34.14, 41.870000000000005, 52.25, 48.089999999999996, 52.339999999999996, 48.43, 51.11, 53.31, 50.57000000000001, 52.019999999999996, 53.0, 49.27, 50.029999999999994, 49.57, 48.559999999999995, 51.51, 52.71, 53.910000000000004, 54.64, 55.14, 51.25999999999999, 51.01, 50.7, 53.669999999999995, 49.84, 48.25, 47.699999999999996, 47.58, 45.69, 48.0, 46.36, 44.57, 44.03, 46.58, 46.08, 43.19, 39.190000000000005, 48.08, 49.54, 47.94, 48.17, 47.71, 48.66, 46.87, 47.199999999999996, 49.71, 48.57, 44.2, 47.07, 42.42]], '125': [[70.86, 61.029999999999994, 58.93000000000001, 58.8]], '25': [[41.870000000000005, 48.92, 52.470000000000006, 51.81, 52.89, 57.3, 56.13, 53.49, 54.54, 50.22, 52.300000000000004, 57.620000000000005, 56.19, 58.099999999999994, 52.949999999999996, 53.16, 54.620000000000005, 56.49999999999999, 59.099999999999994, 57.550000000000004]], '250': [[73.34, 66.69]], '50': [[60.809999999999995, 61.45, 56.71000000000001, 58.86, 55.7, 53.18000000000001, 53.2, 53.339999999999996, 55.84, 57.099999999999994]]}, 'MarginSamplingSelection': {'10': [[37.5, 45.540000000000006, 50.17, 58.17, 62.4, 64.95, 67.80000000000001, 68.77, 69.85, 70.78999999999999, 72.05, 70.41, 67.30000000000001, 72.04, 71.22, 71.87, 69.64, 71.57, 71.78999999999999, 72.66, 72.86, 73.13, 71.53, 72.17, 71.78999999999999, 71.74000000000001, 70.55, 72.33000000000001, 70.54, 70.61, 71.73, 72.49, 73.0, 71.63000000000001, 73.17, 71.58, 72.5, 72.71, 72.05, 72.3, 72.05, 71.5, 70.67999999999999, 66.36999999999999, 71.6, 72.77, 72.38, 73.04, 71.84, 69.45]], '125': [[73.47, 71.32, 72.05, 73.02]], '25': [[51.800000000000004, 63.71, 68.58, 68.17999999999999, 70.16, 70.69, 72.17, 74.33999999999999, 73.95, 71.13000000000001, 74.02, 72.89999999999999, 73.75, 72.55, 72.25, 72.7, 71.47, 70.38, 69.8, 70.06]], '250': [[70.02000000000001, 73.28]], '50': [[63.56, 68.58999999999999, 67.97999999999999, 70.62, 72.67, 74.61, 73.74000000000001, 74.56, 73.1, 75.06]]}, 'RandomSelection': {'10': [[37.63, 50.61, 57.879999999999995, 60.150000000000006, 67.54, 65.03, 65.52, 69.19999999999999, 68.75, 67.02, 67.78999999999999, 68.7, 69.16, 70.19999999999999, 70.43, 69.94, 69.69999999999999, 69.97, 70.09, 70.95, 71.43, 72.78999999999999, 72.33000000000001, 72.78, 72.63, 72.95, 73.83, 74.38, 72.78999999999999, 73.22999999999999, 73.49, 73.54, 73.63, 73.41, 73.61, 72.86, 73.75, 74.0, 74.02, 74.76, 74.72, 74.53, 74.64, 73.82, 74.35000000000001, 75.67, 74.16, 75.7, 75.18, 74.3]], '125': [[72.86, 72.11999999999999, 70.67999999999999, 71.37]], '25': [[54.279999999999994, 58.24, 61.839999999999996, 68.43, 68.44, 71.43, 74.02, 73.87, 73.4, 74.36, 75.39, 74.62, 74.85000000000001, 75.22999999999999, 73.8, 74.85000000000001, 75.14999999999999, 74.63, 74.16, 73.91]], '250': [[74.59, 75.29]], '50': [[61.739999999999995, 69.95, 75.09, 73.91, 74.17, 74.21, 74.19, 73.74000000000001, 73.92, 74.62]]}}, 'RfModel': {'EntropySelection': {'10': [[22.34, 27.01, 32.07, 35.160000000000004, 47.72, 47.97, 52.400000000000006, 51.09, 54.459999999999994, 57.92, 57.489999999999995, 57.269999999999996, 56.65, 56.42, 56.47, 54.620000000000005, 55.11000000000001, 55.05, 55.13, 55.45, 53.769999999999996, 53.33, 53.690000000000005, 53.76, 54.55, 54.96, 55.120000000000005, 53.83, 55.1, 54.71, 55.510000000000005, 56.39999999999999, 55.379999999999995, 56.92, 55.85, 56.699999999999996, 56.21000000000001, 56.379999999999995, 57.31, 56.120000000000005, 56.44, 57.31, 58.47, 55.82, 57.37, 58.60999999999999, 58.85, 57.86, 57.36, 58.18]], '125': [[73.8, 73.65, 74.14, 74.59]], '25': [[49.919999999999995, 57.489999999999995, 63.129999999999995, 65.53, 69.39999999999999, 69.73, 69.32000000000001, 66.67999999999999, 67.25, 66.97999999999999, 66.36999999999999, 68.22, 66.18, 67.42, 67.67999999999999, 67.64, 70.99, 70.59, 70.81, 72.48]], '250': [[82.87, 81.83]], '50': [[58.25, 65.07, 65.14, 65.88000000000001, 64.94, 65.42999999999999, 66.64, 69.8, 69.13, 69.86]]}, 'MarginSamplingSelection': {'10': [[26.56, 45.550000000000004, 56.82000000000001, 67.99, 67.67999999999999, 71.17, 76.08, 78.13, 79.38, 79.69000000000001, 81.76, 82.43, 83.47, 84.99, 85.18, 86.0, 84.94, 86.07000000000001, 86.98, 86.56, 88.03, 87.92999999999999, 88.53, 89.2, 89.2, 89.71000000000001, 90.12, 90.57, 90.24, 90.49000000000001, 90.61, 91.09, 91.3, 91.07, 90.93, 91.17, 90.96, 91.38, 90.84, 91.72, 91.47, 91.56, 92.01, 91.94, 92.43, 92.43, 92.58999999999999, 92.56, 92.97999999999999, 92.80000000000001]], '125': [[73.39, 86.38, 90.11, 91.31]], '25': [[53.339999999999996, 63.85999999999999, 70.77, 75.53999999999999, 79.22, 83.19, 83.17999999999999, 84.82, 86.21, 86.72999999999999, 88.18, 89.2, 88.47, 89.64999999999999, 90.2, 90.68, 91.56, 91.64, 92.10000000000001, 92.30000000000001]], '250': [[80.64, 89.2]], '50': [[57.74, 75.92, 80.57, 86.13, 88.26, 88.62, 89.88000000000001, 90.93, 91.02, 92.17]]}, 'RandomSelection': {'10': [[28.470000000000002, 35.38, 44.85, 50.71, 58.48, 61.3, 63.739999999999995, 65.48, 70.15, 71.58, 74.52, 75.67, 77.11, 77.31, 77.44, 77.61, 78.07, 78.64, 78.99000000000001, 79.33, 79.99000000000001, 80.12, 82.24000000000001, 81.91000000000001, 82.74000000000001, 82.82000000000001, 83.21, 83.71, 83.38, 84.19, 84.61, 84.65, 84.7, 84.99, 85.13, 85.2, 85.72999999999999, 86.18, 86.25, 86.08, 85.76, 85.92999999999999, 86.33, 86.52, 86.94, 87.24, 87.26, 87.85, 87.91, 87.52]], '125': [[75.48, 83.13000000000001, 85.79, 87.78]], '25': [[35.36, 60.41, 67.99, 74.92, 78.18, 80.60000000000001, 81.69999999999999, 81.97, 82.43, 83.53, 84.89999999999999, 84.94, 85.24000000000001, 85.81, 85.96000000000001, 86.8, 87.25, 87.81, 87.9, 87.83]], '250': [[79.44, 87.52]], '50': [[58.269999999999996, 71.76, 79.64, 82.54, 83.82, 83.98, 84.63000000000001, 84.89, 85.77, 86.59]]}}, 'SvmModel': {'EntropySelection': {'10': [[34.22, 36.5, 41.5, 41.699999999999996, 43.05, 46.93, 50.62, 51.129999999999995, 55.74, 57.089999999999996, 56.84, 61.22, 62.029999999999994, 62.83, 62.029999999999994, 62.21, 63.28, 63.54, 65.23, 66.36999999999999, 68.42, 69.95, 69.55, 69.82000000000001, 74.8, 75.44, 74.92999999999999, 76.36, 77.23, 76.91, 75.79, 77.34, 77.81, 78.97, 80.16, 79.45, 79.65, 79.33, 79.41, 79.31, 78.95, 79.33, 78.78, 79.05, 79.11, 79.63, 79.60000000000001, 79.73, 80.13, 80.13]], '125': [[74.17, 79.14999999999999, 79.42, 80.08]], '25': [[52.65, 55.769999999999996, 58.5, 67.9, 68.63, 72.32, 72.37, 72.08, 72.49, 71.94, 73.11, 75.18, 76.25, 75.6, 76.79, 77.42999999999999, 77.56, 77.45, 78.3, 78.86]], '250': [[84.73, 84.64]], '50': [[68.25, 69.56, 71.76, 70.64, 70.59, 74.49, 76.31, 78.17, 77.95, 78.78]]}, 'MarginSamplingSelection': {'10': [[24.41, 39.12, 51.55, 58.15, 64.19, 67.33, 72.46000000000001, 73.94, 78.06, 78.57, 79.01, 78.68, 79.80000000000001, 80.78999999999999, 81.54, 82.21000000000001, 82.08, 83.17999999999999, 83.36, 83.13000000000001, 82.5, 83.24000000000001, 84.03, 84.84, 85.2, 85.17, 85.24000000000001, 85.1, 85.33, 85.00999999999999, 85.57000000000001, 85.91, 85.91, 86.4, 86.53999999999999, 86.78, 87.02, 87.18, 87.41, 87.33, 87.72, 87.8, 87.9, 88.1, 88.41, 88.22, 88.42999999999999, 88.38000000000001, 88.31, 88.6]], '125': [[76.8, 83.96000000000001, 87.08, 88.94]], '25': [[48.209999999999994, 59.870000000000005, 70.07, 73.88, 79.62, 80.99, 82.69999999999999, 83.2, 84.13000000000001, 84.61999999999999, 85.53, 86.32, 86.46000000000001, 87.16000000000001, 87.74, 87.87, 88.16000000000001, 88.24, 88.42, 88.13]], '250': [[82.87, 87.59]], '50': [[59.74, 70.57, 79.12, 83.25, 84.19, 86.44, 87.3, 87.81, 87.58, 88.63]]}, 'RandomSelection': {'10': [[30.12, 41.54, 51.15, 59.5, 64.64999999999999, 65.02, 66.7, 68.81, 70.28, 73.48, 73.83, 76.64, 76.83, 77.68, 77.38000000000001, 77.77, 79.17, 79.59, 80.86, 80.89, 81.24, 81.47999999999999, 82.23, 82.8, 82.96, 83.00999999999999, 83.64, 83.72, 83.35000000000001, 83.41, 83.69, 83.67999999999999, 84.23, 84.26, 84.48, 84.98, 85.38, 85.39, 85.63, 85.74000000000001, 86.17, 86.28, 86.38, 86.57000000000001, 86.42, 86.56, 86.38, 86.37, 86.44, 86.53999999999999]], '125': [[74.53999999999999, 80.67, 84.16, 86.61999999999999]], '25': [[55.489999999999995, 64.21, 71.63000000000001, 74.95, 76.49000000000001, 80.08999999999999, 82.11, 82.25, 82.65, 83.3, 84.02, 85.05, 85.15, 85.67, 86.18, 86.83999999999999, 87.41, 87.63, 87.82, 87.83]], '250': [[84.15, 86.91]], '50': [[67.52, 75.52, 80.19, 84.26, 85.77, 86.16, 86.58, 86.65, 87.18, 87.09]]}}}\n"
     ]
    }
   ],
   "source": [
    "(X, y) = download()\n",
    "(X_train_full, y_train_full, X_test, y_test) = split(trainset_size)\n",
    "print ('train:', X_train_full.shape, y_train_full.shape)\n",
    "print ('test :', X_test.shape, y_test.shape)\n",
    "classes = len(np.unique(y))\n",
    "print ('unique classes', classes)\n",
    "\n",
    "def pickle_save(fname, data):\n",
    "  filehandler = open(fname,\"wb\")\n",
    "  pickle.dump(data,filehandler)\n",
    "  filehandler.close() \n",
    "  print('saved', fname, os.getcwd(), os.listdir())\n",
    "\n",
    "def pickle_load(fname):\n",
    "  print(os.getcwd(), os.listdir())\n",
    "  file = open(fname,'rb')\n",
    "  data = pickle.load(file)\n",
    "  file.close()\n",
    "  print(data)\n",
    "  return data\n",
    "  \n",
    "def experiment(d, models, selection_functions, Ks, repeats, contfrom):\n",
    "    algos_temp = []\n",
    "    print ('stopping at:', max_queried)\n",
    "    count = 0\n",
    "    for model_object in models:\n",
    "      if model_object.__name__ not in d:\n",
    "          d[model_object.__name__] = {}\n",
    "      \n",
    "      for selection_function in selection_functions:\n",
    "        if selection_function.__name__ not in d[model_object.__name__]:\n",
    "            d[model_object.__name__][selection_function.__name__] = {}\n",
    "        \n",
    "        for k in Ks:\n",
    "            d[model_object.__name__][selection_function.__name__][str(k)] = []           \n",
    "            \n",
    "            for i in range(0, repeats):\n",
    "                count+=1\n",
    "                if count >= contfrom:\n",
    "                    print ('Count = %s, using model = %s, selection_function = %s, k = %s, iteration = %s.' % (count, model_object.__name__, selection_function.__name__, k, i))\n",
    "                    alg = TheAlgorithm(k, \n",
    "                                       model_object, \n",
    "                                       selection_function\n",
    "                                       )\n",
    "                    alg.run(X_train_full, y_train_full, X_test, y_test)\n",
    "                    d[model_object.__name__][selection_function.__name__][str(k)].append(alg.clf_model.accuracies)\n",
    "                    fname = 'Active-learning-experiment-' + str(count) + '.pkl'\n",
    "                    pickle_save(fname, d)\n",
    "                    if count % 5 == 0:\n",
    "                        print(json.dumps(d, indent=2, sort_keys=True))\n",
    "                    print ()\n",
    "                    print ('---------------------------- FINISHED ---------------------------')\n",
    "                    print ()\n",
    "    return d\n",
    "\n",
    "\n",
    "max_queried = 500 \n",
    "\n",
    "repeats = 1\n",
    "\n",
    "models = [SvmModel, RfModel, LogModel] \n",
    "\n",
    "selection_functions = [RandomSelection, MarginSamplingSelection, EntropySelection] \n",
    "\n",
    "Ks = [250,125,50,25,10] \n",
    "\n",
    "d = {}\n",
    "stopped_at = -1 \n",
    "\n",
    "# print('directory dump including pickle files:', os.getcwd(), np.sort(os.listdir()))  \n",
    "# d = pickle_load('Active-learning-experiment-' + str(stopped_at) + '.pkl')  \n",
    "# print(json.dumps(d, indent=2, sort_keys=True))\n",
    "\n",
    "d = experiment(d, models, selection_functions, Ks, repeats, stopped_at+1)\n",
    "print (d)\n",
    "results = json.loads(json.dumps(d, indent=2, sort_keys=True))\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HT9kYxtP381F"
   },
   "source": [
    "Independently, we trained several models using a train-test split of 60K-10K, the results indicate that the upper-bound for RF, SVM and LOG are 97., 94. and 92.47, respectively.\n",
    "\n",
    "The following graphs show that the random forest classifier paired with the margin-selection method and k=10 is the best configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1037
    },
    "colab_type": "code",
    "id": "oXoHDRLArYjX",
    "outputId": "91f371fa-abc9-4f30-e297-873906e84191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So which is the better model? under the stopping condition and hyper parameters - random forest is the winner!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOydd5gURfrHP9Xdk3ZnWcLCEgVEQHJOIrJIElFQD3MAPEEw3J13h+kUBTN6dyiiGFDkpyKKcEg0ICsGVIRbclRQssCyeUJ3V/3+6NlhBxZYYRVO+vM8/XRPd3X1OzW7b1W/VfUtoZTCxcXFxeXMQzvVBri4uLi4nBrcCsDFxcXlDMWtAFxcXFzOUNwKwMXFxeUMxa0AXFxcXM5Q3ArAxcXF5QzluBWAEOI1IcTPQog1Jc5VFkJ8LITYHNtXip0XQojnhBBbhBCrhBBtf03jXVxcXFxOnLK8AUwBLjrs3L3AIqVUQ2BR7DNAP6BhbBsOvFg+Zrq4uLi4lDfHrQCUUkuA7MNODwTeiB2/AVxW4vxU5fA1UFEIUaO8jHVxcXFxKT9OtA8gXSm1O3a8B0iPHdcCtpdItyN2zsXFxcXlNMM42QyUUkoI8Yv1JIQQw3HCRPj9/nZnnXXWyZpSrkgp0bTTq4/8dLQJTk+7XJvKhmtT2Tkd7dq0adN+pVTVE85AKXXcDagHrCnxeSNQI3ZcA9gYO34JuLa0dMfaGjVqpE43Fi9efKpNOILT0SalTk+7XJvKhmtT2Tkd7QK+U2Xw4UfbTrQ6+wAYHDseDMwucf6m2GigzkCuOhQqcnFxcXE5jThuCEgIMQ3IANKEEDuAh4AngXeFEH8EfgSuiiWfD1wMbAGKgKG/gs0uLi4uLuXAcSsApdS1R7nUs5S0Crj9ZI1ycXFxcfn1OelOYJf/DUzTZMeOHYTD4XLPOzU1lfXr15d7vieDa1PZcG0qO6fSLr/fT+3atfF4POWar1sBnCHs2LGDlJQU6tWrhxCiXPPOz88nJSWlXPM8WVybyoZrU9k5VXYppThw4AA7duygfv365Zr36TWmyeVXIxwOU6VKlXJ3/i4uLr8uQgiqVKnyq7y9uxXAGYTr/F1c/jf5tf533QrA5ZRSr1499u/fXy55TZo0ialTpwLw1ltvsWvXrl/lOacDDz/8MM8888xv+szfWxm6uH0ALr8TLMtixIgR8c9vvfUW7du3p2bNmqfQqvLBsiwMw/1XdSl/3DcAl9+Myy67jHbt2tGsWTNefvnlI64/8sgjNG7cmPPPP59rr7023sLNysqic+fOtGzZkssvv5yDBw8CkJGRwV/+8hfat2/Ps88+G28Vz5gxg//+979cf/31tG7dmlAoBMCECRNo27YtLVq0YMOGDYDTkh48eDDdunWjbt26zJw5k7vvvpsWLVpw0UUXYZrmEXZmZmZyySWXxD/fcccdTJkyBXBaycX3d+zYkS1btgAwZMiQuK2NGjVi7ty5ANi2zahRo+jQoQMtW7bkpZdeij+jW7duDBgwgKZNm5ZanitXrqRLly40bNiQV155BXA6DEeNGkXz5s1p0aIF06dPL5PNDz300BFlc+DAAfr06UOzZs245ZZbimf3u/yOcJsVZyBj5qxl3a68csvPtm1a1KnEQ5c2O2a61157jcqVKxMKhejQoQN/+MMf4teWLVvG+++/z8qVKzFNk7Zt29KuXTsAbrrpJiZMmED37t0ZPXo0Y8aMYfz48QBEo1G+++47wHHmAIMGDeLZZ5/l3//+N+3bt48/Iy0tjRUrVvDCCy/wzDPP8OqrrwLw/fffs3jxYtatW0eXLl14//33GTduHJdffjnz5s3jsssu45eQmprK6tWrmTp1Kn/5y1/izv7HH3/k22+/5fvvv6dHjx5s2bKFqVOnkpqayrJly4hEInTt2pU+ffoAsGLFCtasWXPUkR+rVq3i66+/prCwkDZt2tC/f3+WLl1KVlYWK1euZP/+/XTo0IELLrjguDaXVjZjxozh/PPPZ/To0cybN4/Jkyf/onJwOf1x3wBcfjOee+45WrVqRefOndm+fTubN2+OX/vyyy8ZOHAgfr+flJQULr30UgByc3PJycmhe/fuAAwePJglS5bE77v66qvL/PwrrrgCgHbt2rFt27b4+X79+uHxeGjRogW2bXPRRc7yFy1atEhIV1auvfba+H7p0qUJz9c0jYYNG3L22WezYcMGPvroI6ZOnUrr1q3p1KkTBw4ciJdLx44djznsb+DAgQQCAdLS0ujRowfffvstX3zxBddeey26rpOenk737t1ZtmzZcW0urWyWLFnCDTfcAED//v2pVKnSLy4Ll9Mb9w3gDOR4LfVfSlnGR2dmZvLJJ5+wdOlSkpKSyMjIKJdhbcnJyWVO6/P5ANB1HcuyjjivaRoejyc+4kLTNCzL4ptvvuHWW28FYOzYsVSuXBkpZfz+w79HyREbRzsu/qyUYsKECfTt2zfhWmZmZsJ3mzhxYjzMM3/+/KPmdzQMwzimzUcrG5ffN+4bgMtvQm5uLpUqVSIpKYkNGzbw9ddfJ1zv2rUrc+bMIRwOU1BQEA+bpKamUqlSJT7//HMA/u///i/+NnAsgsEg+fn55WJ7p06dyMrKIisriwEDBlC3bl3WrVtHJBIhJyeHRYsWJaQvjrtPnz6dLl26xM/PmjULKSXff/89P/zwA40bN6Zv3768+OKL8b6GTZs2UVhYeIQNt99+e9yG4o7t2bNnEw6HOXDgAJmZmXTo0IFu3boxffp0bNtm3759LFmyhI4dOx7X5tK44IILePvttwFYsGBBvO/F5feD+wbg8ptw0UUXMWnSJJo0aULjxo3p3LlzwvUOHTowYMAAWrZsSXp6Oi1atCA1NRWAN954gxEjRlBUVMTZZ5/N66+/ftznXX/99YwYMYJAIJAQhikP6tSpw1VXXUXz5s2pX78+bdq0Sbh+8OBBWrZsic/nY9q0aQn3dezYkby8PCZNmoTf7+eWW25h27ZttG3bFqUUVatW5T//+U+Z7GjZsiU9evRg//79PPjgg9SsWZPLL7+cpUuX0qpVK4QQjBs3jurVqwMc0+bSeOihh7j22mtp1qwZ5513Hqfbmh0u5cDJaEmX1+auB1A2TsamdevWlZ8hh5GXl1cu+eTn5yullCosLFTt2rVTy5cvP+U2/VLq1q2r9u3bd8T5wYMHq6lTp5Zyx6nlVJXTsTgdbVLq1NtV2v8wJ7kegPsG4HLaMHz4cNatW0c4HGbw4MG0bdv2VJvk4vK7xq0AXE4biuPN/8scbdTQlClTyq1PwsWlvHA7gV1cXFzOUIQ6DWb3pdZuqC56cOqpNiOBnJwcKlaseKrNSOBkbLq9TYBa9c8pZ4scbMtGN/RfJe8TxbWpbLg2lZ1TbdfOrVuY+N9Qwrl3R5y3XCnV/ii3HBf3DcDFxcXlDOW0eANo3Lix2rhx46k2I4HMzEwyMjJOtRkJnIxN69evp0mTJuVrUIzTcQEP16ay4dpUdk61XaX9Dwsh3DcAl/8NHnvsMZo1a0bLli1p3bo133zzzUnll5mZiRAirukDjnCcEILnnnuuzPls27aN5s2bn3CaIUOGUL9+fVq3bk2rVq3KNMmqrGRkZMS1jk6GoqIirr/+elq0aEHz5s05//zzKSgoOOY9Jyr/nJmZyVdffRX/XFKm+2QZNWoU5557blwYMCcnB3B+n0AgQOvWrWndunWCMuzy5ctp0aIF55xzDn/6059cUbsSuBWAy2/C0qVLmTt3LitWrGDVqlV88skn1KlT56Tzbd68Oe+++27887Rp02jVqtVJ5/tLefrpp8nKymL8+PEJzud04dlnnyU9PZ3Vq1ezZs0aJk+eXO7ryxZzeAUwYsQIbrrppnLJu3fv3qxZs4ZVq1bRqFEjnnjiifi1Bg0axGdLT5o0KX5+5MiRvPLKK2zevJnNmzezcOHCcrHl94BbAbj8JuzevZu0tLS45kxaWhqrVq3iyiuvjKcpKVkcDAYZNWoUzZo1o1evXnz77bdkZGRw9tln88EHH8TvqVu3LuFwmL1796KUYuHChfTr1y9+/WhS0suXL6dVq1a0atWKiRMnxtMfTZ65rHTp0oWdO3fGP48dO5YOHTrQvHnzhNZnRkYG99xzDx07dqRRo0ZxqYtQKMQ111xDkyZNuPzyy+NS1uBUbsUt+HvuuSd+vixltXv3bmrVqhW/p3HjxvHf4s0336Rjx460bt2aW2+9Fdu2j/heR0uzcOFC2rZtS6tWrejZsyfbtm1j0qRJ/Pvf/6Z169Z8/vnnCYvXHEvau7g82rRpEy+Pw+nTp098bYTOnTuzY8eOY/4eu3fvJi8vj86dOyOE4KabbirzTOszAbcCOBNZcC+83r/ctsD0QU6ex6BPnz5s376dRo0acdttt/HZZ5/Rq1cvvvnmm7j2zfTp07nmmmsAKCws5MILL2Tt2rWkpKTwwAMP8PHHHzNr1ixGjx6dkPegQYN47733+Oqrr2jbtm3csYEjJf3UU0+xatUqWrRowZgxYwAYOnQoEyZMYOXKlQl5TZ48OS7PvGzZMl555RW2bt1a5qJduHBhgnz0HXfcwbJly1izZg2hUCiucQTOQi/ffvst48ePj9v14osvkpSUxPr16xkzZgzLly8HYNeuXdxzzz18+umnZGVlsWzZsrgjK0tZ3XzzzTz11FN06dKFBx54IK44unHjRqZPn86XX35JVlYWuq7z1ltvJXyn9evXl5pm3759DBs2LC7j/d5771GvXj1GjBjBXXfdRVZWFt26dUvI62i/R8nyePLJJxPOH43XXnstobLfunUrbdq0oXv37vEKZOfOndSuXTuepnbt2gkV9JmOOxHM5TchGAyyfPlyPv/8cxYvXszVV1/Nk08+yUUXXcScOXMYNGgQ8+bNY9y4cQB4vd4EWWafzxeXbD58stVVV13F1VdfzYYNG7j22mvj4YfSpKSvvPJKcnJyyMnJievk33jjjSxYsACAjz76iFWrVjFjxox4Hps3b6ZRo0bH/H6jRo3i/vvvZ8eOHQnaQ4sXL2bcuHEUFRVx4MABWrduHZe6PpoE85/+9CfA0fpp2bIl4KyXkJGRQdWqVQFH62jJkiVcdtllZSqr1q1b88MPP/DRRx/xySef0KFDB5YuXUpmZibLly+nQ4cOgPMGUq1atYTvtmjRolLTfP3111xwwQVxyerKlSsfs4yO9nsUU1webdq0Oa4M92OPPYZhGFx//fUA1KhRg59++okqVaqwfPlyLrvsMtauXXvMPFzcCuDMpN+T5ZpdqIyjI3RdJyMjg4yMDFq0aMEbb7zBXXfdxfPPP0/lypVp3759PJ/DZZlLSjYfLldcvXp1PB4PH3/8Mc8++2xC/PmXoo4iz1zSIQ0dOpT//ve/1KxZMy7N/PTTTzNo0CAmTJjAzTffzPLlywmHw9x2221899131KlTh/vuuy9Bhrm8JJjLWlbBYJArrrgivi7B/PnzUUoxePDghFh6aWVSWpo5c+acsM2lUVp5lFbWU6ZMYe7cuSxatCj+vX0+X/z+du3a0aBBAzZt2kStWrUSwkQ7duxICIWd6bghIJffhI0bNyYsAJOVlUXdunXp3r07K1as4JVXXomHf06EsWPH8tRTT6HrhybqHE1KumLFilSsWJEvvvgCICHkURZ55tdff52srKy4QyrJHXfcgZSSDz/8MO7s09LSKCgoYPbs2cf9HiUlmIs7O8FZHOazzz5j//792LbNtGnTyiSLXcyXX34Zj7dHo1HWrVtH3bp1ycjIYMaMGfz8888AZGdn8+OPPybc27Nnz1LTdO7cmSVLlsRDZNnZ2QCkpKSUKntxItLeh5f1woULGTduHB988AFJSUnxdPv27Yv3S/zwww9s3ryZs88+mxo1alChQgW+/vprlFJMnTqVgQMHlrncfu+4bwAuvwkFBQXceeed5OTkYBgG55xzDi+//DK6rnPJJZcwZcoU3njjjRPO/7zzziv1/NGkpF9//XVuvvlmhBDxJRiBk5JnBmdRlgceeIBx48axaNEihg0bRvPmzalevXqZxO1GjhzJ0KFDadKkCU2aNIkvi1mjRg2efPJJevTogVKK/v37/yJH9v333zNy5EiUUkgp6d+/P3/4wx8oKCjg0UcfpU+fPkgp8Xg8TJw4kbp168bvbdq0aalpOnfuzMsvv8wVV1yBlJJq1arx8ccfc+mllzJo0CBmz57NhAkTEuw4EWnvktxxxx1EIhF69+4NOB3BkyZNYsmSJYwePRqPx4OmaUyaNCkeknrhhRcYMmQIoVCIfv36JfQbnOmc1EQwIcSfgWGAAF5RSo0XQlQGpgP1gG3AVUqpY64k4U4EKxvuRLCy49pUNlybys6ptuu0mggmhGiO4/w7Aq2AS4QQ5wD3AouUUg2BRbHPLi4uLi6nGSfTB9AE+EYpVaSUsoDPgCuAgUDxu/wbwGVHud/FxcXF5RRyMhXAGqCbEKKKECIJuBioA6QrpXbH0uwB0k/SRhcXFxeXX4ET7gRWSq0XQjwFfAQUAlmAfVgaJYQotZNBCDEcGA5QtWpVMjMzT9SUX4WCgoLflU2pqam/2oIktm2fdouduDaVDdemsnOq7QqHw+Xuk8pNDVQI8TiwA/gzkKGU2i2EqAFkKqUaH+tetxO4bLidwGXHtalsuDaVnVNt12nVCRx7eLXY/iyc+P/bwAfA4FiSwcDxBz+7uLi4uPzmnOxEsPeFEOuAOcDtSqkc4EmgtxBiM9Ar9tnFxZWDPgFcOehE3nvvPZo1a4amaQnl8vHHH9OuXTtatGhBu3bt+PTTT+PXMjIyaNy4cVwqunhC2+lG8RwNy7KIRqOEw2FCoRCFhYXk5+cTCoWYNWsWb7/9Nq+++uoRcyxOhJOaCKaU6lbKuQNAz5PJ1+X3R0k5aJ/Px/79+4lGoyedb7Ec9C233AKcWjnoQYMGsXjxYoYPH54w6/l0oKQcNDgzsz0eT7n8BoeTmZlJMBiMT84rT3ns5s2bM3PmTG699daE82lpacyZM4eaNWuyZs0a+vbtmyD69tZbb9G+/QlHSn4xUsq4Q7dtiVISKQ9tSils246nKd6ORCGEQgiJaRWxZd9nFAgfuZafAyqplPS/DFcKwuU3wZWDduWgj/V7lFUOukmTJjRufGSXYps2bahZsyYAzZo1IxQKEQ6HsZVCAZZUmFISlZKIlERsSdiWhGxJkW1TZNsUWjb5psWBcJQ9BRG254T4fn8hG/bmsWZXLj/m2azfk8eGvXls/DmPjfvy2Ljf2Tbsz2XdvlzW7s1lzZ5c1u7NZ93eAtb/XMim/SE2H4jw/UGTrXmSHwvgp0LBzrDB7qiHvZaP/crPQZFEjhYgV/OTp/vI1z0U6B5y8XHADpJnJTHxh9688f0F/OfHjmTtP/k1vl0piDOQp759ig3ZG8otP9u2aVa1Gfd0vOeoafr06cPYsWNp1KgRvXr14uqrr6ZXr14MHz6cwsJCkpOTS5WDfvrpp7n88svjEsfr1q1j8ODBDBgwIJ53sRx0mzZtSpWDnjBhAt27d2f06NGMGTOG8ePHM3ToUJ5//nkuuOACRo0aFU9fUg46EonQtWtX+vTpExcdOx6lyUEXSzJfc801zJ07N64GWix/PH/+fMaMGcMnn3ySIAe9atWquHxEsRz08uXLqVSpEn369OE///kPl112WZnK6uabb6ZPnz7MmDGDnj17MnjwYBo2bJggB+3xeLjtttt46623EhZwKSkHXTJNv379GDZsGEuWLKF+/fpkZ2dTuXJlRowYQTAY5O9//ztAQkjsaL9HyfKYMWMGD48Zw4KPPsJWIJXCJrZXYCtFVCp+jpj8FIogcc4Vp13wn1k0atWKjVEJ0RCFtuTGoUPQNJ1eAwYy7K93IxAgFSgQSoEElHLOlUQI0AXKEAglnMu2cx9HGUAjhAANNA2EJtCEAgFCSUChStyuECglDu1V7O+s+GVAAZpwPLUhiLashEoyUEkGwmfAI2X6szwqbgXg8pvgykH/vuSgq1atypIvv6LL+d1IrVWHvRETOynIznCUPMvGNC1+DIWRSnHQNIlEo6zYtYv9Bw9SvV07NhQU0PUPg7hr8E2szS+g0LZpdVE/VuYVUrl1Ozb/sJX1BeEEO5CKmJcnaktyCyPk5kccBw6gFFs2rOdfD/yDl9+eiZYfBQVP/GsS6TVqUliQz1+HD2Ze1be4dJDT0BCAEApNKDQBugcMTeDRBIYu0DUNTQiE0LAiEfw+A01IBDYoC0vaWFKilI0uomhaFEFpoRwNpXSQhrMvcawwQOoopcUscvy+FKBEbI+gAMGVuR7CBRAxbEKGZNsx/yqPj1sBnIEcq6V+IpR1eJwrB316ykHfdNNNPPHE4yhlo5QTry4yC5FKcSCcT04kxOXXXcNfH34YUwlMBFJpfLZgPgW2zfaw048gnHYtIdtCsy0KzAgChSUtbGlhWxFQChWNAArNCiOUxGsXoSlJBY+kgirAEkVIK0pyJJ+77/wL61avoWp6dSZOfS/+XYRUaJZEMy2EkAgUP+/eyV1/vIGnn3uWRg3SERSiCUlqvSCCXKr4JVdfdRGrV35BrSHdMYTNUaYpJaIESDA8zptCSfculMBAdxy5rWPLICg95uQNwABlIISGELG3A1Hs5mN7AegcOqliFZOKlakCISFZwvD9NoYtMWyFYUne5eRw+wBcfhNcOejfTg7a6ViMYttO/0E0epDFi+eye/cGQqEdZOdsZuXqFaRWS6Jt93a88967fPPDejYW5PP19t18vOFHNocEFrDb1Gna7ULmzprNrr170VQEM3sHRdvXcmHHRqz86nPsH/9LHbIJZG8l3c6nasCHlZtDUtjEU2RDFGRE4NMqkVKhIl8v/oZokcHMt2bStsP5hAq8SFsQKvSQn++joNCPUoKiiI+xz7zI7I+X8H/T3iXND7WSBXVTdPy6ID1gUDvgpabXT6Agwu033shD9z7Mha0voEI0QEo0gK/QS9HuMP5IMiLfx6IFn9OkQSsIV8EOV8MOV0NGqiGjVVHRNJRZBczKYFYCMxVhVkCYQYSVhAono0UqokeqYISr4g1Xxxupgd+sRpJdhSAVqaCnUMGTRKrXR6rfINUPqUk2FQImKT6LoMckqFskaRZJwiIJmyRlE5A2AdMmEHU2f9TGZ9p4TYnXknhsiaYUlQ2bihU1Ump7SG5y8p3A7huAy2+CKwd94nLQSknS09N4/PGxZGR0RylJv3696du3E6HQDkBRWPg9SllEIj9jGAFyCrZg4UGh2B0u5LtNWxlx5z1IBVIquvXpS/sBNyGE4LYHH2LI5ddCTOr58fHPUPOc2hjAWR5o3bwpDzz4ECMu+wO2LTEMgwcee5rmbTrwjyee5bprR6KkpHJaVV56exbtMy7h77cOZuH8D/nH2CcRCgwhqWBInnv+Be6/+2+EQkXUq1ef5154kdQUD15DIy3ZQ3rQi8oT6EJQN9mPkAppKWxbIqOKOfM/4P6H7+ZA9n6uvGoQzZu04N23/sPLr77E1m0/8K/x4/jX+HEgYM606QQDfq67YRCmaWLbNheedx63XT4ALTcHpI2S8qix/OOhAIQOmo6K7REaQtPj5xE6wukMOEomEiVtUDZICcou8dnZq9g1VZRNzht3nJCtR6PcZgKfDO5M4LLhzgQuO6ezTU6YxUYpK7bZSGWh5KHPh65ZKHVkTFkBFh4s4ccSXiw8mHgwlY6JdqgzMYZHgFcIvAK8SuFREl0qzFAY3fASlU7HqinBVGArwZFjgUBDoaHQhUJHYQicDYUunOc4/ZUK/fCblUIq4WxSYBcfK83ZI454nkCiKYlQNpq0ELHNObbRlB0rjdIRWqw3VtMQuu7sNc1xzroGmtMBK2OhGU03EJqBFnPmEAvEKzAjJoamg61QspQO40NGg+b0HxMbwgkS4n0HNmAhlAXKcfpORSBjn0uplBSs3/EzvqmDyRUGB4WXfHT+8NLmk5oJ7L4BuLj8SihlY9khwlaIsG0SVTa5+TkopZxRH6Vs4EXhOB7H1Za4XjxqBIHleJfYcBIntcey8dhRki0LzbJRtsJUGlIIbKFjCo2wECihlXCZHrCcTwKBhkRH4UWiSxtD2XhsG4+08Ngmui3RpIzF+0v5zkJDCgNTM4hoBlIYSM1AaQZS6DGveAjHiZvoynmGUDZCWeixTlmhaaBrCF0Dj4bQDdC8JRy5hhICFXPgKt4TAQqFVAplx5yrBGVLx3FLwHJi+JrQEEJDQ4+31CWKktJmCoVQEgsTqSRS2UgkMtZn4hzbscpaxjqVYxvq8K9dXDuAcCo+iUGsmnBsF7FRQqq4nBQF0seHue0Oy+jk5pu4FYCLSykopZxX8tikHedYOf/gR5yXWEoREZKwpohogojQMIXTKofkEhkf8SSEOrRpJY5FzOlosaGKh86BIW280sYrJYaSmEInpHkIC4N8vNjCaYo7/YsyXp3oQqFhowvQhUCgCHgNvLqG19CdUS+aFuusFCXKwwkdSQnSVs6xXfLY2Q6PKAhNoBsahqGhG86xVnysawjtyFZ/fn4+SbG3N6UUtmVhRsJY4TBmJIJtRmIOXSGIOW+hoaEhhI6GFnfqOjpCeI58t4i1zlVxTYCJIOy8jRU785iDt5VEKqc4nEpJoGkCQxNOWWnOs6QynBGiCmypsKXCKp7gJUv+9OqwBr5CCRULKRHfi9gDRewZms+gcs92pAQrkhqsTKWUqvDuvOP9KR8TtwJw+d2gbBsVjaKiUURhIVYkcijGK+WRx1I5r9ulOfmjhEZNw0PU4yHi9RD1eYgaHkyvDzsh4KHwKBOvZRG0w/hMiU9KhGXhMTzOsEJNoAmR0JJ1NkEUnYiEiBRElCJsK+wS9sSdrEbMcRxqj2soPEKSrCn8hsDv0dF1D4ZhoOs6uq4fcvBAXl4eSYHkuAM3LXko5m7Lozp2IBYy0dB1geHVnOPDHL1W0sEXN2mVM4QSKxYKsy2UbSNtCyUlWsSkMD8X2wYlnXiKho4mNAIiCU1oYGjOWP5SiYVYMEGEEUiEJp1wjOaUm7OPlb2Itfw1X4nj4jj+oet5+fkkBZOwpIUlLUxpYdmjGK8AACAASURBVCkr/tk5Z2JJC1lK2A7A0IzETTh7j+ZJOK+V0mdwMCfE0OFjjvKdTwy3AnD5n0JJiTJNVCSCikSR0Yjj9CMRVIkhjzpgxj85Djc2M6fEsQBdR3g8CKHFW1tKaER1nbCuE9F0IkIQEYIosdf2GBo2HqIkiTB+TeDTPSQZPny6z3Huh1GyZVtM2LTJD0UpiFhEIhLTVqgSoQcdhY7ESBiuKBDCaYUK4TjZgEcn6DPwew00TXPquRIOXJqSaFhiW/Zhjh3CBxNHOSEEui7QSjh2TVM40RiFJqQzFl7YCBk9FMd2Xg9QYacDU0pJ1JbYNk6cX2rOmHd0QEegx0MvQhhowotA4ImZ4SkeHgmQ4MRtELbjxHXhhIe0WJhI1xCat4TzPv5AR6lkghO3lIVlhRPPxZw72Uferwkt7rj9hj/u1Etz9mWdUPhb4VYALqcdSqmYk4+iooc5+sO0a4SuI3w+tGAQ4fUhvV4imkEoahIIBBxnLwQCkRCHVbFZo6ZURKSMdYBKTKmwlHJiygAKjFgXa6qI4hUSDzq68AI+bJWMaSvMqCRkKwp0G58Rwe/R8BkaHl1DSRvbtolGo+Tk5lEYtQlZiogtsGMViuMaJX4h8Wjg1QU+Q8PQnRa8rulouo6uOR5RSYVtFYdenFa7GbEJ26bj2I/SQen0gyoMTaEZEmVH8RqgCRsNCw0ToSxn1qqywZJgSmwlsKSGqTRMqWNJp2oqDrk4YRgdgZEYjhGa4+oTnHlx0SonDBPrNEVz5keZtkUgJYjQNYQeC4P8QseplHIcux1xnLcyj3Doxa13W5bW3Q26psdb5z7dh7QkSf6kI5x68W/yv4hbAbicEpRSKMs61HqPRhMcfckQjNA0hNeLFgggUlMRPh/K4yWqGUSkImxKwqZN2JRYUUm87R8Olf7wMlDS3diAjYcwTixZHXZFEwLDeYEgYilyQ2ZCXlqsFQ8CM7YXCLxIklD4AAPNmTgkhROSjucOxLsHE/NNeIaw0YSNgeU4cs1CExY6Vty5C+ShSjDWx6kAYZcYyig8KAKYSseyNaTSUNLpHhax2HrA0I8aflHFsfVip65rCENDGAZarJCO59Sj+fnoAU+p15RSCc67ZNjl8POlha2EEHHn7dW8JBlJR4ZgYk798DBMfn4+KYHTa2TZyeJWAC6/KsVOXkajPP7UU7zz/vtORyPw3OjRdIxJHSAEmteL5vMhUlIQXq/Tsvd6wXBenZVS5IUtDhZGyS+I8u3ST7nlqkt5eNxzXD94CCl+g03rV9Pr/M48Ovoe/nzHrQk6MiXRcYbnacpm+/btXHnDbaz4fBaaMEAcClNI5XRybv1xO4NuvIWvFy84NM4k1jF761338uXXy6iQkoJSiiceuo/u55/nDC+E+B7AE3u2Ea9GDu1F8RTQElVM7ysH89QDf6ddq+YJ10RsZImjFFnsTIUT8oh34Goo4QG8FBVFGHbXfaxetwGlFBUrVGDetP8jKRBAQ6AOm4isIWnauQtfz59DWuXKEM9eO+S8Ned3c96yYscCMj//Cq/Hy3mdHemISZPfICkQ4KbrrirlL8SpBGSJDlcVDVNoH3A6X6Ud64SV2Mrm6XETefut96lcpTIA9953Jz17dUMIjZeem8zbb8/E0HSeenI0fXr1cN5AhNPvoQs91mlcihlSgoxyrErWMMNQVMr1Mr2d/JI3GFHqIWYINn14AvkdHbcCcDl5pESGQo6jL9GaV9EIKqYa+U1WFvPmL2DpzJn4g0GyCwowAW+9eo6zLyFncDhh0+ZAYZTcIhNLSnRNEAh48AcMGjVtxscLZzNo5C0UKsWb702nRbPG6MrEaxXE/Fax0yweaV7sYJ2rfmkhAI8pgWhsi+lwxY58sgANSVCVWBIwlo2Bzbh//IVBl/Rm8ZfLGHHPg2z64oOERCI2uuOY/7biiAOEkBiaiUeLxM6rxIFExXXRUfIuPvfcC69RvXKQtz+ZBsDGLdvwi1w8KnT4I0tgY4jsQ/0PxSMjS4+YxMn8ZCHB5CTOa+qoc464spdzIW/nUe+JRYAwAB8U/wRHkKIkfxt2PX8fcUisDttm3abNzJ05jw2L3mXX3n30umYkAz+flTAz/GQJAISPl+pXpHAfzCytEj1x3ArA5YSQ0Sj2wYPYubkY0SiREteEx+OEbCqkovm8CK+X/WvXUq1ObVJji6rUwFHO/NuYMbw5fTphy2bR4kxeGP8vJr8/i6ZVq3D10Fv47KMPqVotnTvvfpDxTzzM7l07GPXkODIu7k9Ugxp16lCUn0fo512kp1fh20Uf0bNPLyJeD6FkwepV67nrrkcIFYWpX+8sJox/gpSUKizPWs9f/uqogHbv3h0Lgz1URdlRHn/8Cb5aupRoNMqtg6/j5huuJ6QqYiuDg1ZdbHXIqeiaxCSZqKcKVnJtuvSsxs69f0KknQOaxtjHnmTOvPmEQmE6dOjAa6+9hhCCjIwMOnXqxOLFi8nJyeHVV1+lW9fzKSos4uY//pFVq1fSuGFjiqIalrcepvdc3pnxDk89+wxKKvr17Mvj948FoHLjGgy/8Y8sXPwR1aul8/DdD/CPxx9ix84dPPHQI1zUsydbdxdQu1Zd9oVTkUpSsXZz8jQDbMHsuQt4afJkTMukU8dOvPDCRMdx6l6o1hzS0njzzTd57vkJRKMmnTp2ZOLE51FCMW/BfB568GEs26JylUo89dyTTHxzJpqmMXnmAu5/4j6+/vwbkpKT+OPtQ1i/egNjRj1COBSmXv26/GviP6lSpQpX9BtEh47t+eKzL2Pl8RLdu3U/sl5KrgbBIKQ3p+Sb0uzX53HN9Tfhq9OG+nXgnEbn8u22Irp06RxL8UsmvJaSVkFBUSHBpOQjrx3rvuOlLdMtsUQHNBj2aYl7FIzp8AueeSRuBXAGsufxx4ms/+Vy0ArAtp0O2ljLXug6SggCTZqQfu89Tmu+lFbXRf378+gTT9CwUSO69biQfoMG0bzL+XwxbBj/3XuAQHIy70yfTs+BfyC/IEpRYSHtO3blr/c9zF+H3cDL/36E2fPfZMv6tdx+698YenETdqhd+Cni4oHdyJw5mZYtz6VNq3NI8kqEtDGjfoYPf5BHHnmELl268vTT43h83Es8/sgY7vrrKP755GNccP55PPDQWHQhqJQU5NXXplA5NZ1PF3xFUWGY/lf0pkvXyxCkgNAwAj78Xh2PV4+PkPEm+fBXSMFbsQrzYxLN+IIopbj9jj/zwD8eAqm4/sYbmP3eLC7p2x9lSaL5Yb6ck8n8jxfw8D8eYuG0D5j48vMENC8rP1nG6vVr6NSvG8qU7Nq5k388OpovFmZSIZjEgOsGMX3edC7u24fCokK6dOvI6Ifv5Yabb+bhfz7CrBnT2bBpE7fd+Sf6X3YxQ/94MwOvuIL5iz7hwgt7MmTIEBqdXZ/vvvuO2fPn89XSpYeknt+eFpeDjiiT71av4M133ub9j2aiNMV9d93HM6/8i64XdmXEiJG88cEb1K5bm4LcAtKqpHH9zdeTEkzhjrvuwBAG677ZQIo/hbMrNeKqP1+XIAf98r8nM378eDy6Fx0P3323nBkzZvDoo0+S8UmvI/8INZ3nX3iRqW86C7z885//pFKlSuzcvYfOnTuD4QWgdp2z2Ln35/jn8kBpJnj85ZbfL8bwQq3yXezIrQBcjovTYWuC6XSsCSEQXg/CcMI2lm0jfE4nbXH6qFLOghvSWXQjjMZriz9nxVdfsuzzJYy84Xr+PuYhMnr1YMXCGfS9+GK+WLiAu0aNRkVsPF4vV1zciiTPdto0r43P7yfVY9K2xbls/2kXXm8aHk9lhPAycOB1DBkynLVrd9G//1WsWPFfpEwmHPaTn1/IJZcMQAiN4cNGcu111xCOGOTl5dOpQx+KCiUD+l/Pgo8Wk5cT4cOPP2T9hvXM+uB9QJGfn8/WrVk0qF/f0dop2oM0faioD9vwYugepCkZ9be/c/+997Fj106WzPuU6O5CkJJP5i3gny+OpygU4mDOQZo3aMLF5/UGqRjQtz+WbdKyeTO2bd9GWBXx2TefcevQmylQudQ7txZNm5xLoZVL5jdr6dShHd4kie2xuPqaq/hu7SpuGP5HvF4vg667DiEEbdt3wOfzkVarNufVqMlPO3aQUiWNLt268cPWrXE56I4dO7J06VIWZy7mu+Xf0ba9o30UCoXwVvDS+WBnTGmyNWcrCxYsYMWKFfTu1huBIBqOUiO9Bj+t+YkLLriAjFYZeHQPWpoTMKvoq0jQFyQ9KR0An+HDq3sJFYRKlecuplgeu02bNkdIfhczcuRIHnzwQYQQPPjgg/ztb3/jtdde+5X+8n//uBXAGUj1++9P+KyUM9HIsmOzF22JaUvMUAQzHEZZFh4p8XoNvMFkfMEkPIaGLgSmHSKnqBDl8fBjYQ5hqRFRekzWAEDhwcRLlGQ9yiXdGnJFt7p0bZrGW2/P4KZht/P6q1PQvOk0b9WG+tWTSQ2A1+OhasWzEMLA708nJSWFpKQGRKNRLMsmP18nL8/CNBUVKlTF6/XxxRdf8fxzL7Jm1Xo0ZSAjBkpC3t4oSiny94eQliSUG0EpJ76uGxE0rRCUhZD5CCRPP/IYvTJ6OrNJnXml/LT9J3RhkKpXZfhfRpK1dhU10qvzwdT3IWrzxP2PcHn/gUx8fRLD/jyCLxd8SihcxJ3/uIvMeQupWaMGj/9zHAeLDpAd2YNpR4moAvIj+zG1MJZtIb0yFggXaB4dcCY7aYaONxDAG0iiWt2z0XQdf3IQPdY5fjw5aNM2icoopmHS9aKudOzdkQKzgCkzpqAbOv2v7M9dD94FOEMfvboXr+ZFFzo1kmtQyV+JIYOH8NSTTyX008yZM8cZImn4KA9Kk8c+XHo7PT09nn7YsGHxFeRq1arF9u3b49d27NiRsAKaS+m4ctBnMFIpDhRE2LAnn3W78ti0N5/v9xXwY3YRu3LD7Isq8jQvhb5ksv0p7NEC/FQk2fxzAet25bF6Vy4bfjbZHfaxJ2SQa+uARQVRSDUtj7OMXBp682ngMwn/9COFO/dTwVeDiKrLVyt2U6l6A1p06MHGtav4aObb/HHwDVSvWJmAryIAuu5HSjBNk6LCIvbs2cOBAwecMd62wqN50YSBxw5y958f4B+jHqbwQIRIKIo0bZK8XiqmprJ8xeck+RWz50yne9fzqV0tlYoVKrD8yyUELIM5/5mHLgwqeqvSL6MfU/7vLXTTwKt8bP3hRyKRKFrMyepBL69Nfo0V337HnA8+QKaAbUjCWog8mc0NN12JJU3mLZ5HbiQHgIppqeRHC5mzcAFef4DU9Op4fD4q16hF1XpnU7lmbTRdp2J6DXr27sMHCz+kYvUa7Nifzdr166mQVpWMXn344ssvyT54sFQ56IgVIT+aT5FZRF40j5/yfmLLwS1IJJsObmLmRzNZv2M9+4v2k1OUw5aNW2hQvwG9e/Rm8bzFBKNBzq18LtWohp6jUzulNprQSPWncnGfi5k1cxb79u0DIDs7mx9//JHOnTuzZMkStm7dGj8PkJKSQn5+ic7yGEeT5z4Wh0tv7969O35t1qxZNI/1KQ0YMIB33nmHSCTC1q1b2bx5Mx07dvzF/xNnGu4bwBlIVEoOFEY5WBDFsiWGoeHzadhKITWwdT0mepKoCKkphaZsNNtRMRRKgDQwTYmKSjQh8Pt9pPiDVPAbGLrTvjBtyZ7sLdz9tzvIzc1F13XqN2jAxBcmcXbtSgwccKkjB/36FCIhk0jEaaHv3r0HpSSRSARDN8DW0WSszVIUxY6EUNLENvfTvvXZKFUPae/DJxR+TaeC8PD6v1/ijvv+QlEoRP2z6vHKP19AmPDyPycyYtSdCCHofWEvhC7QK/kZfucItmfvovOA7gly0B4tALrAqHiotasDHvx4fD6ClSpT9ax6ADw8ZiwvvPACi264keG33kq33n2pXr067dp3wBsIEAimONouun7EyKfS5KABqqVXY+xjY+me0R0pJT369qBVRis2ZW9CKsmWnC0AFJgFKFMRlVG8ujOztkZyDUJ7Q9x6362gnAXL+/fvz7Drh1FQUMDjjz3OwIsHImNy0BMnTqRu3bpxm5o2bcqjjz5Knz59EtJ07tyZl19+mSuuuAIpJdWqVePjjz/m0ksvZdCgQcyePZsJEyYkfL+jyXOXlbvvvpusrCyEENSrVy++ZnOzZs246qqraNq0KYZhMHHixHIdAfR7xZWDPgq/NznoNevWkX5OQ7JDJpEi01laTxMov46uKXTbxpASr2Hg8XnxGDoeIZzx6jIPZWajZBghNAxPRbyeyui6E/PPy8tDeAPkhUzywham7Qy3DHicCUNFpoUCfJpG0NBJEgKhSgiJSRuJiRI2StjFox0R6OjCgy4USBPbCiMtZxy2putOCETX0WKzZB3JAgM9qmFZNobXODTpSI/p7sSkA3T9t2/7HEuiuniCU1RGidqxLXZs2ia2Shx7aWgGHt2DV/PGQzZe3YtH9/wiyYHTWTb7dONU21WapLsQwpWDPtPJLoyyaP1eckMmFfweKgQ8VAgYRDT4tihEZl4Bf/VGkdkhsCS6EKSqCCn5+ei5Ci05GS0lBZGUXDy/CRkNIVUOUuXhTFLyo6l0kCnYlqCoCJQKgYJoFHQtit9WeKUgKjUiQhGOOqK6SUoQUALDBmFJbA2UZiOFhRQmSncaIZqm4/ME8Hm9YEeJhIowQ/mYsY5nTyCALzUVbyAJw+s9ppOL5ufjSwn+Nj9AGVFKEbEipTt5aSbMXBUIx8HrXgJGINHJa57/afkBl9MHtwL4H2VffoQP1+5hwZrdfP1DNvbRFqcoZkANdEtSwYriwwsiQMTvtOBRQJ6C/EJ0byG6Lx9NN1FKYEeTsSMpKLt4OJ15aF3T2IKmChDFwmGaIEmPqV3qMcEyDWxpEzUjRCJhorHlFgUCn9+Hz+fD5/ViRSKECvIoyHXi/IbXS6BCKr6kJDz+AJp2endZOZ3pdrzTtaSDj9pRLGklTHDShIZX9+LX/aR4U45w8qebcJjL7w+3AvgfIjssef3LrSxYs4dl27JRCs5OS+b6rvXQawRYGg2TlV2IMBX1PQZtPR7q/rCVg//dTpJMp4qtoQk/Xq/Al+KLOxhFGKlysGUuoNA0P4aehmGkIpL12NoV4tCi1ofhvBonrk9q2zaRSISiUDgW03cqKI/HQzAYxOfz4fV6McNhwgX5ZO/bg7QlmmGQlFoRfzAFj698RpeUJ0opTGnGnXuCs7ejR8gAG5qBV/cS9ARRliKYFIw7eV0c2Qfg4vJb4lYApzn5YZMFq/fw/oodfLM1BKyjcXoKQ7ufjUgPsNSO8HJ+CHKjNA8GuK9pHXrn7oN3F7JpfYQ9lVuTZJyLV2ikpHoIpPjQdA2lbEwzB9PMxrbDIDQ8nop4vZXRtMAJqS9Go1HCYcfhFw/j0zQNn9fpU9CEQNk2diREUWE+edEotmUhNIE/OYg/mII3kHTKnaJUMiFEU9LJHxGqEQKP5oRqkoykxLi87k0QFMvPzyfFd/rFtl3OXNwK4DTEsiWfb9nPzBU7+WjtHiKWpH5aMn3P8XJWh0Z8ZUV4Ia8IciI0Dwa4/+wa9Ev2UGHhJ6wfv5bvqE9+Slu0ajb1G/ppcWlz8uw9JFcMYNshQqFsLCsHpSSa7sfvr4nHUxEhyh5XVkphWZbTyi8qoqCgIO4YdeFouivLRJrREuo6Dk4HrgePz0+wcjK+5GRnDdbfiOJQzeEdrcXHlkxURouHagw/FbQKCU7eDdW4/C/jVgCnEZv35vPOsu3MztrF/oIIqQEPXZqn46+TzDpDMrsoAtkH407/krRUqm/ZyA8vTmX1Zsneyi2RKd2pmGxyfq86nNu9Hr4kD7ZdRPb6QgoLt2DbIRACj1ERT2wkz7EcWKSoiEhhASq2jJ0tJbZSztJ3xYmURNg2QtoI23bCRR4vHp8PIxhE93jQDAPdMNB1w1GU/JVRSpXa0XrcUI03mODc3VCNy++Zk6oAhBB3Abfg+ILVwFAcna93gCrAcuBGpdRRtP1cAFbvyOX5xZv5cO1edE1Q96xUgq2qsCUZFgqB3wrTKTlI+6Ic7uzUlrOsCD/PnMu6jzazRD+HwuR2GNUsGjZJpvmlzUmvVwEhBPn569m6cRp79swmtcI/UaoCfn8NDKPScVvctmWRf2A/4aJC0A2UpscW3nZWqxYodKXQcX78QDCI4fVieH3oR1H2fOyxx3j77bfjyxK+9NJLdOrU6YTLLTMzkx49evDKK69w09CbKLKK+Hb5t/Tt2pe/Pfw3ht4+NJ728FBNcYjGo3nYtX0XAy4dwJo1a476rG3btnHJJZeUmmbIkCF89tlnpKamopTiX//6Fz179jzh71WSjIwMnnnmGdq3P+GRfgAUFRUxbNgwVq1a5chBV6zIwoULj3lPvXr1+O6770hLS/tFz8rMzMTr9XLeeecBMGnSJJKSkuL6QifDqFGjmDNnDl6vlwYNGvD6669TsWJFtm3bRpMmTWjcuDEAnTt3ZtKkSSf9vN87J1wBCCFqAX8CmiqlQkKId4FrgIuBfyul3hFCTAL+CLxYLtb+zvh26wGe/mQzy74/gO7REOdUoLBOEuu9Oi1TAoyslMIFlVLokJqMTxN8OTmTvLmfM+tHnZ8rN0dVqE6VFJP2F9WnUdc6eP0Gth1i9+732blrGnl5WWial2rVLgaVRnJyw+O2ZG3bJj/nIKGiEErTwOeMFDIMA7/fH++8LZlPfn4+weOMj166dClz585lxYoV+Hw+9u/fTzR6Yu0CpRQRO0JeNI/GTRsz5a0pdLmsCwDvvvMuTVo0wS/81AzWjI+sMbSjj40vbf3VX8rTTz/NoEGDWLx4McOHD2fz5s0nnWd58uyzz5Kens7q1asB2LhxIx6Ph0gkcpw7fzmZmZkEg8F4BTBixIhyy7t379488cQTGIbBPffcwxNPPMFTTz0FQIMGDcjKyiq3Z50JnGwIyAACQggTSAJ2AxcC18WuvwE8jFsBxNkbjjJ55Q7e/+pHDuwtQnk1rIYVqNqwEj3SU+lWKYWulYJU9jg/jbIs8j/6kJX/9wmbjA6EkurjqWrSpEUFWg5sQZVazlj3goKNbN00jT17/oNl5ZOU1ICGDR+gRvXL8Xgqsn79+lIdYHHnbSQSIRwKYcVUPtE1fD4/gUAAn8930rMqd+/eTVpaWlzvJS0tjYULF/LnP/+Z9957D3AcxzPPPMPcuXMJBoOMHDmS+fPnU6NGDUaPHc19997H9p+2c+9j99K9b3cOhA5QvXZ1QgUhtAKNurXqsuyzZQzsP5CAHqCSvxJZWVnxmacNGjTgtddeo1KlSixfvpybb74ZgD59+sTttG2be++9l8zMTCKRCLfffju33nprmb9nly5d2LnzkO792LFjmTNnDqFQ6Jhy0JMnT6Zbt26EQiGGDh3KypUrOffccwmFDq1qNm3aNB5//HGUUvTv3z/u+A4vq8cff5y7776bn376ifHjxzNgwAB2796dMLu3Qf365B/YRzQUYtrUqbwyZQqWZdGpUydeeOGFI37vN998k+eee45oNJqQZuHChdx///3Ytk1aWhqTJ09m0qRJ6LrOm2++yYQJE1i0aBHBYJC///3vR/09SpZHdnY2r7/+Ot26dTuifEv+Vp07d2bGjBll/m1+TZRSsTDpkXuJPOZ1hbN8ZfEqeTJqgWmjrNiSnApAkbv/Z56+8R5Qh60JcRKccAWglNophHgG+AkIAR/hhHxylIqvL7QDKFWRSQgxHBgOULVqVTIzM0/UlF+FgoKCcrEpomAdBqsxWHFAkr25AC3XBJ9GrXOTuaC2h9a6TbrcD7v3w25YBYhwGP/Spfg+XcK2ihews1Z/fHoBtVtb/D975x1fRZn18e/M3LktN72SQiCE0AOhSe/SRDpSFbCtFF11V1dXxcrqqltUbNgLL4Isig1BiiJFQ49AIBBqCgES0m6f8v4xySUhASmyruWXz/1MZu4zzzxT7jlnzjnP7wSnmBEkL1k5G9FztqDr3wAHABMCHRCF3njcaRzMFTiYa1hEoaGhAX6WzI+PUFzgNB6kmjPBqx40QRSrcu4vzO+t6zqRCUF0GtHwnG26du3KI488QmpqKn369GHMmDF06dKFW265hePHjxMUFMT777/PiBEjKCsvw+l0kt4pndvuv40/XP8H7nvgPl5a9BJHco5w/+z7GXXNKCJNkVgFK0NHDOXzJZ/Ttm1b2rRpAxh0BxUVFUyZMoVnnnmGHj168MQTT/DAAw/w97//nalTp/Lss8/SvXt3HnzwwUD7t956C6vVypo1a/B6vQwcOJBu3bohCEKgzdnw+/243W4qKir47LPPuOaaawLtpk6dyl13GURrN998Mx9++CFDhgxBVVVcLherV69mxYoVzJkzh08++YR58+YhyzKZmZns2rWLnj174nQ6ycnJ4d5772XdunWEhYUxcuRIFi5cyLBhw3A6nXTp0oU5c+YwadIk7rvvPpYuXcrevXu57bbb6Nu3L+PHj2fkyJEsWrSInl27Mmb4MJo0bsyBI0f5z0dL+ej9dzGbzdz/6GO89sorTLr+enRdp7KyksOHD7NgwQK+/PJLZFnmrrvu4rX587l6wABuvvlmli9fTqNGjSgpKSEiIoLp06fjcDi44447APjiiy+QZfm896Pm9Vi+fHngepz9nBlPqPH36vxXGTl6JCXlJZwuP82hQ4dok96G4OBg7nvwPq7qdlWdfapFZ0AAU+P7+rZVr+tG1TKKqbMP6AjVISWhNsW/XvUTEnQQdWMGvPERAtskDSRVxKQKtfZTJR1VPlO8SJV0jib6q0gKDZrCy8XluIDCgRFAY6AU+BAYfKH767o+H5gPBhXEr4l2oRoFHh/XbttPwSkX5v3lCCc9hDrMXD+kGbd3a4RNrnv5S5n26wAAIABJREFUlZMnKXl/Aac/+IBSNYQdGbfjlMJo2z8RX0Q+/fr3xek8QH7BBxQWLkVRyrDbGxMffz8N4kZjNkfU6dPn87F37140TcPj8eBX/OhajSCobkz/lSQJSTZzseXmVFVFNsvnnSYfHBzM9u3b+fbbb1m7di3Tp0/nqaeeYsiQIaxes5qhI4eyfMVy7njkDvL9+chmmYy+GeiiTps2bXDYHLSKaUV6bDpTj02lQVgDQoJCMJlM3HDDDYwfP57Dhw9zww03sHHjRkRRRNM0ysvLGTJkCAC33nor48aNQ1VVysvLGTzYeFxvuukmVq9eTXBwMOvWrSMrK4tPP/0UgLKyMgoLC0lLS0MUxXrPUZZl5syZw+OPP05eXh6bNm0KtFu5ciVPP/00LpeL4uJiMjIyCA4ORpIkJkyYQHBwMD179uS+++4jODiY77//njvuuIPg4GC6du1Keno6QUFBZGdn07dvXxo3bgzADTfcQGZmJhMmTMBsNjNy1EgA2rZri8ViISQshI6dO3L06FGsdiudunQia/sWvvzsc775dgNDRo/l63VrWb9lMz9kZ3PNdePRNQ23y01EaCju4pPomobPXcmqFcvZvm0bvXr0AHQ8Hi9hdht2SaRzh/bEhAbhrijBbpPw+CpRdT9+/LgFF7qu4dd9eDUP+cVHOV16mvROLSnzFjNs7FBm3DSLEv8p/LqfnkN7UqQUkdAmgYNHDlLgL6hjLVfj1X++il/002NkDwp9hRAJK7evJCwijN07d3PrDbeybP0yHD8yG7za/VctVAVBOLMUDCFbva4qKmbZbNSR8+sIfg3Bp4JfvbhaMGdBkERMZguyxYJstmCyWDHVE0dzVai88OTyWtv+9eTlJSdcjgtoAHBI1/WTAIIgLAW6A2GCIJiq3gISgXPXgfsVo9SvMO67HEp+OIk130Ww1cTsoc25oWsjrHJdd4o3N5fit96ifNknaIrK8b4z2EtL7CEWhk9rQWKzMNZ+/RFbt82ntDQTQZCJjh5IQsJEwsO61HpYdF3nxIkT5ObmcuDAAY4cOcKAAQNwOisRNI22/cKNbB105KoHzxocgtl6acUuLpQjRZIk+vTpQ/ee3WnSvAnvvfseN8y4gbfmv4VTdtKybUscwQ4jSCubaR7ZHJNoItQaiiPIgSwZhcKr5xhUIy4uDlmW+eqrr3j6n0+zZt0aNEnjtPs0mq5R7C5GR6fEU4KiKZxynULTNU64TgBQ7C5G0RSOO4/j9rt59JlH6dO/j3Etq37ZR48cRdEU8iryuHvG3ezO2k1sXCzv/OcdnH4n9z56L0NHDuXtV99mytQpfPrNp3g9Xv4w4w98vPZj4hPj+dfcf1FQWkBuaS5uxc0J7wn2n95PSUUJHp+HnJIcKn2VHCs/xr6SfejoeFQPh0oPUVReRJm3jD3FewDIr8inxFPCnuI9SCaJvSVGgZ8Sbwl2k519JQa3ls/v4+DJ/Tg8JiRVYMCQ/nQd1QefVef/li1EluVadNAAsiLiqar94HM68ft9jBkzgr/c9yc0UUcTQBN1Vq9ciyrqePEj+RQkj2H+ai4vumBCKyo3OnT5EAQZsdQLmo5UZsR+5AoFQdWxnFYQ/TohXhOOEh2v04TmVwnxmLnzT/eye9ceYhvEsfDjhQgIfPD+B2xavYmlnyzBbrKg+1V0FDRzCHq5Rt9mV5HaKAVvnpu2XdueEeQ1hTtCnd+MXmUI1fe/rmlUusoQPBp+j/vMxEaLBXNocJXhFOis6mXaeDvQdWM+jPFmLSGIIoIkVm2TatR0/u/jchTAUaCLIAh2DBdQf2ALsBYYi5EJNBVYdrmD/LnhVVT2FJSz41gpO46VsrugnFCbTGq0g9QYB6mxDlKjHSSE2RBFgROVXoYt2UpRzmlkQWB6z8bM6ptKmL12dSJd13Fv2ULxm29RuXYtgsWCaeQkdlh6UpTnJbVjDL0nNsNk8ZH1wwx0fRVeb0NSm9xLgwZjMJvPZGe4XC4OHjwYEPrVLoiQIDvy6RMIqoJZVQ0rw2o1LA2z+YqnZOq6wUy5c/dOvKqX2Eax+FU/GzZvICYhhm49uvHA7Q+w/IPl3HT9TaSEpgT2NYnnfjyr0zz9mp9CZyG33XsbhUWFHCo/RLmvHLtsx2lyEhQaxOerPqdD1w689c5btOvSDq/Ziz3Ezoo1K2jfpT3vL3gfVVcp8ZTQuXdnXn/1dVpd1Qqz2cyhA4eIaxCH0+9E0zVciou5L8wNjMOrelF1FVVXUTSFKTdPYfF7i/lm9Te069AOgKjIKNyVblZ8uoKhI4ciizKiICJLMlaTFZvJSMUNkoPo3rM7X370JVcPuJq9e/aSszuHYEswad3SeOqBp9ArdcLDw1m1bBU3zbiJaHs0giAQY49BEAQcsoMgcxBxQXHoqoaAQKhTZvP27bTskE5kbBwWv4+83DwGDxhMo8aNmD5lOvf/+X5iYmMoKSnBWeEkPjkB0SQRnBDH0FEjGT92PPc88FdiY2MpKSmhsqKSoQOv5fEH/4bLq5OS0piS4hLCQ0OJjIujvKyM4ChjbBaHA6vDQXJacyKjosg+fJQePbrz4ptv07dvX8Ji4zCZZYLCwnFERFLu9iAgIPnhuSf+duamn6jk6w0bmPfs8yxd8D5ypQ8/PgRB4HRFBTExMchmMzl795Gbm0u0PYiyY/mBWgoWmx0dUBQ/qt+PqvhR/QqK4kfz+9G02qnB9cFktmALCTX6tNoQ/8uMo7qm46704yz1Un6y8rL7u5wYwPeCICwBtgEKsB3DpfM58IEgCE9UbXvjskf5X0beaRcbCxTWLtvFjrwysgvK8anGwxEbYqFNQigVHoVV2UUs2nKmCIVNlkiJDiLnlBO/T6VT82j+Nbw1SRG1aRJ0RaFi1SqK33gTzw8/IIWHEzlrNidbDGLdZ/kIFQoDprckrXMsHk8BW7fditO5H0GYRNcujyIIhnvj2LFjAYGfn5+PrutYrVZSUlJISognf+M3HNmyjuRmLQkOCycq6dw++p8Kum5YrS6/C5fiwuV3oWgKh08e5sn7n6SyvBKzbCa1SSqvv/Y60RHRDL92OG+//TYL3ltwzj79mp/TntO4FTc6Otkl2eRX5uNRPJz2nKb9Ve2xSoYwDbeGY5WspEWkseDdBcyaOQu3y03jxo158y0j6LjgnQXcfNPNCILAwIEDsUgWWka25KE7H+LBUw8y+erJteigw9VwzJKZtPC0OuMLMYcQFxRHk7AmADz28GO89OJLTF09ldtuvY1rul9DXFwcnTt0JswSRsOQhlgkC3FBcSQFJ2Hz2pAEiYTgBO678z6mT59O/079A3TQUbYo2jZpyzN/f4YJwyYEgsBTr5sKGJxK0fZoAOyyHbtkw+zScZWVAeAIj6C40sWoEdcZQckqOujrJ1wfoIMec+2YWlTPjqYOBAyllNw2mblPzGXkNSNrtWnWpRmvzX+NiddNrEUHPWbsOMaOHcvyFSt54YUXjLdMswWL3c67775bhw7a6ghGlEzYHME4wiMwl5UjShIxyY3RVBXF50Xx+VB8Pv7ywEN4fT4mTr8JRJEuV13Fq/NfZf3SjxgzaQqyLCOKIq+88iqNmzXH53bjdbvwOp2cHb0RBAFJlpFMMmarFVEyIQgiglhlkQtnXEEIAl6fn5DQ0J/ol1L3Gdc1Dc2noPoUNEVFVTQ0pYoxVxeoLHbxyoxVaBcxYfPH8Jung9Z1nbzTbjYdLOb7gyV8d7CY/FIj88JulmiTEEq7hmFkJIXRLimcuNDabpLTTh8HTlZy4EQl+4sqWH64mDy/n5t6p/BIh8a12mouF6VLP6Lk7bfx5+UhJzckcvp0LFdfw7olh8ndfpL4pmH0n9aCkEgbpWVbycqaga77aN16Hls2O4mOjiY3N5fc3Fw8Hg9gVENKTU2lSZMmJCQkcHBbJl/Nn4fP5aT7+OvpMGwk+/bl1KGS/Smg6RrF5cUgExD41ZOsZFE2BJJsJ8gUZPDT/1gaqqbiVb24FTce1YNH8eBVvAFXjCiI2Ew2rCYrVsmK1WTFIlnq9PtzU/fWhys9Jl3XcVeUU1lSjKaq2IKDcUREIpnkn21Ml4IrMSbF78fndhlC3yQbkxPrqcfwU41L13WjfraiGPWzFQVNUVD9Gqqio2kYH11AQ0BDQq9vbk5VDQ5B1zicf5BT736P3Qb2YBOOCCvN/3zj73TQl4Jv95/ko235fH+oJCDwI4LMXNU4glt6NkYsPsika/oGipqcC+FBZjoFRdCpUQQvHCnikMPPH5KieST1TPKTcuoUJe+/z+mFH6CVlWFr146Yv9xLcL9+HNtXysdP78RT6afrqCa0u7ohoihQWLiU7L1/RZKi8Xpms+iDLE6cMHzWDoeD5s2b06RJE5o0aYLdbrxheJyVrHz53+z5di0xjZow5KG5RFUVKfmpoGpqQNC7FJdhkes6+MEiWQi1hBpCv2qy1fmgaAoexRMQ9G7FjU89MzdAEiVsJhsOmyPgKvmdeqF+eF1OKopPofh8mK02guOikC8xpvPfhK7r6H4/useD5vGgezxIbjdeUTJyEaonH9awyM/eVmc71dtq72+ubqv5wO9HO28f1N2mKGhudy2hrlcJ+YCwV1SD70oX0UQZTZLRRBlVlNHFsxSxoCMKGqKgIws6oqQiSQKiSUSSJSSzCVE2GXUsBIET3pMMeu322n38+cbLuv6/SQWQd9rF9Lc2E2KT6ZISwR96p9AlJZLUaAeiaNz8r78+8qPCvyY+PF7C3IOFjIoJ4+Em8QB4Dx6k5K23KVu2DN3vJ3hAfyKm34i9fQaKT2X9klyy1uYR3iCIYbPbEhlv5+SJQvblPI1f+ZSy0gbs2dMDXT9Cw4YNSUlJYeDAgcTGxp5h8tQ0So8XUpCTzbcL38FZepouYybSZfR4JNPl315FU3D5XTgVJy6/C4/iCXxnM9mIsEYgKAKRwZHn9dn7Nb8h7Ks+btWNX/UHvpdFwx8eagk1LHzJet7JW7916LqOpij4vB48FRV4XU4kWSYstgGWoKD/yeumqyqax4vuPSPsdY+nVkaaYDaDyYQgy4FALFr1UqsVoD37Y8RcjcDrlYAJqDltTkdAk2R0kxVNMqOKdjSLCe2s9ExJArNJRDJLmKo+okk8J7vufxO/SQXw4tpcREHg8zt60CDUdtn9rS0u5669R+kR5uBfzZPwbN1K8RtvBgK7oaNHETF1KpaqFL6TRyv46q09nC500rJ3LCGNK1n20esUlRTStOX3REblUVSQRmVRLzqkJpHaNI2YpIZszdqF6HGx+5vVnDicy4lDBzl55BA+twuAiPhERjz+AHGpdf3UF4JqX3u1de/0OwMWuSAI2E12ou3R2E12bCZboChJRUVFQPhX91Et5KsFfk2CteoiJ+GW8IA753zK43dUke95vfi8HvweN36PB7WacVUSCY6Mwh4S+l/hWfox6LqO7vNVWfU1BH6Nmd+CKCFYLUhhYQhWK6LVimCxoAsiFeUVyPYgBL3KlVK9hICQ16u5qAKCn0C+vl7d/qwaGYJQs+COXrWkemcMka5Xn8SZ9arvvH4N0WRB1QVU1ahoV6NDTCYJWRYxySKSuWppEn92IX8+/OZ+dXmnXXy45RiTrmr4kwj/nRUubtp9mGZ2K88XHaRw4gN4srKQwsKImjWL8EkTMUVGAqBpOttXHmHD8iy0oDLEpiV8s28d7AOLqZy2Hb7Bai/Ddawb6p4IPIVb2ZO5gT01jre9ammyWIhObkyLnn2JaZRCTKMUopMbX5TVX02pUFPgVwtqURAJkoMIt4ZjN9mxmqx1KBOqM3GcqhOn0xkQ9jXLF1pMFhyy4cKp9tv/GqtZaaqK1+VEEEVMsvmcfEiX0m9F8Uk8NdlWZRnZaiPIakW2WjGZ68ZA/lswrHrPGWHvcaN5vYaDuwqC2YJosyGEhSFYrOiyBQ0RVdHxKxqqqqGW6aiKC71KaHvLnJc0nkCxImOlepQ1lARVwv2cPZy1PAuagMkkIltETNVC/hcg6M+F35wCeOlrw/qf0afJZfd12O1l8o5cwrwe5v7rMcqydyM3bEjcw3MIHTkS0WYomMrKSnbt3Mt3a7dT5i1CD68Ssied2LweWmYEE5L8DQgqrVu/TWT/HoAhYJ2lpyktLKCkMJ9d27fSvmt3Yho3ISyuwUVTKGu6hkfxnPHh+10BYW0STQHffZAcVCewWr2vW3HX8ttXB3wFVcAiWQixhNQK0P4UPDv/y/B7vbjLy3BXlgeEF5zJMDHJMpJsxmQ2o6nqeXqqr28PpUXH0RQFW3AIZpsN2Wo9b1D3SqG2Ve85s/SfceMJkgQWG0JopCHkJRlNENFUHVXRUb0aulunliNFEJAkAckkIttNiCYRn9+L3W6r+rp29bkzLv7agv5i3SmBNwtjJaATar9pQE3l4fa6CAl1/CIF/bnwm1IA+aVuPtxyjAmdLt/6P368iOt2HMSnqPzjmYeJi4sm4vnnMHftytHdOzn8zSoqT5/m+4NHqPQbP3xBUZBc5ZgqSmkQHUWHwUMJbVLM/gOPIJvjaZv+GkFBZ/LgBUHAER6BIzyCxJatKZEsNO/e+4LH6PK7yDqVxbaibaRr6ewt2Rt4wM2SmWBLMEGmIOyyvVZwVdO1Wlk4bsWNVz1T1UsURKwmK2GWMKwmK5pXIzwk/Fcv7Kuh6zpepxNXeSk+txtBELA6grGFGCmCqt9IWVT9fhS/D6/LFbh2gt9PUHjEed/UdF3HXV5GRfEpREkiPD4Bs/Xy31YvFLWt+qrl2Va9xYJgD0Iz2VBFGb9mWPS6phtJ4QqACoKGZBKQpDMCXjKJSCYBURIRpbqToLQKHxb7lVVytRTIBc589yo/34StK4XflAJ4ae0BgMuy/r0HD5H33nvclNya4w0SeSnzK3r+6xns7dujKn4+ePgvHD+QA4AgiPjjGmFRBOyaicapcYS3akrTTl2JbdKE3Nxnydk/n/DwbrRp/QKyHHZZ51fqKWXbiW1sK9rGthPbyC7ORtEVBATmtZ4XcOdUC3wwsno8qocKX0XAb+9VzlhokihhlaxEWCMCwdmz0zkr/BUXJPyvJB30zTffDMCOHTvIyMgI8MxcCM5H9Xx2m+++XYe7vAxVUZBkmeDISGb+8S7WrVt3TjpoXddR/X7KTp3EXVGOu7KcoNBw7GFhdd7iNFWl/NQJPJWVWOxBjJowkWf/8Y8rQge9fPly8PtRy8rqteqbDxrEhg8/JLpBA6TwcHTZiiqaUTQRv9fIU8cHCCCbBax2I7i5YeO3WG1muvfsgSgKvPrqqz8ZHfSHH37II488QnZ2NpmZmbWuy5NPPskbb7yBJEk8//zzDBo06LKP92vHb0YB5Je6WbzlGOM7JREfdnHWlK7ruLdto/iNNyn9+hsenHUPOQ0bMz8miGGPzQm0WfX6mxw/kENk8ggqyxoANiIsFtKHJAXSOwEUpZKsH2Zw6tRqEhImk9b0IcSzU8QuAMedx9latDUg8A+UGgpOFmXaRLVhWutptI9pT7uYduTl5hFti8ajeCj1lAas+5pplybRZFS9socEXDg/VdrlT0kHXROtW7dm8eLFAQWwcOFC2rZte9n9ng2v243q91NZUozZZic4KhqLPSgwUeh8dNCCIGAymzEHhxAaHU1lSTGVp0twlZfhCI/AFhKKIAj4vV7KigpRFD/BkZHYQ8NBENA0HZ9HQfGp+L0ail+tymc3LGnJJFZZ1oalLYh179e///lPosPD2b52LZrHw7492agHDmCR5apqbQKixYxotyNYrQgWK4LJhBqXjCcoHL9XRfPpgIogasgWCatDRrZIyGap1jE3fr8eh8NBrz69gJ+WDrp169YsXbq0DkPrnj17+OCDD9i9ezcFBQUMGDCAnJycy2ax/bXjN6MAzlj/qRe8j66qVKxaTfGbb+DZmYUYFsaLjz/L9xFxPNMskSHRERzdU8zhrGJyvsukrPBTJHM69rB2tOwVReP0KKKSavsM3e48srJuxek6QFraIyQlXn9hY9F1jvuPsyRnSUDoFzgLAAiSg2gX3Y4hjYfQIbYDrSJbUeYtI7skm12ndvFhzoeMDh2NVnLmFV6WZGwmW8CNUy3srxQulw66PopjgOTkZMrLyykqKiImJoYvv/ySoUOHBo57uXTQM2bMYPK4sZSfOA5AZELSefPrL4QOOiy2Ab3H9aJtm9Z8u3495RUVvPT887Rr2QKP38+f//oQP+zaRdPUNCrKnZQWOSktcrF02RKef+kfgM7VAwYz5/7H8Lo0GreMZ9qUG1m99itiYmJ58C8P89jfHiIvP48nH3qMa/r04djeHBo2aID/eBGCSSItrSmixYIXWLp8OS+8/DI+r48O7Tvx9Nx/orlBU8FV5sNh0fjosw959fWX8St+rrqqMy+//PLPQgd9rsmMy5YtY8KECVgsFho3bkxqaiqZmZl07dr1Ap7O3y5+EwqgoMr6v65jEgkXYP1rXi+2r78h929P4j96FLlhQ2LnPMT8jj35OL+YG6Qgoj4t5I09u/F7VUTRjbf8UxwR8Ux49D5CY0Lq7be0dEsVp49C27ZvEhnR45xjUDSFfSX7DGF/YhvbT2ynxFMCBRBhjaBDbAeub3k9GTEZ2GU7Oadz2Fuyl9eyXiO7JNtoi0ET0Di0MeZwM7FBsdgkG98teI9TRw9f0rWsD6qi0qBJU/pOu/WcbQYOHMhjjz1GWloaAwYMYPz48QwYMIBbb70Vp9NJUFAQixYtYsKECQA4nU769evHM888w6hRo3jwwQf56quv2LNnD1OnTg0oAICxY8fy4YcfkpGRQfv27QNKBgzWzBdeeIHevXszZ84cHn30Uf79738zffp05s2bR69evbjnnnsC7d944w1CQ0PZvHkzleVl9OjRkw4tmmELCa3Kvjn/5Kovv/ySkSNHBtZnz57NnDnGW+KECRP47LPPuPbaa41sIYuVDd9uYNnSJcx98kmWLPiAd95fhEmysW5lJnv27WbA0J5YHWacymn+9uwjbN26lfDwcAYOHMg3G5czfOAgXC4nA7p15ql77mHijFt48u+PsOStRWQfzOX2P8+m/8CRjJt0K9fdMIr/rF5Lrx59mDRhMmlpaezes4sFCz/k44UG1fNfHrybxf9ZxPVTrkeQBCLigzhRcoxPvviITd9tRJZlZs6cyYIFCxgyZAi33HIL69ato3HjxgE66Ntuuy0g8AFWr179o/cDDJK/zMxMlixZwqOPPsqqVat+9NmrRn5+Pl26dAmsJyYm1lLEv6N+/CYUwEtfG9b/zL4/bv378vLIu+MOQvZkI7VNJ/ruP+Fv1YUXswt5Mb+YjIMeGm4uoSjUTFrnWJJbR7D5k+cprFAY89cHzin8Cwv/Q/beB7Fa6wZ7ATyKhx9O/RBw5+w4sQOXYuT3JzgS6JHQA1uJjZ4ZPSn3lZNdks2aY2t4acdLVPgNlhOTaCI1LJXeib1pEdmCFhEtSAtPwy7byc7OJspmkMf9HMFah8PB1q1bA3TQ48eP56mnnmLw4MF8+umnjB07ls8//5ynn34aALPZHKBrbtOmDRaLBVmWadOmDYcPH67V93XXXcf48ePZu3cvEydOZOPGjYBB5VxaWkrv3r1RFT/XjR7F5Otv4EDWTkqKi+nQNh2/18uUKVMMfzgGfXNWVhaLFy1CUxUqKio5UV5J60a179fZuOeee/jrX/8aoIOuxtq1a2vRQbdq2Ya+Pa5G8Wn06z6EytM6bVr35Fj+48jWSDK3fsfsWbcTGe+gd8MupKenY7OJ7Ni8iV5duxLq86EeOcK4vn35+tNPGdKiBWZZZnCXTkhmnbZtWmENshPTOIropnHkTTpKZIKDHrFdyN61j6+++oo1a1fTf0hvln+8im++/YasH3YwZFQ/BBE8Hg/JTRIJjrAiCCBJIqtXr2br1q106tQJALfbTUxMDN999x29evUKUFRHRNSlIq+JmvcDjFoJ48aNC3w/evRoADIyMurc499xZfCrVwAFpW4Wb85j3AVY/5Xr1pF/z71oGhy9/s/YmvTg22+L2bx5J0u6OWhVojMnNobUv0YHXDuZy5ZwbNcOrr5lNlFJyXX61HWVA7nPcPToa7WCveW+cnac2BFw5+wu3o1fM4JvqWGpDG08lHhHPJIoUVBZQHZJNtml2SxaswggQHY2NGUoLSJa0CKyBalhqT9KvwCc11K/FFwsHXSfPn1o06YN77zzDnfddRfz5s0jIiKCjh07BvqRa+TRi6IYsOpFUTwvHfRzzz3Hxo0bjQlpPi+6plGcdwy/10NlSQk6OrLV6Kvi1EkASgryURUFZ1kpqqIw9+E59OxyFVaHg5CoGERJqiWQpk+fzvbt24mPj+eLL74AzpSEfOGFF7jxxhvZunUrHo+HmTNn8u3ajUSGxfLU03MpL6nEVe4DdIJD7QRHWtHkYHQ0wmJsSBJIihut+ARKVWDWe+QI/hMn0N1utPJyBKsVyW5HdDiwpKQgm83YqmrhyiHB2BwOxKrrpShKVaxAJDougknXj2fS9eOx2s1s2vYNJpvOtOnTePLJJ89533RdZ+rUqXXaVNdM+KlQfY8lSQrc4/qudX1ISEjg2LEzxIx5eXkkJNRbi+p31MCvXgG8/HUuOjozz5P5o2sap156mVMvvoi3VXf2tZ7GqWNeTMcLcbcPZ1kjnbZ2K//p05SgGkGlwv372LDoPdK69KBN/7oZB4pSye49d3Pq1GoiY8dw3N6bZ7a9xLaibeSczkFHxySYaB7ZnKuTryZIDsLld5FblsvHuR8HJmU5ZAfNI5rTw9GDq9teTYuIFjQKbfSLmj27b98+RFGkadOmgOGbT05Opnfv3tx444289tprAffPpeCxxx7jxIkTSJKE3+MBUUApLyMk2MGmzO/p268fX7z9Lv0HXE1yWnMiIiPZdyyfzh3as+zDc3fPAAAgAElEQVTfz4GuU3HqJN06deDNd95h0JChhEREkJOTU0eQvPXWW+ccx+zZs3nzzTf5/LMvaNMiA03TsUgOnC4nn61YxtgxY4lKCsYki1hNfkyuUrSTx9EVBc+ebLo1b86Cd9+lR2oq2UeO8ENODqbISLq178A9//gHFVFRREREsHj5cm6//XZEu/2cY6mJDRs20LJlS8LDw/H5fOzZs4c+ffqQnJzMpEmTuOuuu4iJMeigKyoqapWP7N+/PyNGjKjTpkuXLsycOZNDhw7VcgEFBwdTXl5eZwyhoaGEh4fz7bff0rNnT957773A28C5cL5rXRPDhw9n0qRJ3H333RQUFLB//346d+58Qfv+lvHLkSCXgMIyN4s2H2NshyQSw+v/oailpeTfey/l6zdROPBu9vtTsDo1EroINB3ZiTE/HCRJNrEgI7WW8Pe6nHz+/NM4IiK5+tbZdTJl3O48dmbdSqUzhzWuWD7dshxYjlWy0ii0EV0bdEXVVYpcRew+tZtdp4wUxAhrBC0iWtCjVQ+aRzSnZURLEoITEAXRqFLWpM+VulxXFJWVldx+++2UlpZiMplITU1l/vz5SJLEsGHDePvtt3nnnXcuuf/qAuSq4sfrciIHBxMSHcO7773PrNmz+esjjwXoh8EQLDfeeGOADlqSZaIbNmLW7X+kuKKS7r1716KDvhBomo7H6eePM//MU0/+naULP2PaDdPpN6QbsTHRdGzdCr2iDN/ebDSXC39REUpUFJrbjQCYoqOY9ac/cdPtt9N+7NgAHbQpLIzEpqk89dRT9OvXL0AHPWLEiAu+Prm5ucyYMaMWHfSYMWOorKzkiSeeYODAgbWonmsqgJYtW9bbpkuXLsyfP5/Ro0fXooO+9tprGTt2LMuWLeOFF16oNY533nmnDh30xeCjjz7i9ttv5+TJk1xzzTW0a9eOFStW0KpVK6677jpatmyJyWTixRdf/D0D6ALwq6aDnrNsF//3/VG+vqdPvQrAs2cPebffwUl3EAeumkW520TzrnF0H9uULzI3MtcShV/X+bR9U5JtZwKLuq7z+fPPkPPdeiY8+nfi02pnJlQHezXNz8LyBhSqMibBRKm3lJPuk4F2cUFxhvumyoXTIqJFoLBHfbicMpXZ2dlXhA4a/rcohatTLG2R0YSGXd68iguF36virvThdRpVtExmCZtDxiwqaGWlqGVlBnukKCJW895UfUSLxZhB+zPhf+neVeN/cUzw84+rvt+wIAi/00HXhyPFTj7IPMa4jon1Cv/S/ywl7/GnONhsDMfCOxFst3LtLc1o2DKSMr/CUzgoVVQ+zkitJfwBdq39in0b19Fjwg11hH9B4RL27n0QqzWBdm1f58kvbqPAeYjkkGTax7avJezDreFX9Br81qDrOq6KMiz2oCteqUnTdLxOP+5KP4rPyMu3BJmw2iQEVzna8UJ8Xo9BdRASghQejkvTCA6pP0ngd/yOnwO/SgXw5a5C/vKfHzCbRGaelfeveb0UPTGXA6v3kHPVQ3jEINL7JnLV8BTMVhM/VLi4dfdh8hF5u0kc4fmH2HnsCKeOHaX42BFO5R3FXV5Gw9bpdBoxJtBv3WDvPGQ5lJcGvESsPRaH+fzFqX/H5cPrrERTVOxRofguoLzfpcDvU/FU+PE4/Ya1L4s4wi2YdS9a2UnU4xVGEQ+bDTk+Hik09IyFX3F2Tarf8Tt+XvyqFIDLp/D4Z3tYmHmM9MRQnp+QUascoz8/n4N33scP/lYUpc8kPM7ONTe0IC7FmML/Zt5JHjlQQAgaE1f8H1mvZJNVta9stRGV1JDUjlcRlZRMy979A9P4FaWS3bvv4lTxGhISppDW9MHAzN7qMoG/48rDVV6GJMuY7XZ8lZdfL7UamqbjdflxVxjWPoKA1W7CYgHRWYZaUIpfURBMJkwRkUjhYYi/gGIsv+N3/GoUwO6CMu5YuJ2Dp5zM6NOEuwakYTadyXev+HY92594l72J41DNQXQa2ogOgxshySJlfoW79x3j85Nl9Amx0eHNp7GrCp0mTSOqYTJRSckER0bX65s3gr234HLl0iztURITp/w3T/t3VEHx+fC53TgiIn8iGmYNv1fF51bxuPzomo4kizjCzMiKC630BJrbjSYISI5gQ+g7HP8TfPy/43dcKH7xCkDTdN7ccIinv9xHmF3m/ZuuontqVOB7XdM49sIbbFzvorjxBKIbWOh/c1siEwyXzLYyJ3/Yc4RCr4+Hm8ST9Ml77D9dTMrYKXQeMfa8x645s7dd27eIiOh+Rc/1d5wbrvIyBEHAFnzxPnaDrM0Q+NUfValyIQlgsclYTApiZSlqXjmKriFaLMhxcUZBk5+g8trv+B0/B37RT+7JCi9//nAn3+ScZECLWJ4em05E0JmJUEppGZvum89upSVEynQbkUzbQSmIooCm67xy7CR/O1hAnEXmk4ymhB/ay9Jv19J17ER8EVHnOfKZYK/Nlkjb9New2xuft/3vqB+6pqNpOppqlPqTqimC6yE0Oxc0TcNdUY4lyHFBBXE0Ta8iVjvzqebyF0QhQHRmknQEZzlaSSG6348mSUjhYZjCwhBstl8dNfDv+O3hF6sAdF3npnc2s+94BY+PaMWULsm1fpBFm3ax+pUtnLZ1IDbKy4C7exAWY8QDin0Kf9x7lFXF5QyNCuWfzZOwq37efm0eEQlJdB55Hes3bDjHcVUO5D7N0aOvExHendatX0CWQ6/4+Z4+7iQ/U2Nl7m50zRCWulZVqEPTDap23RCmuk6dNo16mygprKqypGNwoYsgCoawNT4Gc6VYvS4Q+E6suX4OwXdmLFUCvWpZvf70s0+x5D+LESURQRB59m//pn27+jPYRNEoji1KRsEQURIRqzjkqwtnf/PN1/Tr148Xn3+e0UMHYw8JrZcOWlVqW/eK70xhFkkWOX4qnwmTx7BzZxaSCGpFBWrJaTSncb1Eh4M8r5eREybUSxk9bdo0Fi9eTFFRUSBN8M477+S5557j5MmTREWd35i4EHzyySfs2bOH++6775xtNE3jzjvvZM2aNUaNAquVxYsXB6gargQaNWrEli1biIqKolu3bgEajotFUVERN910E8eOHcPr9ZKSknLemb9g0ItUXkKs5+OPPyYtLY2WLVsCMGfOHHr16sWAAQMuaew1MXnyZLZs2YIsy3Tu3JlXX30VWZb5+uuvGTFiROBejB49OsARVU2KqKoqN99883nv8U+NX6wC2HGslKy8Mh4f2Zrru5yZtKKpGpue+5KsvRKiOZoeve2kT+gbEFrflVYyY88Rin0Kc5smcGNCFIIgsHbBm1QUn2LCo09jkutnxVSUCnbvvptTxWtITLiepk0fuCQa54uBrutkbyjk28U5aBroleUGrbQgIIpULWsK5zNCWpQEBJNQax2M8hc6hpJQVWNiULXwvhAIQpWyqOpXVXU8pRXn3X/Ltky+XPEFa1asx2azcrq0GL/iJyjMYgh7yTgnTdXQFB1N1YyxqXotC70myk64adGsJYsXL2bstdfi8wi8+877pLdJR/XrlJ10GzTGqhYYt8ksYg8xGzTGFglREin3WhDQ0U4cRykrQ9c0BLMZU0wMUlgYotmM6Ue4aVJTU1m2bBlTpkxB0zTWrFlz0VQEqqqec/LS8OHDaxHg1YdFixZRUFBAVlYWoiiSl5dHUFDQRY3hcnCpwh8MIXz11Vfzxz/+kYqKCg4dOvQTjqw2Pv74Y4YNGxZQAI899thP1vfkyZN5//33AZg0aRKvv/46M2bMAKBnz5589tlntdqrqsqsWbP46quvSExMpFOnTgwfPjwwtiuNX2zEamHmUexmiZHt4gPbThwsYeEfP2VHjpUYrYAJf21P24ldDCGl6/z78HFGbz+AVRT4rENTbko0AruF+/ex7ctPaTdwKAnN6p8s5XbnsWXrdRSXfEOztEdp1uyRKy78PU4/X76Sxdr39xJld9PO/wmDorYwpOVRhvf1MvK6cMbd3oxx93dk3P2dGPuXjoy5tyOj/9yBUX9qz8i72jPizgyG39EOe4iZsBg7YTF2QquW4XFBRMQHEZXoIDopmOiGwUQlBROZ4CAiPojwuCDCYuyERNkIjrTiCLcSFGrB6pAx20yYZKlKeIPVLmMPteAItxISZTP6bxBEZILRt0cvJy4+lgaNIgiLtdO4WRIHj+Uw7eYp2ILNWOwym75fz7gJowkKs9AgOZq5zzxMzwGdmTh9FIcKsxl3w3Cu6tOOdd+vwhFmwWwzkZSUiMfr4cSpSpxlXlZ8uYLePfqj+Y0JWtk5uxg29mr6D+vBrX+8ASw+HOFWdmVnkZHRjvRWrXh+7lz0qsIoelAQD77+Oj0nT6bDgAG8doEzVSdMmMCiRQZP09dff0337t0x1XBHjRw5kl69etGqVSvmz58f2O5wOPjTn/5E27Zt2bRpE1988QXNmzenQ4cO3HHHHQwbNgyAt99+m9mzZwPGG8cdd9xBt27dSElJYcmSJYBBud2gQQPEqkB0YmIi4eHGXJMZM2bQsWNHWrVqxcMPPxw4fuvWrbn//vtp164dHTt2ZNu2bQwaNIgmTZrwyiuvBM6nV69eXHPNNTRr1ozbbrsNrZ40W4fDEWjfp08fxo4dS/PmzZk8eXKgItq5zq+wsJDExMRAX+np6YH/n3nmGTp16kR6enqtsdfEudq8++67pKen07ZtW66//no2btzIJ598wj333EO7du3Izc1l2rRpgWu4evVqMjIyaNOmDTfeeCNer1EcqVGjRsydO5f27dvTpk0b9u7dW+84hg4dGqgR0blzZ/Ly8uptV43MzExSU1NJSUnBbDYzYcIEli1bdt59fkr8It8Ayj1+Pt1ZyMiMeIKthhAu3H6Ij1/Zj8mv0yUpl/YPTQ8E5054/czOPsK605WMjAnjmWZJBJsMS0tV/Kx89XkcEZH0nDi13uP9t4K9uq7jz8vDvTOLo5kHyTyejBcrqQc/ISlvDbrVwql1K+sUtRZsNuTYWEyxschxsZhi4zDFxSLHxVVti6u1T+mnufgKLq3odn1QVQUpKZSwa8+d8nq5dNAPzXmIVavO0EGPvW409hAzAhrXDhnC2k1ryMhoT6fOHQiNcGCyQFSig1lDb61FP/zII4/wz8ceY9qUKfzzL/fRo2MHHnjuOQSTCWuzZrz2xhuER0WxefNmvF4v3bt3Z+DAgT/q709LS+OTTz7h9OnTLFy4sBbDKMCbb76JLMuYTCY6derEmDFjiIyMxOl0ctVVV/GPf/wDj8dD06ZNA/TKEydOPOfxCgsLWb9+PXv37mX48OGMHTuW6667jh49evDtt9/Sv39/pkyZQkZGBmBUY4uIiEBVVfr3709WVlZAyDZs2JAdO3Zw1113MW3aNDZs2IDH46F169aBYi6ZmZns2bOH5ORkBg8ezNKlSxk79txJEtu3b2f37t3Ex8fTvXt3NmzYQMeOHfnDH/5Q7/nNmjWL8ePHM2/ePHr27Mltt91GfHw8K1euZP/+/WRmZqLrOsOHD2fdunX06tUrsO+52kRGRvLEE0+wceNGoqKiAlxFw4cPZ9iwYXXG7/F4mDZtGqtXryYtLY0bbriBl19+mTvvvBOAyMhItm3bxksvvcSzzz7L66+/fs7z9/v9vPfeezz33HOBbZs2baJt27bEx8fz7LPP0qpVK/Lz80lKSgq0SUxM5Pvvvz9nvz81fpEKYNn2fNx+lYmdGwJQtn4jK187jEmyM3ykndjhtwTariupYFb2ESoUlX80S2JSg4haP+bMZUs4dewII++dg9lWd8ZwQcES9u67MsFetawMd9YPuLN24sn6AXdWFv7SMg41uoYjDQcSRAX9EnOIHz0MW5v72ZCTQ+8ePVBOnsR/vAil6LixPH7c4JUpKsK5eTNK0Qk4qwC5/8V5eCQTgmxCrahA9ylGMe0qd1Lgc4H1US8WV4IOWlNVVFXhunHXcfOsWezbl8OkyZPYuHEjgijUoh/WPB4mDRnCxJtu4sT48ZSWldFn8GCk8DCm3X47KzdtQpCkAB10tUVYVlbG/v37SUtL+9FzHD16NB988AHff/89r776aq3vnn/+ef7zn/8giiLHjh1j//79REZGIkkSY8YYEwr37t1LSkpKwE88ceLEWm8LNTFy5EhEUaRly5YUFRUBhvDYt28fa9asYc2aNfTv358PP/yQ/v37s3jxYubPn4+iKBQWFrJnz56AAqh2LbVp04bKykqCg4MJDg7GYrFQWloKQOfOnUlJSQmMa/369edVAJ07dw5Y9O3atePw4cM4HI5znt+gQYM4ePAgX375JZ988gkZGRns2rWLlStXsnLlyoAiq6ysZP/+/XUUQH1tdu7cybhx4wIxmB+jq963bx+NGzcO3OupU6fy4osvBhRA9XXq0KEDS5cuPW9fM2fOpFevXoGiNu3bt+fIkSM4HA6++OILRo4cWatq3M+FX5wC0HWdBd8fpVV8CK3jQzg1/zU2LTtEZdIABo2NJXZAKwAUTecfh4/z7yNFpNotLG7bhBaO2nTQxXnH+H7pIpp160WTDp3POo7G/gNP/mTBXt3nw7Mvp0rYZ+HemYWv2q8sCJibpEDPIfygd6a4QqZF11h6jO+D2VrjFu3fjyDLyPHxyPHx9R4HjEpmSnExSlER/uPHUY4XUeBwINpt6H4/QR3tRt3XOjxQAoJsQjCZEGS51ofqbSZTnVz3n4sO2us26iU0atq0Dh00gK4ooGl4DxxA83hQS0tBlDAnJSGYTMhxsXWvna7zwgsv1Kkn+2N00ADjx4+nQ4cOTJ06NeCGAcMlsmrVKlatWkVsbCx9+vTB4/EAYLVaL4m0rGbRm5p8XhaLhSFDhjBkyBBiY2P5+OOPSUlJ4dlnn2Xz5s2Eh4czbdq0wPFr9lXzOlevV1/rs9+AfuyNqGY/Nemdz4eIiAgmTZrEtddey8SJE1m3bh26rnP//ffXKQFZE+dqczYR3eWiPrrqQYMGUVRURMeOHQNvBI8++ignT56sZQSE1KAAGTp0KDNnzuTUqVM/O431JSsAQRCaAYtqbEoB5gDvVm1vBBwGrtN1/fSlD7E2dhwrZe/xCh4fkkr+7XdwbMsRjmbcScuuMaRWCf8Cj4+Ze47wXZmTCXERzE1LqMXkCcb8gJXzX0C22uh3Fj++olSi6fM4enQniYnX0zT1QcSLoF6u6cpxZ+3EszMLT3Y2elUNXCkqClt6OqEjR2Jrm461dWsO7K7km4U5iJLAoFuak9oh5pKvkSBJyDExyDEx2Nq0AaAoOxtzjVdNXddBVdH9fuOjKGf+9/vRPF70ykqox9cbUBAmGUE2ISoK/kpn3ZeHGkJi34EDiKJE0yaGFbl1wwaSYmLo1qIlN27Zwqvz5jFu+HCUkyeN/XQd5dQpADSXC00QUIqLA/0pxcV4KysQBBHB6WTOn//MyVOn0MvLDXZNrxfL8eOEBQWxfvNmeg8cyOLFi+lz9QAik5IICwtj/fr19OjRgwULFgT6HTRoEC+//DL9+vVDluWLooNOTk5m7ty5dbJJysrKCA8Px263s3fvXr777rt692/WrBkHDx7k8OHDNGrUKBBTuFBs27aNuLg44uPj0TQt4OYpLy8nKCiI0NBQioqKWL58+UWTCmZmZnLo0CGSk5NZtGgRt9568TUlznd+a9asoUuXLtjtdioqKsjNzaVhw4YEBwfz0EMPMXnyZBwOB/n5+ciyTEzMmd/HoEGD6m3Tr18/Ro0axd13301kZGQtuuqKemg5mjVrxuHDhzlw4ACpqakXRFe9YsWKWuuvv/46K1asYPXq1bWMgOPHjxMbG2vUEMnMRNM0IiMjCQsLY//+/Rw6dIiEhAQ++OAD/u///u+ir+2l4pIVgK7r+4B2AIIgSEA+8BFwH7Ba1/WnBEG4r2r9Lz/BWIGq4K9JIP2pP1NaUEhOn78RGmKnxwQjeLuquJw7so/g0XTmtWjI2Lj6X/t2frWcgn17GDzzLuyhZ1gjVdXFjp03Aj/QLO0xEhMn/+iY6nPlqKcNnSdYrVhbtSJ88mRsbdOxtWmDKT4+YEF53QprFu4jJ7OIBqmhXH1jK4IjrjyNgCAIhlVvMoGt/kI5uq6DptVSDLUUhc+L5nIiahqKIBipRehndwJAWV4ef3ryScoqKjBJEikNGzLv4YfRi08xuHt33l+2jPkPPYS/yp2BruM/btThVSsrUTUNf2Gh8Z2m4S4qQlM1RFXFX1BAp8RESEzEn5+PWlGBEBSEKSKCt995h5l33onrySfPSwddjZtvvpnDhw/Tvn37i6aDBuq1VAcPHswrr7xCx44dadGiRa3ShTVhs9l46aWXGDx4MEFBQYEKXBeKEydOcMsttwQCl507d2b27NlYrVYyMjJo3rw5SUlJdO9+8TGsTp06MXv2bA4cOEDfvn0ZNWrURfdxvvPbunUrs2fPxmQyoSgKN998c+D77OzsQG1fh8PB+++/X0sBDBw4sN42rVq14oEHHqB3795IkkRGRgZvv/02EyZM4JZbbuH5558PuPrAeBt76623GDduHIqi0KlTp4suaH/bbbeRnJwcGEt1uueSJUt4+eWXMZlM2Gw2PvjgAyMrzWRi3rx5DBo0CFVVufHGG2nVqtVFX9tLxU9CBy0IwkDgYV3XuwuCsA/oo+t6oSAIDYCvdV1vdr79L5QOutzjp/NjK+h7ZAt3HV3NoVF/I3e/n9H3dCC2cQhzDxYy7+gJWjmsvNqqEan2uoJU1zQ2f7qUDYveI6lVOmP++lhAGKuql6ysWyk5vRFRuJW+fe+pu/8FuHJsbdINYZ+ejqVpU8OFUg+OHyzjqzd3U1HipfOwRrQf3MhI8TwHful00HWetR9bP8+20pMn8Pu8RMUnBt4YasLp8fzPMW9eyHWqrKzE4XCg6zqzZs2iadOm3HXXXT/rmL7++mueffbZOimMl4ILOb+fm3b5XPi5x/W/TAc9AVhY9X+srutVphrHgbqO1kuA7vPx7t/exKMlMcJcgvDEWxxYeJSOQxsRlxLK6uJy5h09wcQGETzZNBGrVDfDtaL4FMtf/CfHdmeR1qUHV99yppCLpvnZtfsOSk6vp0WLv5OzL+qSXDnSBTwgmqaz7cvDZH52+P/ZO++wKK79D3+GXVj60qUpRfqyywL2jsQK9hZNrDG2RBMTjebGn1dzY6KxxHiNvWKiieWq2BtgiS1SBAREEER6kbJL3XJ+f8COIL2vMO/z8ACzZ858Z3b3lJlz3gNtfQ4mrvCAqW3rTyZrbxTXmhCCovw8iN/kQIXFApvDgaoaB2yOOlQ5HKiwWFXuMZfPUZBDJpFAJpVAKpGgtLgIWnr6UFGrZQnMilbw+8b+/ftx9OhRlJWVwd3dvc573+8jHf383jea3QOgKEoNQCoAHiEkg6KoPEKIXqXXcwkh1cT3FEUtALAAAIyNjT1PnjxZ6zFUcvOgu38/lluNB6WthX8N6YK46xRUNQHbYeWjV9ZAG/lQwXYUgF1DIzr3ZSxeBV0HkcnQdeBQGDq6vi2QSkvAyt4LlZwIsHN6gp1jBKSkQOP1a6hUzDQkqqqQWHWDxNoGEhtrSKytITcwqHKfuyGUFRKkPCQoygK4VoCZJwWWWsPyULSemgKXy4WdnV39CZtAXROY3oXI5SgV5UNWWgqWGgeUCgW5VAp5pYeElIoKVNiqAEWByGQgMmm13oMKiwWOnkGt3v/GxNRWMDE1DGWMCWj/uOLi4pCfn19lm5eXV7v3AEYBCCGEVNy8RQZFUWaVbgFl1rQTIWQfgH1A+S2g2m5tFD58hJQtaxClZogErjk2jHdFaUg+IHuDCUt7wsBcCzey8xEfkYCtjl3xgblhlf0lJSUIPLwH6deuwMbQBD0GDICquAiSCxdRlpJcfs84W/FwURVAGCg1NUiMDKE/bFiDbuU0lLjgTAT5x0AuI/hgriMce5s2av/m3gJqre5rQ7vGZcXFyM9Mh1wmg66RMTR0uZV6YHJIS0shKSst/11aChA52GpqYKlqgsVWBUtVteI3m1ZxNzemtoSJqWEoY0xA+8eleJbTkrREBTAdb2//AIA/gNkANlb8btK0NkII3hw6hMyt26BmbY07k1dCM1EMx1IVPArPxoAp9jAw1wIhBFtfpsBdnIcxr8uQ9/AOJMnJkKQkozAuHoXxcbAsKUX5+JckFPz9BGCzoWpmBlULC8jd9VGgngF9J29Yui+EqqUF2EZGuH3nDvhNLGzfRVIqw92TsYj+Ow0m1roY/okLuMYNW8y7I0AIQWFeLsS5OWCxVWFgYQlVTtXnMyoqKlDT0IBaLQ+kGRgYWp5mVQAURWkBGAag8o28jQBOUhT1CYBXAKY2Nl+ZWIy0b/8F0Y0b0BkxAlrf/RsPfr6O2UbA650nwFcvhHFAAF4dS0FB0mtsTk8HWy5DytvAAH09vCkrgURPG5YDx8DI3QOqlhZQs7QE28QEFJuNlwn/RUrC9vKhnvb/blG7IyHlC4RnJ4lx569Y5GUWwXOkFXqOsQGrhucTHRWZVIqCrAyUFhVBXVsbukYmrb5cIwMDQ8NoVgVACCkEYPjOthwA3o3NS5qbC0lyMoqePEHOvv2Q5eVBzcYGpbGxyPcegkOSsirpxQlGULWwwFMrW6S698a8Xm7Q6GoJVQsLJCQn4tLOrbBwdMHYr/9VoyM+KekQEhK2w8x0Ihzs1zap8CeEoFgkQX5WMfKzipCfWYz8zCLkZRYjP6sYZcXl97W19DgY/6U7LBw71xrAZcXFyMtMB5HJoGtsAg0dXUahzMCgRCjFTGD269d40bdflW0qWlpQ0dSEqoUFruraIVNNH84lhhBO7wWHUW5Q0dDAtex8rIhIwC9OXWFkVl4PxQc/wuXftsHUzgETVtWsd0hJ+RMv4jbA2HgknJx+AkXV3iKnC3m6YC8qL/ArCvuykrfKBYoCdAzVoSmrguoAACAASURBVGeiCVMbXXBNNME11oCZvR44GkpxqduMsuIi5KanQoXFhr5FV6hyONiwYQOOHz8OFosFFRUV7N27F717927yMYKCguDl5YX9+/dj/vz5AFCjDro+EhMT4evrW6PquSFpGB00o4NWsHPnTmzfvh3x8fFV3vs//vgDmzZtAiEEOjo62L17N9zc3ACUX0MdHR2wWCyw2Ww8efKk2XE0FKUolYiWNjR79kDRP0/AcXKCxbZt4NiWf2hDk3Kxedd9jChRRV9nMzhOKB+9QwjBloR0WGuoYUqX8sleCWHBuLDtJ5hY22LSt+trLPzT0/0R83wNDA0Hw5X3S40zfHPTC/H6vhx//f24XClcuZBXoSoKeQ2Y2pqBa6wBrkm5/VLHUB0sdue5vVMbisKfxVaFvpkFWGw2Hjx4gIsXLyIkJAQcDgfZ2dkoKyurP7N6cHV1xcmTJ+kK4MSJE/QXqy1hdNCMDhoA+vfvD19f32qDNWxsbHD79m3o6+vjypUrWLBgQRXpW2BgYIs0FBqLUpRWlKQMRf88gf7MmbA5+Rdd+APAHw9fQQ2AUE0Dgz9ypG8hXM3OR4S4GMutTMFWofAqIgz+WzbAwLIbJv3rP+BoVv/gZ2XdRFT0Cujp9QLfdRdUVKqPISeE4NbRaIhTAU1dNTj1NcOAqfbw/dwNH63vg4X/HYyZ/+mLMUuFGPShA9y8u8KabwS9LppM4Y+aC3+g3F5pZGRE+1SMjIwQHh6OKVOm0PsGBQXRemBtbW2sXLkSPB4PH3zwAR4/fowhQ4bA1tYW/v7+9D5WVlYoKSlBRkYGCCG4evUqRo0aRb8eFhaGPn36QCAQYMKECcitmKEdHBwMNzc3uLm54bfffqPTy2QyrFy5klYLvyt1qw1GB83ooAHA3d0d1tbW1bb369ePfi/69OlTrya6rVCKHgBVVgbzLVvA9fWpsj2/WAL/sFQ4lbIwap4zNLTLC2w5IdiSmA5bDQ4mddFHclQkzm3+D/RMzTD5u/9AvYax8m/e/I2IyKXQ0ebBTbAXLFbNuoX4kCxkJBTAvBeFMfOELX+ySsCVK1eQXqFZaAlkMhksLCzgPWQwctNSwVKtWvgDzddBr1mzBjduvNVBV24NT548GadOnYK7uzs8PDyqiMhmzZpVRQe9fv16bN++HXPnzsXOnTsxaNAgrFz5dsb3wYMHweVyGR00o4Nulg66Lg4ePFilkaLQkVAUhYULFzbJs9RUlKLJKjU1rVb4A8D6k+EokxFM4pnBmv+2e3Q1Ox/PxCVYbt0FmXEx+N+m9dA1NMbkNT9AU7f6jNq8/GA8DV8ILU0bCIWHwWbXPJZXJpXj4bl4GJhrQc+6xU6vUyCTSmst/IG3Ouh9+/bB2NgY06ZNw++//07roKVSKS5duoRx48YBqK6DHjx4cDUdtIKpU6fi1KlTOHHiRJVCpbIOGijX+965cwd5eXnIy8ujC5GZM2fS+1y/fh1+fn4QCoXo3bs3cnJyGqztrayDVmiAFezYsQP9+vVDnz59aB00gHp10LVRlw76p59+goqKCry9vXHr1i0AwMmTJ+Hh4QF3d3c8e/YMUVFRdF6VddC9e/eGjo4OjI2Na9RBs1gsWgddFwodtIqKCq2Druv8FDroTz/9FLGxsXB3d0dWVlYV1bOHhwdiYmKqvR+1pQkICGi2DvrOnTvVrpOnp2e1z2BDCQwMxMGDB7Fp0yZ627179xASEoIrV67gt99+q3LM1kYpegCkhglWf8dk4n/R6ejL4mD6x2/lSPKKe/+2Ghz0FWXhzI//hpaeHqb83wZo6VUfZVMgisTTp5+Aw+kCofAoVFX1qqVR8OxuKvKziuHzmQCJObU/EHzfqdz6aAnycrJRmp9Xa+GvoKV10ApMTU1r1EE3BUYHzeiga6OhOujaCA8Px/z583HlyhUYGr4dPKl4VmRiYoIJEybg8ePHVXo4rYlS9ADepbhMhuXHQ6Eno7BhlkcVJ/7lrHxEFZZghlyE//3nO2jo6GDK//0IbQPDavkUFsYhLGwu2CwdeLgfA4djXOsxy4ql+OdSAiwc9WDlWj0vhpopLS5CSQMK/+fPn1dpuYWFhcHKygqDBw9GSEgI9u/fT9/+aQrff/89Nm3aVKUw5XK50NfXx927dwGA1vvq6enROmgANeqgJRIJACA2NhaFhVVXTzt8+DDCwsKqjVJR6KCXLFlSZXtTdNAAmqSDTk1NBQBaB21lZVWjDrqxKHTQcrkcf/31FwYMGNDoPOo6v4CAABQVla/vUFkHPWLECBw6dIge7ZOSkoLMzKpygdrSDB06FKdOnUJOhUb8zZs3ANAgHTSABuugw8LC6i38k5KSMHHiRBw7dqzK4kKFhYV0LIWFhbh+/TpcXV3rzKslUYoewLv8+3gYMsukWOPaFbZOb7ttinv/FrJSFO/4Aea2dhi74jvoGFR/el5cnITQ0FmgKBW4u/tBXb32BVQAIOT6K5SIJeg30Y4Zq94A5DIZCvNyUZSfBxUWq87CHyj3GC1duhR5eXlgs9mws7PDvn37wGKx4OvriyNHjuDo0aNNjqdfv341bj969CgWLVqEoqIiRgfN6KBbXQe9Y8cO/Pzzz0hPT4dAIMDo0aNx4MABfP/998jJyaEbB4rhnhkZGfS1lEqlmDFjBn3rs00ghLT7j4ODA1HwIDqTWH9zkUxZc5NIJTJSmf8lZ5AuAaFk3r++JZf+u4WUlZaQmiguSSP3/h5Mgm57EJEopsY0lRHnlpA9nweSa/sj6G2BgYH17tfWNCemqKioFolBLpeTwrxckpEQT9LiYkleRhrJz8trkbxbkoKCgvYOoRoNiUkkEhFCyq/z4sWLybZt29o9psDAQOLj49Mix2vI+Snje0dI+8dV03cYwBPSjLJXqW4BlUikWP5HCLQJhZ/neVYZVpmXmYF1wc9gkJuFT/v0wKjPvoKqGqdaHmVlOQgNnQWJJBfuwsPQ1q5zKQIAwOMLLyGXE/QeV/ui5p0dQghKCsXIef0KBdlZYKupwdCyK7gmptWWiGRoOvv374dQKASPx0N+fn6H0yV39PN731CqW0DfH3uKNIkUazysYG3z9mFtcnQkfjr9P2QMGIv1mjL06T2sxv0lkgKEhs1BSUkKhG6HoasrqDFdZXJSxYi+nwaBV1dwjRkRWU1ISkogepONsuJisNXUoGdqDo6mJnOrrBVYvnx5qy4A0xQUD+5bAmU8v86M0lQA/0Rl4s/n6eihoYFPplYs7F5Whme3b+Lmkf24O3UpbNVYmN+r5lmeUmkhnj6dh8LCF3AT7IW+fq8a073Lw7PxUFVno8do65Y6lQ4DIQSinGz6Pj/j82Fg6FgoRQVACPDl70+gTmSYa5OBS//djKxXCchNSwGRy5E9dCwydQ3wvZ0lWDUUPjJZKcIjFiG/4Cn4rv+FoWHdT+4VpMTmIjEiB30ndIe6dvNc/x0NuUyGvMx0lBUVQZPLhba+IWPxZGDoYChFBZCTK0KZnGBU1k3EXH4JXeMuMLayhkPvfjC07o750IcjRWGsSfUx/OVLOS5Fbu59uDhvholJw56gE0Jw/0wctPU5EHhZ1r9DJ0JaVobc9FTIpVLoGpvUOLmOgYHh/UcpKgAxSxN9qGJ8980CGFvZVPH4/C8jF3FRr7CPZw2Vd1r/hMgQFb0S2dm34OiwHmZmExt8zLjgTGS+EmHoLGew1ZiWrYLSokLkZaSDoijom1kwC7QwMHRglGL4BgUKu5eNgKWza5XCX0YItiWmw0lLHb7GVVuhhBDExKxBRsYFdO/+DSwtP27w8RTKB0MLLTj2adyyjB0VUrFql0LnYGjRtcUL/w0bNoDH40EgEEAoFFaxITaFoKAgUBRVZRJOWFgYKIrCjh07GpxPYmJivZNv6kozZ84caGpqVplc9OWXX4KiKGRnZzc4jrrw9/fHxo0b60wjl8uxbNkyuLq6gs/no2fPnq1q1QTKJWmKc6xtLkZDyMjIgK+vL9zc3NCzZ0+MHj263n2auj72uXPnqqgw1q5di5s3bzYpr3eZM2cObGxsIBQKIRQKERYWBqD8+7Vs2TLY2dlBIBAgJCSkRY7XXJSiB6DNptDNrLqf51xGLuKKSrH/ndY/IQQv4n5EatpJWFstgbVV44aSPbubgoLsEvgudYOKCvNAk8jlKMjOQrGoAOpa2tA16VJFZdASMDro+mF00O+/DhooN5O+K5q7cuUKXrx4gRcvXuDRo0dYvHhxsxtALYFS9AC0axBzSuUE2xIz4KKlDp93Wv8JCTvw+vUhWFrOhq3tV406VmmxFP9cSoSlkz66udQth+poyOVySMvKUFpUiKL8fIhyspGXkYbs5CQUiwqgrW8AbhfTFi/8AUYHzeigO4cOujbOnz+PWbNmgaIo9OnTB3l5eUhLS2tUHq2BUvQAOKzqrfCzmbmILy7FQdeqrf9XSQeQkLgDZmaT4WC/ptFDEkOvlSsf+k7o3imGMxaLRfjH/wzUu3VHZkKFm//NHpSUxQOgQFEUKBUKKiw2VPJZQGLjjyGTSaHH5cPB4f9qTcPooBkddGfRQX/33Xf4/vvv4e3tjY0bN4LD4SAlJQVdu3al01haWiIlJQVmZma1XsO2QCl6AO9S3vpPB09bHaOM3rb+U1JOIC7uJ5iYjIaz0491LuVYE+LcUjy99Rr2PbvAxKr6OsHtjTj3DUQ5LXPPuKy4CA/OnMCBzz/BP/5nwFJVhbaBIbgmXaCupQ1VdXWoaahDVV0dbDVOqw/xZHTQjA66M+igf/rpJ8TExOCff/7BmzdvqmiflRGl6AG8y/8yc5FQXIbDlVr/6ennEfP8/2Bo6AWey1ZQVOMLrMcXX0JOCPqMs23pkJuMTCrFy5DHiAi4jsSwEBAiRzdXN/CHDoddz75gq1VftawuJGWleHrtEh6fP41iUQHsevZBv6kfI7uwGNr65V8AZ5f1LXoOIpGI1jjXBaODZnTQddERdNCKFj2Hw8HcuXOxZcsWAOXK59evX9N5JScnN/oZUWugdD0AqZzgl8R0uGprYGRF6z8r6zqioldCX683+K47a1zKsT5yUsSIuZ8G/hBL6Bq1/9DGN6nJuP37IexbMgf+W39EVuJL9Bo/Bf2mfIS8jDRc2rEZexfPRuCRfchKSqw3P5lUgqc3LuPQsk9x+/dDMLHpjhkbtmLcijUw7mbd6udTH4wOmtFBdwYdtOK+PiEE586do0eOjR07Fn5+fiCE4OHDh+Byue1++wdQwh7A6Yw3SCguwxFXG1AUhZw39xAR+QV0dPgQ1LGUY308OBcPNQ02eoyybtmAG4GktASxD/9GRMB1pMQ8A6Wigu6evcAfOgLWbh70bZg+E6fhVeRTRAZcx9MblxFyxR+mdg5gm1gguDAPhfl5KKJ/8st/F+RBJpHA3MEZo5euQFde/R6ktoTRQTM66M6gg/7oo4+QlZUFQgiEQiH9IH306NG4fPky7OzsoKmpSX8O2xuqcvexvXB0dCTPnz+HRE4w4FE0uGwWrvVwQH5+MELD5kBT0woe7sehqtq0GanJz3Nx/pdQ9J3QHR4jrBq0j2IkQ0uQmfgS4beuIeZeEEqLCqFvZg5Xr+HgDfaucRWzyhQV5CP6bhAiAq4hJzkJAKDCYkOTy4Wmrh409fSgqcuFJlcP3XgCWAs9a+yeR0dHw9nZuUXO510aeguoLXlfYxKLxdDW1gYhBJ999hns7e1bVZ7WkJiCgoKwZcsWXLx4sdnHa8j5KeN7B7R/XDV9hymKCiaE9GhqnkrVAziV8QavSsrgx7eBSBSJsKefQF3dtGIpx6YV/kRO8OB/ba98KCsuQszfdxB+6xoyXr4AS1UVDr37g+9dPuGtoSOQNHW58PQZB4/RY3Hj4gUM8hoKjpZWpxjB1BnZv38/jh49irKyMri7u3c4XXJHP7/3DaWpACRygu2JGRDoaKCvegZCQ+dCVZULd6EfOGrVV/xqKHEh5coH7zlto3woyM7Eg9N/4vn9O5CUlsCoqxW85iyA80AvaGg3vfVAURTUdHSh3sTZjwzvB8qoS2Z00B0XpakATqW/QVJJGf6vmxbCwmaBolThLjxW71KOdSGTVCgfLLXh0KttlA9XftuG9LgXcOo/CPyhI2Bm78i01hkYGJSSZlUAFEXpATgAwBUAATAPwHMAfwGwRvm0oqmEkNy68iEAfnmVATctNvQT50NOJPBwPw5NzYbdr6+NyDvlyocxy9pG+ZAaG43kqEgMmfUpPH3GtfrxGBgYGJpDc4eB/grgKiHECYAbgGgAqwHcIoTYA7hV8X+diEHhdUkZxkj2QirNg9DtMLS1HZoVWGmxFE8uK5QPhs3Kq6E8Pn8G6to64HsPrz8xAwMDQzvT5AqAoigugEEADgIAIaSMEJIHYBwAxXi+owDG15dXLlTgoPIaLmUBELodhK4uv6lh0YRce4WSQgn6TbRrdl4NISc5CfFPHsJ9pC/U1Nt/ngEDAwNDfTSnB2ADIAvAYYqiQimKOkBRlBaALoQQheUoHUCX+jKSApgg/wNugj3Q02vyiCYacW4Jnt56DYfeXWDcrW2Gbf3jfwZsDgfCEb5tcrz3EUYH3XQYHXR1lFEH/dFHH8HR0RGurq6YN28ePaEwKCgIXC6X1kS3tIG0qTTnGQAbgAeApYSQRxRF/Yp3bvcQQghFUTVONKAoagGABQCg5WALN/RCRIQMQFAzQion5ZEcchlATDIRFJTVpDzEYjGCghoWS5moAM/uBsKEJ8TjkNAmHa+lY3oXLpdb4+zHlkAmk9Wb96NHj3D+/Hncvn0bHA4HOTk5KCsra1ZMRUVFcHFxwfHjxzFt2jQA5RO/+Hw+5HJ5g/MWi8X1pq8rjUQiga2tLf788098+OGHkMvluHnzJszNzSEWi2mFQH3XqS4dtJeXF7y8vOrc/9SpU0hKSsLff/8NFRUVpKSkgMVi1XvM5rwHhBD6HK9du9bkvL799lsMHDgQS5YsgUwmQ3R0dIPyasrxTp06hZEjR9JyNoUMsL68GnKtJkyYgN27dwMA5s2bh507d2L+/PkoKipC3759cerUqSbHXlJS0uTvf60QQpr0A8AUQGKl/wcCuITyh8BmFdvMADyvLy9zB2vSUmQni8jORbfIvdMvmpVPYGBgg9MGHN5Ltk0fS/KzMpp1zPpoTEzvEhUV1XKBvENBQUG9ac6cOUN8fX2rbLty5QqZPHky/X9gYCDx8fEhhBCipaVFVqxYQVxcXIi3tzd59OgRGTx4MLGxsSHnz5+vkn7gwIEkPT2dyOVyIhAIyOrVq8kPP/xACCEkNDSU9O7dm/D5fDJ+/Hjy5s0bQgghT548IQKBgAgEArJixQrC4/EIIYRIpVKyYsUK0qNHD8Ln88mePXsIIYQkJCTQad5l9uzZZMOGDfT53bp1iyxatIhYWVmRrKwsQggh48aNI0KhkLi4uJC9e/fS+2ppaZGvvvqKCAQCcvfuXXLp0iXi6OhIPDw8yNKlS+nrcfjwYfLZZ5/Rx1u6dCnp27cvsbGxIadOnSKEELJ161by+eef1xjjokWLiKenJ3FxcSFr166lt3fr1o2sXr2auLm5EU9PTxIcHEyGDx9ObG1tye7du+nrPHDgQDJ69Gji4OBAFi5cSGQyGSGEVDlHLS0tOv3gwYPJpEmTiKOjI5kxYwaRy+WEEFLr+Y0ZM4acPn2aEFL98/Tzzz/T70fl2BXHqyvN0aNHCZ/PJwKBgHz88cfk77//Jvr6+sTa2pq4ubmRuLg4Mnv2bPoa3rx5kwiFQuLq6krmzp1LSkpK6PNctWoVcXd3J66uriQ6OrrG61yZbdu2kX/961/0NVGca1Op6TsM4AlpYhlOCGl6D4AQkk5R1GuKohwJIc8BeAOIqviZDWBjxe/z9eWljca7fWrjwdl4cDTY8BzZvBFEDaWoIB/hAdfgPGAIdI1M6t9BCfi/F8mIFBe3WH4yqQxuetr4j33tE+0YHTSjg+4sOmigvFd47Ngx/Prrr/S2Bw8ewM3NDebm5tiyZQt4PF6t+7cVzR0FtBTAHxRFhQMQAvgR5QX/MIqiXgD4oOL/NiE55g1eRebAc6Q11LVU2+SYYdcuQlpaip5jJ7XJ8d5XGB00o4PuDDpoBUuWLMGgQYPoz4GHhwdevXqFp0+fYunSpRg/vt6xMW1Cs+YBEELCANT01Na7Ofk2hWJRGf4+EwdtAw74Xm2jWS0rKUbo1Yvo3qMPDC27tckxW4K6WupNgdFBl8PooGuOrzPpoAFg/fr1yMrKqrKanK7u2/VHRo8ejSVLliA7O5uunNoLpdNBN5ayEikeX0zAsTUPkJMsxoDJ9mCrtr7yAQAibl1HiViEXuNq7wozlMPooBkddGfQQR84cADXrl3DiRMnqjQC0tPT6Yr68ePHkMvlMDRsm/lJdaE0KojGIpPIEXknBU+uJKJELEF3D2P0HmsLfdO2WQRbJpXgyaWzsHRxhbmDU5sc832G0UEzOujOoINetGgRrKys6FgmTpyItWvX4vTp09i9ezfYbDY0NDTw559/KocipjlPkFvqx8HBocFPwmUyOYm+n0qOfHuP7Fx4i5z7JYSkJ+Q3eP+GUt+Im4jAG2TLVB/yMvRJix+7Nt7nUUBtzfsak0gkIoQQIpfLyeLFi8m2bdvaPaaWGMGioCHnp4zvHSHtH5dSjQJqawghSHiajUf+L/EmtRDG3XQwdKYzujrX/WCnVWKRy/HP+dMwtrKBtZtHmx+foePS0XXJHf383jfeiwog9UUuHpyNR/rLAuh10cSIT13R3cO41bpQ+ZkZyHr2FHHaGuAam0DX2AQczbe3luKCH+FNajJ8lq1Ujm4cQ4dBGXXJjA6646LUFUDWaxEennuJpGc50NLjwOtjJzj1NYUKq3WeXRO5HKHXLuHuiSOQlpYi6c4N+jWOphZ0jYyhY2yCnOQkcLuYwqFP4x+EMTAwMCgLSlkB5GUW4fGFBLz4JwMcTTb6TuwOwRDLVl3Q5U1qCq7t+RWpz6NgI/SEhiMf7gIB8rMyUZCdiYJKv8uKiuA1+1N6DV8GBgaG9xGlqgAK80vx5FIiou6lQoVNwXOkFdyHdwNHs/UmdcllMgRfOof7J/8AS00VI5csh8ugobh9+zZM7Rxgatc8LTUDAwODsqIcFQABHp6Lx9OA15BLCVwGmqPHaGtocTn179sMsl+/wrXd25Ee/wJ2PfvA+5Ml0NZv+4fKDAwMDO2BUkwEK8kHgq++go2bMWas743B0x1bvfAPvnQex1Z9gfzMDPh88Q3Gfv0dU/i3MowOuukwOujqKKMOeufOnbCzs6v23hNCsGzZMtjZ2UEgECAkJKRFjtdclKIHoMICpn7XE8Zd28bdn5eehqBjB2Dr3gMjFn8JTV1umxy3M/PgwQNcvHgRISEh4HA4yM7ORllZWbPzdXV1xcmTJzF//nwAwIkTJ+Dm5tbsfBuLnZ0dzp8/j48//hhyuRwBAQGwsGickqQuHfTYsWOrCPBq4q+//kJqairCw8OhoqKC5ORkaGm1zcRIAM1ScKxduxbDhg3DF198AZFI1KoV17lz5+Dr6wsXFxcAaFE3f//+/eHr61tt1NSVK1fw4sULvHjxAo8ePcLixYub3QBqCZSiB6CmgzYr/AEg5Io/VFRYGPbp50zh30akpaXByMiI9qkYGRkhPDwcU6ZModMEBQXB17d8QR1tbW2sXLkSPB4PH3zwAR4/fowhQ4bA1tYW/v7+9D5WVlYoKSlBRkYGCCG4evUqRo0aRb8eFhaGPn36QCAQYMKECcjNLV+eOjg4GG5ubnBzc8Nvv/1Gp5fJZFi5ciV69uwJgUBQxedSFx9++CGtNggKCkL//v3BZr9tX40fPx6DBg0Cj8fDvn376O3a2tr4+uuv4ebmhgcPHuDy5ctwcnKCp6cnli1bRl+PI0eO4PPPPwdQ3uNYtmwZ+vXrB1tbW3o2a1paGszMzGgFgaWlJfT19QEAixcvRo8ePcDj8fDvf/+bPr6rqyu+/fZbCIVC9OjRAyEhIRgxYgS6d++OPXv20OczaNAg+Pj4wNHREYsWLYJcLq92DRQt8qCgIAwZMgSTJ0+Gk5MTPvroI1qDUNv5paWlwdLyraNKYSoFgM2bN9PvR+XYK1NbGj8/PwgEAri5uWHmzJm4f/8+/P39sXLlSgiFQsTHx2POnDn0Nbx16xbc3d3B5/Mxb948ela1tbU1NmzYAA8PD/D5fMTExNQYh7u7O6ytrattP3/+PGbNmgWKotCnTx/k5eUhLS2tegZtjFL0ANqSkkIxIgNvwKn/IGgbtL+Loz1Yf+EZolILWiw/mUwGfld9/HtM7XpbRgfN6KA7kw76XVJSUugFaIDyyjklJQVmZmYNzqM1UIoeQFsScesaJKUl8PRRDh1rZ4HRQTM66M6kg35f6FQ9AJlUipCrF9DNVQATa9v2DqfdqKul3hQYHXQ5jA665vg6mw66JiwsLPD69Wv6/+Tk5EY/I2oNOlUPIPbR3xDnZMPTp/EmQ4bmweigGR10Z9BB18bYsWPh5+cHQggePnwILpfb7rd/gE7UAyCEIPjiOeibW8JG6Nne4XQ6GB00o4PuDDroHTt24Oeff0Z6ejoEAgFGjx6NAwcOYPTo0bh8+TLs7OygqalJfw7bneaoRFvqpzE66KbyOiqCbJnqQ8KuX25Q+uaol1sLRgfdcN7XmBgdtHK+d4S0f1ytoYPuNLeAgi+dg7qOLlwGebV3KAwMtbJ//34IhULweDzk5+d3OF1yRz+/941OcQsoNz0VcU8eoc+EqVDlqLd3OAwMtaKMumRGB91x6RQ9gJDL/mCxWBCO8G3vUBgYGBiUhg5fAZSIxYgMugGn/kOgpaff3uEwMDAwKA0dvgIIv3UV0tJSePqMa+9QGBgYGJSKDl0ByKQShF7xRze+EMZWNu0dDgMDA4NS0aErK9lDGQAAIABJREFUgNgH9yDOfYMejPZBKejIOmgbGxsIhUIIhcJ6tch5eXnYtWtXg+NrDocOHQKfz4dAIICrqyvOnz9fZ/p169Zhy5YtjT7Ou+eUmppapyuoMdy4cQOenp7g8/nw9PREQEAA/dqQIUPg6OhIX3vFJLHS0lJMmzYNdnZ26N27d4dRN7Q0HXYUECEETy6dg4FFV1i7ebR3OJ2ejq6D3rx5c4MLPEVh+e6MYQCQSqVVLKLNITk5GRs2bEBISAi4XC7EYjGysrJaJO93efeczM3Nq0yyag5GRka4cOECzM3NERkZiREjRiAlJYV+/Y8//kCPHj2q7HPw4EHo6+sjLi4Of/75J1atWtXomdWdgQ7VAyCE4E1qMsJvXsXFXzYiMyEenqPHgVLpUKf5XtLRddA1sW7dOsybN4+Oe/fu3QCA1atXIz4+HkKhECtXrkRQUBAGDhyIsWPH0o76bdu2wdXVFa6urti+fTuA8l6IQq/s7OyMyZMno6ioCAEBARg//m0v98aNG5gwYQIyMzOho6NDa5q1tbVpEVt8fDxGjhyJQYMGYeDAgTXqjRVpPD09q6TJyMjAhAkT6Ot3//79audUucdUUlKCuXPngs/nw93dHYGBgQDKFdcTJ07EyJEjYW9vj2+++abG6+ju7g5zc3MAAI/HQ3FxMT3buTbOnz+P2bNnAyi3xd66dauKM4mhnGY1NSiKSgQgAiADICWE9KAoygDAXwCsASQCmEoIyW1emDVDCMGblGQkR0fg9bMIJEdHojCv/FBa+gYQeI+Ey6ChrXHo95srq4H0iBbLTkMmBSzcgVG1r1jV0XXQK1euxA8//ACgvJBS+IViYmIQGBgIkUgEBwcHLF++HBs3bkRkZCTCwsIAlFd8ISEhiIyMhI2NDYKDg3H48GE8evQIhBD07t0bgwcPhr6+Pp4/f46DBw+if//+mDdvHnbt2oWvv/4aS5YsQVZWFoyNjWnNhZubG7p06QIbGxt4e3tj4sSJGDNmDABgwYIF2LNnD0xNTREVFYUlS5ZUubVSOY29vT0ePXpEp1m2bBkGDx6Ms2fPQiaTQSwWVzunyrdcfvvtN1AUhYiICMTExGD48OGIjY0FUF5Bh4aGgsPhwNHREUuXLoWenl6t1/nMmTPV3uO5c+fSVtU1a9aAoqgq+mU2mw0ul4ucnBzaDMpQTkv0Nb0IIZXXvVsN4BYhZCNFUasr/l/VAsepAiEEZzetR0LoEwCAtr4BuvIE6Mrjo6sLH3qm5vV+aRnaDoUO+u7duwgMDMS0adOwceNGWgc9efJkXLp0CT///DOA6jpoDodTpw562rRpiImJwfTp02kbaE066ClTptSog1YI0q5fv47w8HD69kV+fj5evHhBK4Jro7ZbQD4+PuBwOOBwODA2NqbVze/Sq1cvunV+7949TJgwgV7Na+LEibh79y7Gjh1bxeXz8ccfY8eOHVixYgVmzpyJ33//HXPnzsWDBw/g5+cHFouFq1ev4p9//sGtW7ewfPlyBAcHY8WKFbh//z6mTJkCuVwOFRWVai1qsVhMp1GgSBMQEAA/Pz8A5WZMLpdL96xq4t69e1i6dCkAwMnJCVZWVnQF4O3tDS63fFEmFxcXvHr1qtYK4NmzZ1i1ahWuX79Ob/vjjz9gYWEBkUiESZMm4dixY5g1a1atsTBUpTWeAYwDMKTi76MAgtAKFUDc4wdICH2CHmMmQvDBSOh1MWMK/IZSR0u9KRQzOuhaaagWuaFLN9amZZ47dy7GjBkDdXV1TJkyhX6OQFEUevXqhV69emHYsGGYO3cuvvrqK+jp6SEsLKxWlbdcLqfTtCY1XZ8LFy7QDYEDBw6gR48eSE5OxoQJE+Dn54fu3bvT+yiUyjo6OpgxYwYeP36MWbNm0fplS0tLSKVS5Ofnw9Cwcy4AVRfNvTlOAFynKCqYoqgFFdu6EEIUa52lA+jSzGNUQyaV4M7xwzC07IaB02dDn2ntKz2dQQfdUGrTESsYOHAgzp07h6KiIhQWFuLs2bP0AjNJSUl48OABAOD48eO0ltnc3Bzm5ub44YcfMHfuXADlI3EqLz6uuOa6urqwsbHBqVOnAJRXek+fPq0SQ11pvL296ecZMpkM+fn5dZ7TwIED6WscGxuLpKQkODo61nr+Y8aMQVhYGMLCwtCjRw/k5eXBx8cHGzdurGIylUql9MLrEokEFy9epJ87jB07lrbLnj59GkOHDmXKiBpobg9gACEkhaIoEwA3KIqq8iSJEEIoiqrxyUtFhbEAAIyNjREUFNTgg2aEByMvPQ12oyfiTsWXu6URi8WNiqktaE5MXC63zkKnOchksnrzzsjIwMqVK5Gfnw82mw1bW1vs2LEDRUVFGD58OI4fP46dO3dWyUfxd2lpKVRVVau9VlRUBKlUCpFIBD6fT28vLS0Fi8WCSCTCrl278OWXX6K4uBjW1tbYtWsXRCIRdu7cicWLF4OiKAwdOhRyuRwikQjTpk1DbGwshEIhCCEwMjLC8ePHIRaL6TTvIpFIsGLFiiqLiwcGBlaLmxACsVgMQ0ND9OrVCy4uLhg2bBhGjBhBnwcA2NvbY/r06fTIllmzZsHOzg6vXr2Cvb09tm/fjjlz5sDJyQkbNmyg95s4cSLS09NhaWkJkUiE3NxcLF++HGlpaVBXV4eRkRF++eUXiEQi7N27F8uXL8f69eshlUoxadIk2NraVolZkeb777+HRCKh02zYsAHLli3D/v37wWKxsG3bNvTu3bvKOX366af09Zo5cyaWL18OHo8HNpuNXbt2oaysDCUlJSgrK6Pjl0qlKCoqqvZ52rp1K+Li4rBu3TqsW7cOQPnC7pqamhg1ahQkEglkMhmGDBmCDz/8ECKRCFOnTsXNmzdha2sLfX19HD58uNmf/4Z8zluTkpKSli+TmqMSrfwDYB2AFQCeAzCr2GYG4Hl9+zZGB10sEpGd8z4kJ//zHZHL5Q3er7EwOuiG096a3JroiDElJCQQHo9X6+ufffYZOXDgQJvG1BooY0yEtH9cSqWDpihKi6IoHcXfAIYDiATgD2B2RbLZAOqeedJIHp79CyWFYgz+eB7TpWNgqMDT0xPh4eH4+OOP2zsUhveI5twC6gLgbEUhzAZwnBBylaKofwCcpCjqEwCvAExtfpjl5GWkI+zqBfAGe3fqNX0ZOifW1taIjIys8bXg4OA2joahI9DkCoAQ8hJAtSmXhJAcAN7NCao27p44CorFQv9pTCuHgYGBobm8N1NkU2OjEfvgLnr4ToSOATOZg4GBgaG5vBcVACEEQccOQktPHz3HTmzvcBgYGBg6BO9FBfDi0d9Ii41Bv6kfQ01do73DYWBgYOgQKH0FUD7p6wiMulrB1euD9g6HoRkwOuhyGB1048jJyYGXlxe0tbXx+eef09uLiorg4+MDJycn8Hg8rF69mn7tyJEjMDY2pt+Typ8RhrcovQ467Nol5GekY9K366Giwqp/BwalhNFBv4XRQTcOdXV1/Oc//0FkZGS1UVArVqyAl5cXysrK4O3tjStXrtA22GnTpmHnzp0tEkNHRal7AMViER6e+RNWAndYCz3bOxyGZsDooBkddFN10FpaWhgwYADU1dWrbNfU1ISXlxeAcnmgh4cHkpOTm/BOdV6Uugfwz/nTKCkqxOCP57V3KB2KTY83IeZN9S98U5HJZOAZ87CqV+3OP0YHzeigW0IHXRt5eXm4cOECvvjiC3rbmTNncOfOHTg4OOCXX36h9dAMb1HaHoDoTTZCr1yA84AhzHq+HQCFDnrfvn0wNjbGtGnT8Pvvv9M6aKlUikuXLmHcuHEAquugBw8eXKcO+tSpUzhx4gSmT59Ob69JB33nzp0addAKrl+/Dj8/PwiFQvTu3Rs5OTlVJHa1sXnzZlpgVlkup9BBGxkZNUkHra2tTeugAVTTQd+7dw8URdE66Ly8PDx48ACjRo2iddCnT5+mK59169ZVUT33798fCxcuRFpaWpV4KqcRCoVV0gQEBGDx4sUA3uqg6+LevXv0DOXadNDq6uq0DrqxSKVSTJ8+HcuWLYOtbfkE0TFjxiAxMRHh4eEYNmwYvTgMQ1WUtgfw8MyfkMtl6Dflo/YOpcNRV0u9KdSmFH4XRgfN6KDfpaE66LpYsGAB7O3t8eWXX9LbKquf58+fX+vtpc6OUvYActNSEBFwvcLzb9re4TC0AIwO+i2MDrpxOui6WLNmDfLz8+nnJAoq92j8/f3h7OxcZz6dFaXsAfx98g+wVFXRZ2LTCwQG5UIsFmPp0qXIy8sDm82GnZ0d9u3bBxaLBV9fXxw5coT2tzeF2oZeHj16FIsWLUJRURFsbW1x+PBhAKDvk1MUheHDh9Pp58+fj8TERHh4eIAQAmNjY5w7d67e41d+BgAAjx8/rjWtoaEh+vfvD1dXV4waNQo+Pj5VXvfw8MCcOXPQq1cvOiZ3d3ckJibC0dERv/32G+bNmwcXFxf6VgwAfPTRR8jKyqILO4WmOjU1Ferq6jA2NsaePXsAlFd6ixcvxvfffw+ZTIYPP/yw2ugpRZoffvgBEomETvPrr79iwYIFOHjwIFgsFnbv3o2+fftWOafPPvuMzmfJkiVYvHgx+Hw+2Gw2jhw5UqXl3xCsra1RUFCAsrIynDt3DtevX4euri42bNgAJycneHh4AAA+//xzzJ8/Hzt27IC/vz/YbDYMDAxw5MiRRh2v09AclWhL/VTWQWckxJMtU33I3RNHG+9LbUEYHXTDaW9Nbk10xJgYHXT70t5xtYYOWul6APf+9IO6ljZ6jGGUDwwMDcXT0xNaWlrYunVre4fC8B6hVBVAcnQkEkKfYOCMOVDX0m7vcBgYlApGB83Q0ijNQ2BCCO6e8IOWvgHcR/q2dzgMDAwMHR6lqQBehvyD1OdR6DtpOlQ56vXvwMDAwMDQLJSmArj3px/0TM3g6jWsvUNhYGBg6BQoRQUgLSlBdlIi+k/9GKwWEmExMDAwMNSNUlQAkiIxjK1t4dh3YHuHwtCKMDrochgddONITEyEhoYGfX0XLVpEvxYcHAw+nw87OzssW7YM5SMjGRqKUlQARCbDgA9nglJRinAYWoHKOujw8HDcvHmzReRcCh20gvbUQStmr9anoqirAqhNFdEUFDroe/fuITw8HA8fPoRAIGix/Cvz7jm1pA4aALp3705fX8VkNgBYvHgx9u/fjxcvXuDFixe4evVqix2zM6AUJS5LTQ02wrqnfDO83zA6aEYH3VQddG2kpaWhoKAAffr0AUVRmDVrVoNmbTO8RSluuHO4+vXqdhlajvQff0RpdMvpoKUyGQpdeTD9179qTcPooBkddHN00AkJCXB3d4euri5++OEHDBw4ECkpKbC0tKTTWFpaIiUlpc73iaEqStEDYOj4MDpoRgcNNE0HbWZmhqSkJISGhmLbtm2YMWMGCgoK6n5DGBqEUvQAGNqWulrqTYHRQdcOo4Oum4bqoBXpPD090b17d8TGxsLCwqLKCmDJycmwsLBo1Xg7GkwPgKFNYHTQb2F00I3TQWdlZUEmkwEAXr58iRcvXsDW1hZmZmbQ1dXFw4cPQQiBn58f3YNkaBhMBcDQJojFYsyePRsuLi4QCASIiorCunXraB30lStX6AfATaFfv35VHoQqOHr0KFauXAmBQICwsDCsXbsWQHkh/tlnn0EoFFYZOjh//ny4uLjAw8MDrq6uWLhwYYNG5qxcuZIepigUCutc8L6yDrry8wcFlXXQvXv3pnXQAGgdtLOzM3Jzc6vpoLt27VpNB+3k5AShUIi//voLv/76K4DySu/gwYPo168feDxejcNDFWnc3NyqpPn1118RGBgIPp8PT09PREVF1XlOS5YsgVwuB5/Px7Rp0xqtg75z5w49dHjy5MnYs2cPDAwMAAC7du3C/PnzYWdnh+7du1cZAMBQP5QyjJt1dHQkz58/b+8wqhAUFIQhQ4a0dxhVaE5M0dHRrbYoRkNvAbUlHTGmxMRE+Pr61iqE+/zzz+Hu7o5PPvmkzWJqDZQxJqD946rpO0xRVDAhpMlDKJlnAAwMHQBGB83QFJpdAVAUxQLwBEAKIcSXoigbAH8CMAQQDGAmIaT2/jADA0ODYHTQDC1NSzwD+AJAdKX/NwH4hRBiByAXQMP7owwMDAwMbUazKgCKoiwB+AA4UPE/BWAoAMUc8KMAqj+ZY2BgYGBod5p7C2g7gG8AKJ6MGALII4Qohk0kA6hxYC5FUQsALKj4t5SiqJr7tu2HEYDs9g7iHZoc040bN/gymazlRDOVkMlkbBaL1Sp5NxUmpobBxNRw2juu9PR0touLS8Q7m2sfT9sAmlwBUBTlCyCTEBJMUdSQxu5PCNkHYF9FXk+a8yS7NehoMT19+jTR1dW1VSq0yMhIZ1dX1+j6U7YdTEwNg4mp4bR3XDKZzOjd7z9FUU+ak2dzbgH1BzCWoqhElD/0HQrgVwB6FEUpKhZLAIycgwEAsGrVKlM7Ozueg4ODi5OTk0tAQEDDpr/WwsWLF3UoivLctm2bkWLb/fv3NSiK8jx06FCDGzfPnz9Xs7e35zU1zaRJk6wtLCz4Tk5OLk5OTi7u7u5OdeWVnZ3N2rhxo3FD42sO27dvN3RwcHBxcHBwsbe35/3+++/VRTuV+Oqrr8zXrl3bpbHHefecEhMTVUeOHGnblJjf5ezZs7o8Hs/ZwcHBhcfjOfv7+9NjMXv16uVobW3tqrj2KSkpzMjGRtDkCoAQ8i0hxJIQYg3gQwABhJCPAAQCUIjAZwOoW0DO0Cm4efOm1rVr1/QiIiKiYmNjowIDA2NtbW2bPTrM3t6++MyZM/qK/48dO2bg6OhY3Nx8G8sPP/yQHBMTExUTExMVGhpap2kvJyeHdfDgQZOaXlPMQG4J4uPjVbdu3Wr24MGD57GxsVFPnjyJ7tGjR1GLHaAS756TtbW15OrVqy9bIm8TExPJpUuX4mJjY6OOHDmSMH/+fJvKr/v5+b1UXHsLCwulu3WkzLTGTOBVAL6iKCoO5c8EDjZgn32tEEdzYWJqIEZGRln1pUlJSVE1MDCQamhoEAAwMzOTPnnyRGPUqFF0K/HixYs6Xl5edgCgqanpvnDhQks7Oztev379HAIDAzV79erlaGlpyf/jjz9o+5iFhUVZaWmpyuvXr9lyuRwBAQFcb2/vfFVV1UKgvEfg5ubm5ODg4DJs2LDuWVlZLAC4e/eupqOjo4ujo6PLtm3b6IJLKpVi4cKFlq6urs4ODg4umzdvpnsXjeWrr74ynzJlirUi7r/++qsEAL7++mvL169fc5ycnFwWLlxoefHiRR1PT0/HoUOH2tnb27sCwLp167rY29vz7O3ted9//70JUN4LsbGx4Y0dO9bG1taWN3LkSFuRSKTi7++v88EHH3RXHPfs2bO6w4YN656WlqaqpaUl53K5MgDgcrlyJyenMgB49uwZZ+DAgfZTp05le3p6OoaGhlZbiFuRhsfjOVdO8/r1a/awYcO6K67fjRs3tN49p8o9pqKiImry5MnWDg4OLs7Ozi4XLlzQAYAdO3YYDh8+vPvAgQPtraysXBctWmQJVP889e/fv9ja2loCAJ6eniWlpaUqxcXFba4PbsjnvB1oVpnQIt0lQkgQgKCKv18C6NXI/ZWuYOvIMd3yi+76JkWs2RJ5KTCwyNXwnuX8urbXx48fX/DTTz+ZW1tbuw4YMKBg+vTpb8aNG1ewdOlSq4KCAhVdXV35iRMn9KdMmfIGAIqLi1W8vb0L9u7dmzxs2LDua9assbh7925sSEiI+ty5c20++uij/Ep55x47dky/R48eRXw+v4jD4RAOh1MIAHPmzLH55Zdfknx8fMRffvml+apVq8wPHTr0+pNPPrH+9ddfk0aNGiVeuHAh7RTevn27EZfLlUVGRkYXFxdTPXv2dBozZkxBfTroNWvWWG7atMkMABwcHIr9/f0TACAuLk79/v37z/Py8ljOzs6ua9asobZu3Zrs6+urERMTEwWUV3xRUVGaoaGhz5ycnMru3r2refz4ccPg4OBoQgg8PT2dvb29RUZGRrLExET1vXv3Jg4fPrxwypQp1ps3bzZet25dxhdffNEtNTWVbW5uLj106JDh3Llzs/v06VNkZGQk6dq1K79///6iiRMn5s6YMSMfAObPn2+1b9++V3w+vzQgIEBr8eLF3R4+fBhb+ZxqS7No0aJuAwcOFK1duzZeKpUiPz+f9e45PX/+XE2Rz6ZNm0woikJsbGxUaGio+ujRo+3j4+MjASAqKkrz6dOnURoaGnI7OzvXFStWZNjZ2dX6rOro0aP6PB6vSNGQqIjTWkVFBWPGjMndtGlTmkorLSxlamqqbINCml0mMC4ghjaBy+XKIyMjo3bu3PnK2NhYOnv27O67d+82HDJkSMGff/7JlUgkCAgI4E6fPj0PAFRVVcnkyZMLAIDH4xUPGDBAxOFwSK9evYpTUlLUKuc9a9asN2fPnjX4/fffDWfMmPFGsT0nJ4clEolYPj4+YgD49NNPcx4+fKidnZ3NEolErFGjRokBYN68eTmKfW7evKl78uRJw4p7+c65ubnsqKioaq3jd6l8C0hR+APA8OHD8zQ0NIiZmZnUwMBAkpycXGOjSyAQFCpa50FBQdqjR4/O09XVlXO5XLmPj09uYGCgDgCYmpqWDR8+vBAAZs6cmXP//n1tFRUVTJ06NWf//v0G2dnZrJCQEO0pU6bks9ls3Llz58Xx48fj7e3tS1avXt31q6++Ms/Pz1cJDQ3VnjJlSncnJyeXJUuWWGVmZqpWjqeuNPfv39dZuXJlFgCw2WwYGhrK6ro29+/f1545c2YOALi7u5eYm5uXRUREqAPAgAEDCgwNDWWamprEzs6uJD4+vlZJ0JMnT9TXrl1rsX//ftoZ/ddff72MjY2NevDgQcz9+/e1d+3aZVhXLAxVYR6YdELqaqm3Jmw2G76+viJfX1+RQCAoPnbsmOGXX36ZsXPnThMjIyMZn88v0tfXl1ekJYqWXIUOmgDlymCZTFalOd6tWzepqqoquXPnju6hQ4eS7t27p93UGAkh1NatW5MmTZpURThfuUU7efJk68jISM0uXbqU3b59O66u/BRxK2KXSqU1diU0NTXlDYmvNh304sWLc3x8fOzU1dXJmDFjclVVy8tzFRUVeHl5FXl5eRWNGjWqYP78+dZr1qxJ19HRkSpa6zUhk8lQX5qWQE1NrfL1IRKJhPLz89P78ccfzQFg3759iYMGDSqKj49XnTx5st3BgwcTeDxeqWIfGxsbCQDo6+vLp02b9ubx48daAHKqHYihRtqlB0BRVCJFUREURYUphjFRFGVAUdQNiqJeVPzWry+fZsZwiKKozMrzD2qLgSpnB0VRcRRFhVMU5dGGMa2jKCql4lqFURQ1utJr31bE9JyiqBE159o8SkpKVKOjox0iIiJ4ERERvNTUVBMAkEgkrOjoaPvw8HDX6Ohoe4lEwgLKtcEJCQldw8PDXSMiIlxEIpEmADx9+pQTERFBt+5CQ0M1LC0ty0aPHi169uyZ5v79+42mTp36puYoqhMdHe2QkZFhLZVKdVJTU03Wr1+fsmrVqqLIyEhBUVGRsVgs7kJRlLaurq7s6tWr2snJyaY7duxwdnd357BYLC0dHR3ZtWvXtAHgyJEjBop8hw0blr97927j0tJSCgDCw8M5BQUFVb4np0+fToyJiYmqXPjL5XI8e/bMOTIy0iUiIoKXlJRkDgAymYz17Nkzp/DwcFdCiKpcLqe4XK6ssLBQ5cWLF7bh4eGumZmZ3Qgh9DG8vLzEly9f1hOJRCoFBQUqly9f1vfy8hIBQFpamtrNmze1AOCPP/4w6Nevnxgof+japUsXydatW80WLFiQDZSPxLlz546mIq5bt27ZmZqaqhgYGMjNzc2pn3/+2a0iXpegoCA9xftXXFysl5yc7GJubs7as2dPF8X5PXjwQAMA+vfvL9q8ebMxUP7MJCcnh6U4p5req/79+4t///13A8X1TEtLUxMIBCWEEJSWluo/f/7cruLYKpmZmd2EQqHlhQsXSqKioqIHDRpUlJmZyR41ahRv6dKlKhYWFl1LSkrUKj6DSEtLYwNAaWkpdfnyZa6rq2uzBgAQQhAZGemiiCkuLs766dOn/MjISJfIyEgXsVisoUhX0+e8pXn69Ck/IiLCJTIy0iUrK8sMaNlyqj1vAXkRQoSVxrWuBnCLEGIP4FbF/63JEQAj39lWWwyjANhX/CwAsLsNYwLK1RrCip/LAEBRlAvKR1/xKvbZVeFlalEoioKlpWUyn89/5uzsHJ2dnW1SWFionpqaaqajoyMSCASROjo6otTUVFMAyM3N5ZaWlqrz+fxIKyurV0lJSd0AoKCggDVr1iyb7t278xwcHFxiYmI0Nm3alMpms+Ht7Z1/+/Zt7rRp0/LrjuYtlpaWyV26dElksVji7Oxsk379+sl8fX1LjI2NMzQ1NbO0tbUzDAwM8g8fPpzwzTffdPPy8jKPj48Xb9y48fnr16+7HThwIHHZsmXdnJycXAghdLN6+fLl2U5OTiV8Pt/Z3t6e9+mnn1pJJJJ6HziuXbvWctKkSdTkyZMxZcoUkpOToyuTyVRLS0v1TExMMgQCQWTF9dE3NTWVubu7S0eNGqX722+/5Wlpab2Ry+X0baYBAwYUzZgxI8fDw8PZ09PTeebMmVn9+/cvBgBra+uS//73vya2tra8vLw89ooVK+gHkx9++GGOmZlZmYeHRwkAlJWVUd98842lr68va/Lkybhx40bJ6tWrZQUFBVrbtm0T+fv7SyZNmoTx48dTFy9e1AAAmUzGkcvlbD6fH3no0KEEPz8/M0dHRxd7e3vemTNn9ABg9+7dSbdv39ZxcHBwcXV1dQkNDVU3NTWVeXp6iu3t7XmVn6kAwDfffJMpl8spBwcHl2nTpnX6PqSiAAAKeElEQVTfu3dvooaGBikpKdGl/r+9sw1t67rD+HMk3SvJerFsyVZtvTp2bM1RLQcGXWGMQtsFRqGs0DEoNd1WWNftw9q1lEHL0qZ0+bDBPrSEkKX51AWKoaWMsRcKoy1sbC1Uih1Hs6xKsWXZlqzKtqyXq3vv2QdLjuxadhxfSU51fl8s+x5Jj/9HOv/z+lxCtnftyLKsMxgMmbGxsSm1Wi0uLy/bAOCNN97wzs/Pqy9duiQ+9thjXCAQGE0kEppCoaB66KGHTla2h4729fWVn3/++SMt1CaTSbtWq92RRBwOx4Lf77/u9/uvG43GQqUe9/ycNwKfz/c/v99/vaenp3rbNsXaqZbYQVfODnyTUpqu+VsYwAOU0iQhpA/APymlRzrldhs6vAD+TCn176eBEHKx8vjq7nJN0HQWQI5S+rtd5X4NAJTS31Z+/xuAs5TSf+31usFgMBYIBI68iBUOhwd7e3tT8/Pz7pGRkbBWqy2XSiUuHA6PjI2NTUWjUY/JZNro6enJAEAoFPJXyx31vQ/SlMvljCqVSnI4HDvuu7iwsHAPADidziUAuHHjxsn+/v5Fs9m8udfrHRVJklQzMzMjbrf75tzc3FAgEAiqVCqsr68bFhcX+30+32ytBlmWEQwGA+Pj48H9FpvD4TD/yCOPnJydnZ3e6/rExIT79OnT+eeee27Peq7VtbKy0mOxWNZsNtuXtWWaVX+lUomLRqMDfX19yeXlZfvw8HDk888/DygVKyU0jYyMRCKRiLeVcQoGg/eOjo7OcBwnBoNBWyAQ8CrZTrVqDYAC+DshhAK4WFnJttcIXQJw6MMoClBPgwNA7bx51eJC8QRQh18QQiaw5br6K0rpl5X3//cemhpGsVjki8Vih8lkyomiqKl+2HmeL4uiqAGAcrnM8Ty/vb+f4zhBEASuUQmgVlMulzOm0+neTCZj7ejoyLvd7nmO46RyucwbDIbcLk08AEUTAKUU09PTo4IgaK1W64pery+p1WqpupbB87xQLper0xe8VqsVgK15erVaLYmiqOE47o72sZ86deober1evnjx4lfWd3brMpvNmysrKz2Li4uOZDLZZzKZNtxu94JKpaLNqr94PO5yOp0LkiSpAUAURU2zYnW7mqq0Mk4AEA6HTwLA5uZmsfInxdqpViWAb1NKE4SQXgD/IITsODhDKaWV5NAyjoOGChcAnMNW0jwH4PcAftxsEaIoqiKRyKDD4ZjXaDQ7FiyV7ondqSa73b7idDoXAWB+ft5x8+ZN1+DgYKxZeggh8Pv910VRVM/Ozg7m8/kDdw8dhpGREaFe7396erquRcFuXZubmzqXy5Xgeb5MKSXRaNSTSCTucblcTenQZDKZTo1GI5pMpnw2mz0Wd36pp6mVcQIAn893Q6vVlgVB0Hz00UejhJDv1F4/ajvVkjUASmmi8nMFwHvYOjewXBnOoPJzpQXS6mlIAHDVlGuaxQWldJlSKlFKZQCXcOuMRdM0ybJMIpHIYHd3d8Zms2UBQKPRiKVSiQO2hs4ajUYEAI7jypXeNYCt3hvP84r3ivbSxPO8SAgBIQS9vb2pfD5vqGgS9tDUsHtUaDQayWg0buRyOYMkSWpZ3sqXgiDwHMcJVU2lUomv/C+QJEldjWGjdWWz2U6tVlsmhEClUlGbzbZaE6uG19/GxoZxfX3dEgwG743FYidyuZwpHo+7WhmrvTRFIpGBVsYJAGpG2aJOp8tj/7by0G1C0xMAIcRACDFVHwP4LoApAB9gyzoCaJ2FRD0NHwCYqKyyfwvAWiPm//eiWtEVvo+tWFU1/ZAQoq3chOckgP8o/f6UUkSjUY9Opyv29/dvz62bzeZsKpWyAkAqlbJ2dnZmAcBisWRXV1etlFKsr68b1Gq1pPSwuJ6makICgEwmY9HpdAUA6Orqymaz2W5ZlkmhUOBLpZLOZDIpOv0jCIJGFEU1AEiSRDY2Nsx6vb5oMBg2VldXuwAgnU5vx6mzszObTqetALC6utplNBo3GjGSqqerGitKKbLZ7HasmlF/Ho8nMT4+HgoEAte8Xm/UaDRuDA0NfdHKWNXT1Mo4SZKkEkVRVX1cKpV02L+tPHQ71YopIDuA9yoVqAHwJ0rpXwkh/wXwLiHkJwDiAH7QSBGEkKsAHgBgI4QsAPgNgPN1NPwFwPcARADkAfyoiZoeIISMY2sKKAbgpwBAKZ0mhLwL4DoAEcDPKaX7Hsi5E9bX143ZbNaq1WoLU1NTowDQ39+fcDgcyUgkMhgKhWwcxwlDQ0NzANDV1bW2trbWee3aNT8hRPZ6vbFmacpkMt2FQkEPbM0he73eOAAYDIaixWLJTE1NnQIAl8sVV7oBEQSBi8ViA5VNFcRisWS6u7vX9Hp9IRqNDiaTSYdOp8vb7fY0APT29qbn5uYGQqGQX61WSydOnJhTVNABumZmZoYr6zZEr9fnq7FqRv3Vw+VyLbQyVnsRjUYHWhUnQRA0c3Nz1S2yRKvVFg5oKw/dTh2Lm8IzGo9Su4AYDEZrqO4CUvI1mRUEo2k00w76MJbGzA76FsfRDnppaUl93333DXd0dJyemJjYsd/+448/7hgeHh51u93+p556ylVdQ2DcHiwBMJoCs4O+BbODPhwdHR30tddeWzx79uzC7mvPPvus58KFC/FYLDYVjUZ1k5OTZiXes11gCYDRFJptB129fpzsoF9//fVe4HjZQe+2eq6lVXbQuzGbzfKZM2dyOp1uR/c+Ho9zuVxO9eCDD26qVCo88cQTq++//35DLWS+bjAzuDbkbxf+4ErPxxX1LrG5PPkzP/vlsbGDrl47bnbQL774YorZQR9oB31bw6B4PM719fVtl/V4PEIymeT2ew5jJ2wEwGgKzA6a2UEDR7ODZigPGwG0Ifv11BsJs4NmdtC7uV076L2e6/F4yrU9/ng8zteOCBgHw0YAjKagtB30bl599dXEuXPnFjSaW30aq9UqVe2gAeDy5cvW+++/P2ez2SSl7aAPw37WyYCydtCffPLJ9lTfp59+2uFwOITu7m7Z6XQKb7/9dhew0+q5yn5llLKDrvf/T0xMZKujqXqNP7CVAIxGo/zhhx8aZFnGO++8Y3300Uez9cozvgpLAIymoLQd9G4efvjhzSeffPIrX/4rV6588dJLLzmHh4dHQ6GQ/vz584sAcPnyZUXtoF9++WVndRuoz+cbLRaLdZ+zn3UyoKwd9AsvvOAcGBg45fP5RicnJ7vefPPNeQC4evVq9MqVK7bdVs+11CujlB30QTGtxeFw3PvKK6+4JicnrXa7feyzzz7TAcBbb70Vf+aZZ7wej8fv9XpLjz/++B1/htoRdhCsTWAHwe5+jmoHzbi7acRBMLYGwGB8DdjPDprBqAdLAAzGXcKd2kEzGPVgawAMBoPRprAE0D7Isiy35s4tDAbjSFS+u4obHbEE0D5MpVKpTpYEGIy7C1mWSSqV6sSte4EoBlsDaBNEUXx6aWnpj0tLS36wxM9g3E3IAKZEUXxa6Rdm20AZDAajTWE9QQaDwWhTWAJgMBiMNoUlAAaDwWhTWAJgMBiMNoUlAAaDwWhT/g+z839nJm/xngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def performance_plot(fully_supervised_accuracy, dic, models, selection_functions, Ks, repeats):  \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([0,500],[fully_supervised_accuracy, fully_supervised_accuracy],label = 'algorithm-upper-bound')\n",
    "    for model_object in models:\n",
    "      for selection_function in selection_functions:\n",
    "        for idx, k in enumerate(Ks):\n",
    "            x = np.arange(float(Ks[idx]), 500 + float(Ks[idx]), float(Ks[idx]))            \n",
    "            Sum = np.array(dic[model_object][selection_function][k][0])\n",
    "            for i in range(1, repeats):\n",
    "                Sum = Sum + np.array(dic[model_object][selection_function][k][i])\n",
    "            mean = Sum / repeats\n",
    "            ax.plot(x, mean ,label = model_object + '-' + selection_function + '-' + str(k))\n",
    "    ax.legend()\n",
    "    ax.set_xlim([50,500])\n",
    "    ax.set_ylim([40,100])\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "models_str = ['SvmModel', 'RfModel', 'LogModel']\n",
    "selection_functions_str = ['RandomSelection', 'MarginSamplingSelection', 'EntropySelection']\n",
    "Ks_str = ['250','125','50','25','10'] \n",
    "repeats = 1\n",
    "random_forest_upper_bound = 97.\n",
    "svm_upper_bound = 94.\n",
    "log_upper_bound = 92.47\n",
    "total_experiments = len(models_str) * len(selection_functions_str) * len(Ks_str) * repeats\n",
    "\n",
    "print('So which is the better model? under the stopping condition and hyper parameters - random forest is the winner!')\n",
    "performance_plot(random_forest_upper_bound, d, ['RfModel'] , selection_functions_str    , Ks_str, 1)\n",
    "performance_plot(svm_upper_bound, d, ['SvmModel'] , selection_functions_str    , Ks_str, 1)\n",
    "performance_plot(log_upper_bound, d, ['LogModel'] , selection_functions_str    , Ks_str, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 736
    },
    "colab_type": "code",
    "id": "ny0_f1nyOi3H",
    "outputId": "9cb42b48-64d3-406b-a8c0-1e6ef9d94d86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So which is the best sample selection function? margin sampling is the winner!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "So which is the best k? k=10 is the winner\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print('So which is the best sample selection function? margin sampling is the winner!')\n",
    "performance_plot(random_forest_upper_bound, d, ['RfModel'], selection_functions_str    , Ks_str, 1)\n",
    "print()\n",
    "print('So which is the best k? k=10 is the winner')\n",
    "performance_plot(random_forest_upper_bound, d, ['RfModel'] , ['MarginSamplingSelection'], Ks_str, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z82imfIIPoJd"
   },
   "source": [
    "I would like to thank Moshe Hadad for his valueable critique regarding PEP8 and Shay Zweig for his proof-reading and comments.\n",
    "\n",
    "Ori Cohen has done his PhD in computer science in the fields of machine learning, brain-computer-interface and neurobiology.\n",
    "\n",
    "[1] Shay Yehezkel, *High Dimensional Statistical Process Control and Application*, M.Sc Thesis.\n",
    "\n",
    "[2] Ilhan, Hamza Osman, and Mehmet Fatih Amasyali. \"[*Active Learning as a Way of Increasing Accuracy*](http://www.ijcte.org/papers/910-AC0013.pdf).\" International Journal of Computer Theory and Engineering 6, no. 6 (2014): 460.\n",
    "\n",
    "[3] Stefan Hosein [*Active Learning: Curious AI Algorithms*](https://www.datacamp.com/community/tutorials/active-learning)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Active Learning Tutorial",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
